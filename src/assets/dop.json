[
  {
    "no": 8,
    "question": "一家公司的安全团队要求所有外部应用程序负载均衡器（ALB）和Amazon API Gateway API都与AWS WAF网络访问控制列表（ACL）关联。该公司拥有数百个AWS账户，所有这些账户都包含在AWS组织的单一组织中。公司已为该组织配置了AWS Config。在审计期间，公司发现一些面向外部的ALB未与AWS WAF网络ACL关联。DevOps工程师应采取哪些步骤组合来防止未来违规？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "将AWS防火墙管理器委派给安全账户。",
      "B": "将Amazon GuardDuty委派给安全账户。",
      "C": "创建一个AWS防火墙管理器策略，以将AWS WAF网络ACL附加到任何新创建的ALB和API Gateway API。",
      "D": "创建一个Amazon GuardDuty策略，以将AWS WAF网络ACL附加到任何新创建的ALB和API Gateway API。",
      "E": "配置一个AWS Config托管规则，以将AWS WAF网络ACL附加到任何新创建的ALB和API Gateway API。"
    },
    "best": ["A", "C"],
    "analysis": {
      "A": "将AWS防火墙管理器委派给安全账户是一个有效的步骤，因为它可以集中管理和自动化AWS WAF策略的应用，确保所有外部ALB和API Gateway API都符合安全要求。",
      "B": "虽然将Amazon GuardDuty委派给安全账户可以增强安全监控和威胁检测，但它并不直接涉及将AWS WAF网络ACL附加到ALB或API Gateway API。",
      "C": "创建一个AWS防火墙管理器策略以自动将AWS WAF网络ACL附加到新创建的ALB和API Gateway API是确保符合安全要求的直接和有效方法。",
      "D": "Amazon GuardDuty是用于威胁检测和监控的服务，它不提供直接将AWS WAF网络ACL附加到ALB或API Gateway API的功能。",
      "E": "虽然AWS Config可以用于监控和自动化配置合规性，但它本身不支持直接创建和管理AWS WAF网络ACL的策略。"
    },
    "service": [
      "AWS Firewall Manager",
      "Amazon GuardDuty",
      "AWS WAF",
      "AWS Config"
    ],
    "reason": "6.2"
  },
  {
    "no": 5,
    "question": "一家公司正在使用 Amazon Aurora 集群作为其应用程序的数据存储。Aurora 集群配置了单个 DB 实例。应用程序通过使用集群的实例端点对数据库进行读写操作。公司已安排在即将到来的维护窗口期间对集群应用更新。在维护窗口期间，集群必须保持尽可能少的中断可用。DevOps 工程师应该做什么来满足这些要求？",
    "choose": 1,
    "options": {
      "A": "向 Aurora 集群添加一个读取器实例。更新应用程序以使用 Aurora 集群端点进行写操作。更新 Aurora 集群的读取器端点以进行读取。",
      "B": "向 Aurora 集群添加一个读取器实例。为集群创建一个自定义 ANY 端点。更新应用程序以使用 Aurora 集群的自定义 ANY 端点进行读写操作。",
      "C": "打开 Aurora 集群的多可用区选项。更新应用程序以使用 Aurora 集群端点进行写操作。更新 Aurora 集群的读取器端点以进行读取。",
      "D": "打开 Aurora 集群的多可用区选项。为集群创建一个自定义 ANY 端点。更新应用程序以使用 Aurora 集群的自定义 ANY 端点进行读写操作"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项虽然增加了读取器实例以提高读取性能，但在维护期间可能无法保证写操作的高可用性。",
      "B": "此选项通过添加读取器实例并创建自定义 ANY 端点，使得在维护期间应用程序可以无缝地进行读写操作，确保了高可用性。",
      "C": "多可用区选项确实提高了容错能力，但主要针对的是实例故障的恢复，并不直接影响维护窗口期间的可用性。",
      "D": "虽然此选项提供了多可用区的高可用性和自定义 ANY 端点的灵活性，但在维护期间可能存在过度配置，导致不必要的复杂性和成本。"
    },
    "service": ["Amazon Aurora", "AWS"],
    "reason": "3.1"
  },
  {
    "no": 9,
    "question": "一家公司使用 AWS 密钥管理服务（AWS KMS）密钥和手动密钥轮换来满足监管合规要求。安全团队希望在任何密钥超过90天未轮换时得到通知。哪种解决方案能实现这一目标？",
    "choose": 1,
    "options": {
      "A": "配置 AWS KMS 发布到 Amazon 简单通知服务（Amazon SNS）主题，当密钥超过90天时。",
      "B": "配置 Amazon EventBridge 事件以启动 AWS Lambda 函数调用 AWS 可信顾问 API 并发布到 Amazon 简单通知服务（Amazon SNS）主题。",
      "C": "开发一个 AWS Config 自定义规则，当密钥超过90天时发布到 Amazon 简单通知服务（Amazon SNS）主题。",
      "D": "配置 AWS 安全中心发布到 Amazon 简单通知服务（Amazon SNS）主题，当密钥超过90天时。"
    },
    "best": ["C"],
    "analysis": {
      "A": "AWS KMS 本身不提供直接的通知功能来监控密钥的轮换状态。",
      "B": "虽然这种方法可以工作，但它涉及到不必要的复杂性，如调用 AWS 可信顾问 API，这并不是直接检测密钥轮换的最佳或最直接方法。",
      "C": "这是最佳选项，因为 AWS Config 允许创建自定义规则来监控和评估 AWS 资源的配置变化，包括 KMS 密钥的轮换状态，并能直接通知到 SNS。",
      "D": "AWS 安全中心主要用于安全警告和合规性监控，而不是直接用于监控如密钥轮换这样的具体操作。"
    },
    "service": [
      "AWS KMS",
      "Amazon SNS",
      "AWS Config",
      "Amazon EventBridge",
      "AWS Lambda",
      "AWS Trusted Advisor",
      "AWS Security Hub"
    ],
    "reason": "6.2"
  },
  {
    "no": 1,
    "question": "一家公司有一个移动应用程序，该应用程序通过 HTTP API 调用 Application Load Balancer (ALB)。ALB 将请求路由到一个 AWS Lambda 函数。任何时候都有许多不同版本的应用程序在使用中，包括正在由一部分用户测试的版本。应用程序的版本在发送给 API 的所有请求的用户代理头中定义。在最近对 API 进行的一系列更改之后，公司观察到应用程序出现问题。公司需要收集每个 API 操作的每个版本的应用程序的响应代码的指标。一位 DevOps 工程师修改了 Lambda 函数，以提取 API 操作名称、版本信息和响应代码。DevOps 工程师还需要采取哪些额外的操作来收集所需的指标？",
    "choose": 1,
    "options": {
      "A": "修改 Lambda 函数，将 API 操作名称、响应代码和版本号作为日志行写入 Amazon CloudWatch Logs 日志组。配置一个 CloudWatch Logs 指标过滤器，为每个 API 操作名称增加一个指标。指定响应代码和应用程序版本作为指标的维度。",
      "B": "修改 Lambda 函数，将 API 操作名称、响应代码和版本号作为日志行写入 Amazon CloudWatch Logs 日志组。配置一个 CloudWatch Logs Insights 查询，从日志行中填充 CloudWatch 指标。指定响应代码和应用程序版本作为指标的维度。",
      "C": "配置 ALB 访问日志写入 Amazon CloudWatch Logs 日志组。修改 Lambda 函数以响应 ALB，将 API 操作名称、响应代码和版本号作为响应元数据。配置一个 CloudWatch Logs 指标过滤器，为每个 API 操作名称增加一个指标。指定响应代码和应用程序版本作为指标的维度。",
      "D": "在 Lambda 函数上配置 AWS X-Ray 集成。修改 Lambda 函数以创建一个带有 API 操作名称、响应代码和版本号的 X-Ray 子段。配置 X-Ray 洞察以提取每个 API 操作名称的聚合指标，并将指标发布到 Amazon CloudWatch。指定响应代码和应用程序版本作为指标的维度。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它直接使用 CloudWatch Logs 和指标过滤器来增加和维度化指标，这是一种高效且符合要求的方法来监控和分析 API 操作。",
      "B": "此选项使用 CloudWatch Logs Insights 查询，虽然可以实现功能，但相比于直接使用指标过滤器，它的设置和维护更复杂。",
      "C": "此选项涉及修改 Lambda 函数以响应 ALB，并使用响应元数据，这增加了复杂性且不是必需的，因为可以直接在 Lambda 函数中处理。",
      "D": "此选项使用 AWS X-Ray 进行监控，虽然 X-Ray 提供详细的追踪功能，但对于此场景而言，使用 CloudWatch Logs 和指标过滤器会更直接且成本效益更高。"
    },
    "service": [
      "AWS Lambda",
      "Amazon CloudWatch Logs",
      "Application Load Balancer",
      "AWS X-Ray"
    ],
    "reason": "4.1"
  },
  {
    "no": 10,
    "question": "安全审查发现一个 AWS CodeBuild 项目正在使用未经认证的请求从 Amazon S3 存储桶下载数据库填充脚本。安全团队不允许此项目对 S3 存储桶进行未经认证的请求。如何以最安全的方式纠正此问题？",
    "choose": 1,
    "options": {
      "A": "将存储桶名称添加到 CodeBuild 项目设置的 AllowedBuckets 部分。更新构建规范以使用 AWS CLI 下载数据库填充脚本。",
      "B": "修改 S3 存储桶设置以启用 HTTPS 基本认证并指定令牌。更新构建规范以使用 cURL 传递令牌并下载数据库填充脚本。",
      "C": "通过存储桶策略移除 S3 存储桶的未经认证访问权限。修改 CodeBuild 项目的服务角色以包括 Amazon S3 访问权限。使用 AWS CLI 下载数据库填充脚本。",
      "D": "通过存储桶策略移除 S3 存储桶的未经认证访问权限。使用 IAM 访问密钥和秘密访问密钥通过 AWS CLI 下载数据库填充脚本。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项虽然提到了将存储桶名称添加到允许列表，但没有明确提到如何安全地进行认证，因此不是最佳选项。",
      "B": "此选项提到了使用 HTTPS 基本认证，但 AWS S3 不支持基本认证，因此这不是一个可行的解决方案。",
      "C": "此选项通过移除未经认证的访问并修改服务角色以包括 S3 访问，然后使用 AWS CLI 进行安全下载，是最安全和符合要求的方法。",
      "D": "此选项虽然提到了移除未经认证的访问，但使用 IAM 访问密钥和秘密访问密钥的方式不是最佳实践，因为它可能导致密钥管理问题。"
    },
    "service": ["AWS CodeBuild", "Amazon S3", "AWS CLI", "IAM"],
    "reason": "1.1"
  },
  {
    "no": 2,
    "question": "一家公司向客户提供应用程序。该应用程序具有一个 Amazon API Gateway REST API，用于调用 AWS Lambda 函数。在初始化时，Lambda 函数从 Amazon DynamoDB 表中加载大量数据。数据加载过程导致长时间的冷启动时间为 8-10 秒。DynamoDB 表已配置 DynamoDB 加速器 (DAX)。客户报告称，应用程序对请求的响应时有时会很长。该应用程序全天接收数千个请求。在一天中间，应用程序的请求量是其他任何时间的 10 倍。在一天结束时，应用程序的请求量减少到正常总量的 10%。一位 DevOps 工程师需要在一天中的任何时候减少 Lambda 函数的延迟。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "为 Lambda 函数配置预置并发，设置并发值为 1。删除 DynamoDB 表的 DAX 集群。",
      "B": "为 Lambda 函数配置保留并发，设置并发值为 0。",
      "C": "为 Lambda 函数配置预置并发。配置 Lambda 函数的 AWS 应用程序自动扩展，将预置并发值设置为最小 1 和最大 100。",
      "D": "为 Lambda 函数配置保留并发。配置 API Gateway API 的 AWS 应用程序自动扩展，将保留并发最大值设置为 100。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然配置预置并发可以减少冷启动时间，但删除 DAX 集群可能会增加对 DynamoDB 的访问延迟，不是最佳选择。",
      "B": "设置并发值为 0 会阻止 Lambda 函数处理任何事件，这不是一个有效的解决方案。",
      "C": "配置预置并发可以显著减少冷启动时间，而自动扩展可以根据需求动态调整并发量，这是最佳选择。",
      "D": "虽然配置保留并发可以为 API Gateway 保留处理能力，但它不解决 Lambda 函数的冷启动问题，因此不是最佳选择。"
    },
    "service": [
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon DynamoDB",
      "DynamoDB Accelerator (DAX)",
      "AWS Application Auto Scaling"
    ],
    "reason": "3.2"
  },
  {
    "no": 6,
    "question": "一家公司必须加密该公司跨账户共享的所有 AMI。一名 DevOps 工程师可以访问已构建未加密自定义 AMI 的源账户。DevOps 工程师还可以访问目标账户，其中 Amazon EC2 Auto Scaling 组将从 AMI 启动 EC2 实例。DevOps 工程师必须与目标账户共享 AMI。公司在源账户中创建了一个 AWS 密钥管理服务（AWS KMS）密钥。DevOps 工程师还需要执行哪些额外步骤以满足要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "在源账户中，将未加密的 AMI 复制为加密的 AMI。在复制操作中指定 KMS 密钥。",
      "B": "在源账户中，将未加密的 AMI 复制为加密的 AMI。在复制操作中指定默认的 Amazon 弹性块存储（Amazon EBS）加密密钥。",
      "C": "在源账户中，创建一个 KMS 授权，将权限委托给目标账户中的 Auto Scaling 组服务链接角色。",
      "D": "在源账户中，修改密钥策略以授予目标账户创建授权的权限。在目标账户中，创建一个 KMS 授权，将权限委托给 Auto Scaling 组服务链接角色。",
      "E": "在源账户中，与目标账户共享未加密的 AMI。",
      "F": "在源账户中，与目标账户共享加密的 AMI。"
    },
    "best": ["A", "D", "F"],
    "analysis": {
      "A": "正确。复制未加密的 AMI 为加密的 AMI 并指定 KMS 密钥是确保 AMI 加密的正确步骤。",
      "B": "错误。应该使用特定的 KMS 密钥而不是默认的 EBS 加密密钥，以确保符合公司的安全策略。",
      "C": "错误。授权应该在目标账户中创建，并且需要源账户修改密钥策略以允许目标账户创建授权。",
      "D": "正确。修改源账户的密钥策略以允许目标账户创建授权，并在目标账户中创建授权，是确保目标账户可以使用加密 AMI 的正确步骤。",
      "E": "错误。共享未加密的 AMI 不符合公司必须加密所有共享 AMI 的要求。",
      "F": "正确。在源账户中共享加密的 AMI 是确保目标账户可以使用加密 AMI 的正确步骤。"
    },
    "service": ["AWS KMS", "Amazon EC2", "Amazon EBS"],
    "reason": "6.2"
  },
  {
    "no": 4,
    "question": "一家公司要求其开发人员对账户中的所有 Amazon Elastic Block Store (Amazon EBS) 卷进行标记，以指示所需的备份频率。这一要求包括不需要备份的 EBS 卷。公司使用名为 Backup_Frequency 的自定义标签，其值为 none、daily 或 weekly，对应于所需的备份频率。审计发现开发人员偶尔没有对 EBS 卷进行标记。一名 DevOps 工程师需要确保所有 EBS 卷始终具有 Backup_Frequency 标签，以便公司可以至少每周进行一次备份，除非指定了其他值。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在账户中设置 AWS Config。创建一个自定义规则，对所有未应用 Backup Frequency 标签的 Amazon EC2 资源返回合规性失败。配置一个使用自定义 AWS Systems Manager Automation 运行簿的补救措施，以应用值为 weekly 的 Backup_Frequency 标签。",
      "B": "在账户中设置 AWS Config。使用一个管理规则，对所有未应用 Backup Frequency 标签的 EC2::Volume 资源返回合规性失败。配置一个使用自定义 AWS Systems Manager Automation 运行簿的补救措施，以应用值为 weekly 的 Backup_Frequency 标签。",
      "C": "在账户中开启 AWS CloudTrail。创建一个 Amazon EventBridge 规则，对 EBS CreateVolume 事件做出反应。配置一个自定义 AWS Systems Manager Automation 运行簿，以应用值为 weekly 的 Backup_Frequency 标签。指定运行簿作为规则的目标。",
      "D": "在账户中开启 AWS CloudTrail。创建一个 Amazon EventBridge 规则，对 EBS CreateVolume 事件或 EBS ModifyVolume 事件做出反应。配置一个自定义 AWS Systems Manager Automation 运行簿，以应用值为 weekly 的 Backup_Frequency 标签。指定运行簿作为规则的目标。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它涉及到所有 Amazon EC2 资源，而不是特定于 EBS 卷。",
      "B": "此选项是最佳选择，因为它专门针对没有 Backup Frequency 标签的 EC2::Volume 资源，并通过自动化运行簿应用默认标签，确保所有 EBS 卷都被标记。",
      "C": "此选项不是最佳选择，因为它只在创建 EBS 卷时应用标签，没有覆盖现有未标记的卷。",
      "D": "此选项不是最佳选择，尽管它覆盖了创建和修改卷的事件，但它不如选项 B 直接针对所有现有的未标记卷。"
    },
    "service": [
      "AWS Config",
      "AWS Systems Manager",
      "AWS CloudTrail",
      "Amazon EventBridge"
    ],
    "reason": "2.3"
  },
  {
    "no": 3,
    "question": "一家公司正在采用 AWS CodeDeploy 来自动化其 Java-Apache Tomcat 应用程序和 Apache Webserver 的应用程序部署。开发团队从概念验证开始，为开发者环境创建了一个部署组，并在应用程序中进行了功能测试。完成后，团队将为暂存和生产环境创建额外的部署组。当前的日志级别配置在 Apache 设置中，但团队希望在部署时动态更改此配置，以便他们可以根据部署组设置不同的日志级别配置，而无需为每个组使用不同的应用程序修订版本。如何以最小的管理开销满足这些要求，而不需要为每个部署组使用不同的脚本版本？",
    "choose": 1,
    "options": {
      "A": "根据部署组为 Amazon EC2 实例打标签。然后将一个脚本放入应用程序修订中，该脚本调用元数据服务和 EC2 API 来识别实例所属的部署组。使用此信息来配置日志级别设置。在 appspec.yml 文件中的 AfterInstall 生命周期钩子中引用该脚本。",
      "B": "创建一个脚本，使用 CodeDeploy 环境变量 DEPLOYMENT_GROUP_NAME 来识别实例所属的部署组。使用此信息来配置日志级别设置。在 appspec.yml 文件中的 BeforeInstall 生命周期钩子中引用此脚本。",
      "C": "为每个环境创建一个 CodeDeploy 自定义环境变量。然后将一个脚本放入应用程序修订中，该脚本检查此环境变量以识别实例所属的部署组。使用此信息来配置日志级别设置。在 appspec.yml 文件中的 ValidateService 生命周期钩子中引用此脚本。",
      "D": "创建一个脚本，使用 CodeDeploy 环境变量 DEPLOYMENT_GROUP_ID 来识别实例所属的部署组以配置日志级别设置。在 appspec.yml 文件中的 Install 生命周期钩子中引用此脚本。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项涉及使用元数据服务和 EC2 API，这增加了复杂性和管理开销，因此不是最佳选择。",
      "B": "此选项直接使用 CodeDeploy 提供的环境变量来确定部署组，简化了配置过程，是最佳选择。",
      "C": "此选项涉及创建自定义环境变量，这增加了管理开销，因此不是最佳选择。",
      "D": "此选项虽然使用了 CodeDeploy 环境变量，但是在 Install 生命周期钩子中配置日志级别可能不如在 BeforeInstall 生命周期钩子中配置那样有效，因此不是最佳选择。"
    },
    "service": ["AWS CodeDeploy", "Amazon EC2"],
    "reason": "1.4"
  },
  {
    "no": 7,
    "question": "一家公司使用 AWS CodePipeline 管道自动化其应用程序的发布。一个典型的管道包括三个阶段：构建、测试和部署。该公司一直在使用单独的 AWS CodeBuild 项目来运行每个阶段的脚本。然而，该公司现在希望使用 AWS CodeDeploy 来处理管道的部署阶段。公司已将应用程序打包为 RPM 包，并且必须将应用程序部署到一组 Amazon EC2 实例上。这些 EC2 实例位于 EC2 Auto Scaling 组中，并且是从一个公共 AMI 启动的。DevOps 工程师应执行哪两个步骤组合以满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "创建一个带有 CodeDeploy 代理安装的公共 AMI 的新版本。更新 EC2 实例的 IAM 角色以允许访问 CodeDeploy。",
      "B": "创建一个带有 CodeDeploy 代理安装的公共 AMI 的新版本。创建一个包含应用程序部署脚本并授予 CodeDeploy 访问权限的 AppSpec 文件。",
      "C": "在 CodeDeploy 中创建一个应用程序。配置就地部署类型。指定 Auto Scaling 组作为部署目标。在 CodePipeline 管道中添加一个步骤，使用 EC2 Image Builder 创建一个新的 AMI。配置 CodeDeploy 来部署新创建的 AMI。",
      "D": "在 CodeDeploy 中创建一个应用程序。配置就地部署类型。指定 Auto Scaling 组作为部署目标。更新 CodePipeline 管道以使用 CodeDeploy 动作部署应用程序。",
      "E": "在 CodeDeploy 中创建一个应用程序。配置就地部署类型。指定从公共 AMI 启动的 EC2 实例作为部署目标。更新 CodePipeline 管道以使用 CodeDeploy 动作部署应用程序。"
    },
    "best": ["A", "D"],
    "analysis": {
      "A": "这是最优选项之一，因为在使用 CodeDeploy 进行部署之前，确保 EC2 实例中安装了 CodeDeploy 代理并且具有适当的 IAM 角色权限是必要的。",
      "B": "虽然创建 AppSpec 文件是正确的，但是这个选项没有提到更新 IAM 角色，这对于 CodeDeploy 访问 EC2 实例是必要的。",
      "C": "这个选项提到了使用 EC2 Image Builder 创建新的 AMI，这不是必要的，因为应用程序已经打包为 RPM 包，可以直接部署。",
      "D": "这是最优选项之一，因为它正确地配置了 CodeDeploy 以使用就地部署类型，并指定了 Auto Scaling 组作为部署目标。",
      "E": "这个选项没有正确指定部署目标，它应该是 Auto Scaling 组而不是单独的 EC2 实例。"
    },
    "service": [
      "AWS CodePipeline",
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "Amazon EC2",
      "EC2 Auto Scaling",
      "IAM"
    ],
    "reason": "1.4"
  },
  {
    "no": 11,
    "question": "一家电子商务公司选择了 AWS 来托管其新平台。该公司的 DevOps 团队已经开始构建 AWS Control Tower 登陆区。DevOps 团队已将 AWS IAM Identity Center (AWS Single Sign-On) 中的身份存储设置为外部身份提供者 (IdP)，并配置了 SAML 2.0。DevOps 团队希望采用一种健壮的权限模型，该模型应用最小权限原则。该模型必须允许团队仅构建和管理团队自己的资源。哪些步骤的组合可以满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "创建包含所需权限的 IAM 策略。包括 aws:PrincipalTag 条件键。",
      "B": "创建权限集。附加一个包含所需权限的内联策略，并使用 aws:PrincipalTag 条件键来限定权限范围。",
      "C": "在 IdP 中创建一个组。将用户放入该组。将该组分配给账户和 IAM Identity Center 中的权限集。",
      "D": "在 IdP 中创建一个组。将用户放入该组。将该组分配给组织单位和 IAM 策略。",
      "E": "在 IAM Identity Center 中启用访问控制属性。对用户应用标签。将标签映射为键值对。",
      "F": "在 IAM Identity Center 中启用访问控制属性。将 IdP 的属性映射为键值对。"
    },
    "best": ["B", "C", "F"],
    "analysis": {
      "A": "虽然创建 IAM 策略是正确的，但仅包括 aws:PrincipalTag 条件键可能不足以限定权限范围，因此不是最佳选项。",
      "B": "创建权限集并附加内联策略，使用 aws:PrincipalTag 条件键来限定权限范围，这是符合最小权限原则的有效方法。",
      "C": "在 IdP 中创建组并将其分配给权限集是管理用户权限的有效方式，符合题目要求。",
      "D": "将组分配给组织单位和 IAM 策略可能不足以精确控制权限，因此不是最佳选项。",
      "E": "仅启用访问控制属性和应用标签可能不足以实现精确的权限控制。",
      "F": "启用访问控制属性并将 IdP 的属性映射为键值对可以有效地控制访问权限，符合最小权限原则。"
    },
    "service": ["AWS Control Tower", "AWS IAM Identity Center", "SAML 2.0"],
    "reason": "6.1"
  },
  {
    "no": 15,
    "question": "为了运行一个应用程序，一名DevOps工程师启动了一个带有公共IP地址的Amazon EC2实例在一个公共子网中。用户数据脚本在启动时获取应用程序工件并将其安装在实例上。应用程序的安全分类更改现在要求实例在没有访问互联网的情况下运行。虽然实例启动成功并显示为健康状态，但应用程序似乎没有安装。以下哪项应该在遵守新规则的同时成功安装应用程序？",
    "choose": 1,
    "options": {
      "A": "在公共子网中启动实例并附加弹性IP地址。一旦应用程序安装并运行，运行脚本以后解除弹性IP地址的关联。",
      "B": "设置一个NAT网关。将EC2实例部署到一个私有子网。更新私有子网的路由表，使用NAT网关作为默认路由。",
      "C": "将应用程序工件发布到一个Amazon S3存储桶，并为S3创建一个VPC端点。为EC2实例分配一个IAM实例配置文件，以便它们可以从S3存储桶读取应用程序工件。",
      "D": "为应用程序实例创建一个安全组，并仅允许出站流量到工件库。安装完成后移除安全组规则。"
    },
    "best": ["C"],
    "analysis": {
      "A": "这个选项不符合新的安全规定，因为它仍然允许实例在安装过程中访问互联网。",
      "B": "虽然这个选项将实例放在私有子网中，但使用NAT网关意味着实例仍然可以访问互联网，这违反了新的安全规定。",
      "C": "这是最佳选项，因为它允许实例在完全没有访问互联网的情况下从S3存储桶获取应用程序工件。通过使用VPC端点，实例可以安全地访问S3，而无需通过互联网。",
      "D": "这个选项仍然允许实例在安装过程中访问互联网，尽管是限制性的，但不符合新的安全规定。"
    },
    "service": ["Amazon EC2", "Amazon S3", "IAM", "VPC"],
    "reason": "2.1"
  },
  {
    "no": 12,
    "question": "一家电子商务公司收到报告称其订单历史页面在反映订单处理状态时出现延迟。订单处理系统由一个使用保留并发的 AWS Lambda 函数组成。该 Lambda 函数从 Amazon Simple Queue Service (Amazon SQS) 队列处理订单消息，并将处理后的订单插入到一个启用了读写容量自动扩展的 Amazon DynamoDB 表中。DevOps 工程师应采取哪些措施来解决这种延迟？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "检查 SQS 队列的 ApproximateAgeOfOldestMessage 指标。增加 Lambda 函数的并发限制。",
      "B": "检查 SQS 队列的 ApproximateAgeOfOldestMessage 指标。配置 SQS 队列的重试策略。",
      "C": "检查 SQS 队列的 NumberOfMessagesSent 指标。增加 SQS 队列的可见性超时。",
      "D": "检查 DynamoDB 表的 WriteThrottleEvents 指标。增加表的扩展策略的最大写入容量单位（WCUs）。",
      "E": "检查 Lambda 函数的 Throttles 指标。增加 Lambda 函数的超时时间。"
    },
    "best": ["A", "D"],
    "analysis": {
      "A": "最优选项。如果 SQS 队列中最老消息的年龄较大，表明 Lambda 函数处理速度不足以及时处理消息。增加 Lambda 函数的并发限制可以加快处理速度，减少延迟。",
      "B": "不是最优选项。虽然检查最老消息的年龄是正确的，但配置重试策略不会解决根本问题，即处理速度慢。",
      "C": "不是最优选项。增加可见性超时不会解决消息处理速度慢的问题。",
      "D": "最优选项。如果 DynamoDB 表显示写入节流事件，表明写入容量不足。增加最大写入容量单位可以减少写入延迟。",
      "E": "不是最优选项。增加超时时间可能有助于处理更复杂的函数，但不会解决并发处理能力不足的问题。"
    },
    "service": ["AWS Lambda", "Amazon SQS", "Amazon DynamoDB"],
    "reason": "3.2"
  },
  {
    "no": 16,
    "question": "一个开发团队正在使用 AWS CodeCommit 来进行应用代码的版本控制，并使用 AWS CodePipeline 来编排软件部署。团队决定使用远程主分支作为触发管道以集成代码更改的触发器。一名开发人员已将代码更改推送到 CodeCommit 仓库，但注意到即使过了10分钟，管道也没有任何反应。应采取以下哪些措施来排查此问题？",
    "choose": 1,
    "options": {
      "A": "检查是否为主分支创建了一个 Amazon EventBridge 规则以触发管道。",
      "B": "检查 CodePipeline 服务角色是否有权限访问 CodeCommit 仓库。",
      "C": "检查开发者的 IAM 角色是否有权限推送到 CodeCommit 仓库。",
      "D": "检查管道是否因 CodeCommit 错误而未能启动，在 Amazon CloudWatch 日志中查看。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最优选项，因为如果没有为主分支设置触发管道的 EventBridge 规则，即使代码已推送，管道也不会启动。",
      "B": "虽然 CodePipeline 服务角色需要有权限访问 CodeCommit 仓库，但问题描述中并未提及权限问题，而是管道没有触发。",
      "C": "开发者能够推送代码说明其 IAM 角色已经有足够的权限访问 CodeCommit 仓库。",
      "D": "查看 CloudWatch 日志是一个排查错误的方法，但首先应确认是否设置了正确的触发规则。"
    },
    "service": [
      "AWS CodeCommit",
      "AWS CodePipeline",
      "Amazon EventBridge",
      "Amazon CloudWatch"
    ],
    "reason": "1.1"
  },
  {
    "no": 20,
    "question": "一家公司的 DevOps 工程师使用 AWS Systems Manager 在维护窗口期间执行维护任务。该公司有一些 Amazon EC2 实例在收到 AWS Health 的通知后需要重启。DevOps 工程师需要实现一个自动化的解决方案来处理这些通知。DevOps 工程师创建了一个 Amazon EventBridge 规则。DevOps 工程师应该如何配置 EventBridge 规则以满足这些要求？",
    "choose": 1,
    "options": {
      "A": "配置一个事件源为 AWS Health，服务为 EC2，并且事件类型指示实例维护。目标是一个 Systems Manager 文档以重启 EC2 实例。",
      "B": "配置一个事件源为 Systems Manager 并且事件类型指示维护窗口。目标是一个 Systems Manager 文档以重启 EC2 实例。",
      "C": "配置一个事件源为 AWS Health，服务为 EC2，并且事件类型指示实例维护。目标是一个新创建的 AWS Lambda 函数，该函数注册一个自动化任务在维护窗口期间重启 EC2 实例。",
      "D": "配置一个事件源为 EC2 并且事件类型指示实例维护。目标是一个新创建的 AWS Lambda 函数，该函数注册一个自动化任务在维护窗口期间重启 EC2 实例。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然这个选项正确地指出了事件源和事件类型，但它没有提到如何确保在维护窗口期间进行重启，因此不是最佳选项。",
      "B": "这个选项错误地将事件源配置为 Systems Manager，而不是 AWS Health，这不符合题目要求。",
      "C": "这个选项正确地配置了事件源和事件类型，并且通过创建 Lambda 函数来注册自动化任务，确保在维护窗口期间进行重启，因此是最佳选项。",
      "D": "这个选项错误地将事件源配置为 EC2，而不是 AWS Health，这不符合题目要求。"
    },
    "service": [
      "AWS Systems Manager",
      "Amazon EC2",
      "AWS Health",
      "Amazon EventBridge",
      "AWS Lambda"
    ],
    "reason": "2.3"
  },
  {
    "no": 14,
    "question": "一位 DevOps 工程师正在为使用 AWS Lambda 函数的无服务器应用程序构建持续部署管道。公司希望减少不成功部署对客户的影响。公司还希望监控问题。哪种部署阶段配置能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS 无服务器应用程序模型（AWS SAM）模板来定义无服务器应用程序。使用 AWS CodeDeploy 部署 Lambda 函数，并选择 Canary10Percent15Minutes 部署偏好类型。使用 Amazon CloudWatch 警报来监控函数的健康状况。",
      "B": "使用 AWS CloudFormation 发布新的堆栈更新，并在所有资源上包括 Amazon CloudWatch 警报。设置 AWS CodePipeline 审批操作，由开发人员验证并批准 AWS CloudFormation 更改集。",
      "C": "使用 AWS CloudFormation 在每次堆栈更新时发布新版本，并在所有资源上包括 Amazon CloudWatch 警报。使用 AWS::Lambda::Alias 资源的 RoutingConfig 属性在堆栈更新期间更新流量路由。",
      "D": "使用 AWS CodeBuild 为 Lambda 函数添加示例事件有效负载以进行测试。发布函数的新版本，并包括 Amazon CloudWatch 警报。更新生产别名以指向新版本。配置在警报处于 ALARM 状态时回滚。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用了 AWS SAM 来定义无服务器应用程序，并通过 AWS CodeDeploy 的 Canary 部署策略逐步部署，这有助于减少不成功部署的影响。同时，使用 Amazon CloudWatch 警报来监控函数的健康状况，确保及时发现并处理问题。",
      "B": "这个选项虽然使用了 CloudFormation 和 CloudWatch 警报，但是依赖于人工审批过程，这可能会延迟部署并增加错误的风险。",
      "C": "此选项使用 CloudFormation 和 CloudWatch 警报，但是通过 RoutingConfig 更新流量路由可能不如 Canary 部署策略那样有效地控制风险。",
      "D": "此选项包括使用 CodeBuild 和 CloudWatch 警报，但是它依赖于更新生产别名和配置回滚，这可能在部署过程中引入更多的复杂性和风险。"
    },
    "service": [
      "AWS Lambda",
      "AWS Serverless Application Model (AWS SAM)",
      "AWS CodeDeploy",
      "Amazon CloudWatch",
      "AWS CloudFormation",
      "AWS CodePipeline",
      "AWS CodeBuild"
    ],
    "reason": "1.4"
  },
  {
    "no": 21,
    "question": "一家公司已将其所有内部质量控制应用程序容器化。该公司在 Amazon EC2 实例上运行 Jenkins，需要打补丁和升级。合规官员要求 DevOps 工程师开始加密构建工件，因为它们包含公司的知识产权。DevOps 工程师应该如何以最可维护的方式实现这一目标？",
    "choose": 1,
    "options": {
      "A": "使用 AWS Systems Manager 在 EC2 实例上自动化打补丁和升级，并默认加密 Amazon EBS 卷。",
      "B": "将 Jenkins 部署到 Amazon ECS 集群，并将构建工件复制到启用了默认加密的 Amazon S3 存储桶中。",
      "C": "利用 AWS CodePipeline 的构建操作，并使用 AWS Secrets Manager 加密工件。",
      "D": "使用 AWS CodeBuild 并启用工件加密来替换在 EC2 实例上运行的 Jenkins。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然自动化打补丁和升级是有益的，但这个选项没有直接解决构建工件的加密问题。",
      "B": "这个选项通过将 Jenkins 部署到 Amazon ECS 并使用 S3 的默认加密功能来存储构建工件，直接解决了问题，同时也简化了 Jenkins 的管理。",
      "C": "虽然使用 AWS CodePipeline 和 Secrets Manager 可以实现加密，但这需要更多的配置和管理，而且没有利用现有的 Jenkins 设置。",
      "D": "替换 Jenkins 可能导致额外的迁移和配置工作，而且 AWS CodeBuild 虽然提供了加密，但不一定比选项 B 更易于维护。"
    },
    "service": [
      "Amazon EC2",
      "AWS Systems Manager",
      "Amazon EBS",
      "Amazon ECS",
      "Amazon S3",
      "AWS CodePipeline",
      "AWS Secrets Manager",
      "AWS CodeBuild"
    ],
    "reason": "1.4"
  },
  {
    "no": 19,
    "question": "一家公司使用 AWS Organizations 和 AWS Control Tower 管理公司的所有 AWS 账户。该公司使用企业支持计划。一位 DevOps 工程师正在使用 Account Factory for Terraform (AFT) 来配置新账户。当新账户被配置时，DevOps 工程师注意到新账户的支持计划被设置为基础支持计划。DevOps 工程师需要实施一个解决方案来配置新账户，使其具有企业支持计划。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS Config 合规性包部署 account-part-of-organizations AWS Config 规则，并自动修正任何不合规的账户。",
      "B": "创建一个 AWS Lambda 函数来创建一个 AWS 支持工单，将账户添加到企业支持计划中。授予 Lambda 函数 support:ResolveCase 权限。",
      "C": "在 control_tower_parameters 输入中添加一个额外的值，将 AWSEnterpriseSupport 参数设置为组织的管理账户号码。",
      "D": "在 AFT 部署输入配置中将 aft_feature_enterprise_support 特性标志设置为 True。重新部署 AFT 并应用更改。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项不适用，因为 AWS Config 用于监控和评估配置，而不是用于更改支持计划。",
      "B": "虽然这种方法理论上可行，但它涉及手动干预和额外的操作步骤，不是自动化的最佳实践。",
      "C": "此选项不正确，因为 AWSEnterpriseSupport 参数并不是用于设置支持计划的。",
      "D": "这是最佳选项，因为通过设置 AFT 的特性标志来自动化支持计划的应用，符合 DevOps 自动化和无人工干预的原则。"
    },
    "service": [
      "AWS Organizations",
      "AWS Control Tower",
      "Account Factory for Terraform (AFT)",
      "AWS Config",
      "AWS Lambda"
    ],
    "reason": "2.2"
  },
  {
    "no": 13,
    "question": "一家公司在单个 AWS 账户中运行数百个 Amazon EC2 实例，这些实例位于单个 AWS 区域中。该账户每小时启动和终止新的 EC2 实例。账户中还包括运行时间超过一周的现有 EC2 实例。公司的安全政策要求所有运行中的 EC2 实例都使用 EC2 实例配置文件。如果 EC2 实例未附加实例配置文件，则 EC2 实例必须使用一个默认的实例配置文件，该配置文件未分配任何 IAM 权限。一名 DevOps 工程师审查账户时发现有些 EC2 实例在运行时没有实例配置文件。在审查过程中，DevOps 工程师还观察到新启动的 EC2 实例没有使用实例配置文件。哪种解决方案能确保该区域中所有现有和未来的 EC2 实例都附加了实例配置文件？",
    "choose": 1,
    "options": {
      "A": "配置一个 Amazon EventBridge 规则，该规则对 EC2 RunInstances API 调用做出反应。配置该规则以调用一个 AWS Lambda 函数，将默认实例配置文件附加到 EC2 实例上。",
      "B": "配置 ec2-instance-profile-attached AWS Config 托管规则，触发类型为配置更改。配置一个自动修正操作，该操作调用一个 AWS Systems Manager 自动化运行手册，将默认实例配置文件附加到 EC2 实例上。",
      "C": "配置一个 Amazon EventBridge 规则，该规则对 EC2 StartInstances API 调用做出反应。配置该规则以调用一个 AWS Systems Manager 自动化运行手册，将默认实例配置文件附加到 EC2 实例上",
      "D": "配置 iam-role-managed-policy-check AWS Config 托管规则，触发类型为配置更改。配置一个自动修正操作，该操作调用一个 AWS Lambda 函数，将默认实例配置文件附加到 EC2 实例上。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项通过 EventBridge 规则响应 RunInstances API 调用并使用 Lambda 函数来附加实例配置文件。虽然这种方法可以处理新实例，但它不会自动处理已经运行的实例。",
      "B": "此选项使用 AWS Config 托管规则来监控 EC2 实例是否已附加实例配置文件，并通过 Systems Manager 自动化运行手册自动修正。这种方法可以覆盖新实例和已存在的实例，是最全面的解决方案。",
      "C": "此选项通过 EventBridge 规则响应 StartInstances API 调用，但 StartInstances API 通常用于启动已停止的实例，而不是创建新实例，因此它不能覆盖所有情况。",
      "D": "此选项监控 IAM 角色的管理策略，但问题的核心是实例配置文件的附加，而不仅仅是策略的管理，因此不完全符合需求。"
    },
    "service": [
      "Amazon EC2",
      "AWS Lambda",
      "AWS Config",
      "AWS Systems Manager"
    ],
    "reason": "2.3"
  },
  {
    "no": 18,
    "question": "一位 DevOps 工程师正在创建一个 AWS CloudFormation 模板来部署一个 Web 服务。该 Web 服务将在一个私有子网中的 Amazon EC2 实例上运行，并通过一个应用程序负载均衡器（ALB）进行。DevOps 工程师必须确保该服务可以接受具有 IPv6 地址的客户端的请求。DevOps 工程师应该对 CloudFormation 模板做什么，以便 IPv6 客户端可以访问 Web 服务？",
    "choose": 1,
    "options": {
      "A": "向 VPC 和 EC2 实例的私有子网添加 IPv6 CIDR 块。为 IPv6 网络创建路由表条目，使用支持 IPv6 的 EC2 实例类型，并为每个 EC2 实例分配 IPv6 地址。",
      "B": "为每个 EC2 实例分配一个 IPv6 弹性 IP 地址。创建一个目标组，并将 EC2 实例添加为目标。在 ALB 的 443 端口上创建一个监听器，并将目标组与 ALB 关联。",
      "C": "用网络负载均衡器（NLB）替换 ALB。向 VPC 和 NLB 的子网添加 IPv6 CIDR 块，并为 NLB 分配一个 IPv6 弹性 IP 地址。",
      "D": "向 VPC 和 ALB 的子网添加 IPv6 CIDR 块。在 443 端口上创建一个监听器，并在 ALB 上指定双栈 IP 地址类型。创建一个目标组，并将 EC2 实例添加为目标。将目标组与 ALB 关联。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项虽然添加了 IPv6 支持，但没有提到 ALB 的配置，因此不完全。",
      "B": "此选项提到了为 EC2 实例分配 IPv6 弹性 IP 地址，但这通常不是必要的，因为 ALB 可以处理 IPv6 地址转换。",
      "C": "此选项提到了替换 ALB 为 NLB，但这不是必要的，因为 ALB 支持 IPv6。",
      "D": "此选项正确地添加了 IPv6 支持到 VPC 和 ALB 的子网，并正确配置了 ALB 以支持 IPv6，这是最佳选择。"
    },
    "service": [
      "AWS CloudFormation",
      "Amazon EC2",
      "Application Load Balancer (ALB)",
      "IPv6",
      "VPC"
    ],
    "reason": "2.1"
  },
  {
    "no": 17,
    "question": "一家公司的开发人员使用 Amazon EC2 实例作为远程工作站。公司担心用户可以创建或修改 EC2 安全组以允许不受限制的入站访问。DevOps 工程师需要开发一种解决方案来检测用户创建不受限制的安全组规则的情况。该解决方案必须能够近乎实时地检测到安全组规则的变更，移除不受限制的规则，并向安全团队发送电子邮件通知。DevOps 工程师已经创建了一个 AWS Lambda 函数，该函数检查输入中的安全组 ID，移除授予不受限制访问的规则，并通过 Amazon Simple Notification Service (Amazon SNS) 发送通知。DevOps 工程师接下来应该做什么来满足要求？",
    "choose": 1,
    "options": {
      "A": "配置 Lambda 函数由 SNS 主题调用。为 SNS 主题创建 AWS CloudTrail 订阅。为安全组修改事件配置订阅过滤器。",
      "B": "创建一个 Amazon EventBridge 定时规则来调用 Lambda 函数。定义一个运行 Lambda 函数的每小时的时间表模式。",
      "C": "创建一个 Amazon EventBridge 事件规则，将默认事件总线作为源。定义规则的事件模式以匹配 EC2 安全组创建和修改事件。配置规则以调用 Lambda 函数。",
      "D": "创建一个 Amazon EventBridge 自定义事件总线，订阅来自所有 AWS 服务的事件。配置 Lambda 函数由自定义事件总线调用。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项不正确，因为它涉及到通过 CloudTrail 订阅 SNS 主题，这不是直接监控 EC2 安全组变更的标准方法。",
      "B": "此选项不正确，因为它使用定时规则，这不能保证近乎实时地检测安全组规则的变更。",
      "C": "此选项是正确的，因为它使用 EventBridge 事件规则直接针对 EC2 安全组的创建和修改事件，能够近乎实时地触发 Lambda 函数，符合题目要求。",
      "D": "此选项不正确，因为创建自定义事件总线并订阅所有 AWS 服务的事件可能会导致不必要的复杂性和开销，而且不是针对性的解决方案。"
    },
    "service": ["Amazon EC2", "AWS Lambda", "Amazon SNS", "Amazon EventBridge"],
    "reason": "2.3"
  },
  {
    "no": 22,
    "question": "一个 IT 团队构建了一个 AWS CloudFormation 模板，以便公司中的其他人可以快速可靠地部署和终止应用程序。该模板创建了一个 Amazon EC2 实例，并带有一个用户数据脚本来安装应用程序，以及一个 Amazon S3 存储桶，该存储桶在应用程序运行时用于提供静态网页。当 CloudFormation 堆栈被删除时，所有资源都应该被移除。然而，团队观察到在堆栈删除期间 CloudFormation 报告错误，并且堆栈创建的 S3 存储桶没有被删除。团队如何以最有效的方式解决删除错误，以确保所有资源都被无误删除？",
    "choose": 1,
    "options": {
      "A": "为 S3 存储桶资源添加一个 DelelionPolicy 属性，其值为 Delete，强制在堆栈被删除时移除存储桶。",
      "B": "添加一个自定义资源，其中包含一个 AWS Lambda 函数，该函数具有 DependsOn 属性指定 S3 存储桶，并具有一个 IAM 角色。编写 Lambda 函数在 RequestType 为 Delete 时删除存储桶中的所有对象。",
      "C": "识别未被删除的资源。手动清空 S3 存储桶然后删除它。",
      "D": "用单一的 AWS OpsWorks Stacks 资源替换 EC2 和 S3 存储桶资源。为堆栈定义一个自定义配方来创建和删除 EC2 实例和 S3 存储桶。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然 DeletionPolicy 设置为 Delete 可以在删除堆栈时删除 S3 存储桶，但如果存储桶中有内容，这种方法将失败，因为 S3 不允许删除非空的存储桶。",
      "B": "这是最佳选项，因为通过 Lambda 函数自动删除存储桶中的所有对象，可以确保在删除堆栈时 S3 存储桶为空，从而避免删除错误。",
      "C": "手动清空和删除 S3 存储桶虽然可行，但不是最有效的方法，因为它需要手动干预，不符合自动化和可重复使用的原则。",
      "D": "使用 AWS OpsWorks Stacks 是一个更复杂的解决方案，可能不是解决特定问题（即删除 S3 存储桶时的错误）的最直接或最有效的方法。"
    },
    "service": [
      "AWS CloudFormation",
      "Amazon EC2",
      "Amazon S3",
      "AWS Lambda",
      "IAM",
      "AWS OpsWorks"
    ],
    "reason": "2.1"
  },
  {
    "no": 23,
    "question": "一家公司在 eu-west-1 区域配置了一个 AWS CodePipeline 管道，该管道配置了一个 Amazon S3 存储桶。该管道将一个 AWS Lambda 应用程序部署到同一区域。管道包括一个 AWS CodeBuild 项目构建操作和一个 AWS CloudFormation 部署操作。CodeBuild 项目使用 aws cloudformation package AWS CLI 命令构建包含 Lambda 函数代码的 .zip 文件和 CloudFormation 模板的工件。CloudFormation 部署操作引用了 CodeBuild 项目构建操作的输出工件中的 CloudFormation 模板。公司希望通过在 eu-west-1 的管道中也将 Lambda 应用程序部署到 us-east-1 区域。DevOps 工程师已经更新了 CodeBuild 项目，使用 aws cloudformation package 命令为 us-east-1 生成了一个额外的输出工件。DevOps 工程师应采取哪些额外步骤来满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "修改 CloudFormation 模板以包含 Lambda 函数代码的 zip 文件位置参数。为 us-east-1 在管道中创建一个新的 CloudFormation 部署操作。配置新的部署操作以将 us-east-1 工件位置作为参数覆盖传递。",
      "B": "为 us-east-1 在管道中创建一个新的 CloudFormation 部署操作。配置新的部署操作以使用来自 us-east-1 输出工件的 CloudFormation 模板。",
      "C": "在 us-east-1 创建一个 S3 存储桶。配置 S3 存储桶策略以允许 CodePipeline 有读写访问权限。",
      "D": "在 us-east-1 创建一个 S3 存储桶。配置 S3 跨区域复制（CRR）从 eu-west-1 的 S3 存储桶到 us-east-1 的 S3 存储桶。",
      "E": "修改管道以包括 us-east-1 的 S3 存储桶作为工件存储。为 us-east-1 在管道中创建一个新的 CloudFormation 部署操作。配置新的部署操作以使用来自 us-east-1 输出工件的 CloudFormation 模板。"
    },
    "best": ["A", "E"],
    "analysis": {
      "A": "这是最佳选项之一，因为它允许通过参数覆盖来动态指定 Lambda 函数代码的位置，从而实现灵活的多区域部署。",
      "B": "此选项不足以满足需求，因为它没有提供如何处理 Lambda 函数代码位置的细节。",
      "C": "虽然创建 S3 存储桶是必要的，但仅仅允许 CodePipeline 访问并不足以实现部署到另一个区域的需求。",
      "D": "此选项涉及跨区域复制，这在此场景中不是必需的，因为已经有了为 us-east-1 生成的输出工件。",
      "E": "这是最佳选项之一，因为它涉及修改管道以包括新区域的工件存储，并创建新的部署操作，这是实现多区域部署的有效方式。"
    },
    "service": [
      "AWS CodePipeline",
      "Amazon S3",
      "AWS Lambda",
      "AWS CodeBuild",
      "AWS CloudFormation"
    ],
    "reason": "1.4"
  },
  {
    "no": 24,
    "question": "一家公司在一台 Amazon EC2 实例上运行一个应用程序。应用程序元数据存储在 Amazon S3 中，如果实例重新启动，则必须检索这些元数据。如果实例无响应，必须自动重新启动或重新启动实例。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "为 StatusCheckFailed 指标创建一个 Amazon CloudWatch 警报。使用恢复操作停止并启动实例。当实例重新运行时，使用 S3 事件通知将元数据推送到实例。",
      "B": "配置 AWS OpsWorks，并使用自动修复功能停止并启动实例。在 OpsWorks 中使用生命周期事件从 Amazon S3 拉取元数据并更新实例。",
      "C": "使用 EC2 自动恢复在发生故障时自动停止并启动实例。当实例重新运行时，使用 S3 事件通知将元数据推送到实例。",
      "D": "使用 AWS CloudFormation 创建一个包含 EC2 资源的 UserData 属性的 EC2 实例。在 UserData 中添加命令以从 Amazon S3 检索应用程序元数据。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然使用 CloudWatch 警报可以监控实例状态并执行恢复操作，但它不提供自动恢复实例的最佳实践。",
      "B": "AWS OpsWorks 提供了自动修复功能，但它主要用于配置管理，而不是用于处理 EC2 实例的自动恢复。",
      "C": "EC2 自动恢复确保实例在发生故障时自动恢复，结合 S3 事件通知自动推送元数据到实例，完全符合题目要求。",
      "D": "虽然 AWS CloudFormation 可以创建具有自动元数据检索的实例，但它不处理实例的自动恢复。"
    },
    "service": [
      "Amazon EC2",
      "Amazon S3",
      "Amazon CloudWatch",
      "AWS OpsWorks",
      "EC2 Auto Recovery",
      "AWS CloudFormation"
    ],
    "reason": "3.3"
  },
  {
    "no": 25,
    "question": "一家公司拥有多个AWS账户。该公司使用与AWS Toolkit for Microsoft Azure DevOps集成的AWS IAM Identity Center（AWS单一登录），并启用了IAM Identity Center中的访问控制属性功能。属性映射列表包含两个条目。部门键映射到${path:enterprise.department}，成本中心键映射到${path:enterprise.costCenter}。所有现有的Amazon EC2实例都有一个部门标签，对应于公司的三个部门（d1，d2，d3）。DevOps工程师必须根据匹配属性创建策略。这些策略必须尽量减少管理工作，并且只授予每个Azure AD用户访问其各自部门名称标记的EC2实例的权限。DevOps工程师应该在自定义权限策略中包含哪个条件键以满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用“aws:RequestTag/${TagKey}”条件键",
      "B": "使用“aws:TagKeys”条件键",
      "C": "使用“ec2:ResourceTag/${Department}”条件键",
      "D": "使用“s3:x-amz-acl”条件键"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然“aws:RequestTag/${TagKey}”条件键用于限制对标签的请求，但它不适用于根据用户的部门属性直接限制对EC2实例的访问。",
      "B": "“aws:TagKeys”条件键用于限制标签键的使用，但不适用于根据特定的标签值（如部门名称）限制访问。",
      "C": "“ec2:ResourceTag/${Department}”条件键允许基于EC2资源的标签值（在这种情况下是部门名称）限制访问，完全符合题目要求。",
      "D": "“s3:x-amz-acl”条件键用于S3服务，与EC2实例的访问控制无关，因此不适用。"
    },
    "service": [
      "AWS IAM Identity Center",
      "Amazon EC2",
      "AWS Toolkit for Microsoft Azure DevOps"
    ],
    "reason": "6.1"
  },
  {
    "no": 31,
    "question": "一家公司已将其基于容器的应用程序迁移到 Amazon EKS，并希望建立自动化的电子邮件通知。发送到每个电子邮件地址的通知是针对与 EKS 组件相关的特定活动。该解决方案将包括 Amazon SNS 主题和一个 AWS Lambda 函数来评估传入的日志事件并将消息发布到正确的 SNS 主题。哪种日志解决方案将支持这些要求？",
    "choose": 1,
    "options": {
      "A": "启用 Amazon CloudWatch 日志以记录 EKS 组件。为每个组件创建一个 CloudWatch 订阅过滤器，Lambda 作为订阅源目的地。",
      "B": "启用 Amazon CloudWatch 日志以记录 EKS 组件。创建与 Amazon EventBridge 事件链接的 CloudWatch Logs Insights 查询，调用 Lambda。",
      "C": "启用 Amazon S3 日志记录 EKS 组件。为每个组件配置一个 Amazon CloudWatch 订阅过滤器，Lambda 作为订阅源目的地。",
      "D": "启用 Amazon S3 日志记录 EKS 组件。配置 S3 PUT 对象事件通知，AWS Lambda 作为目的地。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用 Amazon CloudWatch Logs 来记录 EKS 组件，并通过 CloudWatch 订阅过滤器将日志事件直接发送到 Lambda 函数，这样可以有效地处理和筛选日志数据，然后将相关通知发送到正确的 SNS 主题。",
      "B": "此选项不是最佳选择，因为它涉及使用 CloudWatch Logs Insights 查询，这虽然可以分析日志数据，但对于实时事件通知和处理可能不如直接使用 Lambda 函数灵活。",
      "C": "此选项不是最佳选择，因为它使用 Amazon S3 来记录日志，这不是处理实时日志数据的最佳方法，特别是当需要实时响应时。",
      "D": "此选项不是最佳选择，因为它依赖于 S3 PUT 事件通知，这主要适用于对象存储事件，而不是实时日志处理。"
    },
    "service": [
      "Amazon EKS",
      "Amazon SNS",
      "AWS Lambda",
      "Amazon CloudWatch Logs",
      "Amazon S3"
    ],
    "reason": "4.1"
  },
  {
    "no": 28,
    "question": "一位开发者正在维护一组50台Amazon EC2 Linux服务器。这些服务器是Amazon EC2 Auto Scaling组的一部分，同时使用Elastic Load Balancing进行负载均衡。偶尔，一些应用服务器在失败ELB HTTP健康检查后被终止。开发者希望对问题进行根本原因分析，但在能够访问应用日志之前，服务器就被终止了。如何自动化日志收集？",
    "choose": 1,
    "options": {
      "A": "使用Auto Scaling生命周期钩子将实例置于Pending:Wait状态。创建一个Amazon CloudWatch警报，用于EC2实例终止成功，并触发一个AWS Lambda函数，该函数调用SSM Run Command脚本收集日志，将它们推送到Amazon S3，并在收集日志后完成生命周期动作。",
      "B": "使用Auto Scaling生命周期钩子将实例置于Terminating:Wait状态。创建一个AWS Config规则，用于EC2实例终止生命周期动作，并触发一个步骤函数，该函数调用脚本收集日志，将它们推送到Amazon S3，并在收集日志后完成生命周期动作。",
      "C": "使用Auto Scaling生命周期钩子将实例置于Terminating:Wait状态。创建一个Amazon CloudWatch订阅过滤器，用于EC2实例终止成功，并触发一个CloudWatch代理，该代理调用脚本收集日志，将它们推送到Amazon S3，并在收集日志后完成生命周期动作。",
      "D": "使用Auto Scaling生命周期钩子将实例置于Terminating:Wait状态。创建一个Amazon EventBridge规则，用于EC2实例终止生命周期动作，并触发一个AWS Lambda函数，该函数调用SSM Run Command脚本收集日志，将它们推送到Amazon S3，并在收集日志后完成生命周期动作。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项提到将实例置于Pending:Wait状态，这是不正确的，因为我们需要在实例终止前收集日志，而不是在实例启动时。",
      "B": "此选项虽然使用了Terminating:Wait状态，但是使用AWS Config规则和步骤函数不是最优的方法来触发日志收集。",
      "C": "此选项使用了CloudWatch订阅过滤器和CloudWatch代理，这不是最直接的方法来触发日志收集脚本。",
      "D": "此选项正确地使用了Terminating:Wait状态，并且使用Amazon EventBridge规则和AWS Lambda函数来触发日志收集，这是一种高效且直接的方法。"
    },
    "service": [
      "Amazon EC2",
      "Auto Scaling",
      "Elastic Load Balancing",
      "Amazon CloudWatch",
      "AWS Lambda",
      "SSM Run Command",
      "Amazon S3",
      "Amazon EventBridge"
    ],
    "reason": "4.1"
  },
  {
    "no": 27,
    "question": "一家公司有一个用 Go 编写的本地应用程序。一位 DevOps 工程师必须将应用程序迁移到 AWS。公司的开发团队希望启用蓝/绿部署并进行 A/B 测试。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在 Amazon EC2 实例上部署应用程序，并创建该实例的 AMI。使用 AMI 创建自动扩展启动配置，该配置用于自动扩展组。使用弹性负载均衡来分配流量。当对应用程序进行更改时，将创建一个新的 AMI，这将启动一个 EC2 实例刷新。",
      "B": "使用 Amazon Lightsail 部署应用程序。将应用程序以压缩格式存储在 Amazon S3 存储桶中。使用此压缩版本将应用程序的新版本部署到 Lightsail。使用 Lightsail 部署选项来管理部署。",
      "C": "使用 AWS CodeArtifact 存储应用程序代码。使用 AWS CodeDeploy 将应用程序部署到 Amazon EC2 实例群。使用弹性负载均衡来分配流量到 EC2 实例。在进行更改时，上传新版本到 CodeArtifact 并创建新的 CodeDeploy 部署。",
      "D": "使用 AWS Elastic Beanstalk 托管应用程序。在 Amazon S3 中存储应用程序的压缩版本。使用该位置部署应用程序的新版本。使用 Elastic Beanstalk 管理部署选项。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然使用了自动扩展和弹性负载均衡，但这种方法涉及手动创建 AMI 和刷新 EC2 实例，这可能不是最高效的蓝/绿部署方法。",
      "B": "Amazon Lightsail 是一个简化的部署和管理选项，但它不支持复杂的蓝/绿部署和 A/B 测试策略。",
      "C": "使用 AWS CodeArtifact 和 AWS CodeDeploy 可以有效地管理代码存储和自动化部署，支持蓝/绿部署和 A/B 测试，是最佳选择。",
      "D": "虽然 Elastic Beanstalk 支持多种部署策略，但它的控制和灵活性可能不如直接使用 CodeDeploy 和 CodeArtifact。"
    },
    "service": [
      "AWS CodeArtifact",
      "AWS CodeDeploy",
      "Amazon EC2",
      "Elastic Load Balancing"
    ],
    "reason": "1.4"
  },
  {
    "no": 26,
    "question": "一家公司在 AWS 账户中托管一个安全审计应用程序。该审计应用程序使用 IAM 角色访问其他 AWS 账户。所有账户都在 AWS Organizations 的同一组织中。最近的安全审计显示，被审计 AWS 账户中的用户可以修改或删除审计应用程序的 IAM 角色。公司需要防止除了受信任的管理员 IAM 角色之外的任何实体修改审计应用程序的 IAM 角色。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个包含拒绝更改审计应用程序的 IAM 角色的声明的 SCP。包括一个条件，允许受信任的管理员 IAM 角色进行更改。将 SCP 附加到组织的根。",
      "B": "创建一个 SCP，其中包括允许受信任的管理员 IAM 角色更改审计应用程序的 IAM 角色的允许声明。包括一个拒绝所有其他 IAM 主体更改的声明。将 SCP 附加到每个 AWS 账户中的 IAM 服务，其中审计应用程序具有 IAM 角色。",
      "C": "创建一个 IAM 权限边界，其中包括拒绝更改审计应用程序的 IAM 角色的声明。包括一个条件，允许受信任的管理员 IAM 角色进行更改。将权限边界附加到被审计的 AWS 账户。",
      "D": "创建一个 IAM 权限边界，其中包括拒绝更改审计应用程序的 IAM 角色的声明。包括一个条件，允许受信任的管理员 IAM 角色进行更改。将权限边界附加到 AWS 账户中的审计应用程序的 IAM 角色。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用 SCP 在组织级别实施安全控制，确保只有受信任的管理员 IAM 角色可以修改审计应用程序的 IAM 角色。",
      "B": "这个选项不是最佳的，因为它需要在每个账户中单独设置 SCP，这在管理上不如选项 A 高效。",
      "C": "这个选项不是最佳的，因为它使用权限边界而不是 SCP，权限边界主要用于限制 IAM 角色的权限，而不是管理跨账户的访问控制。",
      "D": "这个选项不是最佳的，因为它错误地将权限边界附加到 IAM 角色，而不是使用 SCP 控制组织级别的策略。"
    },
    "service": ["AWS Organizations", "IAM", "SCP"],
    "reason": "6.1"
  },
  {
    "no": 33,
    "question": "一家使用电子健康记录的公司正在运行一组带有 Amazon Linux 操作系统的 Amazon EC2 实例。作为患者隐私要求的一部分，公司必须确保操作系统和运行在 EC2 实例上的应用程序的补丁持续合规。如何使用默认和自定义仓库自动化操作系统和应用程序补丁的部署？",
    "choose": 1,
    "options": {
      "A": "使用 AWS Systems Manager 创建一个包括自定义仓库的新补丁基线。使用 run 命令运行 AWS-RunPatchBaseline 文档以验证和安装补丁。",
      "B": "使用 AWS Direct Connect 集成企业仓库，并使用 Amazon CloudWatch 计划事件部署补丁，然后使用 CloudWatch 仪表板创建报告。",
      "C": "使用 yum-config-manager 添加自定义仓库到 /etc/yum.repos.d 并运行 yum-config-manager-enable 来激活仓库。",
      "D": "使用 AWS Systems Manager 创建一个包括企业仓库的新补丁基线。使用 run 命令运行 AWS-AmazonLinuxDefaultPatchBaseline 文档以验证和安装补丁。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用 AWS Systems Manager 创建包含自定义仓库的补丁基线，并通过 AWS-RunPatchBaseline 文档自动化补丁部署，满足题目要求。",
      "B": "这个选项不是最佳选项，因为它使用 AWS Direct Connect 和 CloudWatch，这些工具不是专门用于补丁管理的标准方法。",
      "C": "这个选项不是最佳选项，因为它仅涉及到添加和激活仓库，没有提到如何自动化补丁部署。",
      "D": "这个选项不是最佳选项，因为虽然它使用了 AWS Systems Manager，但是提到的 AWS-AmazonLinuxDefaultPatchBaseline 文档可能不支持自定义仓库。"
    },
    "service": [
      "AWS Systems Manager",
      "AWS Direct Connect",
      "Amazon CloudWatch"
    ],
    "reason": "2.3"
  },
  {
    "no": 29,
    "question": "一家公司在 AWS Organizations 中有一个组织。该组织包括包含企业应用程序的工作负载账户。该公司从一个运营账户集中管理用户。工作负载账户中不能创建用户。该公司最近增加了一个运营团队，并且必须为运营团队成员提供对每个工作负载账户的管理员访问权限。哪种操作组合将提供此访问权限？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "在运营账户中创建一个 SysAdmin 角色。将 AdministratorAccess 策略附加到该角色。修改信任关系以允许来自工作负载账户的 sts:AssumeRole 操作。",
      "B": "在每个工作负载账户中创建一个 SysAdmin 角色。将 AdministratorAccess 策略附加到该角色。修改信任关系以允许来自运营账户的 sts:AssumeRole 操作。",
      "C": "在运营账户中创建一个 Amazon Cognito 身份池。将 SysAdmin 角色作为认证角色附加。",
      "D": "在运营账户中为每个运营团队成员创建一个 IAM 用户。",
      "E": "在运营账户中创建一个名为 SysAdmins 的 IAM 用户组。添加一个 IAM 策略，允许对每个工作负载账户中的 SysAdmin 角色执行 sts:AssumeRole 操作。将所有运营团队成员添加到该组。",
      "F": "在运营账户中创建一个 Amazon Cognito 用户池。为每个运营团队成员创建一个 Amazon Cognito 用户。"
    },
    "best": ["B", "E", "F"],
    "analysis": {
      "A": "这个选项不正确，因为信任关系应该允许来自运营账户的 sts:AssumeRole 操作，而不是来自工作负载账户。",
      "B": "这个选项是正确的，因为它允许运营账户的成员通过 sts:AssumeRole 操作来扮演工作负载账户中的 SysAdmin 角色。",
      "C": "这个选项不正确，因为 Amazon Cognito 身份池主要用于客户端应用程序的身份管理，而不适用于管理 AWS 资源的访问。",
      "D": "这个选项不正确，因为题目要求不能在工作负载账户中创建用户，而应该使用角色和策略来管理访问权限。",
      "E": "这个选项是正确的，因为它通过创建一个用户组并授予该组成员权限来扮演工作负载账户中的 SysAdmin 角色，从而实现了集中管理和访问控制。",
      "F": "这个选项不正确，因为 Amazon Cognito 用户池用于管理应用程序用户的身份，而不是用于管理 AWS 资源的访问。"
    },
    "service": ["AWS Organizations", "IAM", "Amazon Cognito", "sts:AssumeRole"],
    "reason": "2.2"
  },
  {
    "no": 36,
    "question": "一位 DevOps 工程师需要使用 S3 跨区域复制功能备份存储在具有私有存储桶策略的 S3 存储桶中的敏感 Amazon S3 对象。这些对象需要复制到不同 AWS 区域和账户的目标存储桶中。应执行哪些操作组合以启用此复制？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "在源账户中创建复制 IAM 角色",
      "B": "在目标账户中创建复制 IAM 角色",
      "C": "向源存储桶策略添加声明，允许复制 IAM 角色复制对象",
      "D": "向目标存储桶策略添加声明，允许复制 IAM 角色复制对象",
      "E": "在源存储桶中创建复制规则以启用复制",
      "F": "在目标存储桶中创建复制规则以启用复制"
    },
    "best": ["A", "C", "E"],
    "analysis": {
      "A": "创建复制 IAM 角色是必要的，因为它将授权源账户访问目标存储桶进行对象复制。",
      "B": "在目标账户中创建复制 IAM 角色不是必要的，因为复制过程是由源账户控制的。",
      "C": "向源存储桶策略添加声明是必要的，以允许复制 IAM 角色执行复制操作。",
      "D": "向目标存储桶策略添加声明不是必要的，因为复制权限应由源存储桶的策略控制。",
      "E": "在源存储桶中创建复制规则是必要的，以定义复制的目标和条件。",
      "F": "在目标存储桶中创建复制规则不是必要的，因为复制规则应仅在源存储桶中设置。"
    },
    "service": ["Amazon S3", "IAM"],
    "reason": "3.3"
  },
  {
    "no": 30,
    "question": "一家公司在 AWS Organizations 中拥有多个账户。公司的 SecOps 团队需要在组织中的任何账户关闭 Amazon S3 存储桶的阻止公共访问功能时接收 Amazon Simple Notification Service (Amazon SNS) 通知。一名 DevOps 工程师必须在不影响任何 AWS 账户操作的情况下实施此更改。实施必须确保组织中的个别成员账户不能关闭通知。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "指定一个账户作为委派的 Amazon GuardDuty 管理员账户。为组织中的所有账户开启 GuardDuty。在 GuardDuty 管理员账户中，创建一个 SNS 主题。将 SecOps 团队的电子邮件地址订阅到 SNS 主题。在同一账户中，创建一个使用 GuardDuty 发现的事件模式和 SNS 主题为目标的 Amazon EventBridge 规则。",
      "B": "创建一个 AWS CloudFormation 模板，该模板创建一个 SNS 主题并将 SecOps 团队的电子邮件地址订阅到 SNS 主题。在模板中，包括一个使用 CloudTrail 活动的事件模式为 s3:PutBucketPublicAccessBlock 和 SNS 主题为目标的 Amazon EventBridge 规则。使用 CloudFormation StackSets 将堆栈部署到组织中的每个账户。",
      "C": "在组织中启用 AWS Config。在委派的管理员账户中，创建一个 SNS 主题。将 SecOps 团队的电子邮件地址订阅到 SNS 主题。部署一个在每个账户中使用 s3-bucket-level-public-access-prohibited AWS Config 管理规则的合规性包，并使用 AWS Systems Manager 文档发布事件到 SNS 主题以通知 SecOps 团队。",
      "D": "在组织中启用 Amazon Inspector。在 Amazon Inspector 委派管理员账户中，创建一个 SNS 主题。将 SecOps 团队的电子邮件地址订阅到 SNS 主题。在同一账户中，创建一个使用 S3 存储桶的公共网络暴露的事件模式并发布事件到 SNS 主题以通知 SecOps 团队的 Amazon EventBridge 规则。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然 GuardDuty 可以监控安全威胁，但它不专门针对 S3 存储桶的公共访问配置更改。",
      "B": "这个选项可以监控 S3 存储桶公共访问配置的更改，但它需要在每个账户中部署，成员账户可以更改或删除 CloudFormation 模板。",
      "C": "这个选项通过 AWS Config 监控 S3 存储桶的公共访问配置，并且可以在组织级别集中管理，成员账户无法关闭通知，符合题目要求。",
      "D": "Amazon Inspector 主要用于应用程序安全性和合规性的评估，不适用于监控 S3 存储桶的公共访问配置更改。"
    },
    "service": [
      "AWS Organizations",
      "Amazon SNS",
      "AWS Config",
      "Amazon EventBridge",
      "AWS Systems Manager"
    ],
    "reason": "2.1"
  },
  {
    "no": 35,
    "question": "一家公司在多个资源使用的 Amazon S3 存储桶前使用 AWS Storage Gateway 的文件网关模式。在早晨业务开始时，用户看不到第三方前一晚处理的对象。当 DevOps 工程师直接查看 S3 存储桶时，数据在那里，但在 Storage Gateway 中缺失。哪种解决方案可以确保所有更新的第三方文件在早晨都可用？",
    "choose": 1,
    "options": {
      "A": "配置每晚一个 Amazon EventBridge 事件来调用一个 AWS Lambda 函数运行 Storage Gateway 的 RefreshCache 命令。",
      "B": "指示第三方使用 AWS Transfer for SFTP 将数据放入 S3 存储桶。",
      "C": "将 Storage Gateway 修改为运行在卷网关模式。",
      "D": "使用 S3 同区域复制将直接在 S3 存储桶中所做的任何更改复制到 Storage Gateway。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为通过配置 EventBridge 来定期调用 Lambda 函数执行 RefreshCache 命令，可以确保 Storage Gateway 的缓存与 S3 存储桶中的数据保持同步。",
      "B": "这个选项不是最佳的，因为它只改变了数据的上传方式，但没有解决 Storage Gateway 缓存更新的问题。",
      "C": "这个选项不是最佳的，因为改变网关模式并不会解决缓存更新的问题。",
      "D": "这个选项不是最佳的，因为 S3 的复制功能并不直接影响 Storage Gateway 的缓存状态。"
    },
    "service": [
      "AWS Storage Gateway",
      "Amazon S3",
      "Amazon EventBridge",
      "AWS Lambda"
    ],
    "reason": "2.3"
  },
  {
    "no": 32,
    "question": "一家公司正在实施一个Amazon Elastic Container Service (Amazon ECS)集群来运行其工作负载。公司的架构将在集群上运行多个ECS服务。架构包括一个前端的应用程序负载均衡器，并使用多个目标组来路由流量。一名DevOps工程师必须收集应用程序和访问日志。然后，DevOps工程师需要将日志发送到Amazon S3存储桶进行近实时分析。DevOps工程师必须采取哪些步骤的组合来满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "从AWS下载Amazon CloudWatch Logs容器实例。将此实例配置为任务。更新应用程序服务定义以包括日志记录任务。",
      "B": "在ECS实例上安装Amazon CloudWatch Logs代理。更改ECS任务定义中的日志驱动程序为awslogs。",
      "C": "使用Amazon EventBridge安排一个每60秒运行一次的AWS Lambda函数，该函数将运行Amazon CloudWatch Logs create-export-task命令。然后将输出指向日志记录S3存储桶。",
      "D": "在ALB上激活访问日志记录。然后直接将ALB指向日志记录S3存储桶。",
      "E": "激活ECS服务使用的目标组上的访问日志记录。然后直接将日志发送到日志记录S3存储桶。",
      "F": "创建一个目的地为日志记录S3存储桶的Amazon Kinesis Data Firehose传输流。然后为Kinesis Data Firehose创建一个Amazon CloudWatch Logs订阅过滤器。"
    },
    "best": ["B", "D", "F"],
    "analysis": {
      "A": "这个选项不是最佳选择，因为它提到了下载CloudWatch Logs容器实例并将其配置为任务，这不是AWS推荐的实践。",
      "B": "这是一个最佳选择，因为它涉及在ECS实例上安装CloudWatch Logs代理，并更改日志驱动程序为awslogs，这是标准的日志收集方法。",
      "C": "这个选项不是最佳选择，因为它涉及使用Lambda函数和EventBridge来创建导出任务，这种方法不是最高效的日志收集方式。",
      "D": "这是一个最佳选择，因为它涉及激活ALB的访问日志并直接将其发送到S3存储桶，这是直接且有效的日志收集方法。",
      "E": "这个选项不是最佳选择，因为目标组不支持直接日志激活和发送到S3的功能。",
      "F": "这是一个最佳选择，因为它涉及创建一个Kinesis Data Firehose传输流，并为其设置CloudWatch Logs订阅过滤器，这是一种高效的日志收集和分析方法。"
    },
    "service": [
      "Amazon ECS",
      "Amazon CloudWatch Logs",
      "AWS Lambda",
      "Amazon S3",
      "Application Load Balancer",
      "Amazon Kinesis Data Firehose"
    ],
    "reason": "4.1"
  },
  {
    "no": 34,
    "question": "一家公司正在使用 AWS CodePipeline 自动化其发布管道。在管道中使用 AWS CodeDeploy 将应用程序部署到 Amazon Elastic Container Service (Amazon ECS) 并使用蓝/绿部署模型。公司希望在转移流量之前实施脚本来测试绿色版本的应用程序。这些脚本将在 5 分钟或更短时间内完成。如果在这些测试中发现错误，应用程序必须回滚。哪种策略能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在 CodePipeline 管道的源和部署阶段之间添加一个阶段。使用 AWS CodeBuild 创建运行时环境，并在 buildspec 文件中构建命令以调用测试脚本。如果发现错误，使用 aws deploy stop-deployment 命令停止部署。",
      "B": "在 CodePipeline 管道的源和部署阶段之间添加一个阶段。使用此阶段调用一个 AWS Lambda 函数来运行测试脚本。如果发现错误，使用 aws deploy stop-deployment 命令停止部署。",
      "C": "在 CodeDeploy AppSpec 文件中添加一个钩子部分。使用 AfterAllowTestTraffic 生命周期事件调用一个 AWS Lambda 函数来运行测试脚本。如果发现错误，退出 Lambda 函数并返回错误以启动回滚。",
      "D": "在 CodeDeploy AppSpec 文件中添加一个钩子部分。使用 AfterAllowTraffic 生命周期事件调用测试脚本。如果发现错误，使用 aws deploy stop-deployment CLI 命令停止部署。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项使用 CodeBuild 在部署之前进行测试，但不符合使用 CodeDeploy 生命周期事件进行测试的最佳实践。",
      "B": "此选项虽然使用 Lambda 进行测试，但在部署之前而不是在允许测试流量后进行，不符合题目要求。",
      "C": "此选项正确使用了 CodeDeploy 的 AfterAllowTestTraffic 生命周期事件来在允许测试流量后进行测试，并在发现错误时通过退出 Lambda 函数来触发回滚，符合题目要求。",
      "D": "此选项虽然在 AfterAllowTraffic 之后调用测试脚本，但这是在流量已经完全转移后，不符合在测试阶段发现错误就回滚的要求。"
    },
    "service": [
      "AWS CodePipeline",
      "AWS CodeDeploy",
      "Amazon ECS",
      "AWS CodeBuild",
      "AWS Lambda"
    ],
    "reason": "1.4"
  },
  {
    "no": 39,
    "question": "一家公司希望使用 AWS CloudFormation 进行基础设施部署。该公司有严格的标签和资源要求，并希望将部署限制在两个区域。开发人员将需要部署同一应用程序的多个版本。哪种解决方案确保资源按照公司政策部署？",
    "choose": 1,
    "options": {
      "A": "创建 AWS Trusted Advisor 检查以查找和纠正未批准的 CloudFormation StackSets。",
      "B": "创建 Cloud Formation 漂移检测操作以查找和纠正未批准的 CloudFormation StackSets。",
      "C": "创建具有批准的 CloudFormation 模板的 CloudFormation StackSets。",
      "D": "创建具有批准的 CloudFormation 模板的 AWS Service Catalog 产品。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然 AWS Trusted Advisor 可以提供有关资源配置的建议，但它不直接管理或强制执行 CloudFormation StackSets 的部署。",
      "B": "CloudFormation 漂移检测操作用于检测现有堆栈与其模板的差异，而不是限制或管理新部署。",
      "C": "虽然使用批准的模板创建 StackSets 是一个好方法，但它不提供对部署过程中使用的模板的集中管理和控制。",
      "D": "AWS Service Catalog 允许组织创建和管理批准的产品目录，这些目录可以包括 CloudFormation 模板，确保部署符合公司政策。这是最佳选择，因为它提供了对使用的模板和部署过程的集中控制。"
    },
    "service": [
      "AWS CloudFormation",
      "AWS Trusted Advisor",
      "AWS Service Catalog"
    ],
    "reason": "2.1"
  },
  {
    "no": 37,
    "question": "一家公司有多个成员账户，这些账户是 AWS Organizations 中的一部分。安全团队需要审查每个 Amazon EC2 安全组及其入站和出站规则。安全团队希望使用组织管理账户中的 AWS Lambda 函数以编程方式从成员账户检索此信息。哪种访问权限更改组合将满足这些要求？（选择三个。）",
    "choose": 3,
    "options": {
      "A": "创建信任关系，允许成员账户中的用户扮演管理账户的 IAM 角色。",
      "B": "创建信任关系，允许管理账户中的用户扮演成员账户的 IAM 角色。",
      "C": "在每个成员账户中创建一个具有 AmazonEC2ReadOnlyAccess 托管策略访问权限的 IAM 角色。",
      "D": "在每个成员账户中创建一个 IAM 角色，允许对管理账户 IAM 角色的 ARN 执行 sts:AssumeRole 操作。",
      "E": "在管理账户中创建一个 IAM 角色，允许对成员账户 IAM 角色的 ARN 执行 sts:AssumeRole 操作。",
      "F": "在管理账户中创建一个具有 AmazonEC2ReadOnlyAccess 托管策略访问权限的 IAM 角色。"
    },
    "best": ["B", "C", "E"],
    "analysis": {
      "A": "这个选项不正确，因为我们需要的是管理账户能够访问成员账户的资源，而不是成员账户访问管理账户的资源。",
      "B": "这个选项是正确的，因为它允许管理账户中的用户扮演成员账户的 IAM 角色，从而访问成员账户的资源。",
      "C": "这个选项是正确的，因为它在每个成员账户中创建了具有只读访问权限的 IAM 角色，这样管理账户扮演的角色就可以访问 EC2 安全组信息。",
      "D": "这个选项不正确，因为它是反向的，我们需要的是管理账户访问成员账户的资源。",
      "E": "这个选项是正确的，因为它允许管理账户的 IAM 角色扮演成员账户的 IAM 角色，从而访问成员账户的资源。",
      "F": "这个选项不正确，因为它只在管理账户中创建了具有只读权限的角色，但没有提供访问成员账户资源的方法。"
    },
    "service": ["AWS Lambda", "Amazon EC2", "IAM", "AWS Organizations"],
    "reason": "2.2"
  },
  {
    "no": 40,
    "question": "一家公司要求其面向内部的 Web 应用程序具有高可用性。架构由一个 Amazon EC2 Web 服务器实例和一个提供出站互联网访问以进行更新和访问公共数据的 NAT 实例组成。公司应实施哪种架构调整组合以实现高可用性？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "将 NAT 实例添加到跨多个可用区的 EC2 自动扩展组中。更新路由表。",
      "B": "创建跨多个可用区的额外 EC2 实例。添加应用程序负载均衡器以分担负载。",
      "C": "在 EC2 实例前配置应用程序负载均衡器。配置 Amazon CloudWatch 警报以在主机故障时恢复 EC2 实例。",
      "D": "用每个可用区的 NAT 网关替换 NAT 实例。更新路由表。",
      "E": "用跨多个可用区的 NAT 网关替换 NAT 实例。更新路由表。"
    },
    "best": ["B", "D"],
    "analysis": {
      "A": "虽然将 NAT 实例添加到自动扩展组可以提高某种程度的可用性，但使用 NAT 网关是更好的选择，因为它是 AWS 托管的服务，提供更高的可用性和可靠性。",
      "B": "这是最佳选项之一，因为创建多个 EC2 实例并使用应用程序负载均衡器可以有效地在多个可用区之间分配流量，从而提高应用程序的可用性。",
      "C": "虽然配置负载均衡器和 CloudWatch 警报可以提高单个实例的可用性，但不如跨多个可用区部署更多实例来得更有效。",
      "D": "这是最佳选项之一，因为使用 NAT 网关替换传统的 NAT 实例可以提高网络的可靠性和可用性，NAT 网关是 AWS 托管的，自动在多个可用区中提供服务。",
      "E": "NAT 网关不支持跨多个可用区的配置，这个选项是错误的描述。"
    },
    "service": [
      "Amazon EC2",
      "NAT Gateway",
      "Application Load Balancer",
      "Amazon CloudWatch",
      "EC2 Auto Scaling"
    ],
    "reason": "3.1"
  },
  {
    "no": 38,
    "question": "一家太空探索公司从多个卫星接收遥测数据。通过 Amazon API Gateway 接收小数据包，并直接放入 Amazon Simple Queue Service (Amazon SQS) 标准队列中。一个自定义应用程序订阅了该队列，并将数据转换为标准格式。由于卫星产生的数据存在不一致性，应用程序有时无法转换数据。在这些情况下，消息仍保留在 SQS 队列中。一名 DevOps 工程师必须开发一个解决方案，保留失败的消息，并使其可供科学家审查和未来处理。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "配置 AWS Lambda 以轮询 SQS 队列并调用 Lambda 函数检查队列消息是否有效。如果验证失败，将无效数据的副本发送到 Amazon S3 存储桶，以便科学家可以审查和纠正数据。数据纠正后，使用带有纠正数据的重放 Lambda 函数修改 SQS 队列中的消息。",
      "B": "将 SQS 标准队列转换为 SQS FIFO 队列。配置 AWS Lambda 每 10 分钟通过 Amazon EventBridge 计划轮询 SQS 队列。调用 Lambda 函数识别任何 SentTimestamp 值超过 5 分钟的消息，将数据推送到与应用程序的输出位置相同的位置，并从队列中删除消息。",
      "C": "创建一个 SQS 死信队列。通过设置 Maximum Receives 设置为 1 并将死信队列 ARN 设置为新创建队列的 ARN，修改现有队列以包括重驱动策略。指导科学家使用死信队列审查无效数据。稍后重新处理这些数据。",
      "D": "配置 API Gateway 将消息发送到为每个卫星命名的不同 SQS 虚拟队列。更新应用程序以使用新的虚拟队列处理无法转换的数据，并将消息发送到新的虚拟队列。指导科学家使用虚拟队列审查无效数据。稍后重新处理这些数据。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然这个选项提供了处理无效数据的方法，但它涉及修改 SQS 队列中的消息，这在实际操作中可能会引入复杂性和潜在的错误。",
      "B": "这个选项通过转换为 FIFO 队列来处理消息，但它不处理无效数据的保留和审查，而是简单地删除了这些消息。",
      "C": "这是最佳选项，因为它通过创建死信队列来处理无法处理的消息，允许这些消息被保留并供科学家审查，同时还可以在未来重新处理。",
      "D": "这个选项通过创建多个虚拟队列来处理数据，增加了系统的复杂性，而且没有明确说明如何处理无效数据的审查和重新处理。"
    },
    "service": [
      "Amazon API Gateway",
      "Amazon Simple Queue Service",
      "AWS Lambda",
      "Amazon S3",
      "Amazon EventBridge"
    ],
    "reason": "2.3"
  },
  {
    "no": 41,
    "question": "一位 DevOps 工程师正在使用 AWS CodePipeline 构建一个多阶段的管道，以构建、验证、分阶段、测试和部署应用程序。在测试阶段和部署阶段之间需要一个手动审批阶段。开发团队使用一个支持 webhook 的自定义聊天工具，该工具需要近实时通知。DevOps 工程师应如何配置管道活动状态更新和审批请求以发布到聊天工具？",
    "choose": 1,
    "options": {
      "A": "创建一个 Amazon CloudWatch Logs 订阅，过滤 CodePipeline 管道执行状态更改。将订阅事件发布到 Amazon Simple Notification Service (Amazon SNS) 主题。将聊天 webhook URL 订阅到 SNS 主题，并完成订阅验证。",
      "B": "创建一个由 AWS CloudTrail 事件触发的 AWS Lambda 函数。当检测到 CodePipeline 管道执行状态更改事件时，将事件详情发送到聊天 webhook URL。",
      "C": "创建一个 Amazon EventBridge 规则，过滤 CodePipeline 管道执行状态更改。将事件发布到 Amazon Simple Notification Service (Amazon SNS) 主题。创建一个 AWS Lambda 函数，将事件详情发送到聊天 webhook URL。将该函数订阅到 SNS 主题。",
      "D": "修改管道代码，以在每个阶段结束时将事件详情发送到聊天 webhook URL。参数化 URL，以便每个管道可以根据管道环境发送到不同的 URL。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它使用 CloudWatch Logs 订阅，这可能不会提供关于管道状态的直接和实时更新。",
      "B": "此选项不是最佳选择，因为它依赖于 CloudTrail，这通常用于审计日志而不是实时通知。",
      "C": "此选项是最佳选择，因为它使用 EventBridge 直接过滤状态更改事件，并通过 Lambda 函数实现灵活的处理逻辑，可以直接将消息发送到 webhook URL。",
      "D": "此选项不是最佳选择，因为直接修改管道代码增加了维护复杂性，并且可能不如使用 AWS 服务灵活。"
    },
    "service": [
      "AWS CodePipeline",
      "Amazon EventBridge",
      "Amazon SNS",
      "AWS Lambda"
    ],
    "reason": "1.1"
  },
  {
    "no": 43,
    "question": "一个 DevOps 团队管理一个在本地运行的 API，该 API 作为 Amazon API Gateway 端点的后端。客户抱怨响应延迟高，开发团队已经使用 Amazon CloudWatch 中的 API Gateway 延迟指标进行了验证。为了确定原因，团队需要在不引入额外延迟的情况下收集相关数据。应采取哪些措施来实现这一目标？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "在服务器端安装 CloudWatch 代理，并配置代理将相关日志上传到 CloudWatch。",
      "B": "在 API Gateway 中启用 AWS X-Ray 跟踪，修改应用程序以捕获请求段，并在每个请求中上传这些段到 X-Ray。",
      "C": "在 API Gateway 中启用 AWS X-Ray 跟踪，修改应用程序以捕获请求段，并使用 X-Ray 守护程序上传段到 X-Ray。",
      "D": "修改本地应用程序，使其在每个请求中将日志信息发送回 API Gateway。",
      "E": "修改本地应用程序，计算并上传与 API 服务请求相关的统计数据到 CloudWatch 指标。"
    },
    "best": ["A", "C"],
    "analysis": {
      "A": "安装 CloudWatch 代理并配置上传日志是一种有效的监控策略，可以在不增加请求处理时间的情况下收集数据。",
      "B": "虽然启用 AWS X-Ray 跟踪并在请求中上传段可以提供详细的调试信息，但这种方法可能会增加请求的处理时间，从而增加延迟。",
      "C": "启用 AWS X-Ray 并使用守护程序异步上传数据是一种有效的方法，可以在不显著增加处理时间的情况下收集详细的性能数据。",
      "D": "将日志信息发送回 API Gateway 可能会增加网络延迟和处理时间，不适合用于解决响应延迟的问题。",
      "E": "虽然上传统计数据到 CloudWatch 可以帮助监控，但这种方法可能会增加处理时间，尤其是如果统计计算复杂的话。"
    },
    "service": ["Amazon API Gateway", "Amazon CloudWatch", "AWS X-Ray"],
    "reason": "4.1"
  },
  {
    "no": 45,
    "question": "一家公司使用 Amazon EC2 实例和 Amazon EBS 存储托管其暂存网站。该公司希望在 EC2 实例发生网络连接问题或电源故障时能够快速恢复并最小化数据损失。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "将实例添加到 EC2 Auto Scaling 组中，并将最小、最大和期望容量设置为 1。",
      "B": "将实例添加到 EC2 Auto Scaling 组，并添加生命周期钩子以在 EC2 实例关闭或终止时分离 EBS 卷。",
      "C": "为 StatusCheckFailed System 指标创建一个 Amazon CloudWatch 警报，并选择 EC2 操作以恢复实例。",
      "D": "为 StatusCheckFailed Instance 指标创建一个 Amazon CloudWatch 警报，并选择 EC2 操作以重启实例。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然 Auto Scaling 组可以帮助实现高可用性，但仅设置容量为 1 并不能在实例故障时快速恢复。",
      "B": "生命周期钩子允许在实例关闭或终止时执行操作，但这主要用于维护状态，而不是快速恢复。",
      "C": "CloudWatch 警报可以监控系统级别的故障，并且可以配置操作来自动恢复实例，这符合快速恢复和最小化数据损失的要求。",
      "D": "重启实例可能会解决一些问题，但不适用于所有故障类型，特别是硬件故障，也不保证数据不丢失。"
    },
    "service": ["Amazon EC2", "Amazon EBS", "Amazon CloudWatch"],
    "reason": "3.3"
  },
  {
    "no": 44,
    "question": "一家公司的应用程序正在使用兼容 MySQL 的 Amazon Aurora 多可用区数据库集群作为数据库。为了灾难恢复目的，已创建了一个跨区域只读副本。一位 DevOps 工程师希望在发生故障时自动提升副本，使其成为主数据库实例。哪种解决方案可以实现这一目标？",
    "choose": 1,
    "options": {
      "A": "配置基于延迟的 Amazon Route 53 CNAME，并带有健康检查，使其指向主数据库和副本端点。订阅一个 Amazon SNS 主题以接收来自 AWS CloudTrail 的 Amazon RDS 故障通知，并使用该主题来调用一个 AWS Lambda 函数，该函数将提升副本实例为主实例。",
      "B": "创建一个 Aurora 自定义端点指向主数据库实例。配置应用程序使用此端点。配置 AWS CloudTrail 运行一个 AWS Lambda 函数来提升副本实例并修改自定义端点指向新提升的实例。",
      "C": "创建一个 AWS Lambda 函数来修改应用程序的 AWS CloudFormation 模板以提升副本，应用模板以更新堆栈，并指向新提升的实例。创建一个 Amazon CloudWatch 警报来在故障事件发生后调用此 Lambda 函数。",
      "D": "将 Aurora 端点存储在 AWS Systems Manager 参数存储中。创建一个 Amazon EventBridge 事件来检测数据库故障并运行一个 AWS Lambda 函数来提升副本实例并更新存储在 AWS Systems Manager 参数存储中的端点 URL。编码应用程序以在数据库连接失败时重新加载端点。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然这个选项使用了 Amazon Route 53 和 SNS 主题来处理故障通知，但它依赖于 DNS 更改来切换流量，这可能会导致延迟和缓存问题。",
      "B": "这个选项使用了自定义端点和 Lambda 函数，但没有提到如何处理故障检测，这可能导致在故障发生时无法及时响应。",
      "C": "这个选项依赖于修改 CloudFormation 模板和使用 CloudWatch 警报，这可能导致在故障恢复时响应不够迅速。",
      "D": "这个选项通过使用 AWS Systems Manager 参数存储和 Amazon EventBridge 来检测故障并自动更新端点，提供了一个快速且可靠的方法来处理故障转移，使其成为最佳选择。"
    },
    "service": [
      "Amazon Aurora",
      "AWS Lambda",
      "AWS Systems Manager",
      "Amazon EventBridge",
      "Amazon SNS",
      "AWS CloudTrail",
      "Amazon Route 53",
      "Amazon CloudWatch",
      "AWS CloudFormation"
    ],
    "reason": "3.3"
  },
  {
    "no": 42,
    "question": "一家公司的应用程序开发团队使用基于 Linux 的 Amazon EC2 实例作为堡垒主机。入站 SSH 访问到堡垒主机被限制为特定 IP 地址，如关联的安全组中定义的那样。公司的安全团队希望在修改安全组规则以允许来自任何 IP 地址的 SSH 访问时收到通知。DevOps 工程师应该做什么来满足这一要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 Amazon EventBridge 规则，源为 aws.cloudtrail 和事件名称 AuthorizeSecurityGroupIngress。定义一个 Amazon Simple Notification Service (Amazon SNS) 主题作为目标。",
      "B": "启用 Amazon GuardDuty 并检查 AWS Security Hub 中的安全组发现。配置一个 Amazon EventBridge 规则，使用自定义模式匹配 GuardDuty 事件，输出为 NON_COMPLIANT。定义一个 Amazon Simple Notification Service (Amazon SNS) 主题作为目标。",
      "C": "使用 restricted-ssh 管理规则创建一个 AWS Config 规则，以检查安全组是否禁止不受限制的入站 SSH 流量。配置自动修正以将消息发布到 Amazon Simple Notification Service (Amazon SNS) 主题。",
      "D": "启用 Amazon Inspector。包括 Common Vulnerabilities and Exposures-1.1 规则包以检查与堡垒主机关联的安全组。配置 Amazon Inspector 以将消息发布到 Amazon Simple Notification Service (Amazon SNS) 主题。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它直接使用 Amazon EventBridge 监控特定的 CloudTrail 事件（AuthorizeSecurityGroupIngress），这个事件会在修改安全组以允许 SSH 访问时触发。然后，它使用 SNS 主题来发送通知。",
      "B": "这个选项不是最佳选择，因为它依赖于 GuardDuty 的发现，这可能不会即时反映安全组规则的更改。",
      "C": "这个选项不是最佳选择，因为它依赖于 AWS Config 来检测配置更改，而不是实时监控特定的安全组规则更改事件。",
      "D": "这个选项不是最佳选择，因为 Amazon Inspector 主要用于应用程序安全性和漏洞扫描，而不是监控安全组规则的更改。"
    },
    "service": [
      "Amazon EventBridge",
      "Amazon SNS",
      "AWS CloudTrail",
      "Amazon GuardDuty",
      "AWS Config",
      "Amazon Inspector"
    ],
    "reason": "6.3"
  },
  {
    "no": 46,
    "question": "一家公司希望使用 AWS 开发工具替换其当前的 bash 部署脚本。该公司目前将 LAMP 应用程序部署到位于应用程序负载均衡器 (ALB) 后面的一组 Amazon EC2 实例。在部署过程中，公司对提交的应用程序进行单元测试，停止和启动服务，注销和重新注册负载均衡器的实例，并更新文件权限。公司希望在转向使用 AWS 服务的过程中保持相同的部署功能。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS CodeBuild 测试应用程序。使用 AWS CodeDeploy 的 appspec.yml 文件调用的 bash 脚本来重启服务，并注销和重新注册 ALB 的实例。使用 appspec.yml 文件更新文件权限，无需自定义脚本。",
      "B": "使用 AWS CodePipeline 将应用程序从 AWS CodeCommit 仓库移动到 AWS CodeDeploy。使用 CodeDeploy 的部署组测试应用程序，注销和重新注册 ALB 的实例并重启服务。使用 appspec.yml 文件更新文件权限，无需自定义脚本。",
      "C": "使用 AWS CodePipeline 将应用程序源代码从 AWS CodeCommit 仓库移动到 AWS CodeDeploy。使用 CodeDeploy 测试应用程序。使用 CodeDeploy 的 appspec.yml 文件重启服务和更新权限，无需自定义脚本。使用 AWS CodeBuild 注销和重新注册 ALB 的实例。",
      "D": "使用 AWS CodePipeline 触发 AWS CodeBuild 测试应用程序。使用 AWS CodeDeploy 的 appspec.yml 文件调用的 bash 脚本来重启服务。在 AWS CodeDeploy 部署组中注销和重新注册 ALB 的实例。更新 appspec.yml 文件以更新文件权限，无需自定义脚本。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然使用了 CodeBuild 和 CodeDeploy，但是没有提到使用 CodePipeline 来整合整个流程，这可能导致部署流程不够自动化和连贯。",
      "B": "此选项使用了 CodePipeline 和 CodeDeploy，但是将测试任务放在了 CodeDeploy 的部署组中，这不是 CodeDeploy 的常规用途，通常 CodeBuild 更适合处理测试任务。",
      "C": "此选项将注销和重新注册 ALB 的实例的任务放在了 CodeBuild 中，这不是 CodeBuild 的主要功能，通常这应该是 CodeDeploy 的一部分。",
      "D": "此选项整合了 CodePipeline、CodeBuild 和 CodeDeploy，合理分配了各自的任务，符合 AWS 推荐的最佳实践，因此是最佳选项。"
    },
    "service": [
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "AWS CodePipeline",
      "AWS CodeCommit",
      "Application Load Balancer"
    ],
    "reason": "1.1"
  },
  {
    "no": 47,
    "question": "一家公司运行一个应用程序，该应用程序采用 Amazon EC2 和本地配置。一名 DevOps 工程师需要在两个环境中标准化打补丁。公司政策规定只能在非营业时间进行打补丁。哪种组合的操作可以满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "将物理机器添加到 AWS Systems Manager 中，使用 Systems Manager Hybrid Activations。",
      "B": "将 IAM 角色附加到 EC2 实例，允许它们由 AWS Systems Manager 管理。",
      "C": "为本地机器创建 IAM 访问密钥以与 AWS Systems Manager 交互。",
      "D": "运行 AWS Systems Manager Automation 文档以每小时打补丁。",
      "E": "使用 Amazon EventBridge 计划事件来安排打补丁窗口。",
      "F": "使用 AWS Systems Manager 维护窗口来安排打补丁窗口。"
    },
    "best": ["A", "B", "F"],
    "analysis": {
      "A": "最优选项。通过使用 Systems Manager Hybrid Activations，可以将本地服务器作为托管实例纳入 AWS Systems Manager，实现跨环境的统一管理和打补丁。",
      "B": "最优选项。通过将 IAM 角色附加到 EC2 实例，可以确保这些实例可以被 AWS Systems Manager 管理，从而实现自动化打补丁。",
      "C": "不是最优选项。通常不推荐为本地机器创建 IAM 访问密钥，因为这可能带来安全风险。更好的做法是使用 Systems Manager Hybrid Activations。",
      "D": "不是最优选项。每小时打补丁可能会违反公司的非营业时间打补丁的政策，并可能导致不必要的中断。",
      "E": "不是最优选项。虽然 Amazon EventBridge 可以用来安排事件，但在这种情况下，使用 AWS Systems Manager 维护窗口更为直接和专门用于打补丁。",
      "F": "最优选项。使用 AWS Systems Manager 维护窗口可以精确地安排在非营业时间进行打补丁，符合公司政策，并且可以跨 Amazon EC2 和本地环境应用。"
    },
    "service": ["AWS Systems Manager", "IAM", "Amazon EventBridge"],
    "reason": "2.3"
  },
  {
    "no": 49,
    "question": "一家总部位于美国的在线零售公司计划在未来六个月内将其业务扩展到欧洲和亚洲。其产品目前运行在应用程序负载均衡器后的 Amazon EC2 实例上。这些实例在多个可用区的 Amazon EC2 自动扩展组中运行。所有数据都存储在 Amazon Aurora 数据库实例中。当产品部署在多个区域时，公司希望在所有区域中使用单一的产品目录，但出于合规性考虑，其客户信息和购买必须保留在每个区域。公司应如何以最少的应用程序更改来满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 Amazon Redshift 作为产品目录和 Amazon DynamoDB 表格存储客户信息和购买。",
      "B": "使用 Amazon DynamoDB 全局表格作为产品目录和区域表格存储客户信息和购买。",
      "C": "使用带有读副本的 Aurora 作为产品目录和每个区域中额外的本地 Aurora 实例存储客户信息和购买。",
      "D": "使用 Aurora 作为产品目录和 Amazon DynamoDB 全局表格存储客户信息和购买。"
    },
    "best": ["C"],
    "analysis": {
      "A": "Redshift是数据仓库解决方案，主要用于分析，不适合作为主要业务数据库，同时需要大量代码改动来迁移从Aurora到Redshift和DynamoDB",
      "B": "需要从关系型数据库Aurora迁移到NoSQL数据库，需要大量应用程序改动来适应不同的数据库模型",
      "C": "Aurora读取副本可以跨区域部署，保证产品目录的全局一致性，在各区域部署独立的Aurora实例处理客户数据，满足数据本地化要求，由于系统已经在使用Aurora，继续使用相同数据库类型需要最少的代码改动",
      "D": "使用DynamoDB全局表存储客户信息违反了数据必须保存在各个区域的要求，同样需要较大的代码改动来适应DynamoDB"
    },
    "service": [
      "Amazon EC2",
      "Application Load Balancer",
      "Amazon EC2 Auto Scaling",
      "Amazon Aurora",
      "Amazon Redshift",
      "Amazon DynamoDB"
    ],
    "reason": "3.1"
  },
  {
    "no": 48,
    "question": "一家公司选择 AWS 托管一个新应用程序。该公司需要实施多账户策略。一位 DevOps 工程师在 AWS Organizations 中创建了一个新的 AWS 账户和一个组织。DevOps 工程师还为组织创建了 OU 结构，并使用 AWS Control Tower 设置了一个登陆区。DevOps 工程师必须实施一个解决方案，该解决方案可以自动为用户通过 AWS Control Tower Account Factory 创建的新账户部署资源。当用户创建新账户时，该解决方案必须应用 AWS CloudFormation 模板和为 OU 或账户定制的 SCP，以自动部署附加到账户的所有资源。所有 OU 都已注册到 AWS Control Tower。哪种解决方案可以以最自动化的方式满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS Service Catalog 与 AWS Control Tower。在 AWS Service Catalog 中创建投资组合和产品。授予精细的权限来配置这些资源。使用 AWS CLI 和 JSON 文档部署 SCP。",
      "B": "使用所需的模板部署 CloudFormation 堆栈集。启用自动部署。将堆栈实例部署到所需账户。将 CloudFormation 堆栈集部署到组织的管理账户以部署 SCP。",
      "C": "创建一个 Amazon EventBridge 规则来检测 CreateManagedAccount 事件。配置 AWS Service Catalog 作为目标，将资源部署到任何新账户。使用 AWS CLI 和 JSON 文档部署 SCP。",
      "D": "部署 AWS Control Tower 的自定义解决方案 (CfCT)。使用 AWS CodeCommit 仓库作为源。在仓库中创建一个包括 CloudFormation 模板和 SCP JSON 文档的自定义包。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然使用 AWS Service Catalog 可以管理产品和服务的目录，但它需要手动创建和管理产品，不是最自动化的解决方案。",
      "B": "虽然 CloudFormation 堆栈集可以跨账户和区域部署资源，但它不提供与 AWS Control Tower 的直接集成，需要额外的步骤来管理 SCP。",
      "C": "使用 EventBridge 规则可以自动检测账户创建事件，但将 AWS Service Catalog 设置为目标并不直接支持与 AWS Control Tower 的集成。",
      "D": "CfCT 提供了一个高度自动化的方法来扩展 AWS Control Tower 的功能，允许通过 CodeCommit 仓库管理 CloudFormation 模板和 SCP，是最符合题目要求的解决方案。"
    },
    "service": [
      "AWS Organizations",
      "AWS Control Tower",
      "AWS CloudFormation",
      "AWS Service Catalog",
      "AWS CLI",
      "Amazon EventBridge",
      "AWS CodeCommit"
    ],
    "reason": "2.2"
  },
  {
    "no": 51,
    "question": "一家快速增长的公司希望为开发人员对 AWS 开发环境的需求进行扩展。开发环境在 AWS 管理控制台中手动创建。网络团队使用 AWS CloudFormation 管理网络基础设施，并导出 Amazon VPC 和所有子网的堆栈输出值。开发环境具有共同的标准，例如应用程序负载均衡器、Amazon EC2 自动扩展组、安全组和 Amazon DynamoDB 表。为了跟上需求，DevOps 工程师希望自动化创建开发环境。由于支持应用程序的基础设施预计将增长，因此必须有一种方法可以轻松更新已部署的基础设施。CloudFormation 将用于为开发环境创建模板。哪种方法可以满足这些要求并快速为开发人员提供一致的 AWS 环境？",
    "choose": 1,
    "options": {
      "A": "在模板的资源部分使用 Fn::ImportValue 内在函数检索虚拟私有云（VPC）和子网值。使用 CloudFormation StackSets 来管理开发环境，使用 Count 输入参数指示所需的环境数量。使用 UpdateStackSet 命令更新现有的开发环境。",
      "B": "使用嵌套堆栈定义常见的基础设施组件。要访问导出的值，请使用 TemplateURL 引用网络团队的模板。要检索虚拟私有云（VPC）和子网值，请在根模板的参数部分使用 Fn::ImportValue 内在函数。使用 CreateChangeSet 和 ExecuteChangeSet 命令更新现有的开发环境。",
      "C": "使用嵌套堆栈定义常见的基础设施组件。在嵌套堆栈的资源中使用 Fn::ImportValue 内在函数检索虚拟私有云（VPC）和子网值。使用 CreateChangeSet 和 ExecuteChangeSet 命令更新现有的开发环境。",
      "D": "在根模板的参数部分使用 Fn::ImportValue 内在函数检索虚拟私有云（VPC）和子网值。按照需要创建的顺序在 CloudFormation 嵌套堆栈中定义开发资源。使用 CreateChangeSet 和 ExecuteChangeSet 命令更新现有的开发环境。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然使用 StackSets 可以管理多个环境，但它不支持在资源部分使用 Fn::ImportValue，这可能导致模板的使用不够灵活。",
      "B": "使用 TemplateURL 引用外部模板是一个好方法，但在根模板的参数部分使用 Fn::ImportValue 可能导致模板的复杂性增加，且不如直接在资源中使用这一函数灵活。",
      "C": "这个选项使用嵌套堆栈来组织资源，使得模板更加模块化和可管理。同时，直接在资源中使用 Fn::ImportValue 使得模板更加直接和高效。使用 CreateChangeSet 和 ExecuteChangeSet 命令可以灵活地更新环境。",
      "D": "虽然这个选项也使用了嵌套堆栈，但在参数部分使用 Fn::ImportValue 可能不如直接在资源中使用这一函数灵活。"
    },
    "service": [
      "AWS CloudFormation",
      "Amazon VPC",
      "Amazon EC2",
      "Application Load Balancers",
      "Amazon DynamoDB"
    ],
    "reason": "2.1"
  },
  {
    "no": 54,
    "question": "一个开发团队使用 AWS CodeCommit 作为应用程序的版本控制。该开发团队使用 AWS CodePipeline、AWS CodeBuild 和 AWS CodeDeploy 进行 CI/CD 基础设施。在 CodeCommit 中，开发团队最近合并了未通过代码库中长时间运行测试的拉取请求。开发团队需要对代码库中的分支进行回滚，导致时间和精力的浪费。一位 DevOps 工程师必须自动化测试 CodeCommit 中的拉取请求，以确保审阅者更容易看到拉取请求审阅中的自动化测试结果。DevOps 工程师应该做什么来满足这一要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 Amazon EventBridge 规则，该规则对 pullRequestStatusChanged 事件做出反应。创建一个 AWS Lambda 函数，该函数调用一个带有 CodeBuild 动作的 CodePipeline 管道来运行应用程序的测试。编程 Lambda 函数在拉取请求上发布 CodeBuild 徽章作为评论，以便开发人员在代码审查中看到徽章。",
      "B": "创建一个 Amazon EventBridge 规则，该规则对 pullRequestCreated 事件做出反应。创建一个 AWS Lambda 函数，该函数调用一个带有 CodeBuild 动作的 CodePipeline 管道来运行应用程序的测试。编程 Lambda 函数在测试结果完成时在拉取请求上发布 CodeBuild 测试结果作为评论。",
      "C": "创建一个 Amazon EventBridge 规则，该规则对 pullRequestCreated 和 pullRequestSourceBranchUpdated 事件做出反应。创建一个 AWS Lambda 函数，该函数调用一个带有 CodeBuild 动作的 CodePipeline 管道来运行应用程序的测试。编程 Lambda 函数在拉取请求上发布 CodeBuild 徽章作为评论，以便开发人员在代码审查中看到徽章。",
      "D": "创建一个 Amazon EventBridge 规则，该规则对 pullRequestStatusChanged 事件做出反应。创建一个 AWS Lambda 函数，该函数调用一个带有 CodeBuild 动作的 CodePipeline 管道来运行应用程序的测试。编程 Lambda 函数在测试结果完成时在拉取请求上发布 CodeBuild 测试结果作为评论。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它仅在 pullRequestStatusChanged 事件发生时触发，这可能不会涵盖所有必要的测试场景。",
      "B": "此选项是最佳选择，因为它在创建拉取请求时立即触发测试，并在测试完成后将结果作为评论发布，这确保了测试的及时性和可见性。",
      "C": "此选项不是最佳选择，尽管它覆盖了创建和更新源分支的事件，但仅发布徽章而不是详细的测试结果，可能不足以提供足够的信息。",
      "D": "此选项不是最佳选择，因为它仅在 pullRequestStatusChanged 事件发生时触发，这可能不会涵盖所有必要的测试场景。"
    },
    "service": [
      "AWS CodeCommit",
      "AWS CodePipeline",
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "Amazon EventBridge",
      "AWS Lambda"
    ],
    "reason": "1.2"
  },
  {
    "no": 50,
    "question": "一家公司正在为其全球可访问的 API 堆栈实施一个结构良好的设计。该设计需要确保北美和欧洲的用户既有高可靠性又有快速的响应时间。API 堆栈包含以下三层：Amazon API Gateway - AWS Lambda - Amazon DynamoDB - 哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "配置 Amazon Route 53 指向北美和欧洲的 API Gateway API，使用健康检查。配置 API 将请求转发到该区域的 Lambda 函数。配置 Lambda 函数以检索和更新同一区域中的 DynamoDB 表中的数据。",
      "B": "配置 Amazon Route 53 指向北美和欧洲的 API Gateway API，使用基于延迟的路由和健康检查。配置 API 将请求转发到该区域的 Lambda 函数。配置 Lambda 函数以检索和更新 DynamoDB 全局表中的数据。",
      "C": "配置 Amazon Route 53 指向北美的 API Gateway，创建一个欧洲的灾难恢复 API，并配置两个 API 将请求转发到该区域的 Lambda 函数。从 DynamoDB 全局表检索数据。部署一个 Lambda 函数每 5 分钟检查北美 API 的健康状况。在出现故障时，更新 Route 53 指向灾难恢复 API。",
      "D": "配置 Amazon Route 53 指向北美的 API Gateway API，使用基于延迟的路由。配置 API 将请求转发到用户最近的区域的 Lambda 函数。配置 Lambda 函数以检索和更新 DynamoDB 表中的数据。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它没有使用 DynamoDB 全局表，这可能导致数据一致性问题和延迟。",
      "B": "这是最佳选项，因为它使用了基于延迟的路由和健康检查，确保用户请求被路由到最近的区域，同时使用 DynamoDB 全局表确保数据的全球一致性和可用性。",
      "C": "此选项不是最佳选择，因为它依赖于单一区域的 API，直到检测到故障才切换到另一个区域，这可能导致服务中断。",
      "D": "此选项不是最佳选择，因为它没有使用 DynamoDB 全局表，这可能导致数据一致性问题和延迟，且只配置了北美的 API Gateway，没有考虑欧洲用户的响应时间。"
    },
    "service": [
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon DynamoDB",
      "Amazon Route 53"
    ],
    "reason": "3.1"
  },
  {
    "no": 53,
    "question": "一家公司正在为多个账户中的所有 Amazon EC2 实例执行漏洞扫描。这些账户位于 AWS Organizations 的一个组织中。每个账户的 VPC 都连接到一个共享的传输网关。VPC 通过一个中心出口 VPC 将流量发送到互联网。该公司在一个委托管理账户中启用了 Amazon Inspector，并已启用对所有成员账户的扫描。一位 DevOps 工程师发现一些 EC2 实例在 Amazon Inspector 的“未扫描”标签页中列出。DevOps 工程师应采取哪些组合措施来解决这个问题？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "验证 AWS Systems Manager Agent 是否已安装并正在 Amazon Inspector 未扫描的 EC2 实例上运行。",
      "B": "将目标 EC2 实例与允许端口 443 上的出站通信到 AWS Systems Manager 服务端点的安全组关联。",
      "C": "授予 DevOps 工程师正在使用的 IAM 角色 inspector:StartAssessmentRun 权限。",
      "D": "为 Amazon Inspector 未扫描的 EC2 实例配置 EC2 Instance Connect。",
      "E": "将目标 EC2 实例与授予与 AWS Systems Manager 通信权限的实例配置文件关联。",
      "F": "创建托管实例激活。使用激活代码和激活 ID 注册 EC2 实例。"
    },
    "best": ["A", "B", "E"],
    "analysis": {
      "A": "这是最优选项之一，因为确保 AWS Systems Manager Agent 正在运行是 Amazon Inspector 能够扫描 EC2 实例的基本要求。",
      "B": "这是最优选项之一，因为安全组需要允许 EC2 实例与 AWS Systems Manager 服务端点的通信，这对于 Amazon Inspector 的功能至关重要。",
      "C": "这不是最优选项，因为这个权限与解决 EC2 实例未被扫描的问题无关。",
      "D": "这不是最优选项，因为 EC2 Instance Connect 主要用于提供通过 SSH 连接到 EC2 实例的能力，与 Amazon Inspector 的扫描功能无关。",
      "E": "这是最优选项之一，因为实例配置文件需要包含与 AWS Systems Manager 通信的权限，这对于 Amazon Inspector 的功能至关重要。",
      "F": "这不是最优选项，因为托管实例激活主要用于在没有直接连接到互联网的情况下管理 EC2 实例，与 Amazon Inspector 的扫描功能无关。"
    },
    "service": [
      "AWS Organizations",
      "Amazon EC2",
      "Amazon Inspector",
      "AWS Systems Manager",
      "EC2 Instance Connect"
    ],
    "reason": "6.3"
  },
  {
    "no": 52,
    "question": "一家公司使用 AWS Organizations 管理多个账户。信息安全政策要求将所有未加密的 Amazon EBS 卷标记为不合规。一名 DevOps 工程师需要自动部署解决方案，并确保始终存在此合规性检查。哪种解决方案能够实现这一目标？",
    "choose": 1,
    "options": {
      "A": "创建一个 AWS CloudFormation 模板，定义一个 AWS Inspector 规则来检查 EBS 加密是否启用。将模板保存到已与公司内所有账户共享的 Amazon S3 存储桶中。更新账户创建脚本，指向 Amazon S3 中的 CloudFormation 模板。",
      "B": "创建一个 AWS Config 组织规则来检查 EBS 加密是否启用，并使用 AWS CLI 部署规则。创建并应用一个 SCP 来禁止在整个组织中停止和删除 AWS Config。",
      "C": "在 Organizations 中创建一个 SCP。设置策略以防止启动没有在 EBS 卷上加密的 Amazon EC2 实例，使用条件表达式。将 SCP 应用于所有 AWS 账户。使用 Amazon Athena 分析 AWS CloudTrail 输出，寻找拒绝 ec2:RunInstances 操作的事件。",
      "D": "从单个受信任账户向所有账户部署一个 IAM 角色。使用 AWS CodePipeline 构建一个管道，其中一个阶段在 AWS Lambda 中承担 IAM 角色，并列出账户中的所有 EBS 卷。将报告发布到 Amazon S3。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然使用 AWS CloudFormation 可以自动化部署，但 AWS Inspector 主要用于安全评估和漏洞扫描，并不直接用于合规性检查。",
      "B": "AWS Config 是用于评估和审核 AWS 资源配置的服务，能够持续监控和记录 AWS 资源配置的变化，以评估这些配置与所需配置之间的合规性。此选项通过创建组织规则来检查 EBS 加密，并使用 SCP 确保 AWS Config 不能被停止或删除，从而确保合规性检查始终有效。",
      "C": "使用 SCP 防止未加密 EBS 卷的 EC2 实例启动是一种预防措施，但它不提供对现有资源的合规性评估或标记。",
      "D": "此选项涉及使用 IAM 角色和 AWS Lambda 来列出 EBS 卷，但它更多是一种手动审查过程，而不是自动的合规性检查解决方案。"
    },
    "service": [
      "AWS Organizations",
      "Amazon EBS",
      "AWS CloudFormation",
      "AWS Inspector",
      "Amazon S3",
      "AWS Config",
      "SCP",
      "IAM",
      "AWS CodePipeline",
      "AWS Lambda",
      "Amazon Athena",
      "AWS CloudTrail"
    ],
    "reason": "2.2"
  },
  {
    "no": 57,
    "question": "一家公司在一个 AWS 区域托管一个 Web 应用程序。为了灾难恢复目的，使用第二个区域作为备用。灾难恢复要求规定，会话数据必须在接近实时的情况下在区域之间复制，1% 的请求应路由到辅助区域以持续验证系统功能。此外，如果主区域服务中断，流量应自动路由到辅助区域，并且辅助区域必须能够扩展以处理所有流量。DevOps 工程师应如何满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在两个区域中，都在 AWS Elastic Beanstalk 上部署应用程序，并使用 Amazon DynamoDB 全局表进行会话数据。使用带有健康检查的 Amazon Route 53 加权路由策略来分配跨区域的流量。",
      "B": "在两个区域中，都在自动扩展组中启动应用程序，并使用 DynamoDB 进行会话数据。使用带有健康检查的 Route 53 故障转移路由策略来分配跨区域的流量。",
      "C": "在两个区域中，都在 AWS Lambda 中部署应用程序，由 Amazon API Gateway 暴露，并使用带有跨区域复制的 Amazon RDS for PostgreSQL 进行会话数据。使用客户端逻辑部署 Web 应用程序以直接调用 API Gateway。",
      "D": "在两个区域中，都在自动扩展组中启动应用程序，并使用 DynamoDB 全球表进行会话数据。启用跨区域的 Amazon CloudFront 加权分配。将 Amazon Route 53 DNS 记录指向 CloudFront 分配。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用了 Amazon DynamoDB 全局表来实现会话数据的实时复制，并通过 Amazon Route 53 加权路由策略实现了流量的自动分配和健康检查，满足了灾难恢复的要求。",
      "B": "此选项不是最佳选择，因为它没有使用 DynamoDB 全局表，这可能导致会话数据复制延迟。",
      "C": "此选项不是最佳选择，因为它使用了 RDS for PostgreSQL 而不是 DynamoDB 全局表，这可能导致数据复制延迟，并且 API Gateway 的直接调用可能不如 Route 53 的自动路由灵活。",
      "D": "此选项不是最佳选择，因为虽然使用了 DynamoDB 全局表，但是通过 CloudFront 进行流量分配可能不如 Route 53 直接进行健康检查和流量分配灵活和及时。"
    },
    "service": [
      "AWS Elastic Beanstalk",
      "Amazon DynamoDB",
      "Amazon Route 53",
      "Auto Scaling",
      "AWS Lambda",
      "Amazon API Gateway",
      "Amazon RDS",
      "Amazon CloudFront"
    ],
    "reason": "3.3"
  },
  {
    "no": 56,
    "question": "一位 DevOps 工程师使用 AWS CodePipeline 自动化了一个 Web 服务的部署，步骤如下：1. 一个 AWS CodeBuild 项目编译部署构件并运行单元测试。2. 一个 AWS CodeDeploy 部署组将 Web 服务部署到暂存环境中的 Amazon EC2 实例。3. 一个 CodeDeploy 部署组将 Web 服务部署到生产环境中的 EC2 实例。质量保证 (QA) 团队要求在生产环境部署发生之前检查构建构件。QA 团队希望运行一个内部渗透测试工具进行手动测试。该工具将通过 REST API 调用来调用。DevOps 工程师应采取哪些组合措施来满足这一要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "在测试操作和部署操作的管道之间插入一个手动审批操作。",
      "B": "修改编译阶段的 buildspec.yml 文件，要求在完成前进行手动审批。",
      "C": "更新 CodeDeploy 部署组，使其需要手动审批才能继续。",
      "D": "更新管道以直接调用渗透测试工具的 REST API。",
      "E": "更新管道以调用一个 AWS Lambda 函数，该函数调用渗透测试工具的 REST API。"
    },
    "best": ["A", "E"],
    "analysis": {
      "A": "这是最佳选项之一，因为它允许 QA 团队在生产部署之前手动审查和批准构件。",
      "B": "这不是最佳选项，因为它涉及到修改构建规范，可能会影响构建过程的自动化和效率。",
      "C": "这不是最佳选项，因为虽然它提供了审批机制，但不涉及到 QA 团队对构件的检查或渗透测试。",
      "D": "这不是最佳选项，因为直接调用 API 可能会绕过 QA 团队的审查过程。",
      "E": "这是最佳选项之一，因为它通过 Lambda 函数提供了一个灵活的方式来调用渗透测试工具，同时保持了管道的自动化和控制。"
    },
    "service": [
      "AWS CodePipeline",
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "AWS Lambda"
    ],
    "reason": "1.1"
  },
  {
    "no": 59,
    "question": "一位 DevOps 工程师管理一个在 Application Load Balancer (ALB) 后面运行的 Amazon EC2 实例上的 Web 应用程序。这些实例在多个可用区的 EC2 Auto Scaling 组中运行。工程师需要实施一种部署策略，该策略：启动具有与原始舰队相同容量的第二舰队。在启动第二舰队时保持原始舰队不变。当第二舰队完全部署后，将流量转移到第二舰队。在过渡后自动终止原始舰队 1 小时。",
    "choose": 1,
    "options": {
      "A": "使用带有 ALB 保留策略设置为 1 小时的 AWS CloudFormation 模板。更新 Amazon Route 53 记录以反映新的 ALB。",
      "B": "使用两个 AWS Elastic Beanstalk 环境来执行从原始环境到新环境的蓝/绿部署。创建一个应用程序版本生命周期策略，在 1 小时后终止原始环境。",
      "C": "使用 AWS CodeDeploy，配置一个部署组，其中配置了蓝/绿部署配置。选择选项在部署组中终止原始实例，并等待 1 小时。",
      "D": "使用配置设置为 Immutable 的 AWS Elastic Beanstalk。创建一个使用 Resources 键的 .ebextension，将 ALB 的删除策略设置为 1 小时，并部署应用程序。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然 CloudFormation 可以管理资源，但它不支持直接的蓝/绿部署和流量转移。",
      "B": "Elastic Beanstalk 支持蓝/绿部署，但它的生命周期策略不适用于自动在特定时间后终止原始环境。",
      "C": "CodeDeploy 支持蓝/绿部署，并允许配置在部署成功后自动终止原始实例的等待时间，满足题目要求。",
      "D": "Immutable 配置确保部署的原子性，但不支持自动终止原始实例，且 .ebextension 的资源管理不适用于此场景。"
    },
    "service": [
      "AWS CodeDeploy",
      "AWS CloudFormation",
      "AWS Elastic Beanstalk",
      "Amazon Route 53",
      "Application Load Balancer"
    ],
    "reason": "1.4"
  },
  {
    "no": 60,
    "question": "一家视频分享公司将其视频存储在 Amazon S3 中。该公司观察到视频访问请求突然增加，但不知道哪些视频最受欢迎。公司需要识别视频文件的一般访问模式。这种模式包括在特定日子访问某个文件的用户数量，以及对某些文件的拉取请求数量。公司如何以最少的努力满足这些要求？",
    "choose": 1,
    "options": {
      "A": "激活 S3 服务器访问日志记录。将访问日志导入 Amazon Aurora 数据库。使用 Aurora SQL 查询来分析访问模式。",
      "B": "激活 S3 服务器访问日志记录。使用 Amazon Athena 创建一个外部表来存储日志文件。使用 Athena 创建 SQL 查询来分析访问模式。",
      "C": "对每个 S3 对象访问事件调用一个 AWS Lambda 函数。配置 Lambda 函数以将文件访问信息（如用户、S3 存储桶和文件键）写入 Amazon Aurora 数据库。使用 Aurora SQL 查询来分析访问模式。",
      "D": "对每个 S3 对象访问事件记录一个 Amazon CloudWatch Logs 日志消息。配置 CloudWatch Logs 日志流将文件访问信息（如用户、S3 存储桶和文件键）写入 Amazon Kinesis Data Analytics for SQL 应用程序。执行滑动窗口分析。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然这个选项可以分析访问模式，但是将日志导入 Aurora 并使用 SQL 查询会涉及更多的设置和维护工作。",
      "B": "这是最优选项，因为使用 Athena 分析 S3 访问日志可以直接在 S3 上进行，无需额外的数据导入或数据库维护，简化了过程。",
      "C": "这个选项涉及为每个访问事件调用 Lambda 函数，并将数据写入 Aurora，这会产生额外的成本和复杂性。",
      "D": "虽然使用 CloudWatch 和 Kinesis Data Analytics 可以实现功能，但这种方法比直接使用 Athena 更复杂，且可能成本更高。"
    },
    "service": [
      "Amazon S3",
      "Amazon Athena",
      "Amazon Aurora",
      "AWS Lambda",
      "Amazon CloudWatch Logs",
      "Amazon Kinesis Data Analytics"
    ],
    "reason": "4.1"
  },
  {
    "no": 61,
    "question": "一个开发团队希望使用 AWS CloudFormation 堆栈来部署应用程序。然而，开发者 IAM 角色没有权限来配置 AWS CloudFormation 模板中指定的资源。一位 DevOps 工程师需要实施一个解决方案，允许开发者部署堆栈。该解决方案必须遵循最小权限原则。哪个解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 IAM 策略，允许开发者配置所需资源。将该策略附加到开发者 IAM 角色。",
      "B": "创建一个 IAM 策略，允许对 AWS CloudFormation 的完全访问。将该策略附加到开发者 IAM 角色。",
      "C": "创建一个具有所需权限的 AWS CloudFormation 服务角色。授予开发者 IAM 角色 cloudformation:* 操作。在堆栈部署期间使用新的服务角色。",
      "D": "创建一个具有所需权限的 AWS CloudFormation 服务角色。授予开发者 IAM 角色 iam:PassRole 权限。在堆栈部署期间使用新的服务角色。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然这个选项允许开发者直接配置所需资源，但它可能违反了最小权限原则，因为它可能授予比必需更多的权限。",
      "B": "这个选项提供了对 AWS CloudFormation 的完全访问权限，明显违反了最小权限原则。",
      "C": "这个选项虽然使用了服务角色，但授予了开发者角色过宽泛的 cloudformation:* 权限，这可能不符合最小权限原则。",
      "D": "这个选项创建了一个服务角色并仅授予开发者角色 iam:PassRole 权限，这允许开发者仅将服务角色传递给 CloudFormation，符合最小权限原则。"
    },
    "service": ["AWS CloudFormation", "IAM"],
    "reason": "2.1"
  },
  {
    "no": 62,
    "question": "生产账户有一个要求，任何手动登录的 Amazon EC2 实例必须在 24 小时内终止。生产账户中的所有应用程序都使用带有 Amazon CloudWatch Logs 代理配置的自动扩展组。如何自动化此过程？",
    "choose": 1,
    "options": {
      "A": "创建一个 CloudWatch Logs 订阅到一个 AWS Step Functions 应用程序。配置一个 AWS Lambda 函数为产生登录事件的 EC2 实例添加标签，并标记该实例为待废弃。创建一个 Amazon EventBridge 规则，每天调用第二个 Lambda 函数，该函数将终止所有带有此标签的实例。",
      "B": "创建一个由登录事件触发的 Amazon CloudWatch 警报。将通知发送到运维团队订阅的 Amazon Simple Notification Service (Amazon SNS) 主题，并让他们在 24 小时内终止 EC2 实例。",
      "C": "创建一个由登录事件触发的 Amazon CloudWatch 警报。配置警报发送到一个 Amazon Simple Queue Service (Amazon SQS) 队列。使用一组工作实例处理队列中的消息，然后安排一个 Amazon EventBridge 规则被调用。",
      "D": "创建一个 CloudWatch Logs 订阅到一个 AWS Lambda 函数。配置该函数为产生登录事件的 EC2 实例添加标签，并标记该实例为待废弃。创建一个 Amazon EventBridge 规则，每天调用一个 Lambda 函数，该函数将终止所有带有此标签的实例。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然这个选项使用了 AWS Step Functions，但它增加了复杂性，因为 Lambda 函数已足够处理这种情况。",
      "B": "这个选项依赖于人工操作，不符合自动化的要求。",
      "C": "这个选项过于复杂，使用了额外的队列和工作实例，而不是直接使用 Lambda 函数。",
      "D": "这是最优选项，因为它直接使用 Lambda 函数和 EventBridge 规则来自动处理 EC2 实例的终止，满足题目要求的自动化和效率。"
    },
    "service": ["AWS Lambda", "Amazon EventBridge", "Amazon CloudWatch Logs"],
    "reason": "2.3"
  },
  {
    "no": 58,
    "question": "一家公司在 Amazon EC2 实例上运行一个应用程序。该公司使用一系列 AWS CloudFormation 堆栈来定义应用程序资源。开发人员通过在笔记本电脑上构建和测试应用程序，然后将构建输出和 CloudFormation 堆栈模板上传到 Amazon S3 来执行更新。开发人员的同事在开发人员执行 CloudFormation 堆栈更新并将新版本的应用程序安装到 EC2 实例上之前审查更改。部署过程容易出错，当开发人员更新每个 EC2 实例上的新应用程序时，耗时较长。公司希望尽可能自动化应用程序部署过程，同时保留在修改应用程序或资源之前的最终手动审批步骤。公司已将应用程序的源代码和 CloudFormation 模板移至 AWS CodeCommit。公司还创建了一个 AWS CodeBuild 项目来构建和测试应用程序。哪两个步骤的组合将满足公司的要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "在 AWS CodeDeploy 中创建应用程序组和部署组。在 EC2 实例上安装 CodeDeploy 代理。",
      "B": "在 AWS CodeDeploy 中创建应用程序修订版和部署组。在 CodeDeploy 中创建环境。将 EC2 实例注册到 CodeDeploy 环境。",
      "C": "使用 AWS CodePipeline 调用 CodeBuild 作业，运行 CloudFormation 更新，并暂停以进行手动审批步骤。审批后，启动 AWS CodeDeploy 部署。",
      "D": "使用 AWS CodePipeline 调用 CodeBuild 作业，为每个应用程序堆栈创建 CloudFormation 更改集，并暂停以进行手动审批步骤。审批后，运行 CloudFormation 更改集并启动 AWS CodeDeploy 部署。",
      "E": "使用 AWS CodePipeline 调用 CodeBuild 作业，为每个应用程序堆栈创建 CloudFormation 更改集，并暂停以进行手动审批步骤。审批后，启动 AWS CodeDeploy 部署。"
    },
    "best": ["D", "E"],
    "analysis": {
      "A": "此选项提供了在 CodeDeploy 中创建应用程序组和部署组的步骤，以及在 EC2 实例上安装 CodeDeploy 代理的步骤。虽然这是自动化部署的一部分，但它没有涵盖使用 CodePipeline 来集成和自动化整个流程。",
      "B": "此选项提到了在 CodeDeploy 中创建环境并注册 EC2 实例，但这不是 AWS CodeDeploy 的标准用法，因此可能会引起混淆。",
      "C": "此选项包括使用 CodePipeline 调用 CodeBuild 和运行 CloudFormation 更新，但没有提到创建 CloudFormation 更改集，这是最佳实践，以确保更新可以在执行前进行审查。",
      "D": "此选项完整地描述了使用 CodePipeline 来自动化构建、审批和部署过程，包括创建 CloudFormation 更改集和在审批后执行这些更改集以及启动 CodeDeploy 部署的步骤。",
      "E": "此选项与选项 D 类似，但在审批后直接启动 CodeDeploy 部署，没有明确执行更改集。这可能是一个更简化的流程，但在某些情况下可能需要执行更改集以确保更精确的控制。"
    },
    "service": [
      "AWS CodeCommit",
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "AWS CodePipeline",
      "Amazon S3",
      "Amazon EC2",
      "AWS CloudFormation"
    ],
    "reason": "1.1"
  },
  {
    "no": 55,
    "question": "一家公司在单个 AWS 账户的生产 VPC 中部署了一个应用程序。该应用程序很受欢迎，正经历着高强度的使用。公司的安全团队希望为应用程序部署添加额外的安全措施，例如 AWS WAF。然而，应用程序的产品经理担心成本，除非安全团队能证明需要额外的安全措施，否则不愿意批准更改。安全团队认为应用程序的一些需求可能来自于那些 IP 地址在拒绝列表上的用户。安全团队向一名 DevOps 工程师提供了拒绝列表。如果拒绝列表上的任何 IP 地址访问了应用程序，安全团队希望接收到近乎实时的自动通知，以便可以记录应用程序需要额外安全措施的证据。DevOps 工程师为生产 VPC 创建了一个 VPC 流日志。DevOps 工程师应采取哪些额外步骤，以最具成本效益的方式满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在 Amazon CloudWatch Logs 中创建一个日志组。配置 VPC 流日志以捕获接受的流量，并将数据发送到日志组。为拒绝列表上的 IP 地址创建一个 Amazon CloudWatch 指标过滤器。创建一个带有指标过滤器输入的 CloudWatch 警报。设置周期为 5 分钟，报警数据点为 1。使用 Amazon Simple Notification Service (Amazon SNS) 主题向安全团队发送警报通知。",
      "B": "创建一个 Amazon S3 存储桶用于日志文件。配置 VPC 流日志以捕获所有流量，并将数据发送到 S3 存储桶。配置 Amazon Athena 以返回 S3 存储桶中的所有日志文件，用于拒绝列表上的 IP 地址。配置 Amazon QuickSight 以接受来自 Athena 的数据，并将数据发布为安全团队可以访问的仪表板。创建成功访问的阈值警报 1。配置警报以尽可能频繁地在达到警报阈值时自动通知安全团队。",
      "C": "创建一个 Amazon S3 存储桶用于日志文件。配置 VPC 流日志以捕获接受的流量，并将数据发送到 S3 存储桶。配置一个 Amazon OpenSearch Service 集群和域用于日志文件。创建一个 AWS Lambda 函数来检索来自 S3 存储桶的日志，格式化日志，并将日志加载到 OpenSearch Service 集群中。每 5 分钟调度一次 Lambda 函数运行。配置 OpenSearch Service 中的警报和条件，以在检测到来自拒绝列表 IP 地址的访问时通过 Amazon Simple Notification Service (Amazon SNS) 主题向安全团队发送警报。",
      "D": "在 Amazon CloudWatch Logs 中创建一个日志组。创建一个 Amazon S3 存储桶以保存查询结果。配置 VPC 流日志以捕获所有流量，并将数据发送到日志组。在 AWS Lambda 中部署一个 Amazon Athena CloudWatch 连接器。将连接器连接到日志组。配置 Athena 定期查询来自拒绝列表 IP 地址的所有接受流量，并将结果存储在 S3 存储桶中。配置 S3 事件通知以在向 S3 存储桶添加新对象时自动通知安全团队通过 Amazon Simple Notification Service (Amazon SNS) 主题。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用 CloudWatch Logs 和 SNS 实现了成本效率高且实时的监控和通知系统。它直接利用了 CloudWatch 的指标过滤和警报功能，避免了额外的数据处理和存储成本。",
      "B": "此选项涉及使用 Athena 和 QuickSight，这可能导致更高的成本和复杂性，因为需要处理和可视化大量数据。",
      "C": "此选项涉及使用 OpenSearch Service 和 Lambda，这可能导致更高的成本和复杂性，因为需要额外的设置和维护。",
      "D": "此选项涉及使用 Athena 和 S3，以及额外的 Lambda 连接器，这可能导致更高的成本和复杂性，因为需要定期查询和存储大量数据。"
    },
    "service": [
      "Amazon CloudWatch Logs",
      "Amazon SNS",
      "Amazon Athena",
      "Amazon QuickSight",
      "Amazon OpenSearch Service",
      "AWS Lambda",
      "Amazon S3"
    ],
    "reason": "4.1"
  },
  {
    "no": 63,
    "question": "一家公司已为其组织在 AWS Organizations 中启用了所有功能。该组织包含 10 个 AWS 账户。公司已在所有账户中启用 AWS CloudTrail。公司预计在未来一年内组织中的 AWS 账户数量将增加到 500 个。公司计划为这些账户使用多个 OU。公司已在组织中的每个现有 AWS 账户中启用 AWS Config。一位 DevOps 工程师必须实施一种解决方案，以便自动为组织中创建的所有未来 AWS 账户启用 AWS Config。哪种解决方案能满足这一要求？",
    "choose": 1,
    "options": {
      "A": "在组织的管理账户中，创建一个 Amazon EventBridge 规则，该规则对 CreateAccount API 调用做出反应。配置规则以调用一个 AWS Lambda 函数，该函数为组织启用对 AWS Config 的受信任访问。",
      "B": "在组织的管理账户中，创建一个 AWS CloudFormation 堆栈集以启用 AWS Config。配置堆栈集在通过组织创建账户时自动部署。",
      "C": "在组织的管理账户中，创建一个 SCP，允许适当的 AWS Config API 调用以启用 AWS Config。将 SCP 应用于根级 OU。",
      "D": "在组织的管理账户中，创建一个 Amazon EventBridge 规则，该规则对 CreateAccount API 调用做出反应。配置规则以调用一个 AWS Systems Manager Automation 运行簿以启用该账户的 AWS Config。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然使用 Lambda 函数可以实现自动化，但这需要编写和维护额外的代码来管理 AWS Config 的启用，这增加了复杂性。",
      "B": "使用 AWS CloudFormation 堆栈集可以直接在新账户创建时自动部署 AWS Config，无需额外的编程，是一种简单且直接的解决方案。",
      "C": "SCP 可以限制或允许 API 调用，但它本身不会自动启用服务，需要额外的自动化步骤。",
      "D": "使用 AWS Systems Manager Automation 运行簿是一个可行的方法，但相比于 CloudFormation 堆栈集，它通常用于更复杂的任务和操作自动化，对于这种基础配置来说可能过于复杂。"
    },
    "service": [
      "AWS Organizations",
      "AWS CloudTrail",
      "AWS Config",
      "Amazon EventBridge",
      "AWS Lambda",
      "AWS CloudFormation",
      "AWS Systems Manager"
    ],
    "reason": "2.2"
  },
  {
    "no": 65,
    "question": "一家公司的应用程序目前部署在单一 AWS 区域。最近，该公司在另一个大陆开设了新办公室。新办公室的用户经历了高延迟。公司的应用程序在 Application Load Balancer (ALB) 后面运行在 Amazon EC2 实例上，并使用 Amazon DynamoDB 作为数据库层。实例在多个可用区的 EC2 Auto Scaling 组中运行。一名 DevOps 工程师负责最小化应用程序响应时间并提高两个区域用户的可用性。应采取哪种组合的行动来解决延迟问题？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "在新区域创建一个新的 DynamoDB 表，并启用跨区域复制。",
      "B": "创建新的 ALB 和 Auto Scaling 组全局资源，并配置新的 ALB 将流量引导到新的 Auto Scaling 组。",
      "C": "在新区域创建新的 ALB 和 Auto Scaling 组资源，并配置新的 ALB 将流量引导到新的 Auto Scaling 组。",
      "D": "创建 Amazon Route 53 记录、健康检查和基于延迟的路由策略以路由到 ALB。",
      "E": "创建 Amazon Route 53 别名、健康检查和故障转移路由策略以路由到 ALB。",
      "F": "将 DynamoDB 表转换为全局表。"
    },
    "best": ["C", "D", "F"],
    "analysis": {
      "A": "虽然创建新区域的 DynamoDB 表并启用跨区域复制可以提高数据访问速度，但转换现有表为全局表（选项 F）更为直接且易于管理。",
      "B": "创建全局资源并不是最佳实践，因为 ALB 和 Auto Scaling 组应该在特定区域内配置以最大化性能和响应。",
      "C": "在新区域创建新的 ALB 和 Auto Scaling 组资源，并正确配置 ALB 可以有效减少延迟，确保新办公室用户的快速访问。",
      "D": "使用 Amazon Route 53 的基于延迟的路由策略可以智能地将用户请求路由到响应最快的区域，从而减少延迟。",
      "E": "故障转移路由策略主要用于提供高可用性而非优化延迟。",
      "F": "将 DynamoDB 表转换为全局表可以实现数据的自动复制到多个区域，从而减少数据访问延迟，是解决方案的关键部分。"
    },
    "service": [
      "Amazon EC2",
      "Application Load Balancer",
      "Amazon DynamoDB",
      "EC2 Auto Scaling",
      "Amazon Route 53"
    ],
    "reason": "3.1"
  },
  {
    "no": 64,
    "question": "一家公司拥有许多应用程序。公司不同的团队使用多种语言和框架开发了这些应用程序。这些应用程序在本地和不同的服务器上运行，这些服务器具有不同的操作系统。每个团队都有自己的发布协议和流程。公司希望减少这些应用程序的发布和维护的复杂性。公司正在将其技术栈迁移到 AWS，包括这些应用程序。公司希望集中控制源代码，实现一致和自动的交付管道，并尽可能少地维护底层基础设施。DevOps工程师应该做什么来满足这些要求？",
    "choose": 1,
    "options": {
      "A": "为所有应用程序创建一个AWS CodeCommit仓库。将每个应用程序的代码放在不同的分支中。合并这些分支，并使用AWS CodeBuild来构建应用程序。使用AWS CodeDeploy将应用程序部署到一个集中的应用服务器上。",
      "B": "为每个应用程序创建一个AWS CodeCommit仓库。使用AWS CodeBuild逐个构建应用程序。使用AWS CodeDeploy将应用程序部署到一个集中的应用服务器上。",
      "C": "为每个应用程序创建一个AWS CodeCommit仓库。使用AWS CodeBuild逐个构建应用程序并为每个服务器创建一个AMI。使用AWS CloudFormation StackSets自动配置和解除配置Amazon EC2机群，使用这些AMI。",
      "D": "为每个应用程序创建一个AWS CodeCommit仓库。使用AWS CodeBuild为每个应用程序在Amazon Elastic Container Registry（Amazon ECR）中构建一个Docker镜像。使用AWS CodeDeploy将应用程序部署到AWS Fargate管理的基础设施上的Amazon Elastic Container Service（Amazon ECS）。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它使用单一的应用服务器，这可能导致单点故障，并且不利于实现高可用性和可扩展性。",
      "B": "此选项不是最佳选择，因为虽然它为每个应用程序使用单独的仓库，但仍然使用单一的应用服务器，这限制了应用程序的可扩展性和高可用性。",
      "C": "此选项不是最佳选择，因为它涉及创建AMI和管理EC2机群，这增加了维护的复杂性，尽管使用了自动化工具。",
      "D": "此选项是最佳选择，因为它使用容器化和无服务器架构，这有助于简化部署和扩展，同时减少对底层基础设施的维护需求。"
    },
    "service": [
      "AWS CodeCommit",
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "Amazon Elastic Container Registry",
      "Amazon Elastic Container Service",
      "AWS Fargate"
    ],
    "reason": "1.4"
  },
  {
    "no": 66,
    "question": "一位 DevOps 工程师需要将一组核心安全控制应用于一组现有的 AWS 账户。这些账户位于 AWS Organizations 的一个组织中。各个团队将使用 AdministratorAccess AWS 管理策略管理各自的账户。对于所有账户，必须在所有可用的 AWS 区域中启用 AWS CloudTrail 和 AWS Config。各个账户管理员不得编辑或删除任何基线资源。然而，各个账户管理员必须能够编辑或删除他们自己的 CloudTrail 跟踪和 AWS Config 规则。哪种解决方案以最高的操作效率满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 AWS CloudFormation 模板，定义标准账户资源。使用 CloudFormation StackSets 从组织的管理账户将模板部署到所有账户。设置堆栈策略以拒绝 Update:Delete 操作。",
      "B": "启用 AWS Control Tower。将现有账户注册到 AWS Control Tower。授予各个账户管理员访问 CloudTrail 和 AWS Config 的权限。",
      "C": "指定一个 AWS Config 管理账户。使用 AWS CloudFormation StackSets 在所有账户中创建 AWS Config 记录器。使用 AWS Config 管理账户将 AWS Config 规则部署到组织。在组织的管理账户中创建一个 CloudTrail 组织跟踪。使用 SCP 拒绝修改或删除 AWS Config 记录器。",
      "D": "创建一个 AWS CloudFormation 模板，定义标准账户资源。使用 Cloud Formation StackSets 从组织的管理账户将模板部署到所有账户。创建一个 SCP 防止更新或删除 CloudTrail 资源或 AWS Config 资源，除非该主体是组织管理账户的管理员。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然这个选项使用了 CloudFormation StackSets 来部署资源，但它没有提供对 CloudTrail 和 AWS Config 的特定管理，也没有提到如何允许账户管理员管理自己的资源。",
      "B": "这个选项启用了 AWS Control Tower 并允许管理员访问 CloudTrail 和 AWS Config，但没有明确阻止管理员修改基线安全控制。",
      "C": "这个选项通过在所有账户中使用 CloudFormation StackSets 创建 AWS Config 记录器，并在组织的管理账户中创建 CloudTrail 组织跟踪，同时使用 SCP 策略阻止修改或删除基线配置，满足了题目的所有要求。",
      "D": "这个选项虽然提到了使用 SCP 防止对 CloudTrail 和 AWS Config 资源的修改，但没有明确允许账户管理员编辑或删除他们自己的资源。"
    },
    "service": [
      "AWS CloudFormation",
      "AWS Config",
      "AWS CloudTrail",
      "AWS Organizations",
      "SCP"
    ],
    "reason": "2.2"
  },
  {
    "no": 68,
    "question": "一家公司希望将其托管在 Amazon EC2 上的内容共享 Web 应用迁移到无服务器架构。该公司目前通过创建新的 Auto Scaling 组和新的 Elastic Load Balancer 来部署对其应用的更改，然后使用 Amazon Route 53 加权路由策略将流量转移。对于其新的无服务器应用，该公司计划使用 Amazon API Gateway 和 AWS Lambda。该公司将需要更新其部署流程以适应新应用。它还需要保留在将新功能推广到整个用户群之前，先在少数用户上测试新功能的能力。哪种部署策略能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS CDK 部署 API Gateway 和 Lambda 函数。当代码需要更改时，更新 AWS CloudFormation 堆栈并部署 API 和 Lambda 函数的新版本。使用 Route 53 故障转移路由策略进行金丝雀发布策略。",
      "B": "使用 AWS CloudFormation 部署 API Gateway 和 Lambda 函数，使用 Lambda 函数版本。当代码需要更改时，更新 CloudFormation 堆栈以及新的 Lambda 代码，并使用金丝雀发布策略更新 API 版本。测试完成后推广新版本。",
      "C": "使用 AWS Elastic Beanstalk 部署 API Gateway 和 Lambda 函数。当代码需要更改时，部署 API 和 Lambda 函数的新版本。使用 Elastic Beanstalk 蓝/绿部署逐渐转移流量。",
      "D": "使用 AWS OpsWorks 部署 API Gateway 在服务层和 Lambda 函数在自定义层。当代码需要更改时，使用 OpsWorks 进行蓝/绿部署并逐渐转移流量。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然使用 AWS CDK 和 CloudFormation 可以有效部署和管理 API Gateway 和 Lambda 函数，但 Route 53 故障转移路由策略主要用于故障恢复而不是功能发布，因此不适合作为金丝雀发布策略。",
      "B": "这是最佳选项，因为它使用 AWS CloudFormation 和 Lambda 函数版本来管理部署，并且明确提到了使用金丝雀发布策略，这可以满足在全面部署前对新功能进行小规模测试的需求。",
      "C": "虽然 Elastic Beanstalk 支持蓝/绿部署，但它主要用于传统的服务器或容器化应用，对于无服务器架构如 Lambda 和 API Gateway 的管理不如 CloudFormation 直接和灵活。",
      "D": "OpsWorks 提供了蓝/绿部署能力，但它更适用于管理复杂的应用堆栈和自定义层，对于简单的无服务器应用部署来说可能过于复杂，且没有提到金丝雀发布策略。"
    },
    "service": [
      "AWS CloudFormation",
      "AWS Lambda",
      "Amazon API Gateway",
      "Amazon Route 53",
      "AWS Elastic Beanstalk",
      "AWS OpsWorks",
      "AWS CDK"
    ],
    "reason": "1.4"
  },
  {
    "no": 72,
    "question": "一家公司希望建立一个持续交付管道。该公司在私有 GitHub 仓库中存储应用程序代码。公司需要将应用程序组件部署到 Amazon Elastic Container Service (Amazon ECS)、Amazon EC2 和 AWS Lambda。管道必须支持手动批准操作。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS CodePipeline，将 Amazon ECS、Amazon EC2 和 Lambda 作为部署提供者。",
      "B": "使用 AWS CodePipeline，将 AWS CodeDeploy 作为部署提供者。",
      "C": "使用 AWS CodePipeline，将 AWS Elastic Beanstalk 作为部署提供者。",
      "D": "使用 AWS CodeDeploy 与 GitHub 集成来部署应用程序。"
    },
    "analysis": {
      "A": "不正确。虽然CodePipeline可以直接与这些服务集成，但它们不是部署提供者(deploy providers)，CodePipeline需要通过专门的部署服务来完成部署。",
      "B": "正确。CodePipeline结合CodeDeploy是最佳实践。CodeDeploy支持部署到EC2、ECS和Lambda，同时CodePipeline支持手动审批操作。CodeDeploy作为部署提供者可以处理所有需要的部署场景。",
      "C": "不正确。Elastic Beanstalk虽然可以作为部署提供者，但它主要用于Web应用程序的部署，不适合处理ECS和Lambda的部署需求。",
      "D": "不正确。CodeDeploy虽然可以与GitHub集成，但它本身不提供完整的管道功能，无法支持手动审批操作。需要CodePipeline来编排整个持续交付流程。"
    },
    "best": ["B"],
    "service": [
      "AWS CodePipeline",
      "Amazon ECS",
      "Amazon EC2",
      "AWS Lambda",
      "AWS CodeDeploy",
      "AWS Elastic Beanstalk"
    ],
    "reason": "选择B是最佳方案，原因如下：\n1. CodePipeline提供了完整的持续交付管道功能，支持手动审批操作\n2. CodeDeploy作为部署提供者支持所有需要的目标平台(ECS、EC2、Lambda)\n3. CodePipeline可以轻松集成私有GitHub仓库作为源\n4. CodePipeline + CodeDeploy是AWS推荐的持续交付最佳实践\n这个组合可以完全满足题目中的所有要求。"
  },
  {
    "no": 67,
    "question": "一家公司在 AWS Organizations 中拥有其 AWS 账户。每个 AWS 账户都手动配置了 AWS Config。该公司需要实施一种解决方案，以便为组织中的所有账户集中配置 AWS Config。该解决方案还必须记录到中央账户的资源更改。DevOps 工程师应执行哪些操作组合以满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "为 AWS Config 配置委托管理员账户。在组织中启用 AWS Config 的受信任访问。",
      "B": "为 AWS Config 配置委托管理员账户。在组织的管理账户中创建 AWS Config 的服务链接角色。",
      "C": "创建一个 AWS CloudFormation 模板以创建 AWS Config 聚合器。配置 CloudFormation 堆栈集以将模板部署到组织中的所有账户。",
      "D": "在组织的管理账户中创建 AWS Config 组织聚合器。配置从组织中的所有 AWS 账户和所有 AWS 区域收集数据。",
      "E": "在委托管理员账户中创建 AWS Config 组织聚合器。配置从组织中的所有 AWS 账户和所有 AWS 区域收集数据。"
    },
    "best": ["A", "E"],
    "analysis": {
      "A": "这是正确选项。委托管理员账户是 AWS 推荐的最佳实践，启用可信访问是必需的，它允许 AWS Config 与 Organizations 集成。这是设置集中式 AWS Config 管理的基础步骤，同时会自动创建必要的服务关联角色和权限。",
      "B": "这是错误选项。虽然设置委托管理员是正确的，但手动创建服务关联角色是不必要的。当启用可信访问时，AWS 会自动创建所需的服务关联角色，因此手动创建是多余且不必要的步骤。",
      "C": "这是错误选项。不需要在每个账户中创建聚合器，只需要在委托管理员账户中创建一个组织级聚合器即可。使用 CloudFormation 部署聚合器是不必要的复杂化，这种方法会造成额外的资源和管理开销。",
      "D": "这是错误选项。聚合器不应该在管理账户中创建，这违反了职责分离原则。管理账户应该只用于组织级别的管理任务，而配置管理应该在委托管理员账户中进行。",
      "E": "这是正确选项。在委托管理员账户中创建聚合器是正确的做法，这样可以从所有账户和区域收集数据，提供了集中式的配置可视性，并且符合 AWS 的安全最佳实践。这种方式确保了正确的权限分配和职责分离。"
    },
    "service": ["AWS Config", "AWS Organizations", "AWS CloudFormation"],
    "reason": "2.1"
  },
  {
    "no": 69,
    "question": "一个开发团队使用 AWS CodeCommit、AWS CodePipeline 和 AWS CodeBuild 来开发和部署应用程序。代码的更改通过拉取请求提交。开发团队审查并合并拉取请求，然后管道构建和测试应用程序。随着时间的推移，拉取请求的数量增加了。由于测试失败，管道经常被阻塞。为了防止这种阻塞，开发团队希望在合并每个拉取请求之前对其进行单元和集成测试。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 CodeBuild 项目来运行单元和集成测试。创建一个 CodeCommit 审批规则模板。配置模板以要求成功调用 CodeBuild 项目。将审批规则附加到项目的 CodeCommit 仓库。",
      "B": "创建一个 Amazon EventBridge 规则以匹配 CodeCommit 的 pullRequestCreated 事件。创建一个 CodeBuild 项目来运行单元和集成测试。将 CodeBuild 项目配置为 EventBridge 规则的目标，其中包括一个自定义事件有效负载，其中包含来自事件的 CodeCommit 仓库和分支信息。",
      "C": "创建一个 Amazon EventBridge 规则以匹配 CodeCommit 的 pullRequestCreated 事件。修改现有的 CodePipeline 管道，以便如果从拉取请求启动构建，则不运行部署步骤。配置 EventBridge 规则以使用包含 CodeCommit 仓库和分支信息的自定义有效负载运行管道。",
      "D": "创建一个 CodeBuild 项目来运行单元和集成测试。创建一个 CodeCommit 通知规则，匹配创建或更新拉取请求时的情况。配置通知规则以调用 CodeBuild 项目。"
    },
    "best": ["B"],
    "analysis": {
      "A": "这个方案虽然可以确保PR在合并前通过测试，但通过审批规则模板的方式过于繁琐。需要手动审批流程会降低开发效率，且增加了团队工作负担。虽然可以强制执行测试要求，但缺乏足够的自动化程度。",
      "B": "这是最佳解决方案。通过EventBridge规则可以自动响应pullRequestCreated事件并触发CodeBuild测试，实现了完全自动化的流程。自定义事件负载能确保准确传递仓库和分支信息，无需人工干预，提供及时反馈，且完全符合AWS最佳实践。",
      "C": "这个方案试图通过修改现有的部署管道来处理PR测试，虽然是常见做法但并非最佳选择。修改主管道可能影响现有的部署流程，增加了管道的复杂性和维护难度。此外，将测试和部署逻辑混在一起不利于系统的清晰度。",
      "D": "这个方案在技术实现上存在限制，因为CodeCommit的通知规则只能触发SNS主题或Chatbot，无法直接调用CodeBuild项目。虽然考虑到了PR的创建和更新场景，但实现机制不够可靠，无法提供真正的自动化测试流程。"
    },
    "service": [
      "AWS CodeCommit",
      "AWS CodePipeline",
      "AWS CodeBuild",
      "Amazon EventBridge"
    ],
    "reason": "1.2"
  },
  {
    "no": 71,
    "question": "一位 DevOps 工程师在一家公司支持一个 AWS 环境，该环境中所有用户都使用 AWS IAM Identity Center (AWS Single Sign-On)。公司希望立即禁用任何新 IAM 用户的凭证，并希望安全团队收到通知。DevOps 工程师应采取哪些步骤组合以满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "创建一个 Amazon EventBridge 规则，该规则对 AWS CloudTrail 中的 IAM CreateUser API 调用做出反应。",
      "B": "创建一个 Amazon EventBridge 规则，该规则对 AWS CloudTrail 中的 IAM GetLoginProfile API 调用做出反应。",
      "C": "创建一个 AWS Lambda 函数，作为 EventBridge 规则的目标。配置 Lambda 函数以禁用任何访问密钥并删除与 IAM 用户关联的登录配置文件。",
      "D": "创建一个 AWS Lambda 函数，作为 EventBridge 规则的目标。配置 Lambda 函数以删除与 IAM 用户关联的登录配置文件。",
      "E": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题，作为 EventBridge 规则的目标。订阅安全团队的组邮箱地址到该主题。",
      "F": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列，作为 Lambda 函数的目标。订阅安全团队的组邮箱地址到该队列。"
    },
    "best": ["A", "C", "E"],
    "analysis": {
      "A": "正确。需要监控CreateUser API调用来检测新IAM用户的创建。这是触发自动化流程的关键起点。",
      "B": "不正确。监控GetLoginProfile API调用不能有效检测新用户创建，这是查询现有用户登录配置的API。",
      "C": "正确。Lambda函数需要执行两个关键操作：禁用访问密钥和删除登录配置文件。这样可以确保新创建的IAM用户无法使用任何形式的凭证。",
      "D": "不正确。这个选项只删除登录配置文件，没有处理访问密钥，不够完整。",
      "E": "正确。使用SNS主题来通知安全团队是最合适的方式。SNS支持邮件订阅，可以直接发送通知到安全团队的邮箱。",
      "F": "不正确。SQS是消息队列服务，不适合用于直接通知。而且不支持直接发送邮件通知。"
    },
    "service": [
      "AWS IAM Identity Center",
      "Amazon EventBridge",
      "AWS Lambda",
      "Amazon SNS",
      "Amazon SQS"
    ],
    "reason": "需求是在使用IAM Identity Center的环境中，检测并禁用新IAM用户凭证，并通知安全团队。需要选择三个步骤来完成这个自动化流程。选择A、C、E组合最合理，因为：\n1. EventBridge监控CreateUser操作(A)\n2. Lambda执行完整的禁用操作(C)\n3. SNS发送通知给安全团队(E)\n这三个步骤形成了一个完整的自动化流程。"
  },
  {
    "no": 70,
    "question": "一家公司有一个在Amazon EC2实例群上运行的应用程序。该应用程序需要频繁重启。应用程序日志在需要重启时包含错误消息。应用程序日志发布到Amazon CloudWatch Logs中的日志组。当日志包含大量与重启相关的错误消息时，一个Amazon CloudWatch警报通过Amazon Simple Notification Service（Amazon SNS）主题通知应用程序工程师。应用程序工程师在收到SNS主题的通知后手动重启实例上的应用程序。DevOps工程师需要实施一个解决方案，以自动化方式重启实例上的应用程序，而无需重启实例。哪种解决方案能以最高的操作效率满足这些要求？",
    "choose": 1,
    "options": {
      "A": "配置一个AWS Systems Manager自动化运行手册，运行一个脚本在实例上重启应用程序。配置SNS主题以调用运行手册。",
      "B": "创建一个AWS Lambda函数，重启实例上的应用程序。将Lambda函数配置为SNS主题的事件目的地。",
      "C": "配置一个AWS Systems Manager自动化运行手册，运行一个脚本在实例上重启应用程序。创建一个AWS Lambda函数来调用运行手册。将Lambda函数配置为SNS主题的事件目的地。",
      "D": "配置一个AWS Systems Manager自动化运行手册，运行一个脚本在实例上重启应用程序。配置一个Amazon EventBridge规则，当CloudWatch警报进入ALARM状态时触发。指定运行手册作为规则的目标。"
    },
    "best": ["D"],
    "analysis": {
      "A": "这个方案不可行。SNS主题无法直接调用Systems Manager自动化运行手册。需要中间层来处理这种集成。",
      "B": "此方案可行但不是最优。虽然Lambda函数可以通过AWS SDK调用命令来重启应用程序，但直接使用Lambda增加了不必要的复杂性和潜在的故障点。",
      "C": "此方案可行但过于复杂。引入Lambda作为中间层来调用Systems Manager运行手册是不必要的额外步骤，降低了操作效率。",
      "D": "这是最佳解决方案，原因如下：\n1. 直接使用EventBridge规则监听CloudWatch告警状态\n2. 可以直接触发Systems Manager运行手册\n3. 无需额外的中间组件\n4. 最简单和直接的自动化流程\n5. 提供最高的操作效率"
    },
    "service": [
      "Amazon EC2",
      "Amazon CloudWatch Logs",
      "Amazon SNS",
      "AWS Systems Manager",
      "AWS Lambda",
      "Amazon EventBridge"
    ],
    "reason": "2.3"
  },
  {
    "no": 73,
    "question": "一家公司有一个应用程序运行在Amazon EC2实例上，这些实例位于一个自动扩展组中。当应用程序启动时，需要先从Amazon S3存储桶处理数据，然后应用程序才能开始处理请求。存储在S3存储桶中的数据量正在增长。当自动扩展组添加新实例时，应用程序现在需要几分钟时间下载和处理数据才能开始处理请求。公司必须减少新EC2实例准备处理请求前的时间。哪种解决方案是减少应用程序启动时间的最具成本效益的方式？",
    "choose": 1,
    "options": {
      "A": "为自动扩展组配置预热池，预热的EC2实例处于停止状态。在自动扩展组上配置autoscaling:EC2_INSTANCE_LAUNCHING生命周期钩子。修改应用程序以在应用程序准备好处理请求时完成生命周期钩子。",
      "B": "增加自动扩展组的最大实例数。在自动扩展组上配置autoscaling:EC2_INSTANCE_LAUNCHING生命周期钩子。修改应用程序以在应用程序准备好处理请求时完成生命周期钩子。",
      "C": "为自动扩展组配置预热池，预热的EC2实例处于运行状态。在自动扩展组上配置autoscaling:EC2_INSTANCE_LAUNCHING生命周期钩子。修改应用程序以在应用程序准备好处理请求时完成生命周期钩子。",
      "D": "增加自动扩展组的最大实例数。在自动扩展组上配置autoscaling:EC2_INSTANCE_LAUNCHING生命周期钩子。修改应用程序以在应用程序准备好处理请求时完成生命周期钩子并将新实例置于待机状态。"
    },
    "best": ["A"],
    "analysis": {
      "A": "正确。使用处于Stopped状态的预热池是最具成本效益的解决方案。这些实例不会产生计算费用，但可以保留已下载和处理的数据。当需要扩展时，实例可以快速启动并立即服务请求。",
      "B": "不正确。仅增加最大实例数并不能解决启动时间长的问题。这种方法不能减少数据处理时间，而且可能会增加成本。",
      "C": "不正确。使用Running状态的预热池虽然可以减少启动时间，但会产生不必要的EC2运行成本，因为这些实例即使在空闲时也会产生费用。",
      "D": "不正确。将实例置于Standby状态不会解决问题，反而会增加复杂性和成本。这种方法既不能减少启动时间，也不够经济。"
    },
    "service": ["Amazon EC2", "Auto Scaling", "Amazon S3"],
    "reason": "选择A是最佳解决方案，原因如下：\n1. 预热池中的Stopped状态实例可以保留EBS卷数据，这样已处理的S3数据可以保留在卷上\n2. Stopped状态的实例不会产生EC2计算费用，只需支付EBS存储费用\n3. 使用生命周期钩子可以确保应用程序完全准备好后才投入服务\n4. 当需要扩展时，预热池中的实例可以快速启动，无需重新下载和处理S3数据\n这个方案既能显著减少启动时间，又能最大限度地降低成本，完全符合题目要求的'最具成本效益'的解决方案。"
  },
  {
    "no": 79,
    "question": "一家公司正在实施 AWS CodePipeline 以自动化其测试过程。该公司希望在执行状态失败时得到通知，并使用了以下自定义事件模式在 Amazon EventBridge 中：这种事件模式将匹配哪种类型的事件？",
    "choose": 1,
    "options": {
      "A": "所有管道中失败的部署和构建操作",
      "B": "所有管道中所有被拒绝或失败的审批操作",
      "C": "所有管道中的所有事件",
      "D": "所有管道中的审批操作"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最优选项，因为事件模式指定了对失败的状态进行匹配，这通常涉及部署和构建操作的失败。",
      "B": "这不是最优选项，因为事件模式没有特别指出审批操作，而是更广泛地关注于执行状态的失败。",
      "C": "这不是最优选项，因为事件模式特定于失败的状态，而不是所有类型的事件。",
      "D": "这不是最优选项，因为虽然审批操作可能会失败，但事件模式并不局限于审批操作。"
    },
    "service": ["AWS CodePipeline", "Amazon EventBridge"],
    "reason": "1.2"
  },
  {
    "no": 77,
    "question": "一位 DevOps 工程师正在为一家公司的软件即服务（SaaS）Web应用制定持续开发策略，该应用运行在 AWS 上。出于应用和安全原因，订阅此应用的用户分布在多个应用程序负载均衡器（ALB）上，每个ALB都有一个专用的自动扩展组和 Amazon EC2 实例群。该应用程序不需要构建阶段，当其提交到 AWS CodeCommit 时，必须同时触发对所有 ALB、自动扩展组和 EC2 群的部署。哪种架构能以最少的配置满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个单一的 AWS CodePipeline 管道，使用为每个 ALB-自动扩展组对创建的唯一 AWS CodeDeploy 应用程序和部署组并行部署应用程序。",
      "B": "创建一个单一的 AWS CodePipeline 管道，使用一个 AWS CodeDeploy 应用程序和单一部署组部署应用程序。",
      "C": "创建一个单一的 AWS CodePipeline 管道，使用一个 AWS CodeDeploy 应用程序和为每个 ALB-自动扩展组对创建的唯一部署组并行部署应用程序。",
      "D": "为每个 ALB-自动扩展组对创建一个 AWS CodePipeline 管道，使用为同一 ALB-自动扩展组对创建的 AWS CodeDeploy 应用程序和部署组部署应用程序。"
    },
    "best": ["C"],
    "analysis": {
      "A": "不正确。使用多个CodeDeploy应用程序和部署组会增加配置复杂性，不符合'最少配置'的要求。每个ALB-ASG对都需要单独的应用程序配置。",
      "B": "不正确。单一的CodeDeploy应用程序和部署组无法有效处理多个ALB和ASG的并行部署需求。这可能导致部署不同步或失败。",
      "C": "正确。这种架构提供了最佳平衡：\n1. 使用单一CodeDeploy应用程序减少了基础配置\n2. 为每个ALB-ASG对使用独立的部署组允许并行部署\n3. 单一管道确保同步触发所有部署",
      "D": "不正确。为每个ALB-ASG对创建单独的管道会大大增加配置和维护工作。这是最复杂的方案，不符合最少配置的要求。"
    },
    "service": [
      "AWS CodePipeline",
      "AWS CodeDeploy",
      "AWS CodeCommit",
      "Application Load Balancer",
      "Auto Scaling",
      "Amazon EC2"
    ],
    "reason": "选择C是最佳解决方案，原因如下：\n\n1. 配置效率：\n   - 只需要配置一个CodePipeline管道\n   - 只需要一个CodeDeploy应用程序\n   - 每个ALB-ASG对使用独立的部署组实现并行部署\n\n2. 功能完整性：\n   - 支持同时触发所有部署\n   - 可以并行部署到所有目标\n   - 保持部署的同步性\n\n3. 管理简便：\n   - 集中化的部署管理\n   - 简化的监控和故障排除\n   - 更容易维护和更新\n\n4. 扩展性：\n   - easily添加新的ALB-ASG对\n   - 不需要创建新的管道或应用程序\n\n这个方案在保持最少配置的同时，完全满足了所有技术要求。"
  },
  {
    "no": 74,
    "question": "一家公司正在使用 AWS CodeBuild 项目来构建和打包应用程序。打包后的文件被复制到一个共享的 Amazon S3 存储桶中，然后在多个 AWS 账户中部署。buildspec.yml 文件包含以下内容：DevOps 工程师注意到任何拥有 AWS 账户的人都能下载这些构件。DevOps 工程师应该采取哪些步骤来阻止这种情况？",
    "choose": 1,
    "options": {
      "A": "修改 post_build 命令以使用 --acl public-read 并配置存储桶策略，仅授予相关 AWS 账户读取权限。",
      "B": "为 S3 存储桶配置默认 ACL，将认证用户定义为仅相关 AWS 账户，并授予只读访问权限。",
      "C": "创建一个 S3 存储桶策略，授予相关 AWS 账户读取权限，并拒绝主体“*”的读取权限。",
      "D": "修改 post_build 命令以移除 --acl authenticated-read 并配置存储桶策略，仅允许相关 AWS 账户读取权限。"
    },
    "best": ["D"],
    "analysis": {
    "A": "不正确。使用public-read ACL会使对象公开可读，这会让安全性问题更严重。",
    "B": "不正确。S3桶的默认ACL无法精确指定特定AWS账户的访问权限。而且authenticated-read ACL允许任何已认证的AWS用户访问。",
    "C": "不正确。虽然可以通过桶策略授予特定账户访问权限，但是明确拒绝'*'可能会产生意外的副作用，影响其他必要的访问。",
    "D": "正确。这是最佳实践方案：\n1. 移除authenticated-read ACL，因为它允许所有AWS认证用户访问\n2. 通过桶策略精确控制哪些AWS账户可以读取对象\n3. 遵循最小权限原则"
  },
    "service": ["AWS CodeBuild", "Amazon S3"],
    "reason": "选择D是最佳解决方案，原因如下：\n1. authenticated-read ACL允许任何已认证的AWS用户访问对象，这个范围太大，存在安全风险\n2. 应该完全移除ACL设置，改用更精细的桶策略控制\n3. 通过桶策略可以准确指定哪些AWS账户具有读取权限\n4. 这种方式符合AWS安全最佳实践，实现了最小权限原则\n此方案可以有效阻止未授权的AWS账户访问artifacts，同时确保需要访问的账户仍然具有必要的权限。"
  },
  {
    "no": 75,
    "question": "一家公司开发了一个托管在 AWS 上的无服务器 Web 应用程序。该应用程序包括 Amazon S3、Amazon API Gateway、几个 AWS Lambda 函数和一个 Amazon RDS for MySQL 数据库。公司使用 AWS CodeCommit 存储源代码。源代码是 AWS Serverless Application Model (AWS SAM) 模板和 Python 代码的组合。安全审计和渗透测试显示，用于数据库认证的用户名和密码在 CodeCommit 仓库中硬编码。DevOps 工程师必须实施一个解决方案来自动检测和防止硬编码的秘密。哪种解决方案最安全，符合这些要求？",
    "choose": 1,
    "options": {
      "A": "启用 Amazon CodeGuru Profiler。用 @with_lambda_profiler() 装饰处理函数。手动审查推荐报告。将秘密写入 AWS Systems Manager Parameter Store 作为安全字符串。更新 SAM 模板和 Python 代码以从 Parameter Store 拉取秘密。",
      "B": "将 CodeCommit 仓库与 Amazon CodeGuru Reviewer 关联。手动检查代码审查以获取任何建议。选择保护秘密的选项。更新 SAM 模板和 Python 代码以从 AWS Secrets Manager 拉取秘密。",
      "C": "启用 Amazon CodeGuru Profiler。用 @with_lambda_profiler() 装饰处理函数。手动审查推荐报告。选择保护秘密的选项。更新 SAM 模板和 Python 代码以从 AWS Secrets Manager 拉取秘密。",
      "D": "将 CodeCommit 仓库与 Amazon CodeGuru Reviewer 关联。手动检查代码审查以获取任何建议。将秘密写入 AWS Systems Manager Parameter Store 作为字符串。更新 SAM 模板和 Python 代码以从 Parameter Store 拉取秘密。"
    },
    "best": ["B"],
    "analysis": {
      "A": "不正确。CodeGuru Profiler主要用于性能分析，不适合检测代码中的密钥。Parameter Store虽然可以存储密钥，但Secrets Manager提供了更专门的密钥管理功能。",
      "B": "正确。这个方案提供了最完整和安全的解决方案：\n1. CodeGuru Reviewer可以自动检测代码中的硬编码密钥\n2. Secrets Manager专门用于管理密钥，提供自动轮换等高级功能\n3. 整个流程符合安全最佳实践",
      "C": "不正确。虽然使用了Secrets Manager，但CodeGuru Profiler不是检测代码中密钥的合适工具。它主要关注应用性能而非安全审查。",
      "D": "不正确。虽然使用了CodeGuru Reviewer进行检测，但Parameter Store的普通字符串不如Secrets Manager安全，缺少专门的密钥管理功能。"
    },
    "service": [
      "Amazon S3",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon RDS for MySQL",
      "AWS CodeCommit",
      "AWS Serverless Application Model (AWS SAM)",
      "Amazon CodeGuru Profiler",
      "AWS Systems Manager Parameter Store",
      "Amazon CodeGuru Reviewer",
      "AWS Secrets Manager"
    ],
    "reason": "选择B是最安全的解决方案，原因如下：\n1. Amazon CodeGuru Reviewer能够自动检测代码中的安全问题，包括硬编码的密钥\n2. AWS Secrets Manager是专门的密钥管理服务，提供：\n   - 自动密钥轮换功能\n   - 细粒度的访问控制\n   - 加密存储\n   - 与数据库集成的专门支持\n3. 这个组合实现了：\n   - 自动检测防止硬编码密钥\n   - 安全存储和管理密钥\n   - 符合安全最佳实践\n这个方案不仅解决了当前的安全问题，还提供了长期的安全维护机制。"
  },
  {
    "no": 78,
    "question": "一家公司从 Amazon S3 存储桶托管静态网站，网站可通过 example.com 向客户提供。公司使用 Amazon Route 53 加权路由策略，TTL 为 1 天。公司决定用动态 Web 应用程序替换现有的静态网站。动态 Web 应用程序在一组 Amazon EC2 实例前使用应用程序负载均衡器（ALB）。在向客户生产发布的当天，公司创建了一个额外的 Route 53 加权 DNS 记录条目，指向 ALB，权重为 255，TTL 为 1 小时。两天后，一名 DevOps 工程师注意到，当客户导航到 example.com 时，有时会显示之前的静态网站。DevOps 工程师如何确保公司仅为 example.com 提供动态内容？",
    "choose": 1,
    "options": {
      "A": "删除包含静态网站内容的 S3 存储桶中的所有对象，包括以前的版本。",
      "B": "更新指向 S3 存储桶的加权 DNS 记录条目。应用权重为 0。指定域重置选项以立即传播更改。",
      "C": "在 S3 存储桶上配置网页重定向请求，使用指向 ALB 的主机名重定向。",
      "D": "从 example.com 托管区域中删除指向 S3 存储桶的加权 DNS 记录条目。等待 DNS 传播完成。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然删除 S3 存储桶中的静态内容可以防止其被访问，但这并不影响 DNS 记录，用户仍可能被解析到旧的静态网站。",
      "B": "将权重设置为 0 会减少指向 S3 存储桶的流量，但由于 DNS 缓存和传播延迟，这可能不会立即生效。",
      "C": "配置重定向可以临时解决问题，但这不是彻底的解决方案，因为它依赖于重定向而不是 DNS 解析。",
      "D": "删除指向 S3 存储桶的 DNS 记录是最彻底的解决方案，这将确保所有流量都被直接解析到 ALB，从而只提供动态内容。等待 DNS 传播完成是必要的步骤，以确保所有用户都看到更新。"
    },
    "service": [
      "Amazon S3",
      "Amazon Route 53",
      "Application Load Balancer",
      "Amazon EC2"
    ],
    "reason": "3.1"
  },
  {
    "no": 76,
    "question": "一家公司正在使用 Amazon S3 存储桶存储重要文件。公司发现一些 S3 存储桶未加密。目前，公司的 IAM 用户可以创建未加密的新 S3 存储桶。公司正在实施一个新要求，即所有 S3 存储桶都必须加密。DevOps 工程师必须实施一种解决方案，以确保所有现有 S3 存储桶和所有新 S3 存储桶都启用了服务器端加密。新创建的 S3 存储桶必须在创建时立即启用加密。默认加密类型必须是 256 位高级加密标准 (AES-256)。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 AWS Lambda 函数，该函数由 Amazon EventBridge 定时规则定期调用。编程 Lambda 函数以扫描所有当前的 S3 存储桶的加密状态，并为任何没有加密配置的 S3 存储桶设置 AES-256 作为默认加密。",
      "B": "设置并激活 s3-bucket-server-side-encryption-enabled AWS Config 管理规则。配置该规则以使用 AWS-EnableS3BucketEncryption AWS Systems Manager 自动化运行簿作为补救措施。手动运行重新评估过程以确保现有 S3 存储桶符合要求。",
      "C": "创建一个 AWS Lambda 函数，该函数由 Amazon EventBridge 事件规则调用。定义规则，使用与新创建的 S3 存储桶匹配的事件模式。编程 Lambda 函数以解析 EventBridge 事件，检查事件中的 S3 存储桶配置，并设置 AES-256 作为默认加密。",
      "D": "配置一个 IAM 策略，如果 s3:x-amz-server-side-encryption 条件键的值不是 AES-256，则拒绝 s3:CreateBucket 操作。为公司的所有 IAM 用户创建一个 IAM 组。将 IAM 策略与 IAM 组关联。"
    },
    "best": ["B"],
    "analysis": {
      "A": "不正确。虽然这个方案可以处理现有和新的S3桶，但不是最佳实践。定期扫描会有延迟，可能会在检查间隔期间出现未加密的桶。",
      "B": "正确。这个解决方案提供了完整的自动化控制和修复：\n1. AWS Config规则持续监控所有S3桶的加密状态\n2. 自动修复功能可以立即处理不合规的桶\n3. 可以处理现有和新创建的桶\n4. 提供合规性报告和审计能力",
      "C": "不正确。虽然可以响应新桶创建事件，但无法处理现有的未加密桶。而且如果Lambda函数失败，可能会导致桶保持未加密状态。",
      "D": "不正确。IAM策略可以预防新建未加密的桶，但不能处理现有的未加密桶。而且可能会影响依赖特定加密设置的应用程序。"
    },
    "service": [
      "AWS Lambda",
      "Amazon EventBridge",
      "AWS Config",
      "AWS Systems Manager",
      "IAM",
      "Amazon S3"
    ],
    "reason": "选择B是最佳解决方案，原因如下：\n1. 完整性：\n   - 可以检测和修复现有的未加密桶\n   - 自动处理新创建的桶\n   - 确保所有桶使用AES-256加密\n\n2. 自动化：\n   - AWS Config持续监控合规性\n   - Systems Manager自动执行修复操作\n   - 无需人工干预\n\n3. 可靠性：\n   - 内置的重试机制\n   - 详细的审计日志\n   - 状态跟踪和报告\n\n4. 最佳实践：\n   - 使用AWS原生服务\n   - 符合安全标准\n   - 易于管理和维护\n\n这个方案提供了最全面、可靠和自动化的解决方案，完全满足题目要求。"
  },
  {
    "no": 81,
    "question": "一家公司管理一个应用程序，该应用程序将日志存储在 Amazon CloudWatch Logs 中。公司希望将日志归档到 Amazon S3 存储桶中。日志在 90 天后很少被访问，并且必须保留 10 年。DevOps 工程师应采取哪些步骤组合来满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "配置 CloudWatch Logs 订阅过滤器，使用 AWS Glue 将所有日志传输到 S3 存储桶。",
      "B": "配置 CloudWatch Logs 订阅过滤器，使用 Amazon Kinesis Data Firehose 将所有日志流式传输到 S3 存储桶。",
      "C": "配置 CloudWatch Logs 订阅过滤器，将所有日志流式传输到 S3 存储桶。",
      "D": "配置 S3 存储桶生命周期策略，在 90 天后将日志转移到 S3 Glacier，并在 3650 天后过期日志。",
      "E": "配置 S3 存储桶生命周期策略，在 90 天后将日志转移到 Reduced Redundancy，并在 3650 天后过期日志。"
    },
    "best": ["B", "D"],
    "analysis": {
      "A": "AWS Glue 主要用于数据集成和 ETL 作业，不适用于直接将日志从 CloudWatch Logs 转移到 S3。",
      "B": "Amazon Kinesis Data Firehose 是一个完全托管的服务，可以实现实时数据流处理，适用于将 CloudWatch Logs 实时传输到 S3。",
      "C": "此选项缺乏具体的实现细节，如何实现流式传输未说明。",
      "D": "配置 S3 生命周期策略以在 90 天后转移到成本更低的 S3 Glacier，并在 10 年后过期，符合题目要求。",
      "E": "Reduced Redundancy 存储类已不再推荐使用，且不适合长期数据存储和归档。"
    },
    "service": [
      "Amazon CloudWatch Logs",
      "Amazon S3",
      "Amazon Kinesis Data Firehose",
      "S3 Glacier"
    ],
    "reason": "4.1"
  },
  {
    "no": 80,
    "question": "在一个自动扩展组中运行的应用程序需要一个配置文件来操作，这些实例是通过 AWS CloudFormation 创建和维护的。DevOps 工程师希望在启动时实例能够拥有最新的配置文件，并希望在 CloudFormation 模板更新时，所有实例上的配置文件更改能够尽可能快地反映出来。公司政策要求将应用程序配置文件与 AWS 基础设施配置文件一起保存在源代码控制中。哪种解决方案能够实现这一目标？",
    "choose": 1,
    "options": {
      "A": "在 CloudFormation 模板中添加一个 AWS Config 规则。将配置文件内容放在规则的 InputParameters 属性中，并将 Scope 属性设置为 EC2 自动扩展组。在模板中添加一个 AWS Systems Manager Resource Data Sync 资源以轮询配置的更新。",
      "B": "在 CloudFormation 模板中添加一个 EC2 启动模板资源。将配置文件内容放在启动模板中。配置 cfn-init 脚本在实例启动时运行，并配置 cfn-hup 脚本以轮询配置的更新。",
      "C": "在 CloudFormation 模板中添加一个 EC2 启动模板资源。将配置文件内容放在启动模板中。在模板中添加一个 AWS Systems Manager Resource Data Sync 资源以轮询配置的更新。",
      "D": "在 CloudFormation 模板中添加 CloudFormation init 元数据。将配置文件内容放在元数据中。配置 cfn-init 脚本在实例启动时运行，并配置 cfn-hup 脚本以轮询配置的更新。"
    },
    "best": ["D"],
    "analysis": {
      "A": "AWS Config 主要用于配置合规性和审计，而不适合用于管理应用程序配置文件。",
      "B": "虽然这个选项使用了 EC2 启动模板和 cfn-init/cfn-hup 脚本，但没有使用 CloudFormation init 元数据，这使得管理配置文件的灵活性和可维护性较差。",
      "C": "这个选项没有使用 cfn-init 和 cfn-hup 脚本，这些脚本对于处理 CloudFormation 模板中的配置更新非常重要。",
      "D": "这个选项使用了 CloudFormation init 元数据和 cfn-init/cfn-hup 脚本，这些工具可以确保实例在启动时和模板更新后都能获取最新的配置，符合题目要求。"
    },
    "service": [
      "AWS CloudFormation",
      "Amazon EC2",
      "AWS Systems Manager",
      "AWS Config"
    ],
    "reason": "2.1"
  },
  {
    "no": 85,
    "question": "一个应用程序在 Application Load Balancer (ALB) 后面的 Amazon EC2 实例上运行。一位 DevOps 工程师正在使用 AWS CodeDeploy 发布新版本。部署在 AllowTraffic 生命周期事件期间失败，但部署日志中没有指示失败的原因。可能导致这种情况的原因是什么？",
    "choose": 1,
    "options": {
      "A": "appspec.yml 文件包含在 AllowTraffic 生命周期钩子中运行的无效脚本。",
      "B": "启动部署的用户没有与 ALB 交互所需的权限。",
      "C": "为 ALB 目标组指定的健康检查配置错误。",
      "D": "CodeDeploy 代理未安装在 ALB 目标组的 EC2 实例中。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然 appspec.yml 文件中的脚本错误可能导致部署问题，但这通常会在日志中有明确的错误信息，而题目指出日志中没有失败原因的指示。",
      "B": "用户权限问题通常会在 AWS 的日志中明确记录，因此如果是权限问题，日志中应该有相关的错误信息。",
      "C": "如果 ALB 的目标组健康检查配置错误，可能会导致流量无法正确路由到新部署的实例，从而导致部署在 AllowTraffic 阶段失败。这种情况可能不会在 CodeDeploy 日志中直接反映出来，因为它是由 ALB 的配置问题引起的。",
      "D": "如果 CodeDeploy 代理未安装，通常会在 CodeDeploy 的日志中看到与代理相关的错误。"
    },
    "service": ["Amazon EC2", "AWS CodeDeploy", "Application Load Balancer"],
    "reason": "1.4"
  },
  {
    "no": 83,
    "question": "一位 DevOps 工程师正在为公司的应用程序部署新版本，该版本与其 Amazon EC2 实例相关联的 AWS CodeDeploy 部署组。一段时间后，部署失败。工程师意识到与特定部署 ID 相关的所有事件都处于跳过状态，并且代码未部署在与部署组关联的实例中。这次失败的有效原因是什么？（选择两个。）",
    "choose": 2,
    "options": {
      "A": "网络配置不允许 EC2 实例通过 NAT 网关或互联网网关访问互联网，且无法访问 CodeDeploy 端点。",
      "B": "触发应用程序部署的 IAM 用户没有权限与 CodeDeploy 端点交互。",
      "C": "目标 EC2 实例未正确注册到 CodeDeploy 端点。",
      "D": "未将具有适当权限的实例配置文件附加到目标 EC2 实例。",
      "E": "应用程序修订中未包含 appspec.yml 文件。"
    },
    "best": ["A", "D"],
    "analysis": {
      "A": "这是一个最优选项，因为如果 EC2 实例无法通过互联网或 NAT 网关访问 CodeDeploy 端点，它们将无法接收部署命令或下载应用程序代码。",
      "B": "这不是最优选项，因为 IAM 用户权限问题通常会导致权限错误，而不是部署状态为 'Skipped'。",
      "C": "这不是最优选项，因为如果实例未注册到 CodeDeploy 端点，通常会导致错误或未注册的实例状态，而不是 'Skipped' 状态。",
      "D": "这是一个最优选项，因为如果 EC2 实例没有附加正确的 IAM 角色（实例配置文件），它们可能没有执行 CodeDeploy 操作的必要权限。",
      "E": "这不是最优选项，因为缺少 appspec.yml 文件通常会导致部署错误或失败，而不是 'Skipped' 状态。"
    },
    "service": ["AWS CodeDeploy", "Amazon EC2"],
    "reason": "1.4"
  },
  {
    "no": 82,
    "question": "一家公司正在开发一款新应用程序。该应用程序使用 AWS Lambda 函数作为其计算层。公司必须对 Lambda 函数的任何更改使用金丝雀部署。如果报告任何失败，必须自动回滚。公司的 DevOps 团队需要为此解决方案创建基础设施即代码 (IaC) 和 CI/CD 管道。哪种步骤组合将满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "为应用程序创建一个 AWS CloudFormation 模板。在模板中使用 AWS::Lambda::Function 资源类型定义每个 Lambda 函数。在模板中，使用 AWS::Lambda::Version 资源类型为 Lambda 函数包括一个版本。声明 CodeSha256 属性。配置一个引用 Lambda 函数最新版本的 AWS::Lambda::Alias 资源。",
      "B": "为应用程序创建一个 AWS Serverless Application Model (AWS SAM) 模板。在模板中使用 AWS::Serverless::Function 资源类型定义每个 Lambda 函数。对于每个函数，包括 AutoPublishAlias 属性和 DeploymentPreference 属性的配置。将部署配置类型配置为 LambdaCanary10Percent10Minutes。",
      "C": "创建一个 AWS CodeCommit 仓库。创建一个 AWS CodePipeline 管道。在新的源阶段中使用 CodeCommit 仓库启动管道。创建一个 AWS CodeBuild 项目来部署 AWS Serverless Application Model (AWS SAM) 模板。将模板和源代码上传到 CodeCommit 仓库。在 CodeCommit 仓库中，创建一个包含构建和部署 SAM 应用程序命令的 buildspec.yml 文件。",
      "D": "创建一个 AWS CodeCommit 仓库。创建一个 AWS CodePipeline 管道。在新的源阶段中使用 CodeCommit 仓库启动管道。创建一个配置为金丝雀部署的 AWS CodeDeploy 部署组，部署偏好类型为 Canary10Percent10Minutes。将 AWS CloudFormation 模板和源代码上传到 CodeCommit 仓库。在 CodeCommit 仓库中，创建一个包含部署 CloudFormation 模板命令的 appspec.yml 文件。",
      "E": "为所有 Lambda 函数创建一个 Amazon CloudWatch 综合警报。为 Lambda 配置评估周期和维度。如果检测到任何错误或数据不足，配置警报进入 ALARM 状态。",
      "F": "为每个 Lambda 函数创建一个 Amazon CloudWatch 警报。配置警报在检测到任何错误时进入 ALARM 状态。配置评估周期，为每个 Lambda 函数和版本配置维度，以及将命名空间配置为 AWS/Lambda 的 Errors 指标。"
    },
    "best": ["B", "C", "D"],
    "analysis": {
      "A": "虽然这个选项使用了 CloudFormation 和 Lambda 版本，但它没有提供自动化的金丝雀部署和回滚机制。",
      "B": "这个选项使用 AWS SAM，它支持自动化的金丝雀部署和回滚，符合题目要求。",
      "C": "这个选项创建了一个完整的 CI/CD 管道，包括代码存储、构建和部署，适用于自动化部署。",
      "D": "这个选项通过 CodeDeploy 实现了金丝雀部署，符合题目要求。",
      "E": "这个选项创建了警报，但没有涉及到部署和回滚的自动化。",
      "F": "这个选项同样只涉及到警报，没有包括自动化部署和回滚。"
    },
    "service": [
      "AWS Lambda",
      "AWS CloudFormation",
      "AWS Serverless Application Model (AWS SAM)",
      "AWS CodeCommit",
      "AWS CodePipeline",
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "Amazon CloudWatch"
    ],
    "reason": "1.4"
  },
  {
    "no": 87,
    "question": "在 VPC 中运行的 Amazon EC2 实例需要从受限的 Amazon S3 存储桶下载一个对象。当 DevOps 工程师尝试下载该对象时，收到一个 AccessDenied 错误。这个错误的可能原因是什么？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "S3 存储桶默认加密已启用。",
      "B": "S3 存储桶策略中存在错误。",
      "C": "该对象已被移动到 S3 Glacier。",
      "D": "IAM 角色配置中存在错误。",
      "E": "S3 版本控制已启用。"
    },
    "best": ["B", "D"],
    "analysis": {
      "A": "S3 存储桶的默认加密启用与访问权限无直接关联，因此不是导致 AccessDenied 错误的原因。",
      "B": "如果 S3 存储桶策略配置错误，可能会错误地限制访问权限，导致无法下载对象。",
      "C": "对象移动到 S3 Glacier 主要影响检索时间而非访问权限，因此不是此错误的直接原因。",
      "D": "IAM 角色配置错误可能导致 EC2 实例没有足够的权限访问 S3 存储桶中的对象。",
      "E": "S3 版本控制的启用主要用于管理对象的不同版本，与访问权限无直接关系，因此不是导致 AccessDenied 错误的原因。"
    },
    "service": ["Amazon EC2", "Amazon S3", "IAM"],
    "reason": "6.1"
  },
  {
    "no": 84,
    "question": "一家公司有一个指导方针，规定每个 Amazon EC2 实例必须从公司安全团队生成的 AMI 启动。每个月，安全团队都会通过电子邮件向所有开发团队发送最新批准的 AMI。开发团队使用 AWS CloudFormation 部署他们的应用程序。当开发人员启动新服务时，他们必须搜索电子邮件以找到安全部门发送的最新 AMI。一位 DevOps 工程师希望自动化安全团队向开发团队提供 AMI ID 的过程。哪种解决方案最具可扩展性，同时满足这些要求？",
    "choose": 1,
    "options": {
      "A": "指导安全团队使用 CloudFormation 创建 AMI 的新版本，并在堆栈的 Outputs 部分列出加密的 Amazon S3 对象中的 AMI ARN。指导开发人员使用跨堆栈引用来加载加密的 S3 对象并获取最新的 AMI ARN。",
      "B": "指导安全团队使用 CloudFormation 堆栈创建一个 AWS CodePipeline 管道，该管道构建新的 AMI 并将最新的 AMI ARN 放置在管道输出的加密 Amazon S3 对象中。指导开发人员在他们自己的 CloudFormation 模板中使用跨堆栈引用来获取 S3 对象位置和最新的 AMI ARN。",
      "C": "指导安全团队使用 Amazon EC2 Image Builder 创建新的 AMI，并将 AMI ARN 作为参数放置在 AWS Systems Manager 参数存储中。指导开发人员在他们的 CloudFormation 堆栈中指定一个类型为 SSM 的参数，以从参数存储中获取最新的 AMI ARN。",
      "D": "指导安全团队使用 Amazon EC2 Image Builder 创建新的 AMI，并创建一个 Amazon Simple Notification Service (Amazon SNS) 主题，以便每个开发团队都可以接收通知。当开发团队接收到通知时，指导他们编写一个 AWS Lambda 函数，该函数将更新他们的 CloudFormation 堆栈以包含最新的 AMI ARN。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然使用 CloudFormation 和 S3 对象是一个可行的方法，但它涉及到跨堆栈引用和加密对象的管理，这可能增加复杂性。",
      "B": "这个选项也涉及到使用 CodePipeline 和 CloudFormation，但同样增加了管理复杂性，尤其是在处理跨堆栈引用和管道输出时。",
      "C": "这是最佳选项，因为它使用 Amazon EC2 Image Builder 自动创建 AMI，并使用 AWS Systems Manager 参数存储来管理 AMI ARN，这简化了开发人员在 CloudFormation 中获取最新 AMI 的过程。",
      "D": "这个选项涉及到创建 SNS 主题和编写 Lambda 函数，这增加了额外的开发和管理工作，而且不如直接从参数存储中获取 AMI ARN 那样直接有效。"
    },
    "service": [
      "Amazon EC2",
      "AWS CloudFormation",
      "Amazon S3",
      "AWS CodePipeline",
      "Amazon EC2 Image Builder",
      "AWS Systems Manager",
      "Amazon Simple Notification Service (Amazon SNS)",
      "AWS Lambda"
    ],
    "reason": "2.1"
  },
  {
    "no": 88,
    "question": "一家公司希望在 AWS 上为其专有企业内存数据存储使用网格系统。该系统可以在任何基于 Linux 的发行版中的多个服务器节点上运行。每次添加或删除节点时，系统必须能够重新配置整个集群。添加或删除节点时，必须更新 /etc/cluster/nodes.config 文件，列出该集群的当前节点成员的 IP 地址。公司希望自动化添加新节点到集群的任务。DevOps 工程师可以做什么来满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS OpsWorks Stacks 来分层集群的服务器节点。创建一个 Chef 配方，用于填充 /etc/cluster/nodes.config 文件的内容，并使用该层的当前成员重启服务。将该配方分配给配置生命周期事件。",
      "B": "将 nodes.config 文件放入版本控制中。基于 Amazon EC2 标签值为集群节点创建一个 AWS CodeDeploy 部署配置和部署组。添加新节点到集群时，更新文件以包含所有标记的实例，并在版本控制中进行提交。部署新文件并重启服务。",
      "C": "创建一个 Amazon S3 存储桶并上传 /etc/cluster/nodes.config 文件的版本。创建一个 crontab 脚本，定期轮询该 S3 文件并下载。使用进程管理器，如 Monit 或 systemd，当检测到新文件被修改时重启集群服务。添加节点到集群时，编辑文件的最新成员。上传新文件到 S3 存储桶。",
      "D": "创建一个用户数据脚本，列出集群的当前安全组的所有成员，并在添加新实例时自动更新 /etc/cluster/nodes.config 文件。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为 AWS OpsWorks Stacks 提供了一个管理应用程序栈的平台，可以使用 Chef 自动化配置管理，适合处理集群节点的动态变化。",
      "B": "这个选项不是最佳的，因为虽然使用 AWS CodeDeploy 可以自动化部署过程，但它主要适用于应用程序部署而不是动态集群配置。",
      "C": "这个选项不是最佳的，因为它依赖于定期轮询和下载配置文件，这可能导致配置更新的延迟，并且处理复杂性较高。",
      "D": "这个选项不是最佳的，因为虽然用户数据脚本可以在实例启动时执行，但它不适合管理一个动态变化的集群配置。"
    },
    "service": [
      "AWS OpsWorks",
      "Chef",
      "AWS CodeDeploy",
      "Amazon EC2",
      "Amazon S3",
      "Monit",
      "systemd"
    ],
    "reason": "2.3"
  },
  {
    "no": 89,
    "question": "一位 DevOps 工程师正在处理一个数据归档项目，该项目需要将本地数据迁移到 Amazon S3 存储桶。DevOps 工程师开发了一个脚本，该脚本逐步将超过 1 个月的本地数据归档到 Amazon S3。传输到 Amazon S3 的数据将从本地位置删除。该脚本使用 S3 PutObject 操作。在代码审查期间，DevOps 工程师注意到该脚本没有验证数据是否成功复制到 Amazon S3。DevOps 工程师必须更新脚本以确保数据在传输过程中不会损坏。该脚本必须使用 MD5 校验和来验证本地数据在删除之前的数据完整性。哪些脚本解决方案能满足这些要求？（选择两个。）",
    "choose": 2,
    "options": {
      "A": "检查返回的响应中的 VersionId。将返回的 VersionId 与 MD5 校验和进行比较。",
      "B": "在 Content-MD5 参数中包含 MD5 校验和。检查操作调用的返回状态以确定是否返回了错误。",
      "C": "在标签参数中作为 URL 查询参数包含校验和摘要。",
      "D": "检查返回的响应中的 ETag。将返回的 ETag 与 MD5 校验和进行比较。",
      "E": "在 Metadata 参数中作为名称-值对包含校验和摘要。上传后，使用 S3 HeadObject 操作从对象检索元数据。"
    },
    "best": ["B", "D"],
    "analysis": {
      "A": "VersionId 用于对象版本控制，与 MD5 校验和无直接关联，因此不适用于验证数据完整性。",
      "B": "Content-MD5 参数用于提供数据的 MD5 校验和，S3 会验证上传的数据的完整性，如果校验和不匹配，操作将失败，返回错误。这是一个有效的方法来确保数据完整性。",
      "C": "在 URL 查询参数中包含校验和摘要不是一个标准的验证数据完整性的方法，且 S3 不会自动使用这些参数来验证数据。",
      "D": "ETag 通常是上传对象的 MD5 校验和（除非对象是多部分上传），可以用来验证数据的完整性。比较 ETag 和本地计算的 MD5 校验和是一个有效的方法。",
      "E": "将校验和存储在元数据中并不会自动验证数据的完整性，需要额外的步骤来检索和比较这些值，这使得它不是一个最优的选择。"
    },
    "service": ["Amazon S3"],
    "reason": "领域 1-SDLC 自动化"
  },
  {
    "no": 86,
    "question": "一家公司有20个服务团队。每个服务团队负责自己的微服务。每个服务团队使用单独的AWS账户为其微服务和一个具有192.168.0.0/22 CIDR块的VPC。公司使用AWS Organizations管理AWS账户。每个服务团队在应用程序负载均衡器后面的多个Amazon EC2实例上托管其微服务。微服务之间通过公共互联网进行通信。公司的安全团队发布了新的指导方针，要求所有微服务之间的通信必须使用HTTPS通过私有网络连接进行，并且不能穿越公共互联网。一名DevOps工程师必须实施一个解决方案以满足这些要求，并最小化每个服务团队的变更数量。哪种解决方案将满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在AWS Organizations中创建一个新的AWS账户。在此账户中创建一个VPC，并使用AWS资源访问管理器共享该VPC的私有子网给组织。指导服务团队启动一个新的网络负载均衡器（NLB）和使用共享的私有子网的EC2实例。使用NLB的DNS名称进行微服务之间的通信。",
      "B": "在每个微服务VPC中创建一个网络负载均衡器（NLB）。使用AWS PrivateLink在每个AWS账户中为NLBs创建VPC端点。在每个其他AWS账户中创建对每个VPC端点的订阅。使用VPC端点的DNS名称进行微服务之间的通信。",
      "C": "在每个微服务VPC中创建一个网络负载均衡器（NLB）。创建每个微服务VPC之间的VPC对等连接。更新每个VPC的路由表以使用对等链接。使用NLB的DNS名称进行微服务之间的通信。",
      "D": "在AWS Organizations中创建一个新的AWS账户。在此账户中创建一个过渡网关，并使用AWS资源访问管理器与组织共享过渡网关。在每个微服务VPC中创建一个到共享过渡网关的过渡网关附件。更新每个VPC的路由表以使用过渡网关。在每个微服务VPC中创建一个网络负载均衡器（NLB）。使用NLB的DNS名称进行微服务之间的通信。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项通过共享私有子网实现了私有网络通信，但需要服务团队进行较大的架构更改，如启动新的NLB和EC2实例。",
      "B": "此选项通过PrivateLink实现了私有网络通信，但需要在每个账户中创建和管理多个VPC端点，这增加了复杂性。",
      "C": "此选项通过VPC对等连接实现了私有网络通信，但对等连接在多个VPC间管理较为复杂，且需要更新多个路由表。",
      "D": "此选项通过创建一个中心过渡网关并共享给所有微服务，简化了网络管理并保持了私有网络通信。此方案最小化了每个服务团队需要做的更改，只需创建过渡网关附件和更新路由表。因此，这是最优选项。"
    },
    "service": [
      "AWS Organizations",
      "Amazon EC2",
      "Application Load Balancer",
      "AWS Resource Access Manager",
      "Network Load Balancer",
      "AWS PrivateLink",
      "VPC Peering",
      "Transit Gateway"
    ],
    "reason": "2.2"
  },
  {
    "no": 94,
    "question": "一家企业有一个应用程序，由五个独立的AWS Lambda函数组成。DevOps工程师使用AWS CodePipeline和AWS CodeBuild构建了一个CI/CD管道，该管道按顺序构建、测试、打包和部署每个Lambda函数。管道使用Amazon EventBridge规则来确保在对应用程序源代码进行更改后尽快启动管道。在使用管道几个月后，DevOps工程师注意到管道完成所需的时间过长。DevOps工程师应该实施什么来最好地提高管道的速度？",
    "choose": 1,
    "options": {
      "A": "修改管道中的CodeBuild项目，使用具有更多可用网络吞吐量的计算类型。",
      "B": "创建一个自定义的CodeBuild执行环境，包括对称多处理配置以并行运行构建。",
      "C": "修改CodePipeline配置，通过指定相同的runOrder，使每个Lambda函数的操作并行运行。",
      "D": "修改每个CodeBuild项目在VPC内运行，并使用专用实例来增加吞吐量。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然增加网络吞吐量可能有助于提高构建速度，但这并不直接解决构建序列化的问题。",
      "B": "自定义执行环境可能提高单个构建的效率，但并行化构建操作更直接地解决了问题。",
      "C": "通过使每个Lambda函数的构建和部署操作并行运行，可以显著减少整个管道的完成时间，这是提高CI/CD管道速度的最直接和有效的方法。",
      "D": "在VPC内运行和使用专用实例可能提高安全性和资源的专用性，但对于减少CI/CD管道的总体时间帮助不大。"
    },
    "service": [
      "AWS Lambda",
      "AWS CodePipeline",
      "AWS CodeBuild",
      "Amazon EventBridge"
    ],
    "reason": "1.1"
  },
  {
    "no": 95,
    "question": "一家公司使用 AWS CloudFormation 堆栈来部署其应用程序的更新。堆栈由不同的资源组成。资源包括 AWS Auto Scaling 组、Amazon EC2 实例、应用程序负载均衡器（ALB）以及启动和维护独立堆栈所需的其他资源。不允许在 CloudFormation 堆栈更新之外更改应用程序资源。该公司最近尝试使用 AWS CLI 更新应用程序堆栈，但更新失败并产生以下错误消息：“错误：部署和 CloudFormation 堆栈回滚均失败。部署失败是因为以下资源无法更新：[AutoScalingGroup]。”堆栈的状态仍然是 UPDATE_ROLLBACK_FAILED。哪种解决方案将解决此问题？",
    "choose": 1,
    "options": {
      "A": "更新为 ALB 配置的子网映射。运行 aws cloudformation update-stack-set AWS CLI 命令。",
      "B": "更新 IAM 角色，提供更新堆栈所需的权限。运行 aws cloudformation continue-update-rollback AWS CLI 命令。",
      "C": "提交增加账户的 EC2 实例数量的配额请求。运行 aws cloudformation cancel-update-stack AWS CLI 命令。",
      "D": "删除 Auto Scaling 组资源。运行 aws cloudformation rollback-stack AWS CLI 命令。"
    },
    "best": ["B"],
    "analysis": {
      "A": "更新 ALB 的子网映射不会解决 Auto Scaling 组更新失败的问题。",
      "B": "更新 IAM 角色以提供必要的权限，并运行 aws cloudformation continue-update-rollback 命令可以解决堆栈更新失败并处于 UPDATE_ROLLBACK_FAILED 状态的问题。",
      "C": "取消更新堆栈并不会解决 Auto Scaling 组更新失败的问题。",
      "D": "删除 Auto Scaling 组资源可能会导致更多问题，而不是解决当前的更新回滚失败问题。"
    },
    "service": [
      "AWS CloudFormation",
      "AWS Auto Scaling",
      "Amazon EC2",
      "Application Load Balancers"
    ],
    "reason": "2.1"
  },
  {
    "no": 91,
    "question": "一家公司开发了一个处理通过 API 接收的订单的 AWS Lambda 函数。该公司使用 AWS CodeDeploy 作为 CI/CD 管道的最后阶段来部署 Lambda 函数。一位 DevOps 工程师注意到，在部署后的几秒钟内，订购 API 会出现间歇性故障。经过一些调查，DevOps 工程师认为这些故障是由于数据库更改尚未完全传播就调用了 Lambda 函数所致。DevOps 工程师应如何克服这个问题？",
    "choose": 1,
    "options": {
      "A": "在 AppSpec 文件中添加 BeforeAllowTraffic 钩子，测试并等待任何必要的数据库更改在流量可以流向 Lambda 函数的新版本之前完成。",
      "B": "在 AppSpec 文件中添加 AfterAllowTraffic 钩子，强制流量等待任何挂起的数据库更改完成后，再允许新版本的 Lambda 函数响应。",
      "C": "在 AppSpec 文件中添加 BeforeInstall 钩子，测试并等待任何必要的数据库更改在部署新版本的 Lambda 函数之前完成。",
      "D": "在 AppSpec 文件中添加 ValidateService 钩子，检查传入流量并拒绝负载，如果依赖的服务（如数据库）尚未准备好的话。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为 BeforeAllowTraffic 钩子允许在流量被路由到新版本的 Lambda 函数之前，确保所有依赖的服务（如数据库）都已准备就绪，从而避免在部署后立即出现服务中断。",
      "B": "这个选项不是最佳的，因为 AfterAllowTraffic 钩子是在流量已经开始流向新版本后才执行，这可能无法防止初始的服务中断。",
      "C": "这个选项虽然考虑到了在部署前进行数据库更改的检查，但 BeforeInstall 钩子通常用于准备部署环境，而不是控制流量。",
      "D": "这个选项不是最佳的，因为 ValidateService 钩子虽然可以在服务层面进行检查，但它不专门用于处理数据库这样的依赖服务的就绪状态。"
    },
    "service": ["AWS Lambda", "AWS CodeDeploy"],
    "reason": "1.4"
  },
  {
    "no": 90,
    "question": "一家公司每周几次通过使用 AWS CodePipeline 管道部署其 Amazon API Gateway API 的更新。作为更新过程的一部分，该公司从 API Gateway 控制台导出 API 的 JavaScript SDK，并将 SDK 上传到 Amazon S3 存储桶。公司配置了一个使用 S3 存储桶作为源的 Amazon CloudFront 分发。然后，Web 客户端通过使用 CloudFront 分发的端点下载 SDK。一位 DevOps 工程师需要实施一个解决方案，以在新的 API 部署期间自动使新的 SDK 可用。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在 API 的部署阶段之后立即创建一个 CodePipeline 操作。配置该操作以调用一个 AWS Lambda 函数。配置 Lambda 函数以从 API Gateway 下载 SDK，将 SDK 上传到 S3 存储桶，并为 SDK 路径创建一个 CloudFront 失效。",
      "B": "在 API 的部署阶段之后立即创建一个 CodePipeline 操作。配置该操作使用 CodePipeline 与 API Gateway 的集成来导出 SDK 到 Amazon S3。创建另一个操作，使用 CodePipeline 与 Amazon S3 的集成来使 SDK 路径的缓存失效。",
      "C": "创建一个 Amazon EventBridge 规则，该规则对来自 aws.apigateway 的 UpdateStage 事件做出反应。配置规则以调用一个 AWS Lambda 函数来从 API Gateway 下载 SDK，将 SDK 上传到 S3 存储桶，并调用 CloudFront API 为 SDK 路径创建失效。",
      "D": "创建一个 Amazon EventBridge 规则，该规则对来自 aws.apigateway 的 CreateDeployment 事件做出反应。配置规则以调用一个 AWS Lambda 函数来从 API Gateway 下载 SDK，将 SDK 上传到 S3 存储桶，并调用 S3 API 使 SDK 路径的缓存失效。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它直接在 CodePipeline 中集成了 Lambda 函数来处理 SDK 的下载、上传和 CloudFront 缓存失效，确保了自动化和流程的连续性。",
      "B": "此选项不是最佳选择，因为 CodePipeline 目前没有直接与 API Gateway 和 S3 的集成来导出 SDK 和处理缓存失效。",
      "C": "此选项虽然使用了 EventBridge 和 Lambda，但它依赖于 UpdateStage 事件，这可能不会在每次部署时触发，因此可能不会总是有效。",
      "D": "此选项不是最佳选择，因为它错误地提到了调用 S3 API 来使缓存失效，而实际上应该是调用 CloudFront API。"
    },
    "service": [
      "AWS CodePipeline",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon S3",
      "Amazon CloudFront",
      "Amazon EventBridge"
    ],
    "reason": "1.4"
  },
  {
    "no": 92,
    "question": "一家公司使用单一AWS账户在Amazon EC2实例上测试应用程序。该公司已在AWS账户中启用AWS Config，并激活了restricted-ssh AWS Config管理规则。该公司需要一个自动化监控解决方案，如果账户中的任何安全组不符合restricted-ssh规则，该解决方案将实时提供自定义通知。自定义通知必须包含不合规安全组的名称和ID。一位DevOps工程师在账户中创建了一个Amazon Simple Notification Service（Amazon SNS）主题，并订阅了适当的人员到该主题。DevOps工程师接下来应该做什么来满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个Amazon EventBridge规则，匹配AWS Config评估结果为NON_COMPLIANT的restricted-ssh规则。为EventBridge规则配置输入转换器。配置EventBridge规则以发布通知到SNS主题。",
      "B": "配置AWS Config将restricted-ssh规则的所有评估结果发送到SNS主题。在SNS主题上配置过滤策略，仅发送包含NON_COMPLIANT文本的通知给订阅者。",
      "C": "创建一个Amazon EventBridge规则，匹配AWS Config评估结果为NON_COMPLIANT的restricted-ssh规则。配置EventBridge规则以调用AWS Systems Manager Run Command在SNS主题上自定义通知并发布通知。",
      "D": "创建一个Amazon EventBridge规则，匹配所有AWS Config评估结果为NON_COMPLIANT的。为restricted-ssh规则配置输入转换器。配置EventBridge规则以发布通知到SNS主题。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它直接匹配了NON_COMPLIANT的restricted-ssh规则，并通过输入转换器自定义通知内容，确保通知包含安全组的名称和ID，然后发布到SNS主题。",
      "B": "此选项不是最佳选择，因为它将所有评估结果发送到SNS主题，这可能包括不必要的数据，增加了处理和过滤的复杂性。",
      "C": "此选项不是最佳选择，因为使用AWS Systems Manager Run Command来自定义通知增加了额外的复杂性和潜在的延迟。",
      "D": "此选项不是最佳选择，因为它匹配所有NON_COMPLIANT结果而不是特定于restricted-ssh规则，可能导致接收到不相关的通知。"
    },
    "service": ["AWS Config", "Amazon SNS", "Amazon EventBridge"],
    "reason": "2.3"
  },
  {
    "no": 98,
    "question": "一家公司在 Auto Scaling 组中的 Amazon EC2 实例上运行应用程序。最近发生了一个问题，导致 EC2 实例无法成功启动，并且支持团队花了几个小时才发现问题。支持团队希望在 EC2 实例未能成功启动时通过电子邮件得到通知。哪项操作可以实现这一目标？",
    "choose": 1,
    "options": {
      "A": "向 Auto Scaling 组添加健康检查，以在实例状态受损时调用 AWS Lambda 函数。",
      "B": "配置 Auto Scaling 组在发生实例启动失败时发送通知到 Amazon SNS 主题。",
      "C": "创建一个 Amazon CloudWatch 警报，当发生失败的 AttachInstances Auto Scaling API 调用时调用 AWS Lambda 函数。",
      "D": "在 Amazon EC2 上创建状态检查警报，以在状态检查失败时发送通知到 Amazon SNS 主题。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然这个选项提到了健康检查和 Lambda 函数，但它并没有涉及到通过电子邮件发送通知的部分。",
      "B": "这是最佳选项，因为它直接涉及到在实例启动失败时通过 SNS 主题发送通知，这可以配置为发送电子邮件。",
      "C": "这个选项涉及到 CloudWatch 警报和 Lambda 函数，但是它是针对 AttachInstances API 调用失败，而不是实例启动失败。",
      "D": "这个选项虽然涉及到 EC2 状态检查和 SNS 主题，但是它是针对状态检查失败，而不是特定于实例启动失败。"
    },
    "service": [
      "Amazon EC2",
      "Auto Scaling",
      "AWS Lambda",
      "Amazon SNS",
      "Amazon CloudWatch"
    ],
    "reason": "4.3"
  },
  {
    "no": 96,
    "question": "一家公司正在部署一个新应用，该应用使用 Amazon EC2 实例。公司需要一个解决方案来查询应用日志和 AWS 账户 API 活动。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 Amazon CloudWatch 代理将 EC2 实例的日志发送到 Amazon CloudWatch 日志。配置 AWS CloudTrail 将 API 日志传送到 Amazon S3。使用 CloudWatch 查询这两组日志。",
      "B": "使用 Amazon CloudWatch 代理将 EC2 实例的日志发送到 Amazon CloudWatch 日志。配置 AWS CloudTrail 将 API 日志传送到 CloudWatch 日志。使用 CloudWatch 日志洞察力查询这两组日志。",
      "C": "使用 Amazon CloudWatch 代理将 EC2 实例的日志发送到 Amazon Kinesis。配置 AWS CloudTrail 将 API 日志传送到 Kinesis。使用 Kinesis 将数据加载到 Amazon Redshift。使用 Amazon Redshift 查询这两组日志。",
      "D": "使用 Amazon CloudWatch 代理将 EC2 实例的日志发送到 Amazon S3。使用 AWS CloudTrail 将 API 日志传送到 Amazon S3。使用 Amazon Athena 查询 Amazon S3 中的这两组日志。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然可以使用 CloudWatch 和 S3 查询日志，但 CloudWatch 本身不支持直接查询 S3 中的日志。",
      "B": "这是最佳选项，因为它使用 CloudWatch Logs 和 CloudTrail 的组合，并利用 CloudWatch Logs Insights 进行高效查询，这是处理日志数据的推荐方法。",
      "C": "虽然这种方法可以工作，但它涉及多个服务和步骤，使得解决方案复杂且成本较高。",
      "D": "使用 Athena 查询 S3 是可行的，但这需要额外的步骤来设置和维护 Athena，而且不如直接在 CloudWatch 中查询那样简单直接。"
    },
    "service": [
      "Amazon EC2",
      "Amazon CloudWatch",
      "AWS CloudTrail",
      "Amazon S3",
      "CloudWatch Logs Insights",
      "Amazon Kinesis",
      "Amazon Redshift",
      "Amazon Athena"
    ],
    "reason": "4.1"
  },
  {
    "no": 93,
    "question": "一家公司要求其数据和应用程序在任何时候都有2小时的恢复点目标（RPO）和10分钟的恢复时间目标（RTO）。一个应用程序使用MySQL数据库和Amazon EC2 Web服务器。开发团队需要一个故障转移和灾难恢复的策略。哪种部署策略组合能满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "在一个可用区跨多个区域创建一个Amazon Aurora集群作为数据存储。在灾难发生时使用Aurora的自动恢复能力。",
      "B": "在两个区域创建一个Amazon Aurora全球数据库作为数据存储。在发生故障时，将次要区域提升为应用程序的主要区域。",
      "C": "在多个区域创建一个Amazon Aurora多主集群作为数据存储。使用网络负载均衡器在不同区域平衡数据库流量。",
      "D": "在两个区域设置应用程序，并使用Amazon Route 53基于故障转移的路由指向两个区域的应用程序负载均衡器。使用健康检查来确定给定区域的可用性。在每个区域使用自动扩展组根据需求调整容量。",
      "E": "在两个区域设置应用程序，并使用跨多个区域的自动扩展组在应用程序负载均衡器后面管理基于需求的容量。在灾难发生时，调整自动扩展组的期望实例数量以增加故障转移区域的基线容量。"
    },
    "best": ["B", "D"],
    "analysis": {
      "A": "虽然Amazon Aurora的自动恢复能力是一个优点，但单一可用区的部署不能提供足够的地理冗余来满足10分钟的RTO要求。",
      "B": "Amazon Aurora全球数据库可以在两个区域之间提供数据复制和低延迟，使得在主要区域发生故障时可以快速提升次要区域为主要区域，满足10分钟的RTO和2小时的RPO要求。",
      "C": "多主集群提供了高可用性，但在灾难恢复方面可能不如全球数据库那样快速有效。",
      "D": "使用Amazon Route 53的故障转移路由和健康检查，结合自动扩展组，可以确保在一个区域不可用时快速切换到另一个区域，满足10分钟的RTO要求。",
      "E": "虽然跨区域的自动扩展可以提供一定的灾难恢复能力，但它依赖于手动调整实例数量，可能无法在10分钟内完成故障转移。"
    },
    "service": [
      "Amazon Aurora",
      "Amazon EC2",
      "Amazon Route 53",
      "Auto Scaling"
    ],
    "reason": "3.3"
  },
  {
    "no": 97,
    "question": "一家公司希望确保他们的 EC2 实例是安全的。他们希望在发现实例上的任何新漏洞时得到通知，并且还希望对实例上的所有登录活动进行审计跟踪。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS Systems Manager 检测 EC2 实例上的漏洞。安装 Amazon Kinesis Agent 来捕获系统日志并将其传送到 Amazon S3。",
      "B": "使用 AWS Systems Manager 检测 EC2 实例上的漏洞。安装 Systems Manager Agent 来捕获系统日志并在 CloudTrail 控制台中查看登录活动。",
      "C": "配置 Amazon CloudWatch 以检测 EC2 实例上的漏洞。安装 AWS Config 守护程序以捕获系统日志并在 AWS Config 控制台中查看。",
      "D": "配置 Amazon Inspector 以检测 EC2 实例上的漏洞。安装 Amazon CloudWatch Agent 来捕获系统日志并通过 Amazon CloudWatch Logs 记录。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然 AWS Systems Manager 可以用于管理和检测 EC2 实例，但 Amazon Kinesis Agent 主要用于数据流处理，不适合直接用于安全审计和漏洞检测。",
      "B": "AWS Systems Manager 可以检测漏洞，但 Systems Manager Agent 并不直接支持在 CloudTrail 控制台查看登录活动，这不符合题目要求。",
      "C": "Amazon CloudWatch 主要用于监控和警报，而不是直接检测漏洞。AWS Config 守护程序用于配置记录和评估，并不适合直接用于漏洞检测。",
      "D": "Amazon Inspector 专门用于安全漏洞检测，而 Amazon CloudWatch Agent 可以捕获系统日志并通过 CloudWatch Logs 进行记录，完全符合题目要求。"
    },
    "service": [
      "AWS Systems Manager",
      "Amazon Kinesis Agent",
      "Amazon S3",
      "CloudTrail",
      "Amazon CloudWatch",
      "AWS Config",
      "Amazon Inspector",
      "Amazon CloudWatch Agent",
      "Amazon CloudWatch Logs"
    ],
    "reason": "4.2"
  },
  {
    "no": 105,
    "question": "一位 DevOps 工程师使用 AWS CloudFormation 自定义资源来设置 AD Connector。AWS Lambda 函数运行并创建了 AD Connector，但 CloudFormation 没有从 CREATE_IN_PROGRESS 转变为 CREATE_COMPLETE。工程师应采取哪些措施来解决这个问题？",
    "choose": 1,
    "options": {
      "A": "确保 Lambda 函数代码已成功退出。",
      "B": "确保 Lambda 函数代码返回响应到预签名的 URL。",
      "C": "确保 Lambda 函数 IAM 角色具有 cloudformation:UpdateStack 权限以用于堆栈 ARN。",
      "D": "确保 Lambda 函数 IAM 角色具有 ds:ConnectDirectory 权限以用于 AWS 账户。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然确保 Lambda 函数成功退出是一个好的实践，但它并不直接影响 CloudFormation 的状态转换。",
      "B": "当使用 CloudFormation 自定义资源时，Lambda 函数需要向预签名的 URL 发送响应，以通知 CloudFormation 自定义资源的创建、更新或删除操作已完成。这是解决问题的正确方法。",
      "C": "cloudformation:UpdateStack 权限允许更新堆栈，但在这种情况下，问题是 Lambda 函数没有向 CloudFormation 发送完成信号。",
      "D": "ds:ConnectDirectory 权限允许连接目录服务，但与 CloudFormation 状态转换无关。"
    },
    "service": ["AWS CloudFormation", "AWS Lambda", "AD Connector"],
    "reason": "2.1"
  },
  {
    "no": 99,
    "question": "一家公司正在使用 AWS Organizations 来集中管理其 AWS 账户。该公司已通过使用 AWS CloudFormation StackSets 在每个成员账户中启用了 AWS Config。公司已为 AWS Config 配置了 Organizations 的受信任访问，并已配置一个成员账户作为 AWS Config 的委托管理员账户。一位 DevOps 工程师需要实施一项新的安全政策。该政策必须要求所有当前和未来的 AWS 成员账户使用包含从中央账户管理的修正操作的 AWS Config 规则的共同基线。无法修改部署到每个成员账户中的这些 AWS Config 规则的共同基线的非管理员用户。哪种解决方案将满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个包含 AWS Config 规则和修正操作的 CloudFormation 模板。通过使用 CloudFormation StackSets 从组织管理账户部署模板。",
      "B": "创建一个包含 AWS Config 规则和修正操作的 AWS Config 合规性包。通过使用 CloudFormation StackSets 从组织管理账户部署包。",
      "C": "创建一个包含 AWS Config 规则和修正操作的 CloudFormation 模板。通过使用 AWS Config 从委托管理员账户部署模板。",
      "D": "创建一个包含 AWS Config 规则和修正操作的 AWS Config 合规性包。通过使用 AWS Config 从委托管理员账户部署包。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然这个选项使用了 CloudFormation StackSets，但它没有利用 AWS Config 的合规性包功能，这是为了集中管理和自动化修正操作而设计的。",
      "B": "这是最佳选项，因为 AWS Config 合规性包允许集中管理 AWS Config 规则和修正操作，并且可以通过 CloudFormation StackSets 从组织管理账户部署，确保所有成员账户都应用相同的配置，且非管理员用户无法修改。",
      "C": "这个选项没有利用 AWS Organizations 的集中管理能力，而是从委托管理员账户部署，这不符合要求中的“从中央账户管理”的指示。",
      "D": "虽然使用了 AWS Config 合规性包，但是从委托管理员账户部署不符合要求中的“从中央账户管理”的指示。"
    },
    "service": [
      "AWS Organizations",
      "AWS Config",
      "AWS CloudFormation",
      "CloudFormation StackSets"
    ],
    "reason": "2.2"
  },
  {
    "no": 100,
    "question": "一位 DevOps 工程师管理着一个运行在 Amazon EC2 上的大型商业网站。该网站使用 Amazon Kinesis Data Streams 收集和处理网络日志。DevOps 工程师管理着 Kinesis 消费者应用程序，该应用程序也运行在 Amazon EC2 上。数据的突然增加导致 Kinesis 消费者应用程序落后，Kinesis 数据流在记录能被处理之前丢弃了记录。DevOps 工程师必须实施一个解决方案来改善流处理。哪种解决方案在操作效率上最高？",
    "choose": 1,
    "options": {
      "A": "修改 Kinesis 消费者应用程序，将日志持久存储在 Amazon S3 中。使用 Amazon EMR 直接在 Amazon S3 上处理数据以获取客户洞察。将结果存储在 Amazon S3 中。",
      "B": "通过基于 Amazon CloudWatch GetRecords.IteratorAgeMilliseconds 指标增加更多 EC2 实例来水平扩展 Kinesis 消费者应用程序。增加 Kinesis 数据流的保留期。",
      "C": "将 Kinesis 消费者应用程序转换为运行为 AWS Lambda 函数。配置 Kinesis 数据流作为事件源，由 Lambda 函数处理数据流。",
      "D": "增加 Kinesis 数据流的分片数量以增加整体吞吐量，使消费者应用程序更快地处理数据。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项虽然提供了持久存储和批处理的能力，但在处理实时数据流方面可能不如其他选项有效。",
      "B": "此选项通过增加更多的 EC2 实例来处理更多的负载，但这可能导致成本增加，并且在处理突发流量时可能仍然存在延迟。",
      "C": "此选项通过将处理逻辑转移到 AWS Lambda，可以更灵活地处理数据流的突增，Lambda 可以自动扩展以匹配输入流的大小，提供了最高的操作效率。",
      "D": "增加分片可以提高吞吐量，但这需要精确的分片管理和可能导致成本增加，而且不一定能解决数据突增时的处理问题。"
    },
    "service": [
      "Amazon EC2",
      "Amazon Kinesis Data Streams",
      "Amazon S3",
      "Amazon EMR",
      "AWS Lambda",
      "Amazon CloudWatch"
    ],
    "reason": "3.2"
  },
  {
    "no": 104,
    "question": "一家公司被划分为多个团队。每个团队都有一个 AWS 账户，所有账户都在 AWS Organizations 的一个组织中。每个团队必须保留对其 AWS 账户的完全管理权限。每个团队还必须只能访问公司批准使用的 AWS 服务。AWS 服务必须通过请求和批准过程获得批准。DevOps 工程师应如何配置账户以满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS CloudFormation StackSets 在每个账户中配置 IAM 策略以拒绝访问受限制的 AWS 服务。在每个账户中配置 AWS Config 规则以确保策略附加到账户中的 IAM 主体。",
      "B": "使用 AWS Control Tower 将账户配置到组织中的 OUs。配置 AWS Control Tower 启用 AWS IAM Identity Center（AWS 单点登录）。配置 IAM Identity Center 提供管理访问权限。在用户角色上包括拒绝受限制 AWS 服务的策略。",
      "C": "将所有账户置于组织内的一个新的顶级 OU 下。创建一个 SCP 以拒绝访问受限制的 AWS 服务。将 SCP 附加到 OU。",
      "D": "创建一个仅允许访问批准的 AWS 服务的 SCP。将 SCP 附加到组织的根 OU。从组织的根 OU 中移除 FullAWSAccess SCP。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项使用 CloudFormation StackSets 和 AWS Config 规则，但这种方法需要在每个账户中单独配置，可能不如使用 SCP 直接在组织级别控制更有效。",
      "B": "此选项涉及使用 AWS Control Tower 和 IAM Identity Center，但主要关注单点登录和用户角色的管理，而不是直接限制服务访问。",
      "C": "此选项直接使用 SCP 在组织级别限制服务访问，符合题目要求，确保每个团队只能访问批准的服务。",
      "D": "此选项虽然使用了 SCP，但是它涉及到修改根 OU 的 SCP，这可能会影响到组织中所有账户的访问权限，不如选项 C 中直接在新的顶级 OU 中配置更为安全和清晰。"
    },
    "service": [
      "AWS Organizations",
      "AWS CloudFormation",
      "AWS Config",
      "AWS Control Tower",
      "AWS IAM Identity Center",
      "Service Control Policies (SCP)"
    ],
    "reason": "2.2"
  },
  {
    "no": 108,
    "question": "一家大型企业正在 AWS 上部署一个 Web 应用程序。该应用程序在 Application Load Balancer 后面的 Amazon EC2 实例上运行。实例在多个可用区的自动扩展组中运行。应用程序在 Amazon RDS for Oracle DB 实例和 Amazon DynamoDB 中存储数据。开发、测试和生产环境是分开的。在部署过程中获取密码凭证的最安全和最灵活的方式是什么？",
    "choose": 1,
    "options": {
      "A": "从 AWS Systems Manager SecureString 参数中检索访问密钥以访问 AWS 服务。从 Systems Manager SecureString 参数中检索数据库凭证。",
      "B": "使用 EC2 IAM 角色启动 EC2 实例以访问 AWS 服务。从 AWS Secrets Manager 中检索数据库凭证。",
      "C": "从 AWS Systems Manager 纯文本参数中检索访问密钥以访问 AWS 服务。从 Systems Manager SecureString 参数中检索数据库凭证。",
      "D": "使用 EC2 IAM 角色启动 EC2 实例以访问 AWS 服务。将数据库密码存储在应用程序工件中的加密配置文件中。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然使用 Systems Manager SecureString 参数来存储敏感数据是安全的，但使用访问密钥不如使用 IAM 角色灵活和安全。",
      "B": "这是最佳选项，因为使用 EC2 IAM 角色可以更安全地管理权限，并且使用 AWS Secrets Manager 来管理数据库凭证可以提供更好的安全性和灵活性。",
      "C": "使用 Systems Manager 纯文本参数存储访问密钥是不安全的，因为它可能会暴露敏感信息。",
      "D": "虽然使用加密配置文件可以提供一定的安全性，但这种方法不如直接使用 AWS Secrets Manager 灵活和安全。"
    },
    "service": [
      "Amazon EC2",
      "Application Load Balancer",
      "Auto Scaling",
      "Amazon RDS",
      "Oracle DB",
      "Amazon DynamoDB",
      "AWS Systems Manager",
      "AWS Secrets Manager",
      "IAM"
    ],
    "reason": "6.1"
  },
  {
    "no": 101,
    "question": "一家公司最近在 AWS Organizations 的新组织中创建了一个新的 AWS Control Tower 登陆区。登陆区必须能够展示与互联网安全中心（CIS）基准的 AWS 基础设施的合规性。公司的安全团队希望使用 AWS Security Hub 查看所有账户的合规性。只有安全团队可以被允许查看聚合的 Security Hub 发现。此外，特定用户必须能够查看他们自己账户内的发现。所有账户在创建后必须注册到 Security Hub。哪种步骤组合以最自动化的方式满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "在组织的管理账户中开启 Security Hub 的受信任访问。使用 AWS Control Tower 创建一个新的安全账户。将新的安全账户配置为 Security Hub 的委托管理员账户。在新的安全账户中，为 Security Hub 提供 CIS 基准的 AWS 基础设施标准。",
      "B": "在组织的管理账户中开启 Security Hub 的受信任访问。从管理账户为 Security Hub 提供 CIS 基准的 AWS 基础设施标准。",
      "C": "创建一个 AWS IAM 身份中心（AWS Single Sign-On）权限集，包括所需的权限。使用 CreateAccountAssignment API 操作将安全团队用户与权限集和委托的安全账户关联。",
      "D": "创建一个 SCP，明确拒绝任何不在安全团队中的用户访问 Security Hub。",
      "E": "在 Security Hub 中开启自动启用。",
      "F": "在组织的管理账户中创建一个 Amazon EventBridge 规则，该规则对 CreateManagedAccount 事件做出反应。创建一个 AWS Lambda 函数，使用 Security Hub 的 CreateMembers API 操作将新账户添加到 Security Hub。配置 EventBridge 规则以调用 Lambda 函数。"
    },
    "best": ["A", "E", "F"],
    "analysis": {
      "A": "这是最优选项，因为它涉及创建一个专门的安全账户并将其设置为 Security Hub 的委托管理员，这有助于集中管理和查看所有账户的安全发现。",
      "B": "这不是最优选项，因为它没有提到创建专门的安全账户，这可能导致安全管理和权限控制不够集中。",
      "C": "这不是最优选项，因为它主要关注权限设置而不是自动化 Security Hub 的账户注册。",
      "D": "这不是最优选项，因为它只是限制访问而没有提供自动化的解决方案来注册账户和管理安全标准。",
      "E": "这是最优选项，因为自动启用确保所有新账户都会自动注册到 Security Hub，这有助于自动化合规性监控。",
      "F": "这是最优选项，因为它提供了一种自动化方式来确保所有新创建的账户都被添加到 Security Hub，从而实现自动合规性监控。"
    },
    "service": [
      "AWS Control Tower",
      "AWS Organizations",
      "AWS Security Hub",
      "AWS IAM Identity Center",
      "Amazon EventBridge",
      "AWS Lambda"
    ],
    "reason": "2.2"
  },
  {
    "no": 103,
    "question": "一家公司的 DevOps 工程师在多账户环境中工作。该公司使用 AWS Transit Gateway 将所有出站流量通过网络运营账户路由。在网络运营账户中，所有账户流量在流向互联网网关之前都会通过防火墙设备进行检查。防火墙设备将日志发送到 Amazon CloudWatch Logs，并包括 CRITICAL、HIGH、MEDIUM、LOW 和 INFO 的事件严重性。安全团队希望在发生任何 CRITICAL 事件时收到警报。DevOps 工程师应该做什么来满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 Amazon CloudWatch Synthetics canary 来监控防火墙状态。如果防火墙达到 CRITICAL 状态或记录 CRITICAL 事件，使用 CloudWatch 警报发布通知到 Amazon Simple Notification Service (Amazon SNS) 主题。订阅安全团队的电子邮件地址到该主题。",
      "B": "使用搜索 CRITICAL 事件的 Amazon CloudWatch 指标过滤器创建一个。发布一个自定义指标以进行查找。使用基于自定义指标的 CloudWatch 警报发布通知到 Amazon Simple Notification Service (Amazon SNS) 主题。订阅安全团队的电子邮件地址到该主题。",
      "C": "在网络运营账户中启用 Amazon GuardDuty。配置 GuardDuty 监控流日志。创建一个由 GuardDuty 事件触发的 CRITICAL 的 Amazon EventBridge 事件规则。定义一个 Amazon Simple Notification Service (Amazon SNS) 主题作为目标。订阅安全团队的电子邮件地址到该主题。",
      "D": "使用 AWS Firewall Manager 应用跨所有账户的一致策略。创建一个由 Firewall Manager 事件触发的 CRITICAL 的 Amazon EventBridge 事件规则。定义一个 Amazon Simple Notification Service (Amazon SNS) 主题作为目标。订阅安全团队的电子邮件地址到该主题。"
    },
    "best": ["B"],
    "analysis": {
      "A": "这个选项不是最佳选择，因为 CloudWatch Synthetics canary 主要用于监控网页或 API 的可用性和延迟，而不是处理日志和事件监控。",
      "B": "这是最佳选择，因为它直接使用 CloudWatch Logs 中的日志数据创建指标过滤器来搜索 CRITICAL 事件，并通过 CloudWatch 警报和 SNS 主题来通知安全团队。",
      "C": "这个选项不是最佳选择，因为 GuardDuty 主要用于威胁检测和持续监控，而不是专门用于处理特定日志文件中的事件。",
      "D": "这个选项不是最佳选择，因为 AWS Firewall Manager 主要用于管理防火墙规则，而不是处理特定的日志事件或创建警报。"
    },
    "service": [
      "AWS Transit Gateway",
      "Amazon CloudWatch Logs",
      "Amazon SNS",
      "Amazon CloudWatch",
      "Amazon GuardDuty",
      "AWS Firewall Manager",
      "Amazon EventBridge"
    ],
    "reason": "4.2"
  },
  {
    "no": 106,
    "question": "一家公司使用 AWS CodeCommit 进行源代码控制。开发人员将更改应用于各种功能分支，并在更改准备好投入生产时创建拉取请求以将这些更改移动到主分支。开发人员不应能够直接将更改推送到主分支。该公司将 AWSCodeCommitPowerUser 托管策略应用于开发人员的 IAM 角色，现在这些开发人员可以直接在 AWS 账户中的每个存储库上将更改推送到主分支。公司应该做些什么来限制开发人员直接将更改推送到主分支的能力？",
    "choose": 1,
    "options": {
      "A": "创建一个额外的策略，包括一个拒绝规则，用于 GitPush 和 PutFile 操作。在策略声明中包括针对特定存储库的限制，并附带一个引用主分支的条件。",
      "B": "移除 IAM 策略，并添加一个 AWSCodeCommitReadOnly 托管策略。在策略声明中为特定存储库添加一个允许 GitPush 和 PutFile 操作的规则，并附带一个引用主分支的条件。",
      "C": "修改 IAM 策略。在策略声明中为特定存储库包括一个拒绝 GitPush 和 PutFile 操作的规则，并附带一个引用主分支的条件。",
      "D": "创建一个额外的策略，包括一个允许规则，用于 GitPush 和 PutFile 操作。在策略声明中包括针对特定存储库的限制，并附带一个引用功能分支的条件。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它通过创建一个额外的策略并在其中设置拒绝规则，直接阻止开发人员对主分支执行 GitPush 和 PutFile 操作，这符合题目要求限制直接推送到主分支的能力。",
      "B": "这个选项不是最佳选择，因为它提议移除现有的权限并添加只读权限，这将阻止开发人员在所有分支上进行推送，而不仅仅是主分支。",
      "C": "虽然这个选项也提到了拒绝规则，但它涉及修改现有的 IAM 策略，这可能会影响到其他未提及的权限设置，因此不如选项A中创建额外策略来得安全和清晰。",
      "D": "这个选项不适合，因为它允许对功能分支进行操作，而不是限制对主分支的直接推送，与题目要求不符。"
    },
    "service": ["AWS CodeCommit", "IAM"],
    "reason": "1.1"
  },
  {
    "no": 102,
    "question": "一家公司在 AWS Organizations 中的组织中的 AWS 账户中运行应用程序。这些应用程序使用 Amazon EC2 实例和 Amazon S3。该公司希望检测潜在受损的 EC2 实例、可疑的网络活动和不寻常的 API 活动，无论是在其现有的 AWS 账户中还是在该公司未来创建的任何 AWS 账户中。当公司检测到这些事件之一时，公司希望使用现有的 Amazon Simple Notification Service (Amazon SNS) 主题向其运营支持团队发送通知，以进行调查和补救。哪种解决方案将符合 AWS 最佳实践以满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在组织的管理账户中，将一个 AWS 账户配置为 Amazon GuardDuty 管理员账户。在 GuardDuty 管理员账户中，将公司的现有 AWS 账户添加为 GuardDuty 成员。在 GuardDuty 管理员账户中，创建一个 Amazon EventBridge 规则，其事件模式与 GuardDuty 事件匹配，并将匹配的事件转发到 SNS 主题。",
      "B": "在组织的管理账户中，配置 Amazon GuardDuty 通过邀请添加新创建的 AWS 账户，并向现有的 AWS 账户发送邀请。创建一个 AWS CloudFormation 堆栈集，接受 GuardDuty 邀请并创建 Amazon EventBridge 规则。配置规则的事件模式以匹配 GuardDuty 事件，并将匹配的事件转发到 SNS 主题。配置 CloudFormation 堆栈集以部署到组织中的所有 AWS 账户。",
      "C": "在组织的管理账户中，创建一个 AWS CloudTrail 组织跟踪。在组织中的所有 AWS 账户中激活组织跟踪。创建一个 SCP，使每个账户中的 VPC 流日志启用。为组织配置 AWS Security Hub。创建一个 Amazon EventBridge 规则，其事件模式与 Security Hub 事件匹配，并将匹配的事件转发到 SNS 主题。",
      "D": "在组织的管理账户中，将一个 AWS 账户配置为 AWS CloudTrail 管理员账户。在 CloudTrail 管理员账户中，创建一个 CloudTrail 组织跟踪。将公司的现有 AWS 账户添加到组织跟踪中。创建一个 SCP，使每个账户中的 VPC 流日志启用。为组织配置 AWS Security Hub。创建一个 Amazon EventBridge 规则，其事件模式与 Security Hub 事件匹配，并将匹配的事件转发到 SNS 主题。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它直接使用 Amazon GuardDuty 来检测潜在的威胁和异常行为，并通过 Amazon EventBridge 规则将警报转发到 Amazon SNS，从而实现自动化的监控和响应。这种方法符合 AWS 的最佳实践，可以有效地覆盖新旧账户。",
      "B": "此选项虽然使用了 GuardDuty 和 EventBridge，但通过 CloudFormation 堆栈集的使用增加了复杂性，可能导致部署和管理上的挑战。",
      "C": "此选项使用了 CloudTrail 和 Security Hub，但主要关注于日志和安全状态监控，而不是专门针对 GuardDuty 能够提供的威胁检测和异常行为分析。",
      "D": "此选项与选项 C 类似，也是使用 CloudTrail 和 Security Hub，但同样没有利用 GuardDuty 的专门威胁检测功能，因此不是最佳选择。"
    },
    "service": [
      "AWS Organizations",
      "Amazon EC2",
      "Amazon S3",
      "Amazon SNS",
      "Amazon GuardDuty",
      "Amazon EventBridge",
      "AWS CloudFormation",
      "AWS CloudTrail",
      "AWS Security Hub"
    ],
    "reason": "6.3"
  },
  {
    "no": 107,
    "question": "一家公司管理一个在应用程序负载均衡器（ALB）后面运行的 Amazon EC2 实例的 Web 应用程序。EC2 实例在多个可用区的自动扩展组中运行。该应用程序使用 Amazon RDS for MySQL DB 实例来存储数据。公司已经配置了 Amazon Route 53，并创建了一个指向 ALB 的别名记录。新的公司指导方针要求具有地理隔离的灾难恢复（DR）站点，具有 4 小时的恢复时间目标（RTO）和 15 分钟的恢复点目标（RPO）。哪种 DR 策略将在对应用程序堆栈更改最少的情况下满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在不同可用区启动除 Amazon RDS 之外的所有环境的副本。在新的可用区创建一个 RDS 只读副本，并配置新堆栈指向本地 RDS DB 实例。使用健康检查将新堆栈添加到 Route 53 记录集中，配置故障转移路由策略。",
      "B": "在不同 AWS 区域启动除 Amazon RDS 之外的所有环境的副本。在新区域创建一个 RDS 只读副本，并配置新堆栈指向本地 RDS DB 实例。使用健康检查将新堆栈添加到 Route 53 记录集中，配置延迟路由策略。",
      "C": "在不同 AWS 区域启动除 Amazon RDS 之外的所有环境的副本。在发生故障时，从主区域复制并恢复最新的 RDS 快照到 DR 区域。调整 Route 53 记录集指向 DR 区域的 ALB。",
      "D": "在不同 AWS 区域启动除 Amazon RDS 之外的所有环境的副本。在新区域创建一个 RDS 只读副本，并配置新环境指向本地 RDS DB 实例。使用健康检查将新堆栈添加到 Route 53 记录集中，配置故障转移路由策略。在发生故障时，将只读副本提升为主库。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项不考虑地理隔离，因为它只在不同的可用区而不是不同的区域部署。",
      "B": "此选项使用延迟路由策略，不适用于灾难恢复场景，因为它主要用于优化延迟而不是处理故障转移。",
      "C": "此选项在故障发生时才开始数据恢复过程，可能无法满足 15 分钟的 RPO 要求。",
      "D": "此选项在不同的区域创建环境和 RDS 只读副本，并在故障时提升只读副本为主库，满足地理隔离和快速恢复的需求，是最佳选择。"
    },
    "service": [
      "Amazon EC2",
      "Application Load Balancer",
      "Auto Scaling",
      "Amazon RDS",
      "Amazon Route 53"
    ],
    "reason": "3.3"
  },
  {
    "no": 114,
    "question": "一家公司使用 Amazon S3 存储专有信息。开发团队每天为新项目创建存储桶。安全团队希望确保所有现有和未来的存储桶都启用了加密、日志记录和版本控制。此外，不允许任何存储桶具有公共读写访问权限。DevOps 工程师应该采取什么措施来满足这些要求？",
    "choose": 1,
    "options": {
      "A": "启用 AWS CloudTrail 并使用 AWS Lambda 配置自动修复。",
      "B": "启用 AWS Config 规则并使用 AWS Systems Manager 文档配置自动修复。",
      "C": "启用 AWS Trusted Advisor 并使用 Amazon EventBridge 配置自动修复。",
      "D": "启用 AWS Systems Manager 并使用 Systems Manager 文档配置自动修复。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然 AWS CloudTrail 可以用于监控和记录 API 调用，但它不直接支持自动修复配置问题，如 S3 存储桶的加密和访问策略。",
      "B": "AWS Config 可以评估 AWS 资源的配置并与预期的配置进行比较。通过使用 AWS Systems Manager 文档，可以自动修复不符合要求的配置，如确保 S3 存储桶加密、启用版本控制和日志记录，以及防止公共访问。",
      "C": "AWS Trusted Advisor 提供最佳实践建议，但主要用于成本优化、性能改进等，并不直接支持对资源配置的自动修复。",
      "D": "AWS Systems Manager 主要用于管理和自动化服务器，不直接支持对 S3 存储桶等资源的配置管理和自动修复。"
    },
    "service": [
      "AWS Config",
      "AWS Systems Manager",
      "AWS CloudTrail",
      "AWS Trusted Advisor"
    ],
    "reason": "2.3"
  },
  {
    "no": 109,
    "question": "安全团队依赖 AWS CloudTrail 来检测公司 AWS 账户中的敏感安全问题。DevOps 工程师需要一个解决方案来自动修复 AWS 账户中 CloudTrail 被关闭的问题。哪种解决方案确保 CloudTrail 日志传递的停机时间最少？",
    "choose": 1,
    "options": {
      "A": "为 CloudTrail StopLogging 事件创建一个 Amazon EventBridge 规则。创建一个使用 AWS SDK 调用 StopLogging 被调用的资源的 ARN 上的 StartLogging 的 AWS Lambda 函数。将 Lambda 函数 ARN 添加为 EventBridge 规则的目标。",
      "B": "部署 AWS 管理的启用 CloudTrail 的 AWS Config 规则，设置为每小时的周期性间隔。为 AWS Config 规则合规性变更创建一个 Amazon EventBridge 规则。创建一个使用 AWS SDK 调用 StopLogging 被调用的资源的 ARN 上的 StartLogging 的 AWS Lambda 函数。将 Lambda 函数 ARN 添加为 EventBridge 规则的目标。",
      "C": "为每 5 分钟的计划事件创建一个 Amazon EventBridge 规则。创建一个使用 AWS SDK 在 AWS 账户中调用 CloudTrail 轨迹上的 StartLogging 的 AWS Lambda 函数。将 Lambda 函数 ARN 添加为 EventBridge 规则的目标。",
      "D": "启动一个 t2.nano 实例，运行每 5 分钟使用 AWS SDK 查询当前账户的 CloudTrail 的脚本。如果 CloudTrail 轨迹被禁用，让脚本重新启用轨迹。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最优选项，因为它通过 EventBridge 监控特定的 StopLogging 事件，并立即触发 Lambda 函数来重新启动日志记录，从而减少了停机时间。",
      "B": "这个选项不是最优的，因为它依赖于每小时检查一次的 Config 规则，这可能导致最多一小时的延迟。",
      "C": "这个选项不是最优的，因为它每 5 分钟检查一次，相比选项 A，它的响应时间更长。",
      "D": "这个选项不是最优的，因为它依赖于运行在 EC2 实例上的脚本，这不仅增加了成本，而且效率低下，响应时间也比 Lambda 函数慢。"
    },
    "service": [
      "AWS CloudTrail",
      "Amazon EventBridge",
      "AWS Lambda",
      "AWS SDK",
      "AWS Config",
      "Amazon EC2"
    ],
    "reason": "6.3"
  },
  {
    "no": 111,
    "question": "一家公司使用一系列单独的 Amazon CloudFormation 模板来部署其多区域应用程序。这些模板必须按特定顺序部署。公司对模板的更改比预期的要多，希望更高效地部署新模板。此外，数据工程团队必须被通知所有模板的更改。公司应该怎么做才能实现这些目标？",
    "choose": 1,
    "options": {
      "A": "创建一个 AWS Lambda 函数来按所需顺序部署 CloudFormation 模板。使用堆栈策略来通知数据工程团队。",
      "B": "在 Amazon S3 中托管 CloudFormation 模板。使用 Amazon S3 事件直接触发 CloudFormation 更新和 Amazon SNS 通知。",
      "C": "实施 CloudFormation StackSets 并使用漂移检测来触发更新警报到数据工程团队。",
      "D": "利用 CloudFormation 嵌套堆栈和堆栈集进行部署。使用 Amazon SNS 通知数据工程团队。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然 AWS Lambda 可以自动化部署，但使用堆栈策略来通知数据工程团队不是一个标准的做法，因此这不是最佳选项。",
      "B": "虽然 S3 事件可以触发更新，但这种方法可能不足以处理复杂的部署顺序和通知需求。",
      "C": "StackSets 是一个好的选择，但漂移检测主要用于监控配置漂移，而不是作为通知工具。",
      "D": "嵌套堆栈和堆栈集可以有效管理多区域部署的复杂性，并且使用 Amazon SNS 通知数据工程团队是一个直接且有效的方法。因此，这是最佳选项。"
    },
    "service": [
      "AWS Lambda",
      "Amazon CloudFormation",
      "Amazon S3",
      "Amazon SNS",
      "CloudFormation StackSets"
    ],
    "reason": "2.1"
  },
  {
    "no": 110,
    "question": "一家公司使用 AWS CodeArtifact 来集中存储 Python 包。CodeArtifact 仓库配置了以下仓库策略：一个开发团队正在一个属于 AWS Organizations 组织的账户中构建一个新项目。开发团队希望使用已经存储在组织中的 CodeArtifact 仓库中的一个 Python 库。开发团队使用 AWS CodePipeline 和 AWS CodeBuild 来构建新应用程序。CodeBuild 作业配置为在一个 VPC 中运行。由于合规性要求，该 VPC 没有互联网连接。开发团队为 CodeArtifact 创建了 VPC 终端节点并更新了 CodeBuild buildspec.yaml 文件。然而，开发团队无法从仓库下载 Python 库。开发团队无法从仓库下载 Python 库。DevOps 工程师应采取哪些组合步骤，以便开发团队可以使用 CodeArtifact？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "创建一个 Amazon S3 网关终端节点。更新运行 CodeBuild 作业的子网的路由表。",
      "B": "更新仓库策略的 Principal 语句，包括 CodeBuild 项目使用的角色的 ARN。",
      "C": "使用 AWS 资源访问管理器（AWS RAM）与组织共享 CodeArtifact 仓库。",
      "D": "更新 CodeBuild 项目使用的角色，使该角色具有使用 CodeArtifact 仓库的足够权限。",
      "E": "指定托管仓库的账户作为组织中 CodeArtifact 的委托管理员。"
    },
    "best": ["B", "D"],
    "analysis": {
      "A": "创建 S3 网关终端节点并更新路由表通常用于直接访问 S3，而不是 CodeArtifact。",
      "B": "更新仓库策略以包括 CodeBuild 角色的 ARN 是必要的，以确保该角色可以访问仓库。",
      "C": "共享仓库与组织并不直接解决 VPC 中的访问问题。",
      "D": "确保 CodeBuild 角色有足够的权限访问 CodeArtifact 是必要的，以便从仓库中下载和使用包。",
      "E": "指定委托管理员主要用于管理权限和策略，但不直接影响特定 CodeBuild 作业的访问权限。"
    },
    "service": [
      "AWS CodeArtifact",
      "AWS CodePipeline",
      "AWS CodeBuild",
      "AWS Organizations",
      "AWS Resource Access Manager"
    ],
    "reason": "1.1"
  },
  {
    "no": 115,
    "question": "一位 DevOps 工程师正在研究在 AWS 上实现图像批处理集群的最经济的方法。该应用程序不能在 Docker 容器中运行，必须在 Amazon EC2 上运行。批处理作业在 NFS 卷上存储检查点数据，并且可以容忍中断。从通用 EC2 Linux 映像配置集群软件需要 30 分钟。最具成本效益的解决方案是什么？",
    "choose": 1,
    "options": {
      "A": "使用 Amazon EFS 存储检查点数据。使用 EC2 自动扩展组和按需定价模型临时配置 EC2 实例来完成作业。",
      "B": "在 EC2 实例上使用 GlusterFS 存储检查点数据。手动配置 EC2 实例运行批处理作业。作业完成后，手动关闭实例。",
      "C": "使用 Amazon EFS 存储检查点数据。使用 EC2 Fleet 启动 EC2 Spot 实例，并利用用户数据在启动时配置 EC2 Linux 实例。",
      "D": "使用 Amazon EFS 存储检查点数据。使用 EC2 Fleet 启动 EC2 Spot 实例。创建集群的自定义 AMI，并在创建实例时使用最新的 AMI。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然使用 Amazon EFS 是合适的，但使用按需定价模型的 EC2 实例可能成本较高，不是最经济的选择。",
      "B": "手动配置和关闭实例会增加操作复杂性和可能的人为错误，使用 GlusterFS 而不是 Amazon EFS 也可能增加配置和维护的复杂性。",
      "C": "使用 Spot 实例可以节省成本，但在启动时配置实例可能导致启动延迟，特别是配置时间长达 30 分钟。",
      "D": "使用 Spot 实例节省成本，并通过创建自定义 AMI，可以预先配置集群软件，减少每次启动实例时的配置时间，是最经济且效率高的选择。"
    },
    "service": ["Amazon EC2", "Amazon EFS", "EC2 Fleet", "EC2 Spot Instances"],
    "reason": "1.4"
  },
  {
    "no": 117,
    "question": "一家公司在 Amazon S3 存储桶中存储了 100 GB 的日志数据（.csv 格式）。SQL 开发人员希望查询这些数据并生成图表以进行可视化。SQL 开发人员还需要一种高效的自动化方式来存储来自 .csv 文件的元数据。哪种步骤组合可以以最少的努力满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "通过 AWS X-Ray 过滤数据以可视化数据。",
      "B": "通过 Amazon QuickSight 过滤数据以可视化数据。",
      "C": "使用 Amazon Athena 查询数据。",
      "D": "使用 Amazon Redshift 查询数据。",
      "E": "使用 AWS Glue Data Catalog 作为持久的元数据存储。",
      "F": "使用 Amazon DynamoDB 作为持久的元数据存储。"
    },
    "best": ["B", "C", "E"],
    "analysis": {
      "A": "AWS X-Ray 主要用于分析和调试生产中的应用程序，而不是用于数据可视化。",
      "B": "Amazon QuickSight 是一个快速、易于使用的商业智能服务，适用于构建可视化和进行数据分析，适合 SQL 开发人员的需求。",
      "C": "Amazon Athena 允许直接在 S3 上使用 SQL 查询数据，无需加载或转换数据，非常适合查询大量日志数据。",
      "D": "虽然 Amazon Redshift 是一个强大的数据仓库服务，可以处理大规模数据集，但对于直接在 S3 上查询数据，Athena 是更简单直接的选择。",
      "E": "AWS Glue Data Catalog 提供中央元数据存储库，适用于管理不同数据源的元数据，与 Athena 配合使用可以高效管理和查询数据。",
      "F": "虽然 Amazon DynamoDB 是一个高效的键值和文档数据库，但它不是专为元数据管理设计的，使用 AWS Glue Data Catalog 更合适。"
    },
    "service": ["Amazon QuickSight", "Amazon Athena", "AWS Glue Data Catalog"],
    "reason": "4.1"
  },
  {
    "no": 116,
    "question": "一家公司最近将其传统应用程序从本地迁移到了 AWS。该应用程序托管在 Amazon EC2 实例上，这些实例位于 Application Load Balancer 后面，而 Application Load Balancer 又位于 Amazon API Gateway 后面。公司希望在部署新版本的应用程序时，用户体验到的中断最小。公司还希望能够在出现问题时快速回滚更新。哪种解决方案能够在对应用程序进行最少更改的情况下满足这些要求？",
    "choose": 1,
    "options": {
      "A": "将更改引入作为现有环境的一个单独的并行环境。配置 API Gateway 使用金丝雀发布部署，将少量用户流量发送到新环境。",
      "B": "将更改引入作为现有环境的一个单独的并行环境。更新应用程序的 DNS 别名记录，指向新环境。",
      "C": "将更改引入作为现有 Application Load Balancer 后面的一个单独目标组。配置 API Gateway 以分步路由用户流量到新目标组。",
      "D": "将更改引入作为现有 Application Load Balancer 后面的一个单独目标组。配置 API Gateway 将所有流量路由到 Application Load Balancer，然后将流量发送到新目标组。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为金丝雀发布允许公司向一小部分用户推出新版本，从而最小化风险并在必要时快速回滚。",
      "B": "虽然这种方法引入了一个新环境，但它不允许渐进式部署或快速回滚，因为所有流量都会立即切换到新环境。",
      "C": "这种方法允许分步流量管理，但与金丝雀部署相比，它的控制和灵活性较低。",
      "D": "这种方法将所有流量立即路由到新目标组，增加了风险，不利于快速发现和解决问题。"
    },
    "service": [
      "Amazon EC2",
      "Application Load Balancer",
      "Amazon API Gateway"
    ],
    "reason": "1.4"
  },
  {
    "no": 112,
    "question": "一位 DevOps 工程师实施了一个 CI/CD 管道来部署一个 AWS CloudFormation 模板，该模板提供了一个 Web 应用程序。Web 应用程序包括一个应用程序负载均衡器（ALB）、一个目标组、一个使用 Amazon Linux 2 AMI 的启动模板、一个 Amazon EC2 实例的自动扩展组、一个安全组和一个 Amazon RDS for MySQL 数据库。启动模板包括用户数据，指定了一个脚本来安装和启动应用程序。应用程序的初始部署成功了。DevOps 工程师进行了更改，使用用户数据更新了应用程序的版本。CI/CD 管道已经部署了新版本的模板。然而，ALB 上的健康检查现在失败了。健康检查将所有目标标记为不健康。在调查期间，DevOps 工程师注意到 CloudFormation 堆栈的状态为 UPDATE_COMPLETE。然而，当 DevOps 工程师连接到其中一个 EC2 实例并检查 /var/log/messages 时，他注意到 Apache Web 服务器由于配置错误而未能成功启动。DevOps 工程师如何确保如果用户数据未成功完成运行，CloudFormation 部署将失败？",
    "choose": 1,
    "options": {
      "A": "使用 cfn-signal 帮助脚本向 CloudFormation 发出成功或失败的信号。在 CloudFormation 模板中使用 WaitOnResourceSignals 更新策略。为更新策略设置适当的超时。",
      "B": "为 UnhealthyHostCount 指标创建一个 Amazon CloudWatch 报警。为目标组包括适当的报警阈值。创建一个 Amazon Simple Notification Service (Amazon SNS) 主题作为向 CloudFormation 发出成功或失败信号的目标。",
      "C": "在自动扩展组上创建一个生命周期钩子，使用 AWS::AutoScaling::LifecycleHook 资源。创建一个 Amazon Simple Notification Service (Amazon SNS) 主题作为向 CloudFormation 发出成功或失败信号的目标。在生命周期钩子上设置适当的超时。",
      "D": "使用 Amazon CloudWatch 代理来流式传输 cloud-init 日志。创建一个包括适当调用超时的 AWS Lambda 函数的订阅过滤器。配置 Lambda 函数使用 SignalResource API 操作向 CloudFormation 发出成功或失败的信号。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它直接使用 CloudFormation 的内置机制（cfn-signal 和 WaitOnResourceSignals）来确保堆栈更新仅在用户数据脚本成功执行后才标记为完成。这确保了部署的健壮性和可靠性。",
      "B": "虽然这个选项使用了监控和通知，但它并不直接与 CloudFormation 堆栈的状态集成，因此不能保证堆栈更新仅在用户数据脚本成功执行后才完成。",
      "C": "这个选项涉及到生命周期钩子，这对于管理 EC2 实例的状态转换很有用，但它不直接与 CloudFormation 的部署状态集成，因此不是最佳选择。",
      "D": "这个选项虽然提供了日志监控和 Lambda 函数的使用，但其复杂性较高，且不如选项 A 中直接使用 CloudFormation 的内置功能来得直接有效。"
    },
    "service": [
      "AWS CloudFormation",
      "Amazon EC2",
      "Amazon RDS",
      "Amazon CloudWatch",
      "Amazon SNS",
      "AWS Lambda"
    ],
    "reason": "2.1"
  },
  {
    "no": 119,
    "question": "一家公司正在测试一个在应用程序负载均衡器后面的Amazon EC2实例上运行的Web应用程序。实例在多个可用区的自动扩展组中运行。公司在部署新软件时使用蓝/绿部署过程和不可变实例。在测试期间，用户被随机自动注销应用程序。测试人员还报告说，当部署新版本的应用程序时，所有用户都被注销。开发团队需要一个解决方案，以确保用户在扩展事件和应用程序部署期间保持登录状态。确保用户在这些事件中保持登录状态的最有效的操作方式是什么？",
    "choose": 1,
    "options": {
      "A": "在负载均衡器上启用智能会话，并修改应用程序以检查现有会话。",
      "B": "在负载均衡器上启用会话共享，并修改应用程序以从会话存储中读取。",
      "C": "将用户会话信息存储在Amazon S3存储桶中，并修改应用程序以从存储桶读取会话信息。",
      "D": "修改应用程序以将用户会话信息存储在Amazon ElastiCache集群中。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然启用智能会话可以帮助管理会话，但它不适用于所有应用程序，并且可能需要额外的配置和管理。",
      "B": "会话共享可以在多个实例之间共享会话信息，但它通常依赖于特定的配置和可能不支持所有类型的应用程序。",
      "C": "使用Amazon S3存储会话信息可能会引入额外的延迟，并且对于需要频繁访问和更新会话信息的应用程序来说，可能不是最佳选择。",
      "D": "使用Amazon ElastiCache存储会话信息可以提供快速的数据访问速度和高可用性，适合需要高性能和可扩展性的Web应用程序。这是确保用户会话在多个实例和部署中持续存在的有效方法。"
    },
    "service": [
      "Amazon EC2",
      "Application Load Balancer",
      "Auto Scaling",
      "Amazon S3",
      "Amazon ElastiCache"
    ],
    "reason": "3.2"
  },
  {
    "no": 123,
    "question": "一家媒体公司在一个 AWS 账户中拥有数千个 Amazon EC2 实例。该公司使用 Slack 和共享电子邮件收件箱进行团队沟通和重要更新。一名 DevOps 工程师需要将所有 AWS 计划的 EC2 维护通知发送到 Slack 频道和共享收件箱。解决方案必须包括实例的 Name 和 Owner 标签。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "将 AWS Trusted Advisor 与 AWS Config 集成。配置自定义 AWS Config 规则以调用 AWS Lambda 函数，将通知发布到 Amazon Simple Notification Service (Amazon SNS) 主题。订阅 Slack 频道端点和共享收件箱到该主题。",
      "B": "使用 Amazon EventBridge 监控 AWS Health 事件。配置维护事件以目标为 Amazon Simple Notification Service (Amazon SNS) 主题。订阅一个 AWS Lambda 函数到 SNS 主题，以发送通知到 Slack 频道和共享收件箱。",
      "C": "创建一个 AWS Lambda 函数，将 EC2 维护通知发送到 Slack 频道和共享收件箱。通过使用 Amazon CloudWatch 指标监控 EC2 健康事件。配置一个 CloudWatch 警报，当收到维护通知时调用 Lambda 函数。",
      "D": "配置 AWS 支持与 AWS CloudTrail 集成。创建一个 CloudTrail 查找事件以调用 AWS Lambda 函数，将 EC2 维护通知传递到 Amazon Simple Notification Service (Amazon SNS)。配置 Amazon SNS 以目标为 Slack 频道和共享收件箱。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项不是最佳选择，因为 AWS Trusted Advisor 主要用于提供最佳实践建议，而不是用于处理和转发维护事件通知。",
      "B": "此选项是最佳选择，因为 Amazon EventBridge 可以直接监控 AWS Health 事件，这包括 EC2 维护事件。通过配置 SNS 主题并订阅 Lambda 函数，可以有效地将通知发送到 Slack 和电子邮件。",
      "C": "此选项不是最佳选择，因为它依赖于 CloudWatch 指标和警报来触发维护通知，这可能不如 EventBridge 直接监控 AWS Health 事件那样及时和准确。",
      "D": "此选项不是最佳选择，因为它涉及到使用 CloudTrail 来查找事件，这通常用于审计 API 调用而不是作为处理和转发维护事件通知的主要方法。"
    },
    "service": ["Amazon EventBridge", "Amazon SNS", "AWS Lambda"],
    "reason": "5.1"
  },
  {
    "no": 113,
    "question": "一家公司有一个跨多个AWS账户运行的数据摄取应用程序。这些账户位于AWS组织中的一个组织中。公司需要监控应用程序并整合对应用程序的访问。目前，公司在几个自动扩展组中的Amazon EC2实例上运行应用程序。由于数据敏感，EC2实例无法访问互联网。工程师已部署了必要的VPC端点。EC2实例运行专为该应用程序构建的自定义AMI。为了维护和排除应用程序的故障，系统管理员需要能够登录到EC2实例。这种访问必须是自动化的，并且由中央控制。每当访问实例时，公司的安全团队必须收到通知。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个Amazon EventBridge规则，以便在用户登录到EC2实例时向安全团队发送通知。使用EC2 Instance Connect登录到实例。使用AWS CloudFormation部署自动扩展组。使用cfn-init帮助脚本部署适当的VPC路由以实现外部访问。重建自定义AMI，使自定义AMI包含AWS Systems Manager Agent。",
      "B": "部署一个NAT网关和一个具有互联网访问权限的堡垒主机。创建一个安全组，允许来自堡垒主机的所有EC2实例的传入流量。在所有EC2实例上安装AWS Systems Manager Agent。使用自动扩展组生命周期挂钩进行监控和审计访问。使用Systems Manager Session Manager登录到实例。将日志发送到Amazon CloudWatch Logs中的日志组。将数据导出到Amazon S3进行审计。使用S3事件通知向安全团队发送通知。",
      "C": "使用EC2 Image Builder重建自定义AMI。在映像中包含最新版本的AWS Systems Manager Agent。配置自动扩展组以将AmazonSSMManagedInstanceCore角色附加到所有EC2实例。使用Systems Manager Session Manager登录到实例。启用会话详细信息记录到Amazon S3。为新文件上传创建S3事件通知，通过Amazon Simple Notification Service (Amazon SNS)主题向安全团队发送消息。",
      "D": "使用AWS Systems Manager Automation构建自定义AMI中的Systems Manager Agent。配置AWS Config以附加SCP到根组织账户，允许EC2实例连接到Systems Manager。使用Systems Manager Session Manager登录到实例。启用会话详细信息记录到Amazon S3。为新文件上传创建S3事件通知，通过Amazon Simple Notification Service (Amazon SNS)主题向安全团队发送消息。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它提到了使用cfn-init帮助脚本部署适当的VPC路由以实现外部访问，这与题目中提到的EC2实例无法访问互联网的要求相矛盾。",
      "B": "此选项不是最佳选择，因为它提到了部署NAT网关和堡垒主机，这可能会导致安全问题，尤其是在处理敏感数据的情况下。",
      "C": "此选项是最佳选择，因为它使用EC2 Image Builder来重建自定义AMI，并包含最新版本的AWS Systems Manager Agent，这有助于集中管理和自动化访问。此外，它使用Systems Manager Session Manager来安全地登录到实例，并通过Amazon SNS向安全团队发送访问通知，满足题目的所有要求。",
      "D": "此选项不是最佳选择，因为它涉及配置AWS Config来附加SCP，这可能不是必要的，且可能增加配置复杂性。"
    },
    "service": [
      "AWS Organizations",
      "Amazon EC2",
      "Auto Scaling",
      "VPC",
      "EC2 Instance Connect",
      "AWS CloudFormation",
      "AWS Systems Manager",
      "NAT Gateway",
      "Systems Manager Session Manager",
      "Amazon CloudWatch Logs",
      "Amazon S3",
      "EC2 Image Builder",
      "Amazon Simple Notification Service",
      "AWS Config"
    ],
    "reason": "4.1"
  },
  {
    "no": 122,
    "question": "一家公司正在使用 AWS Organizations 中的组织来管理多个 AWS 账户。公司的开发团队希望使用 AWS Lambda 函数来满足弹性要求，并且正在重写所有应用程序，以便与部署在 VPC 中的 Lambda 函数一起工作。开发团队正在组织中的账户 A 中使用 Amazon Elastic File System (Amazon EFS) 作为共享存储。公司希望继续使用 Amazon EFS 与 Lambda。公司政策要求所有无服务器项目都部署在账户 B 中。DevOps 工程师需要重新配置现有的 EFS 文件系统，以允许 Lambda 函数通过现有的 EFS 访问点访问数据。DevOps 工程师应采取哪些步骤组合来满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "",
      "B": "创建 SCPs 以设置具有细粒度控制的权限护栏，用于 Amazon EFS。",
      "C": "在账户 B 中创建一个新的 EFS 文件系统。使用 AWS 数据库迁移服务 (AWS DMS) 保持账户 A 和账户 B 的数据同步。",
      "D": "更新 Lambda 执行角色，授予其访问 VPC 和 EFS 文件系统的权限。",
      "E": "创建 VPC 对等连接以连接账户 A 和账户 B。",
      "F": "配置账户 B 中的 Lambda 函数以承担账户 A 中的现有 IAM 角色。"
    },
    "best": ["D", "E", "F"],
    "analysis": {
      "A": "虽然 SCPs 可以用于设置权限护栏，但在这种情况下，它们不直接涉及配置 EFS 以供 Lambda 访问。",
      "B": "创建新的 EFS 文件系统并使用 AWS DMS 同步数据是一种可能的解决方案，但这不是最直接或最有效的方法来实现跨账户的 EFS 访问。",
      "C": "创建新的 EFS 文件系统并使用 AWS DMS 同步数据是一种可能的解决方案，但这不是最直接或最有效的方法来实现跨账户的 EFS 访问。",
      "D": "更新 Lambda 执行角色以包括对 EFS 的访问权限是必要的，因为这将允许 Lambda 函数访问存储在 EFS 中的数据。",
      "E": "创建 VPC 对等连接是必要的，因为它允许不同账户中的 VPC 网络互相通信，从而使得账户 B 中的 Lambda 函数可以访问账户 A 中的 EFS。",
      "F": "配置 Lambda 函数以承担账户 A 中的现有 IAM 角色是实现跨账户访问的一种有效方法，这样 Lambda 函数就可以访问账户 A 中的资源，包括 EFS。"
    },
    "service": [
      "AWS Organizations",
      "AWS Lambda",
      "Amazon EFS",
      "AWS Database Migration Service",
      "IAM",
      "VPC"
    ],
    "reason": "3.2"
  },
  {
    "no": 118,
    "question": "一家公司在多个 AWS 区域和可用区中部署了其企业基础设施。基础设施部署在 Amazon EC2 实例上，并与 AWS IoT Greengrass 设备连接。公司在企业总部的本地服务器上部署了额外资源。公司希望减少维护和更新其资源所涉及的开销。公司的 DevOps 团队计划使用 AWS Systems Manager 实现自动化管理和应用补丁。DevOps 团队确认 Systems Manager 在部署资源的区域中可用。Systems Manager 也可用于靠近企业总部的一个区域。DevOps 团队必须采取哪些步骤组合来实现对公司的 EC2 实例、IoT 设备和本地基础设施的自动化补丁和配置管理？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "为所有 EC2 实例、AWS IoT Greengrass 设备和本地服务器应用标签。使用 Systems Manager 会话管理器向所有标记的设备推送补丁。",
      "B": "使用 Systems Manager 运行命令来安排 EC2 实例、AWS IoT Greengrass 设备和本地服务器的补丁。",
      "C": "使用 Systems Manager 补丁管理器安排 EC2 实例、AWS IoT Greengrass 设备和本地服务器的补丁作为 Systems Manager 维护窗口任务。",
      "D": "配置 Amazon EventBridge 以监控 Systems Manager 补丁管理器对补丁基线的更新。将 Systems Manager 运行命令与事件关联，以启动所有 EC2 实例、AWS IoT Greengrass 设备和本地服务器的补丁操作。",
      "E": "为 Systems Manager 创建一个 IAM 实例配置文件。将实例配置文件附加到 AWS 账户中的所有 EC2 实例。对于 AWS IoT Greengrass 设备和本地服务器，创建一个 Systems Manager 的 IAM 服务角色。",
      "F": "生成一个托管实例激活。使用激活代码和激活 ID 在本地环境中的每个服务器上安装 Systems Manager 代理（SSM 代理）。更新 AWS IoT Greengrass IAM 令牌交换角色。使用该角色在所有 IoT 设备上部署 SSM 代理。"
    },
    "best": ["C", "D", "F"],
    "analysis": {
      "A": "此选项不是最佳选择，因为 Systems Manager 会话管理器主要用于启动交互式会话，而不是用于自动化补丁管理。",
      "B": "此选项不是最佳选择，因为虽然 Systems Manager 运行命令可以用于执行脚本和命令，但它不如补丁管理器那样专门用于补丁管理。",
      "C": "此选项是最佳选择，因为 Systems Manager 补丁管理器可以专门用于安排和应用补丁，且可以作为维护窗口任务进行管理。",
      "D": "此选项是最佳选择，因为它利用了 Amazon EventBridge 来监控补丁更新，并通过 Systems Manager 运行命令自动触发补丁操作。",
      "E": "此选项不是最佳选择，因为仅创建 IAM 角色和实例配置文件并不足以实现自动化补丁管理。",
      "F": "此选项是最佳选择，因为它涉及到在本地服务器和 IoT 设备上安装 Systems Manager 代理，这是实现这些设备补丁管理的必要步骤。"
    },
    "service": [
      "AWS Systems Manager",
      "Amazon EC2",
      "AWS IoT Greengrass",
      "Amazon EventBridge"
    ],
    "reason": "2.3"
  },
  {
    "no": 120,
    "question": "一位 DevOps 工程师需要为现有的三层应用配置蓝/绿部署。该应用在 Amazon EC2 实例上运行，并使用 Amazon RDS 数据库。EC2 实例位于应用程序负载均衡器（ALB）后面，并处于自动扩展组中。DevOps 工程师为蓝色环境创建了一个启动模板和一个自动扩展组。DevOps 工程师还为绿色环境创建了一个启动模板和一个自动扩展组。每个自动扩展组都部署到匹配的蓝色或绿色目标组。目标组还指定了哪个软件，蓝色或绿色，加载到 EC2 实例上。ALB 可以配置为将流量发送到蓝色环境的目标组或绿色环境的目标组。Amazon Route 53 记录 www.example.com 指向 ALB。部署必须一次性将流量从蓝色环境的 EC2 实例上的软件移动到绿色环境的 EC2 实例上新部署的软件。DevOps 工程师应该做什么来满足这些要求？",
    "choose": 1,
    "options": {
      "A": "为绿色环境的自动扩展组启动滚动重启以在绿色环境的 EC2 实例上部署新软件。滚动重启完成后，使用 AWS CLI 命令更新 ALB 以将流量发送到绿色环境的目标组。",
      "B": "使用 AWS CLI 命令更新 ALB 以将流量发送到绿色环境的目标组。然后为绿色环境的自动扩展组启动滚动重启以在绿色环境的 EC2 实例上部署新软件。",
      "C": "更新启动模板以在蓝色环境的 EC2 实例上部署绿色环境的软件。保持两个环境的目标组和自动扩展组不变。对蓝色环境的 EC2 实例执行滚动重启。",
      "D": "为绿色环境的自动扩展组启动滚动重启以在绿色环境的 EC2 实例上部署新软件。滚动重启完成后，更新 Route 53 DNS 以指向 ALB 上的绿色环境端点。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它确保了在将流量切换到绿色环境之前，绿色环境的 EC2 实例已经成功部署了新软件。这符合蓝/绿部署的最佳实践，即先确保新环境完全准备就绪再进行流量切换。",
      "B": "这个选项先切换流量再部署新软件，这可能导致在新软件完全部署之前用户访问到未更新的实例，从而影响用户体验。",
      "C": "这个选项提出了在蓝色环境中部署绿色环境的软件，这违背了蓝/绿部署的基本原则，即保持两个独立的环境。",
      "D": "这个选项在滚动重启完成后更新 DNS 而不是 ALB，这可能导致 DNS 缓存问题，用户可能在一段时间内无法访问到新部署的环境。"
    },
    "service": [
      "Amazon EC2",
      "Amazon RDS",
      "Application Load Balancer",
      "Auto Scaling",
      "AWS CLI",
      "Amazon Route 53"
    ],
    "reason": "4.1"
  },
  {
    "no": 121,
    "question": "一家公司正在使用 AWS CodePipeline 和 AWS CodeBuild 在构建账户中构建新的管道。该管道包括两个阶段。第一阶段是一个 CodeBuild 作业，用于构建和打包 AWS Lambda 函数。第二阶段包括在两个不同的 AWS 账户上操作的部署动作：一个开发环境账户和一个生产环境账户。部署阶段使用 CodePipeline 调用的 AWS CloudFormation 动作来部署 Lambda 函数所需的基础设施。DevOps 工程师创建了 CodePipeline 管道，并配置管道使用 AWS Key Management Service (AWS KMS) AWS 管理的密钥为 Amazon S3 (aws/s3 密钥) 加密构建工件。工件存储在 S3 存储桶中。当管道运行时，CloudFormation 动作因访问被拒绝错误而失败。DevOps 工程师必须执行哪两项操作来解决此错误？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "在每个 AWS 账户中创建一个 S3 存储桶用于工件。允许管道写入 S3 存储桶。创建一个 CodePipeline S3 动作将工件复制到每个 AWS 账户中的 S3 存储桶。更新 CloudFormation 动作以引用生产账户中的工件 S3 存储桶。",
      "B": "创建一个客户管理的 KMS 密钥。配置 KMS 密钥策略以允许 CloudFormation 动作使用的 IAM 角色执行解密操作。修改管道以使用客户管理的 KMS 密钥加密工件。",
      "C": "创建一个 AWS 管理的 KMS 密钥。配置 KMS 密钥策略以允许开发账户和生产账户执行解密操作。修改管道以使用 KMS 密钥加密工件。",
      "D": "在开发账户和生产账户中，为 CodePipeline 创建一个 IAM 角色。配置角色具有执行 CloudFormation 操作的权限以及从工件 S3 存储桶检索和解密对象的权限。在 CodePipeline 账户中，配置 CodePipeline CloudFormation 动作以使用这些角色。",
      "E": "在开发账户和生产账户中，为 CodePipeline 创建一个 IAM 角色。配置角色具有执行 CloudFormation 操作的权限以及从工件 S3 存储桶检索和解密对象的权限。在 CodePipeline 账户中，修改工件 S3 存储桶策略以允许角色访问。配置 CodePipeline CloudFormation 动作以使用这些角色。"
    },
    "best": ["B", "E"],
    "analysis": {
      "A": "此选项不涉及解决跨账户 KMS 密钥权限问题，因此不是最佳选择。",
      "B": "此选项通过创建客户管理的 KMS 密钥并配置策略允许 IAM 角色解密，解决了跨账户访问权限问题，是最佳选择之一。",
      "C": "虽然此选项创建了 AWS 管理的 KMS 密钥，但通常 AWS 管理的密钥不允许用户修改策略来允许跨账户访问，因此不是最佳选择。",
      "D": "此选项虽然创建了必要的 IAM 角色，但没有解决 KMS 密钥的跨账户权限问题，因此不是最佳选择。",
      "E": "此选项不仅创建了必要的 IAM 角色，还修改了 S3 存储桶策略和配置了 CloudFormation 动作使用这些角色，解决了权限问题，是最佳选择之一。"
    },
    "service": [
      "AWS CodePipeline",
      "AWS CodeBuild",
      "AWS Lambda",
      "AWS CloudFormation",
      "AWS Key Management Service (AWS KMS)",
      "Amazon S3"
    ],
    "reason": "2.1"
  },
  {
    "no": 126,
    "question": "一家高度受监管的公司有一项政策，即 DevOps 工程师除非在紧急情况下，否则不得登录其 Amazon EC2 实例。如果 DevOps 工程师确实登录了，必须在发生后 15 分钟内通知安全团队。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在每个 EC2 实例上安装 Amazon Inspector 代理。订阅 Amazon EventBridge 通知。调用 AWS Lambda 函数检查消息是否关于用户登录。如果是，使用 Amazon SNS 向安全团队发送通知。",
      "B": "在每个 EC2 实例上安装 Amazon CloudWatch 代理。配置代理将所有日志推送到 Amazon CloudWatch 日志，并设置一个 CloudWatch 指标过滤器来搜索用户登录。如果找到登录，使用 Amazon SNS 向安全团队发送通知。",
      "C": "设置 AWS CloudTrail 与 Amazon CloudWatch 日志。订阅 CloudWatch 日志到 Amazon Kinesis。附加 AWS Lambda 到 Kinesis 以解析并确定日志是否包含用户登录。如果是，使用 Amazon SNS 向安全团队发送通知。",
      "D": "在每个 Amazon EC2 实例上设置脚本以将所有日志推送到 Amazon S3。设置 S3 事件以调用 AWS Lambda 函数，该函数调用 Amazon Athena 查询运行。Athena 查询检查登录并将输出发送给安全团队使用 Amazon SNS。"
    },
    "best": ["C"],
    "analysis": {
      "A": "Amazon Inspector 主要用于安全漏洞扫描，不适用于监控和通知登录事件。",
      "B": "虽然 CloudWatch 可以用于监控和警报，但它不直接与登录事件集成，需要额外的配置和管理。",
      "C": "AWS CloudTrail 用于记录 API 调用和相关事件，结合 CloudWatch 和 Lambda 可以有效监控和响应 EC2 实例的登录事件，满足题目要求。",
      "D": "使用 Amazon S3 和 Athena 进行日志分析虽然可行，但处理时间可能较长，不适合紧急通知的需求。"
    },
    "service": [
      "AWS CloudTrail",
      "Amazon CloudWatch Logs",
      "Amazon Kinesis",
      "AWS Lambda",
      "Amazon SNS"
    ],
    "reason": "4.1"
  },
  {
    "no": 124,
    "question": "一个 AWS CodePipeline 管道已实施代码发布流程。该管道与 AWS CodeDeploy 集成，以便为每个 CodePipeline 阶段将应用程序的版本部署到多个 Amazon EC2 实例。在最近的一次部署中，由于 CodeDeploy 问题，管道失败了。DevOps 团队希望在部署期间改善监控和通知，以减少解决时间。DevOps 工程师应该怎样做才能在发现问题时创建通知？",
    "choose": 1,
    "options": {
      "A": "为 CodePipeline 和 CodeDeploy 实施 Amazon CloudWatch 日志，创建一个 AWS Config 规则来评估代码部署问题，并创建一个 Amazon Simple Notification Service (Amazon SNS) 主题以通知利益相关者部署问题。",
      "B": "为 CodePipeline 和 CodeDeploy 实施 Amazon EventBridge，创建一个 AWS Lambda 函数来评估代码部署问题，并创建一个 Amazon Simple Notification Service (Amazon SNS) 主题以通知利益相关者部署问题。",
      "C": "实施 AWS CloudTrail 以记录 CodePipeline 和 CodeDeploy 的 API 调用信息，创建一个 AWS Lambda 函数来评估代码部署问题，并创建一个 Amazon Simple Notification Service (Amazon SNS) 主题以通知利益相关者部署问题。",
      "D": "为 CodePipeline 和 CodeDeploy 实施 Amazon EventBridge，创建一个 Amazon Inspector 评估目标来评估代码部署问题，并创建一个 Amazon Simple Notification Service (Amazon SNS) 主题以通知利益相关者部署问题。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然 CloudWatch 日志可以用于监控和日志记录，但 AWS Config 主要用于配置和合规性评估，不适合用于实时问题评估。",
      "B": "Amazon EventBridge 可以捕获来自 CodePipeline 和 CodeDeploy 的事件，Lambda 函数可以用于处理这些事件并评估问题，SNS 主题可以用于发送通知，这是一个完整的解决方案。",
      "C": "AWS CloudTrail 主要用于审计 API 调用，而不是实时监控和问题评估。",
      "D": "Amazon Inspector 主要用于安全评估和合规性检查，不适合用于实时的代码部署问题评估。"
    },
    "service": [
      "AWS CodePipeline",
      "AWS CodeDeploy",
      "Amazon EventBridge",
      "AWS Lambda",
      "Amazon SNS"
    ],
    "reason": "4.2"
  },
  {
    "no": 127,
    "question": "一家公司更新了一个关键业务应用程序的 AWS CloudFormation 模板。由于更新模板中的错误，堆栈更新过程失败，AWS CloudFormation 自动开始了堆栈回滚过程。后来，一位 DevOps 工程师发现应用程序仍然不可用，并且堆栈处于 UPDATE_ROLLBACK_FAILED 状态。DevOps 工程师应该执行哪两项操作组合，以便堆栈回滚可以成功完成？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "将 AWSCloudFormationFullAccess IAM 策略附加到 AWS CloudFormation 角色。",
      "B": "使用 AWS CloudFormation 漂移检测自动恢复堆栈资源。",
      "C": "从 AWS CloudFormation 控制台或 AWS CLI 发出 ContinueUpdateRollback 命令。",
      "D": "手动调整资源以匹配堆栈的期望。",
      "E": "使用原始模板更新现有的 AWS CloudFormation 堆栈。"
    },
    "best": ["C", "D"],
    "analysis": {
      "A": "附加 AWSCloudFormationFullAccess IAM 策略可能不会解决特定的堆栈回滚问题，因为这通常涉及特定资源的权限问题，而不是 CloudFormation 服务的全局权限问题。",
      "B": "漂移检测用于识别堆栈资源与预期配置的偏差，并不直接用于解决回滚失败的问题。",
      "C": "发出 ContinueUpdateRollback 命令是处理 UPDATE_ROLLBACK_FAILED 状态的推荐方法，可以尝试继续回滚过程。",
      "D": "手动调整资源以匹配堆栈的期望是解决回滚失败的有效方法，特别是当自动回滚因资源配置错误而失败时。",
      "E": "使用原始模板更新堆栈通常用于恢复到已知的工作状态，但在回滚失败的情况下，首先需要解决回滚问题，然后才能考虑使用原始模板。"
    },
    "service": ["AWS CloudFormation"],
    "reason": "2.1"
  },
  {
    "no": 129,
    "question": "一位 DevOps 工程师正在处理一个托管在 Amazon Linux 上的项目，该项目未能通过安全审查。DevOps 经理被要求审查公司的 buildspec.yaml 文件，该文件用于 AWS CodeBuild 项目，并提供建议。buildspec.yaml 文件配置如下：应该提出哪些更改以符合 AWS 安全最佳实践？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "在终止容器之前添加一个 post-build 命令以删除临时文件，以确保其他 CodeBuild 用户无法看到这些文件。",
      "B": "更新 CodeBuild 项目角色所需的权限，然后从环境变量中删除 AWS 凭证。",
      "C": "将 DB_PASSWORD 存储为 AWS Systems Manager 参数存储中的 SecureString 值，然后从环境变量中删除 DB_PASSWORD。",
      "D": "将环境变量移动到 'db-deploy-bucket' Amazon S3 存储桶中，添加一个 prebuild 阶段来下载，然后导出变量。",
      "E": "使用 AWS Systems Manager 运行命令而不是直接使用 scp 和 ssh 命令到实例。",
      "F": "使用 XOR 和 Base64 混淆环境变量，添加一个部分来安装，然后在构建阶段运行 XOR 和 Base64。"
    },
    "best": ["A", "B", "C"],
    "analysis": {
      "A": "删除临时文件可以防止其他用户访问敏感数据，符合安全最佳实践。",
      "B": "移除硬编码的 AWS 凭证并使用适当的 IAM 角色增强安全性，符合最佳实践。",
      "C": "使用 AWS Systems Manager 参数存储来安全地管理敏感信息，如数据库密码，符合安全最佳实践。",
      "D": "将敏感数据存储在 S3 存储桶中可能会增加数据泄露的风险，不推荐。",
      "E": "虽然使用 Systems Manager 可以提高安全性，但此选项与直接改进 buildspec.yaml 文件的安全性关联不大。",
      "F": "仅仅使用 XOR 和 Base64 混淆并不是一种安全的做法，因为它们可以被轻易逆向，不符合安全最佳实践。"
    },
    "service": ["AWS CodeBuild", "AWS Systems Manager", "IAM"],
    "reason": "6.2"
  },
  {
    "no": 125,
    "question": "一家全球公司通过使用 AWS Control Tower 管理多个 AWS 账户。该公司托管内部应用程序和公共应用程序。公司中的每个应用程序团队都有自己的 AWS 账户用于应用程序托管。这些账户在 AWS Organizations 中合并为一个组织。AWS Control Tower 的一个成员账户充当集中的 DevOps 账户，拥有应用程序团队用来将应用程序部署到各自目标 AWS 账户的 CI/CD 管道。集中的 DevOps 账户中存在一个用于部署的 IAM 角色。一个应用程序团队正在尝试将其应用程序部署到应用程序 AWS 账户中的 Amazon Elastic Kubernetes Service (Amazon EKS) 集群。应用程序 AWS 账户中存在一个用于部署的 IAM 角色。部署是通过在集中的 DevOps 账户中设置的 AWS CodeBuild 项目进行的。CodeBuild 项目使用 CodeBuild 的 IAM 服务角色。尝试从 CodeBuild 连接到跨账户 EKS 集群时，部署失败并显示 Unauthorized 错误。哪种解决方案将解决此错误？",
    "choose": 1,
    "options": {
      "A": "将应用程序账户的部署 IAM 角色配置为与集中的 DevOps 账户建立信任关系。配置信任关系以允许 sts:AssumeRole 操作。将应用程序账户的部署 IAM 角色配置为具有访问 EKS 集群所需的权限。将 EKS 集群的 aws-auth ConfigMap 配置为将角色映射到适当的系统权限。",
      "B": "将集中的 DevOps 账户的部署 IAM 角色配置为与应用程序账户建立信任关系。配置信任关系以允许 sts:AssumeRole 操作。将集中的 DevOps 账户的部署 IAM 角色配置为允许访问 CodeBuild 所需的权限。",
      "C": "将集中的 DevOps 账户的部署 IAM 角色配置为与应用程序账户建立信任关系。配置信任关系以允许 sts:AssumeRoleWithSAML 操作。将集中的 DevOps 账户的部署 IAM 角色配置为允许访问 CodeBuild 所需的权限。",
      "D": "将应用程序账户的部署 IAM 角色配置为与 AWS Control Tower 管理账户建立信任关系。配置信任关系以允许 sts:AssumeRole 操作。将应用程序账户的部署 IAM 角色配置为具有访问 EKS 集群所需的权限。将 EKS 集群的 aws-auth ConfigMap 配置为将角色映射到适当的系统权限。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它正确地配置了跨账户角色托管和权限，允许 DevOps 账户的 CodeBuild 服务通过应用程序账户的 IAM 角色访问 EKS 集群。",
      "B": "此选项不正确，因为它试图在 DevOps 账户和应用程序账户之间建立不正确的信任关系方向。",
      "C": "此选项不正确，因为它使用了 sts:AssumeRoleWithSAML，这在这种情况下不是必要的，且可能导致配置错误。",
      "D": "此选项不正确，因为它错误地建议与 AWS Control Tower 管理账户建立信任关系，而不是直接与 DevOps 账户建立信任关系。"
    },
    "service": [
      "AWS Control Tower",
      "AWS Organizations",
      "IAM",
      "Amazon EKS",
      "AWS CodeBuild"
    ],
    "reason": "2.2"
  },
  {
    "no": 128,
    "question": "一个开发团队手动在本地构建一个工件，然后将其放置在 Amazon S3 存储桶中。应用程序有一个本地缓存，当部署发生时必须清除该缓存。团队运行一个命令来清除缓存，从 Amazon S3 下载工件，并解压工件以完成部署。DevOps 团队希望迁移到 CI/CD 流程，并在部署失败时构建检查以停止和回滚部署。这需要团队跟踪部署的进展。哪些组合的操作可以实现这一目标？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "允许开发人员将代码检入代码仓库。使用 Amazon EventBridge，在每次拉取到主分支时，调用 AWS Lambda 函数来构建工件并将其存储在 Amazon S3 中。",
      "B": "创建一个自定义脚本来清除缓存。在 AppSpec 文件中的 BeforeInstall 生命周期钩子中指定脚本。",
      "C": "为每个 Amazon EC2 实例创建用户数据，其中包含清除缓存的脚本。部署后测试应用程序。如果不成功，再次部署。",
      "D": "设置 AWS CodePipeline 来部署应用程序。允许开发人员将代码作为管道的源代码检入代码仓库。",
      "E": "使用 AWS CodeBuild 构建工件并将其放置在 Amazon S3 中。使用 AWS CodeDeploy 将工件部署到 Amazon EC2 实例。",
      "F": "使用 AWS Systems Manager 从 Amazon S3 获取工件并将其部署到所有实例。"
    },
    "best": ["A", "D", "E"],
    "analysis": {
      "A": "这是最优选项之一，因为它实现了代码的自动构建和存储，符合 CI/CD 的实践。",
      "B": "虽然这个选项提供了清除缓存的方法，但它没有涉及到 CI/CD 流程中的自动化部署和监控。",
      "C": "这个选项没有提供自动化的部署和回滚机制，只是简单地重试，不符合最佳实践。",
      "D": "这是最优选项之一，因为它设置了一个完整的 CI/CD 管道，包括代码的自动部署。",
      "E": "这是最优选项之一，因为它涵盖了构建和部署的整个流程，使用了 AWS CodeBuild 和 CodeDeploy，符合自动化部署的要求。",
      "F": "虽然这个选项使用了 AWS Systems Manager 来部署工件，但它没有提供构建工件的步骤，也没有集成到 CI/CD 流程中。"
    },
    "service": [
      "Amazon S3",
      "Amazon EventBridge",
      "AWS Lambda",
      "AWS CodePipeline",
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "AWS Systems Manager"
    ],
    "reason": "领域 1-SDLC 自动化"
  },
  {
    "no": 132,
    "question": "一家公司手动为其员工配置IAM访问权限。该公司希望用自动化流程替换手动流程。该公司已配置了一个带有外部SAML 2.0身份提供商（IdP）的现有Active Directory系统。公司希望员工使用其现有的企业凭据访问AWS。现有Active Directory系统中的组必须可用于AWS身份和访问管理（IAM）中的权限管理。一名DevOps工程师已在公司的AWS账户中完成了AWS IAM身份中心（AWS单一登录）的初始配置。DevOps工程师接下来应该做什么以满足要求？",
    "choose": 1,
    "options": {
      "A": "将外部IdP配置为身份源。使用SCIM协议配置用户和组的自动配置。",
      "B": "将AWS目录服务配置为身份源。使用SAML协议配置用户和组的自动配置。",
      "C": "将AD连接器配置为身份源。使用SCIM协议配置用户和组的自动配置。",
      "D": "将外部IdP配置为身份源。使用SAML协议配置用户和组的自动配置。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它涉及将外部IdP配置为身份源，并使用SCIM协议自动配置用户和组，这符合题目要求使用现有的Active Directory和SAML 2.0 IdP。",
      "B": "这个选项不是最佳选项，因为它提到了使用AWS目录服务作为身份源，而不是使用现有的Active Directory系统。",
      "C": "这个选项不是最佳选项，因为虽然它提到了使用SCIM协议，但是使用的是AD连接器作为身份源，而不是直接使用现有的Active Directory系统。",
      "D": "这个选项不是最佳选项，因为它提到了使用SAML协议进行自动配置，而SAML通常用于身份验证而不是用户和组的自动配置。"
    },
    "service": [
      "AWS IAM",
      "AWS Single Sign-On",
      "Active Directory",
      "SAML 2.0",
      "SCIM"
    ],
    "reason": "6.1"
  },
  {
    "no": 134,
    "question": "一家公司使用 AWS Organizations 管理其 AWS 账户。组织根部有一个名为 Environments 的 OU。Environments OU 有两个子 OU，分别名为 Development 和 Production。Environments OU 和子 OU 都有默认的 FullAWSAccess 策略。一位 DevOps 工程师计划从 Development OU 中移除 FullAWSAccess 策略，并用一个允许对 Amazon EC2 资源执行所有操作的策略替换。这种策略替换的结果会是什么？",
    "choose": 1,
    "options": {
      "A": "Development OU 中的所有用户将被允许对所有资源执行所有 API 操作。",
      "B": "Development OU 中的所有用户将被允许对 EC2 资源执行所有 API 操作。所有其他 API 操作将被拒绝。",
      "C": "Development OU 中的所有用户将被拒绝对所有资源执行所有 API 操作。",
      "D": "Development OU 中的所有用户将被拒绝对 EC2 资源执行所有 API 操作。所有其他 API 操作将被允许。"
    },
    "best": ["B"],
    "analysis": {
      "A": "这个选项不正确，因为新策略仅允许对 EC2 资源的操作，而不是所有资源。",
      "B": "这是正确的选项，因为新策略将替换 FullAWSAccess，只允许对 EC2 资源进行操作，其他资源的操作将被拒绝。",
      "C": "这个选项不正确，因为新策略允许对 EC2 资源进行操作，而不是拒绝所有资源的操作。",
      "D": "这个选项不正确，因为新策略允许对 EC2 资源进行操作，而不是拒绝 EC2 资源的操作。"
    },
    "service": ["AWS Organizations", "Amazon EC2"],
    "reason": "2.2"
  },
  {
    "no": 130,
    "question": "一家公司拥有一个遗留应用程序。DevOps工程师需要自动化构建遗留应用程序的可部署工件的过程。解决方案必须将可部署工件存储在现有的Amazon S3存储桶中，以便将来的部署可以参考。哪种解决方案以最高的操作效率满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个包含遗留应用程序所有依赖项的自定义Docker镜像。将自定义Docker镜像存储在新的Amazon Elastic Container Registry（Amazon ECR）仓库中。配置一个新的AWS CodeBuild项目，使用自定义Docker镜像来构建可部署工件，并将工件保存到S3存储桶中。",
      "B": "启动一个新的Amazon EC2实例。在EC2实例上安装遗留应用程序的所有依赖项。使用EC2实例构建可部署工件并将工件保存到S3存储桶中。",
      "C": "创建一个自定义的EC2 Image Builder镜像。在镜像上安装遗留应用程序的所有依赖项。从该镜像启动一个新的Amazon EC2实例。使用新的EC2实例构建可部署工件并将工件保存到S3存储桶中。",
      "D": "创建一个Amazon Elastic Kubernetes Service（Amazon EKS）集群，并配置一个在多个可用区运行的AWS Fargate配置文件。创建一个包含遗留应用程序所有依赖项的自定义Docker镜像。将自定义Docker镜像存储在新的Amazon Elastic Container Registry（Amazon ECR）仓库中。在EKS集群内使用自定义Docker镜像构建可部署工件，并将工件保存到S3存储桶中。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用AWS CodeBuild和Amazon ECR来自动化构建过程，同时利用Docker容器化技术确保依赖管理的一致性和可移植性。此方案操作效率高，易于维护。",
      "B": "此选项虽然可行，但每次构建都需要手动设置EC2实例，操作效率较低，且不易于扩展和自动化。",
      "C": "此选项通过EC2 Image Builder提供了一定的自动化，但相比于使用CodeBuild和ECR的方案，其操作效率和维护性稍逊一筹。",
      "D": "此选项引入了EKS和Fargate，增加了复杂性，对于单纯的构建任务来说，这种配置过于复杂，操作效率不是最优。"
    },
    "service": [
      "AWS CodeBuild",
      "Amazon ECR",
      "Amazon S3",
      "Amazon EC2",
      "EC2 Image Builder",
      "Amazon Elastic Kubernetes Service",
      "AWS Fargate"
    ],
    "reason": "1.1"
  },
  {
    "no": 131,
    "question": "一家公司在 AWS CodeBuild 项目中通过运行 Docker 命令构建容器映像。容器映像构建完成后，CodeBuild 项目将容器映像上传到 Amazon S3 存储桶。CodeBuild 项目具有访问 S3 存储桶的 IAM 服务角色权限。一位 DevOps 工程师需要用 Amazon Elastic Container Registry（Amazon ECR）仓库替换 S3 存储桶以存储容器映像。DevOps 工程师在 CodeBuild 项目相同的 AWS 区域中创建了一个 ECR 私有映像仓库。DevOps 工程师调整了 IAM 服务角色的权限，使其能够与新的 ECR 仓库一起工作。DevOps 工程师还将新仓库信息放入 buildspec.yml 文件中使用的 docker build 命令和 docker push 命令中。当 CodeBuild 项目运行构建作业时，尝试访问 ECR 仓库的作业失败。哪种解决方案将解决访问 ECR 仓库失败的问题？",
    "choose": 1,
    "options": {
      "A": "更新 buildspec.yml 文件以使用 aws ecr get-login-password AWS CLI 命令登录到 ECR 仓库以获取认证令牌。更新 docker login 命令以使用认证令牌访问 ECR 仓库。",
      "B": "向 CodeBuild 项目添加一个类型为 SECRETS_MANAGER 的环境变量。在环境变量中，包括 CodeBuild 项目的 IAM 服务角色的 ARN。更新 buildspec.yml 文件以使用新的环境变量通过 docker login 命令登录以访问 ECR 仓库。",
      "C": "将 ECR 仓库更新为公共映像仓库。添加一个 ECR 仓库策略，允许 IAM 服务角色访问。",
      "D": "更新 buildspec.yml 文件以使用 AWS CLI 假设 ECR 操作的 IAM 服务角色。添加一个 ECR 仓库策略，允许 IAM 服务角色访问。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它直接解决了认证问题，通过获取 ECR 的登录密码并使用 docker login 命令正确认证。",
      "B": "这个选项不是最佳选项，因为仅仅添加 IAM 角色的 ARN 到环境变量并不会解决认证问题。",
      "C": "这个选项不是最佳选项，因为将仓库设为公共可能会引入安全风险，且不符合最佳实践。",
      "D": "这个选项不是最佳选项，因为仅仅假设角色并不解决需要正确认证的问题。"
    },
    "service": ["AWS CodeBuild", "Amazon S3", "Amazon ECR", "IAM"],
    "reason": "1.3"
  },
  {
    "no": 136,
    "question": "一个 DevOps 团队正在合并一个使用 Amazon RDS 多可用区数据库集群作为其生产数据库的应用程序的代码修订。DevOps 团队使用持续集成来定期验证应用程序是否有效。DevOps 团队需要在将更改部署到生产数据库之前测试更改。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在 AWS CodeBuild 中使用 buildspec 文件从生产数据库的快照中恢复 DB 集群，运行集成测试，并在验证后删除恢复的数据库。",
      "B": "将应用程序部署到生产环境。配置数据控制语言 (DCL) 操作的审计日志，以捕获数据库活动，以便在验证失败时执行。",
      "C": "在部署应用程序之前创建 DB 集群的快照。在 AWS CloudFormation 中使用 Update requires:Replacement 属性部署应用程序并应用更改。",
      "D": "确保 DB 集群是多可用区部署。使用更新部署应用程序。如果验证失败，则故障转移到备用实例。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它允许在不影响生产数据库的情况下测试更改。通过从生产数据库的快照中恢复数据库，可以确保测试环境与生产环境的一致性，同时集成测试可以验证更改的有效性。测试完成后删除数据库确保资源的清理和成本效率。",
      "B": "这不是最佳选项，因为它涉及在生产环境中直接部署和测试，这可能会影响生产环境的稳定性和安全性。",
      "C": "这不是最佳选项，因为它涉及在生产环境中直接更改数据库实例，这增加了风险，如果更改有问题，可能会影响生产环境。",
      "D": "这不是最佳选项，因为虽然多可用区部署提供了高可用性，但直接在生产环境中部署和测试更改仍然存在风险。"
    },
    "service": ["AWS CodeBuild", "Amazon RDS"],
    "reason": "1.2"
  },
  {
    "no": 135,
    "question": "一家公司正在审查其灾难恢复能力，并希望能够将其日常运营切换到辅助 AWS 区域。该公司在主要区域使用 AWS CodeCommit 作为源代码控制工具。一名 DevOps 工程师必须为公司提供在辅助区域开发代码的能力。如果公司需要使用辅助区域，开发人员可以在其本地 Git 配置中添加一个额外的远程 URL。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在辅助区域创建一个 CodeCommit 仓库。创建一个 AWS CodeBuild 项目来执行主要区域的 CodeCommit 仓库到辅助区域的 CodeCommit 仓库的 Git 镜像操作。创建一个 AWS Lambda 函数来调用 CodeBuild 项目。创建一个 Amazon EventBridge 规则，该规则对主要区域的 CodeCommit 仓库中的合并事件做出反应。配置 EventBridge 规则以调用 Lambda 函数。",
      "B": "在辅助区域创建一个 Amazon S3 桶。创建一个 AWS Fargate 任务来执行主要区域的 CodeCommit 仓库的 Git 镜像操作，并将结果复制到 S3 桶中。创建一个 AWS Lambda 函数来启动 Fargate 任务。创建一个 Amazon EventBridge 规则，该规则对 CodeCommit 仓库中的合并事件做出反应。配置 EventBridge 规则以调用 Lambda 函数。",
      "C": "在辅助区域创建一个 AWS CodeArtifact 仓库。创建一个 AWS CodePipeline 管道，该管道使用主要区域的 CodeCommit 仓库作为源操作。创建一个跨区域阶段，在该阶段中，当合并请求合并到 CodeCommit 仓库时，将 CodeCommit 仓库的内容打包并存储在 CodeArtifact 仓库中。",
      "D": "在辅助区域创建一个 AWS Cloud9 环境和一个 CodeCommit 仓库。将主要区域的 CodeCommit 仓库配置为 AWS Cloud9 环境中的一个远程仓库。将辅助区域的 CodeCommit 仓库连接到 AWS Cloud9 环境。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它通过创建辅助区域的 CodeCommit 仓库，并使用 CodeBuild 和 Lambda 自动同步主区域的更改，确保了代码的一致性和可用性。",
      "B": "此选项不是最佳选择，因为它使用 S3 桶而不是直接使用 CodeCommit 仓库，这可能会增加管理复杂性并降低效率。",
      "C": "此选项不是最佳选择，因为它使用 CodeArtifact 而不是 CodeCommit，CodeArtifact 主要用于依赖管理而不是源代码控制。",
      "D": "此选项不是最佳选择，因为虽然它提供了一个工作环境，但没有说明如何自动处理代码同步，可能需要手动维护。"
    },
    "service": [
      "AWS CodeCommit",
      "AWS CodeBuild",
      "AWS Lambda",
      "Amazon EventBridge",
      "Amazon S3",
      "AWS Fargate",
      "AWS CodeArtifact",
      "AWS CodePipeline",
      "AWS Cloud9"
    ],
    "reason": "3.3"
  },
  {
    "no": 139,
    "question": "一家公司的 DevOps 工程师正在创建一个 AWS Lambda 函数来处理来自 Amazon Simple Notification Service (Amazon SNS) 主题的通知。Lambda 函数将处理通知消息，并将通知消息的内容写入 Amazon RDS Multi-AZ DB 实例。在测试期间，数据库管理员意外关闭了 DB 实例。在数据库关闭期间，公司丢失了在此期间传递的几条 SNS 通知消息。DevOps 工程师需要防止将来丢失通知消息。哪些解决方案能满足这一要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "将 RDS Multi-AZ DB 实例替换为 Amazon DynamoDB 表。",
      "B": "将 Amazon Simple Queue Service (Amazon SQS) 队列配置为 Lambda 函数的目的地。",
      "C": "为 SNS 主题配置 Amazon Simple Queue Service (Amazon SQS) 死信队列。",
      "D": "订阅 Amazon Simple Queue Service (Amazon SQS) 队列到 SNS 主题。配置 Lambda 函数以处理来自 SQS 队列的消息。",
      "E": "将 SNS 主题替换为 Amazon EventBridge 事件总线。在新的事件总线上配置 EventBridge 规则以对每个事件调用 Lambda 函数。"
    },
    "best": ["C", "D"],
    "analysis": {
      "A": "虽然 DynamoDB 提供高可用性和持久性，但仅更换数据库类型并不能解决消息丢失问题。",
      "B": "配置 SQS 队列作为 Lambda 函数的目的地可以帮助缓存消息，但不直接解决 SNS 消息的丢失问题。",
      "C": "配置死信队列可以捕获无法成功处理的消息，确保消息不会因为处理失败而丢失。",
      "D": "通过订阅 SQS 队列到 SNS 主题并让 Lambda 从 SQS 处理消息，可以确保消息在处理前被妥善存储，防止丢失。",
      "E": "使用 EventBridge 可以提供更复杂的事件路由选项，但对于防止消息丢失并不比直接使用 SNS 和 SQS 更有优势。"
    },
    "service": [
      "AWS Lambda",
      "Amazon SNS",
      "Amazon RDS",
      "Amazon SQS",
      "Amazon DynamoDB",
      "Amazon EventBridge"
    ],
    "reason": "3.1"
  },
  {
    "no": 137,
    "question": "一家公司在其 VPC 中管理多租户环境，并为相应的 AWS 账户配置了 Amazon GuardDuty。该公司将所有 GuardDuty 发现发送到 AWS Security Hub。来自可疑来源的流量正在产生大量发现。DevOps 工程师需要实施一种解决方案，当 GuardDuty 发现新的可疑来源时，自动拒绝整个 VPC 的流量。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 GuardDuty 威胁列表。配置 GuardDuty 引用该列表。创建一个 AWS Lambda 函数，用于更新威胁列表。配置 Lambda 函数以响应来自 GuardDuty 的新 Security Hub 发现运行。",
      "B": "配置一个包含自定义规则组的 AWS WAF 网络访问控制列表。创建一个 AWS Lambda 函数，该函数将在自定义规则组中创建一个阻止规则。配置 Lambda 函数以响应来自 GuardDuty 的新 Security Hub 发现运行。",
      "C": "配置 AWS Network Firewall 中的防火墙。创建一个 AWS Lambda 函数，该函数将在防火墙策略中创建一个 Drop 动作规则。配置 Lambda 函数以响应来自 GuardDuty 的新 Security Hub 发现运行。",
      "D": "创建一个 AWS Lambda 函数，该函数将创建一个 GuardDuty 抑制规则。配置 Lambda 函数以响应来自 GuardDuty 的新 Security Hub 发现运行。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然这个选项使用了 GuardDuty 和 Lambda，但是更新威胁列表并不会直接阻止流量。",
      "B": "AWS WAF 主要用于防护 Web 应用，而不是用于 VPC 级别的流量控制。",
      "C": "这是最佳选项，因为它直接在网络层面阻止可疑的流量，符合题目要求。",
      "D": "抑制规则用于减少或过滤 GuardDuty 的发现，而不是阻止流量。"
    },
    "service": [
      "Amazon GuardDuty",
      "AWS Security Hub",
      "AWS Lambda",
      "AWS Network Firewall",
      "AWS WAF"
    ],
    "reason": "6.2"
  },
  {
    "no": 133,
    "question": "一家公司正在使用 AWS 运行数字工作负载。公司中的每个应用程序团队都有自己的 AWS 账户用于应用程序托管。这些账户在 AWS Organizations 中合并为一个组织。公司希望在整个组织中执行安全标准。为了避免因安全配置错误而导致的不合规，公司已强制使用 AWS CloudFormation。生产支持团队可以使用 AWS 管理控制台修改生产环境中的资源，以便排查和解决与应用程序相关的问题。DevOps 工程师必须实施一种解决方案，以实时识别任何导致不合规的 AWS 服务配置错误。该解决方案必须在识别问题后 15 分钟内自动纠正该问题。该解决方案还必须在集中式仪表板上跟踪不合规资源和事件，并准确记录时间戳。哪种解决方案能在最小的开发开销下满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 CloudFormation 漂移检测来识别不合规资源。使用 CloudFormation 的漂移检测事件调用 AWS Lambda 函数进行修复。配置 Lambda 函数将日志发布到 Amazon CloudWatch Logs 日志组。配置 Amazon CloudWatch 仪表板以使用日志组进行跟踪。",
      "B": "在 AWS 账户中开启 AWS CloudTrail。使用 Amazon Athena 分析 CloudTrail 日志以识别不合规资源。使用 AWS Step Functions 跟踪 Athena 上的查询结果以进行漂移检测，并调用 AWS Lambda 函数进行修复。对于跟踪，设置一个使用 Athena 作为数据源的 Amazon QuickSight 仪表板。",
      "C": "在所有 AWS 账户中开启 AWS Config 的配置记录器以识别不合规资源。在所有 AWS 账户中启用 AWS Security Hub，并使用 --no-enable-default-standards 选项。设置 AWS Config 管理规则和自定义规则。使用 AWS Config 合规性包设置自动修复。对于跟踪，设置一个在指定的 Security Hub 管理员账户上的 Security Hub 仪表板。",
      "D": "在 AWS 账户中开启 AWS CloudTrail。使用 Amazon CloudWatch Logs 分析 CloudTrail 日志以识别不合规资源。使用 CloudWatch Logs 过滤器进行漂移检测。使用 Amazon EventBridge 调用 Lambda 函数进行修复。将过滤后的 CloudWatch 日志流式传输到 Amazon OpenSearch Service。设置一个在 OpenSearch Service 上的仪表板进行跟踪。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然使用 CloudFormation 漂移检测可以识别资源配置的变化，但它不提供自动修复功能，也不易于集成实时监控和响应。",
      "B": "分析 CloudTrail 日志可以识别安全问题，但使用 Athena 和 Step Functions 的组合增加了开发和维护的复杂性，且不如 AWS Config 直接支持的自动修复功能强大。",
      "C": "AWS Config 提供了全面的资源配置管理和自动修复功能，结合 AWS Security Hub 可以提供集中的安全和合规性监控，满足题目要求的实时监控、自动修复和集中跟踪。",
      "D": "虽然使用 CloudWatch Logs 和 EventBridge 可以实现监控和响应，但与 AWS Config 相比，它在自动修复和集中管理方面的能力较弱。"
    },
    "service": [
      "AWS CloudFormation",
      "AWS Management Console",
      "AWS Lambda",
      "Amazon CloudWatch Logs",
      "Amazon CloudWatch",
      "AWS CloudTrail",
      "Amazon Athena",
      "AWS Step Functions",
      "Amazon QuickSight",
      "AWS Config",
      "AWS Security Hub",
      "Amazon EventBridge",
      "Amazon OpenSearch Service"
    ],
    "reason": "2.1"
  },
  {
    "no": 143,
    "question": "一家公司的生产环境使用 AWS CodeDeploy 蓝/绿部署来部署应用程序。部署包括启动运行 Amazon Linux 2 的实例的 Amazon EC2 Auto Scaling 组。代码库中存在一个有效的 appspec.yml 文件，其中包含以下文本：DevOps 工程师需要确保在替换实例开始处理请求流量之前，脚本下载并安装许可文件到实例上。DevOps 工程师在 appspec.yml 文件中添加了一个 hooks 部分。DevOps 工程师应使用哪个钩子来运行下载并安装许可文件的脚本？",
    "choose": 1,
    "options": {
      "A": "AfterBlockTraffic",
      "B": "BeforeBlockTraffic",
      "C": "BeforeInstall",
      "D": "DownloadBundle"
    },
    "best": ["B"],
    "analysis": {
      "A": "AfterBlockTraffic 钩子在流量被阻止后执行，此时实例已开始处理流量，不适合在此时安装许可文件。",
      "B": "BeforeBlockTraffic 钩子在阻止流量之前执行，适合在此时下载并安装许可文件，确保所有配置在实例处理流量前完成。",
      "C": "BeforeInstall 钩子在安装应用程序之前执行，但在流量阻止之后，可能不适合许可文件的安装需求。",
      "D": "DownloadBundle 钩子用于处理应用程序包的下载，不涉及许可文件的安装。"
    },
    "service": ["AWS CodeDeploy", "Amazon EC2", "Amazon Linux"],
    "reason": "1.4"
  },
  {
    "no": 138,
    "question": "一家公司使用 AWS Secrets Manager 存储一组敏感的 API 密钥，AWS Lambda 函数在被调用时会检索这些 API 密钥并向外部服务发起 API 调用。Secrets Manager 的密钥使用默认的 AWS Key Management Service (AWS KMS) 密钥加密。一位 DevOps 工程师需要更新基础设施，以确保只有 Lambda 函数的执行角色可以访问 Secrets Manager 中的值。解决方案必须应用最小权限原则。哪两个步骤的组合可以满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "将 Secrets Manager 的默认 KMS 密钥更新为仅允许 Lambda 函数的执行角色解密",
      "B": "创建一个 KMS 客户管理密钥，信任 Secrets Manager 并允许 Lambda 函数的执行角色解密。更新 Secrets Manager 以使用新的客户管理密钥",
      "C": "创建一个 KMS 客户管理密钥，信任 Secrets Manager 并允许账户的根主体解密。更新 Secrets Manager 以使用新的客户管理密钥",
      "D": "确保 Lambda 函数的执行角色具有在资源级别限定的 KMS 权限。配置权限以使 KMS 密钥可以加密 Secrets Manager 的密钥",
      "E": "从 Lambda 函数的执行角色中移除所有 KMS 权限"
    },
    "best": ["B", "D"],
    "analysis": {
      "A": "仅更新默认 KMS 密钥的权限可能不足以限制对 Secrets Manager 的访问，因为它不涉及对 Secrets Manager 自身的访问控制。",
      "B": "创建一个新的客户管理密钥并专门为 Lambda 函数的执行角色配置解密权限，然后将 Secrets Manager 配置为使用这个新密钥，是一种符合最小权限原则的做法。",
      "C": "允许账户的根主体解密并不符合最小权限原则，因为它可能允许比必要更广泛的访问。",
      "D": "确保 Lambda 函数的执行角色具有适当的 KMS 权限，并在资源级别进行配置，可以确保只有该角色可以使用 KMS 密钥加密和解密 Secrets Manager 的密钥。",
      "E": "移除所有 KMS 权限将阻止 Lambda 函数执行角色访问任何 KMS 密钥，这不符合需求，因为需要对特定密钥有访问权限。"
    },
    "service": [
      "AWS Secrets Manager",
      "AWS Lambda",
      "AWS Key Management Service (AWS KMS)"
    ],
    "reason": "6.1"
  },
  {
    "no": 141,
    "question": "一家公司计划使用 Amazon CloudWatch 监控其 Amazon EC2 实例。该公司需要在 12 小时的时间窗口内，当 NetworkPacketsIn 指标的平均值至少 3 小时小于 5 时停止 EC2 实例。公司必须每小时评估一次指标。如果在评估期间 NetworkPacketsIn 指标的数据丢失，EC2 实例必须继续运行。一位 DevOps 工程师为 NetworkPacketsIn 指标创建了一个 CloudWatch 警报。DevOps 工程师将阈值配置为 5，评估周期为 1 小时。为了满足这些要求，DevOps 工程师应采取哪些额外的措施？",
    "choose": 1,
    "options": {
      "A": "将 Datapoints to Alarm 值配置为 12 中的 3。将警报配置为将丢失的数据视为触犯阈值。添加一个 AWS Systems Manager 操作以在警报进入 ALARM 状态时停止实例。",
      "B": "将 Datapoints to Alarm 值配置为 12 中的 3。将警报配置为将丢失的数据视为未触犯阈值。添加一个 EC2 操作以在警报进入 ALARM 状态时停止实例。",
      "C": "将 Datapoints to Alarm 值配置为 12 中的 9。将警报配置为将丢失的数据视为触犯阈值。添加一个 EC2 操作以在警报进入 ALARM 状态时停止实例。",
      "D": "将 Datapoints to Alarm 值配置为 12 中的 9。将警报配置为将丢失的数据视为未触犯阈值。添加一个 AWS Systems Manager 操作以在警报进入 ALARM 状态时停止实例。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项将丢失的数据视为触犯阈值，这与题目要求不符。",
      "B": "此选项正确地将 Datapoints to Alarm 值配置为 12 中的 3，并将丢失的数据视为未触犯阈值，符合题目要求。",
      "C": "此选项将 Datapoints to Alarm 值配置为 12 中的 9，这与题目要求不符。",
      "D": "此选项将 Datapoints to Alarm 值配置为 12 中的 9，并将丢失的数据视为未触犯阈值，但 Datapoints to Alarm 值与题目要求不符。"
    },
    "service": ["Amazon CloudWatch", "Amazon EC2", "AWS Systems Manager"],
    "reason": "4.3"
  },
  {
    "no": 142,
    "question": "一家公司管理着500个AWS账户，这些账户都在AWS组织中。公司发现所有账户中有许多未连接的Amazon Elastic Block Store（Amazon EBS）卷。公司希望自动标记未连接的EBS卷以进行调查。一名DevOps工程师需要将一个AWS Lambda函数部署到所有AWS账户中。Lambda函数必须每30分钟运行一次，以标记已经断开连接7天或更长时间的所有EBS卷。哪种解决方案以最高的操作效率满足这些要求？",
    "choose": 1,
    "options": {
      "A": "为组织配置一个委派的管理员账户。创建一个包含Lambda函数的AWS CloudFormation模板。使用CloudFormation StackSets从委派的管理员账户向组织中的所有成员账户部署CloudFormation模板。在委派的管理员账户中创建一个Amazon EventBridge事件总线，每30分钟调用每个成员账户中的Lambda函数。",
      "B": "在组织的成员账户中创建一个跨账户IAM角色。附加AWSLambda_FullAccess策略和AWSCloudFormationFullAccess策略到角色上。创建一个包含Lambda函数和一个Amazon EventBridge计划规则的AWS CloudFormation模板，以每30分钟调用一次Lambda函数。在组织的管理账户中创建一个自定义脚本，该脚本承担角色并将CloudFormation模板部署到成员账户。",
      "C": "为组织配置一个委派的管理员账户。创建一个包含Lambda函数和一个Amazon EventBridge计划规则的AWS CloudFormation模板，以每30分钟调用一次Lambda函数。使用CloudFormation StackSets从委派的管理员账户向组织中的所有成员账户部署CloudFormation模板",
      "D": "在组织的成员账户中创建一个跨账户IAM角色。附加AmazonS3FullAccess策略和AWSCodeDeployDeployerAccess策略到角色上。使用AWS CodeDeploy承担角色从组织的管理账户部署Lambda函数。在成员账户中配置一个Amazon EventBridge计划规则，每30分钟调用一次Lambda函数。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然这个选项使用了CloudFormation StackSets和EventBridge，但它在每个成员账户中单独创建事件总线，这增加了管理复杂性。",
      "B": "这个选项涉及创建自定义脚本和手动承担角色，这增加了操作复杂性和潜在的错误点。",
      "C": "这是最佳选项，因为它使用CloudFormation StackSets和EventBridge计划规则来自动化部署和调用Lambda函数，操作简单且易于管理。",
      "D": "这个选项使用了AWS CodeDeploy和IAM角色，但没有利用CloudFormation的自动化部署能力，操作效率较低。"
    },
    "service": [
      "AWS Lambda",
      "AWS CloudFormation",
      "Amazon EventBridge",
      "AWS Organizations",
      "Amazon EBS",
      "IAM",
      "AWS CodeDeploy"
    ],
    "reason": "2.1"
  },
  {
    "no": 140,
    "question": "一家公司有一个在Amazon EC2实例上运行的应用程序。该公司使用AWS CodePipeline管道将应用程序部署到多个AWS区域。管道配置有每个区域的阶段。每个阶段包含每个区域的AWS CloudFormation操作。当管道将应用程序部署到一个区域时，公司希望在管道继续到下一个区域之前确认应用程序处于健康状态。为每个区域配置的应用程序的Amazon Route 53记录集。一位DevOps工程师为部署应用程序的每个区域创建了一个基于Amazon CloudWatch报警的Route 53健康检查。DevOps工程师接下来应该做什么来满足要求？",
    "choose": 1,
    "options": {
      "A": "创建一个AWS Step Functions工作流来检查CloudWatch报警的状态。配置Step Functions工作流在报警处于ALARM状态时退出并报错。在每个区域部署阶段之间创建一个新的管道阶段。在每个新阶段中，包括一个调用Step Functions工作流的动作。",
      "B": "配置一个AWS CodeDeploy应用程序来部署带有自动回滚的CloudFormation模板。将CloudWatch报警配置为CodeDeploy应用程序的实例健康检查。从管道中移除CloudFormation动作。在每个区域的管道阶段中创建一个CodeDeploy动作。",
      "C": "为部署应用程序的每个区域创建一个新的管道阶段。为新阶段配置一个CloudWatch报警动作，以检查CloudWatch报警的状态，并在报警处于ALARM状态时退出并报错。",
      "D": "在EC2实例上配置CloudWatch代理，以将应用程序状态报告给Route 53健康检查。为部署应用程序的每个区域创建一个新的管道阶段。配置一个CloudWatch报警动作，以在CloudWatch报警处于ALARM状态时退出并报错。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用AWS Step Functions来检查CloudWatch报警的状态，并在检测到问题时阻止管道继续执行，这符合题目要求在部署到下一个区域前确认应用程序的健康状态。",
      "B": "这个选项不是最佳的，因为它建议移除CloudFormation动作并完全依赖CodeDeploy，这可能不符合公司当前使用CloudFormation的部署策略。",
      "C": "虽然这个选项考虑了在报警状态为ALARM时停止管道，但它没有使用AWS Step Functions，可能不如选项A那样灵活和可控。",
      "D": "这个选项提出了在EC2实例上配置CloudWatch代理，这增加了复杂性，并且与直接使用AWS Step Functions相比，管理起来可能更困难。"
    },
    "service": [
      "AWS CodePipeline",
      "Amazon EC2",
      "AWS CloudFormation",
      "Amazon Route 53",
      "Amazon CloudWatch",
      "AWS Step Functions",
      "AWS CodeDeploy"
    ],
    "reason": "领域 1-SDLC 自动化"
  },
  {
    "no": 145,
    "question": "一家公司在 AWS Organizations 中管理多个 AWS 账户。公司的安全政策规定不得使用成员账户的 AWS 账户根用户凭证。公司监控对根用户凭证的访问。最近的警报显示，成员账户中的根用户启动了一个 Amazon EC2 实例。一名 DevOps 工程师必须在组织的根级别创建一个 SCP，以防止成员账户中的根用户进行任何 AWS 服务 API 调用。哪个 SCP 能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "禁止根用户对所有 AWS 服务的 API 调用。",
      "B": "允许根用户对所有 AWS 服务的 API 调用。",
      "C": "仅允许根用户对 Amazon EC2 和 Amazon S3 的 API 调用。",
      "D": "禁止根用户对 Amazon EC2 的 API 调用，但允许对其他服务的调用。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最优选项，因为它符合公司的安全政策，防止根用户进行任何 AWS 服务的 API 调用。",
      "B": "这个选项不符合公司的安全政策，因为它允许根用户进行所有 AWS 服务的 API 调用。",
      "C": "这个选项不符合公司的安全政策，因为它允许根用户对某些服务进行 API 调用。",
      "D": "这个选项不符合公司的安全政策，因为它允许根用户对除 Amazon EC2 外的其他服务进行 API 调用。"
    },
    "service": ["AWS Organizations", "Amazon EC2"],
    "reason": "2.2"
  },
  {
    "no": 148,
    "question": "一位 DevOps 工程师正在设计一个与传统 REST API 集成的应用程序。该应用程序有一个 AWS Lambda 函数，该函数从 Amazon Kinesis 数据流中读取记录。Lambda 函数将记录发送到传统的 REST API。大约 10% 的 Lambda 函数从 Kinesis 数据流发送的记录存在数据错误，必须手动处理。Lambda 函数的事件源配置有一个 Amazon Simple Queue Service (Amazon SQS) 死信队列作为失败时的目的地。DevOps 工程师已将 Lambda 函数配置为批量处理记录，并已实现失败重试。在测试期间，DevOps 工程师注意到死信队列中包含许多没有数据错误且已由传统 REST API 处理的记录。DevOps 工程师需要配置 Lambda 函数的事件源选项，以减少发送到死信队列的无错误记录的数量。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "增加重试次数。",
      "B": "配置设置以在发生错误时拆分批次。",
      "C": "增加每个分片的并发批次。",
      "D": "减少记录的最大年龄。"
    },
    "best": ["B"],
    "analysis": {
      "A": "增加重试次数可能会导致更多已处理的记录因重复处理而进入死信队列，不是最佳选择。",
      "B": "配置设置以在发生错误时拆分批次可以确保只有错误记录被发送到死信队列，而正确的记录可以继续被处理，是最佳选择。",
      "C": "增加每个分片的并发批次可能会增加处理量，但不会直接减少错误记录进入死信队列的问题。",
      "D": "减少记录的最大年龄可能会导致有效记录因未及时处理而被错误地发送到死信队列，不是最佳选择。"
    },
    "service": ["AWS Lambda", "Amazon Kinesis", "Amazon SQS"],
    "reason": "3.2"
  },
  {
    "no": 144,
    "question": "一家公司有一个包括 AWS Lambda 函数的应用程序。Lambda 函数运行存储在 AWS CodeCommit 仓库中的 Python 代码。该公司最近因 Python 代码中的错误而在生产环境中遇到失败。一位工程师为 Lambda 函数编写了单元测试，以帮助避免将来的缺陷发布到生产环境中。公司的 DevOps 团队需要实施一个解决方案，将单元测试集成到现有的 AWS CodePipeline 管道中。该解决方案必须生成有关单元测试的报告供公司查看。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "将 CodeCommit 仓库与 Amazon CodeGuru Reviewer 关联。创建一个新的 AWS CodeBuild 项目。在 CodePipeline 管道中，配置一个使用新 CodeBuild 项目的测试阶段。在 CodeCommit 仓库中创建一个 buildspec.yml 文件。在 buildspec.yml 文件中，定义运行 CodeGuru 审查的操作。",
      "B": "创建一个新的 AWS CodeBuild 项目。在 CodePipeline 管道中，配置一个使用新 CodeBuild 项目的测试阶段。创建一个 CodeBuild 报告组。在 CodeCommit 仓库中创建一个 buildspec.yml 文件。在 buildspec.yml 文件中，定义在构建阶段部分运行单元测试并输出 JUNITXML 的操作。配置测试报告上传到新的 CodeBuild 报告组。",
      "C": "创建一个新的 AWS CodeArtifact 仓库。创建一个新的 AWS CodeBuild 项目。在 CodePipeline 管道中，配置一个使用新 CodeBuild 项目的测试阶段。在原始 CodeCommit 仓库中创建一个 appspec.yml 文件。在 appspec.yml 文件中，定义在构建阶段部分运行单元测试并输出 CUCUMBERJSON 的操作。配置测试报告发送到新的 CodeArtifact 仓库。",
      "D": "创建一个新的 AWS CodeBuild 项目。在 CodePipeline 管道中，配置一个使用新 CodeBuild 项目的测试阶段。创建一个新的 Amazon S3 桶。在 CodeCommit 仓库中创建一个 buildspec.yml 文件。在 buildspec.yml 文件中，定义在阶段部分运行单元测试并输出 HTML 的操作。在报告部分，上传测试报告到 S3 桶。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然使用了 CodeBuild 和 CodePipeline，但是 CodeGuru Reviewer 主要用于代码审查，不适用于运行单元测试和生成测试报告。",
      "B": "这是最佳选项，因为它涉及创建 CodeBuild 项目和报告组，以及在 buildspec.yml 中定义运行单元测试和生成 JUNITXML 格式的测试报告，符合题目要求。",
      "C": "使用了 CodeArtifact 和 appspec.yml，但 CodeArtifact 主要用于依赖管理而不是测试报告，且 appspec.yml 通常用于 CodeDeploy 而非 CodeBuild。",
      "D": "虽然使用了 CodeBuild 和 S3，但输出格式 HTML 不适合单元测试报告，且 S3 不是用于管理测试报告的最佳选择。"
    },
    "service": [
      "AWS Lambda",
      "AWS CodeCommit",
      "AWS CodePipeline",
      "AWS CodeBuild",
      "Amazon S3",
      "AWS CodeArtifact",
      "Amazon CodeGuru Reviewer"
    ],
    "reason": "1.2"
  },
  {
    "no": 147,
    "question": "AnyCompany 使用 AWS Organizations 创建和管理多个 AWS 账户。AnyCompany 最近收购了一家较小的公司 Example Corp。在收购过程中，Example Corp 的单个 AWS 账户通过 Organizations 邀请加入了 AnyCompany 的管理账户。AnyCompany 将新成员账户移至专门用于 Example Corp 的 OU 下。AnyCompany 的 DevOps 工程师拥有一个 IAM 用户，该用户假设名为 OrganizationAccountAccessRole 的角色以访问成员账户。该角色配置了完全访问策略。当 DevOps 工程师尝试使用 AWS 管理控制台假设 Example Corp 新成员账户中的角色时，DevOps 工程师收到以下错误消息：“一个或多个字段中的信息无效。检查您的信息或联系您的管理员。”哪种解决方案将使 DevOps 工程师能够访问新成员账户？",
    "choose": 1,
    "options": {
      "A": "在管理账户中，授予 DevOps 工程师的 IAM 用户权限以假设新成员账户中的 OrganizationAccountAccessRole IAM 角色。",
      "B": "在管理账户中，创建一个新的 SCP。在 SCP 中，授予 DevOps 工程师的 IAM 用户新成员账户中所有资源的完全访问权限。将 SCP 附加到包含新成员账户的 OU。",
      "C": "在新成员账户中，创建一个名为 OrganizationAccountAccessRole 的新 IAM 角色。将 AdministratorAccess AWS 管理策略附加到该角色。在角色的信任策略中，授予管理账户权限以假设该角色。",
      "D": "在新成员账户中，编辑 OrganizationAccountAccessRole IAM 角色的信任策略。授予管理账户权限以假设该角色。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项不正确，因为问题不在于 DevOps 工程师的 IAM 用户权限，而是新成员账户中的角色配置问题。",
      "B": "此选项不正确，因为 SCP 用于限制账户级别的权限，而不是解决角色信任策略的问题。",
      "C": "此选项不正确，因为它建议创建一个新的角色，而不是使用已经存在的 OrganizationAccountAccessRole，这可能导致更多的配置和权限问题。",
      "D": "此选项是正确的，因为它直接解决了问题的根源：新成员账户中的 OrganizationAccountAccessRole 角色的信任策略需要更新，以允许管理账户的 IAM 用户假设该角色。"
    },
    "service": ["AWS Organizations", "IAM", "AWS Management Console"],
    "reason": "2.2"
  },
  {
    "no": 149,
    "question": "一家公司在 AWS Lambda 中运行微服务，这些微服务从 Amazon DynamoDB 读取数据。Lambda 代码在成功测试后由开发人员手动部署。该公司现在需要测试和部署自动化，并在云中运行。此外，在部署后，需要逐渐将流量转移到每个微服务的新版本上。哪种解决方案满足所有要求，确保最大的开发速度？",
    "choose": 1,
    "options": {
      "A": "创建 AWS CodePipeline 配置，并设置 post-commit 钩子以在测试通过后触发管道。使用 AWS CodeDeploy 并创建 Canary 部署配置，指定流量百分比和间隔。",
      "B": "创建 AWS CodeBuild 配置，当测试代码被推送时触发。使用 AWS CloudFormation 触发 AWS CodePipeline 配置，部署新的 Lambda 版本并指定流量转移百分比和间隔。",
      "C": "创建 AWS CodePipeline 配置，并设置源代码步骤在代码推送时触发。设置构建步骤使用 AWS CodeBuild 运行测试。设置 AWS CodeDeploy 配置进行部署，然后选择 CodeDeployDefault.LambdaLinear10PercentEvery3Minutes 选项。",
      "D": "使用 AWS CLI 设置 post-commit 钩子，测试通过后将代码上传到 Amazon S3 存储桶。设置 S3 事件触发器，运行一个 Lambda 函数部署新版本。在 Lambda 函数中使用间隔将代码逐渐部署到所需百分比。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然使用了 CodeDeploy 和 Canary 部署，但没有明确提到自动化测试的集成。",
      "B": "涉及了 CodeBuild 和 CodePipeline，但使用 CloudFormation 触发部署可能不是最直接的方法，且没有明确使用 CodeDeploy。",
      "C": "这个选项完全符合题目要求，使用 CodePipeline 和 CodeBuild 实现自动化测试和部署，且通过 CodeDeploy 实现了渐进式流量转移。",
      "D": "使用 CLI 和 S3 事件触发器的方法较为复杂，且没有使用 CodeDeploy，可能不是最优的自动化和渐进式部署策略。"
    },
    "service": [
      "AWS Lambda",
      "Amazon DynamoDB",
      "AWS CodePipeline",
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "AWS CloudFormation",
      "Amazon S3",
      "AWS CLI"
    ],
    "reason": "1.4"
  },
  {
    "no": 152,
    "question": "一位 DevOps 工程师正在使用 AWS CodeDeploy 在一个 EC2 Auto Scaling 组的 Amazon EC2 实例群中进行部署。与 EC2 Auto Scaling 集成的关联 CodeDeploy 部署组配置为使用 CodeDeployDefault.OneAtATime 进行就地部署。在一次新的部署进行中，工程师发现尽管整体部署成功完成，但五个实例中有两个实例部署了之前的应用程序版本。其他三个实例部署了最新的应用程序版本。这个问题可能是什么原因造成的？",
    "choose": 1,
    "options": {
      "A": "受影响的两个实例未能获取新的部署。",
      "B": "失败的 AfterInstall 生命周期事件钩子导致 CodeDeploy 代理在受影响的实例上回滚到之前的版本。",
      "C": "两个受影响的实例中没有安装 CodeDeploy 代理。",
      "D": "EC2 Auto Scaling 在新部署尚未完成时启动了两个新实例，导致在受影响的实例上部署了之前的版本。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然这是一个可能的原因，但通常如果实例无法获取部署，CodeDeploy 会标记部署为失败，而不是成功。",
      "B": "如果 AfterInstall 生命周期事件钩子失败，通常会导致整个部署失败，而不是部分实例回滚。",
      "C": "如果没有安装 CodeDeploy 代理，这些实例通常不会被包括在部署过程中。",
      "D": "这是最可能的原因。由于 CodeDeployDefault.OneAtATime 策略，新启动的实例可能在部署过程中被错误地配置为使用旧版本。"
    },
    "service": ["AWS CodeDeploy", "Amazon EC2", "EC2 Auto Scaling"],
    "reason": "1.4"
  },
  {
    "no": 146,
    "question": "一家公司使用 AWS，并拥有一个包含关键计算基础设施的 VPC，该基础设施具有可预测的流量模式。公司已配置 VPC 流日志，并将其发布到 Amazon CloudWatch Logs 中的日志组。公司的 DevOps 团队需要为 VPC 流日志配置监控解决方案，以便随时间发现网络流量到 VPC 的异常。如果监控解决方案检测到异常，公司需要能够启动对异常的响应。DevOps 团队应如何配置监控解决方案以满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 Amazon Kinesis 数据流。订阅日志组到数据流。配置 Amazon Kinesis Data Analytics 来检测数据流中的日志异常。创建一个 AWS Lambda 函数作为数据流的输出。配置 Lambda 函数在发现异常时写入默认的 Amazon EventBridge 事件总线。",
      "B": "创建一个 Amazon Kinesis Data Firehose 传输流，将事件传送到 Amazon S3 存储桶。订阅日志组到传输流。配置 Amazon Lookout for Metrics 来监控 S3 存储桶中的数据异常。创建一个 AWS Lambda 函数以响应 Lookout for Metrics 异常发现。配置 Lambda 函数发布到默认的 Amazon EventBridge 事件总线。",
      "C": "创建一个 AWS Lambda 函数来检测异常。如果 Lambda 函数检测到异常，配置该函数发布事件到默认的 Amazon EventBridge 事件总线。订阅 Lambda 函数到日志组。",
      "D": "创建一个 Amazon Kinesis 数据流。订阅日志组到数据流。创建一个 AWS Lambda 函数来检测日志异常。如果 Lambda 函数检测到异常，配置该函数写入默认的 Amazon EventBridge 事件总线。将 Lambda 函数设置为数据流的处理器。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用了 Amazon Kinesis Data Analytics 来有效地处理和分析大规模数据流中的异常，然后使用 Lambda 函数和 EventBridge 来响应这些异常。",
      "B": "此选项不是最佳选择，因为它涉及将数据存储在 S3 中，这可能导致在响应异常时有延迟，而且 Lookout for Metrics 主要用于监控指标而不是日志数据。",
      "C": "此选项不是最佳选择，因为它依赖单个 Lambda 函数来处理所有日志数据，这可能不够高效且难以扩展。",
      "D": "此选项不是最佳选择，因为虽然它使用了 Kinesis 数据流，但没有利用 Kinesis Data Analytics 的强大数据处理能力，而是直接使用 Lambda 函数处理，可能不如选项 A 高效。"
    },
    "service": [
      "Amazon Kinesis",
      "AWS Lambda",
      "Amazon EventBridge",
      "Amazon CloudWatch Logs",
      "Amazon Kinesis Data Analytics",
      "Amazon S3",
      "Amazon Lookout for Metrics"
    ],
    "reason": "4.2"
  },
  {
    "no": 150,
    "question": "一家公司正在构建一个使用由 AWS Lambda 和 Amazon API Gateway 提供支持的无服务器架构的 Web 和移动应用程序。该公司希望根据推送到 AWS CodeCommit 仓库中适当环境分支的代码，完全自动化后端 Lambda 部署。部署必须具有以下特点：• 分别为测试和生产环境设置独立的环境管道 • 仅为测试环境自动进行部署。应采取哪些步骤来满足这些要求？",
    "choose": 1,
    "options": {
      "A": "配置新的 AWS CodePipeline 服务。为每个环境创建一个 CodeCommit 仓库。设置 CodePipeline 从适当的仓库检索源代码。设置部署步骤，使用 AWS CloudFormation 部署 Lambda 函数。",
      "B": "为测试和生产环境创建两个 AWS CodePipeline 配置。将生产管道配置为具有手动批准步骤。为每个环境创建一个 CodeCommit 仓库。设置每个 CodePipeline 从适当的仓库检索源代码。设置部署步骤，使用 AWS CloudFormation 部署 Lambda 函数。",
      "C": "为测试和生产环境创建两个 AWS CodePipeline 配置。将生产管道配置为具有手动批准步骤。创建一个具有每个环境分支的 CodeCommit 仓库。设置每个 CodePipeline 从仓库中适当的分支检索源代码。设置部署步骤，使用 AWS CloudFormation 部署 Lambda 函数。",
      "D": "为测试和生产环境创建一个 AWS CodeBuild 配置。将生产管道配置为具有手动批准步骤。创建一个具有每个环境分支的 CodeCommit 仓库。将 Lambda 函数代码推送到 Amazon S3 存储桶。设置部署步骤，从 S3 存储桶部署 Lambda 函数。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项没有提到生产环境的手动批准步骤，这是一个重要的安全和质量控制措施。",
      "B": "此选项为每个环境创建了单独的仓库，这增加了管理复杂性，不如使用单个仓库的多分支策略灵活。",
      "C": "此选项满足了题目要求：为测试和生产环境创建独立的管道，生产管道具有手动批准步骤，并且使用单个仓库的多分支策略，这简化了源代码管理。因此，这是最佳选择。",
      "D": "此选项使用了 CodeBuild 而不是 CodePipeline，不符合题目要求的自动化部署流程。"
    },
    "service": [
      "AWS Lambda",
      "Amazon API Gateway",
      "AWS CodeCommit",
      "AWS CodePipeline",
      "AWS CloudFormation",
      "Amazon S3"
    ],
    "reason": "1.1"
  },
  {
    "no": 151,
    "question": "一位 DevOps 工程师希望找到一个解决方案，将一个应用程序从本地迁移到 AWS。该应用程序在 Linux 上运行，并且需要在特定版本的 Apache Tomcat、HAProxy 和 Varnish Cache 上运行才能正常工作。应用程序的操作系统级参数需要调整。解决方案必须包括自动化部署新应用程序版本的方法。基础设施应该是可扩展的，并且应该能自动替换故障服务器。DevOps 工程师应该使用哪种解决方案？",
    "choose": 1,
    "options": {
      "A": "将应用程序作为包含所有必要软件的 Docker 映像上传到 Amazon ECR。创建一个使用 AWS Fargate 启动类型和自动扩展组的 Amazon ECS 集群。创建一个使用 Amazon ECR 作为源和 Amazon ECS 作为部署提供者的 AWS CodePipeline 管道。",
      "B": "将应用程序代码上传到 AWS CodeCommit 仓库，并保存配置文件以配置和安装软件。创建一个使用 Tomcat 解决方案堆栈的 AWS Elastic Beanstalk Web 服务器层和负载均衡类型环境。创建一个使用 CodeCommit 作为源和 Elastic Beanstalk 作为部署提供者的 AWS CodePipeline 管道。",
      "C": "将应用程序代码上传到 AWS CodeCommit 仓库，并使用一组 .ebextensions 文件来配置和安装软件。创建一个使用 Tomcat 解决方案堆栈的 AWS Elastic Beanstalk 工作层环境。创建一个使用 CodeCommit 作为源和 Elastic Beanstalk 作为部署提供者的 AWS CodePipeline 管道。",
      "D": "将应用程序代码上传到 AWS CodeCommit 仓库，并使用 appspec.yml 文件来配置和安装必要的软件。创建一个与 Amazon EC2 自动扩展组关联的 AWS CodeDeploy 部署组。创建一个使用 CodeCommit 作为源和 CodeDeploy 作为部署提供者的 AWS CodePipeline 管道。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用 Docker 容器来确保应用程序和其依赖的特定版本的软件可以一起打包，并且使用 AWS Fargate 和 ECS 确保基础设施的可扩展性和容错能力。同时，使用 AWS CodePipeline 实现自动化部署。",
      "B": "这个选项不是最佳的，因为虽然它使用了 Elastic Beanstalk 和 CodePipeline，但没有明确提到如何确保特定版本的软件依赖，且 Elastic Beanstalk 在处理特定软件版本和操作系统级参数调整方面可能不如容器解决方案灵活。",
      "C": "这个选项不是最佳的，因为它指定了工作层环境，这通常用于后台任务处理而不是运行 Web 应用程序。此外，它也没有明确如何确保软件版本的一致性。",
      "D": "虽然这个选项使用了 CodeDeploy 和 EC2 Auto Scaling，但它依赖于 appspec.yml 来配置软件，这可能在确保特定版本的软件依赖方面不如 Docker 容器解决方案直接和有效。"
    },
    "service": [
      "Amazon ECR",
      "Amazon ECS",
      "AWS Fargate",
      "AWS CodePipeline",
      "AWS CodeCommit",
      "AWS Elastic Beanstalk",
      "AWS CodeDeploy",
      "Amazon EC2 Auto Scaling"
    ],
    "reason": "3.2"
  },
  {
    "no": 153,
    "question": "安全团队担心开发人员可能会无意中将弹性 IP 地址附加到生产中的 Amazon EC2 实例上。不允许任何开发人员将弹性 IP 地址附加到实例上。如果任何生产服务器在任何时候都有弹性 IP 地址，必须通知安全团队。如何自动完成此任务？",
    "choose": 1,
    "options": {
      "A": "使用 Amazon Athena 查询 AWS CloudTrail 日志以检查任何关联地址尝试。创建一个 AWS Lambda 函数来解除实例的弹性 IP 地址，并通知安全团队。",
      "B": "将 IAM 策略附加到开发人员的 IAM 组以拒绝关联地址权限。创建一个自定义 AWS Config 规则来检查是否有弹性 IP 地址与任何标记为生产的实例关联，并通知安全团队。",
      "C": "确保与开发人员关联的所有 IAM 组都没有关联地址权限。创建一个定时的 AWS Lambda 函数来检查是否有弹性 IP 地址与任何标记为生产的实例关联，并在实例有弹性 IP 地址关联时通知安全团队。",
      "D": "创建一个 AWS Config 规则来检查所有生产实例是否具有包括拒绝关联地址权限的 EC2 IAM 角色。验证是否有弹性 IP 地址与任何实例关联，并在实例有弹性 IP 地址关联时通知安全团队。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然使用 Athena 查询 CloudTrail 日志可以检测关联地址尝试，但这种方法可能存在延迟，并且需要手动创建查询，不如实时监控和自动化响应有效。",
      "B": "这是最佳选项，因为它结合了预防措施（IAM 策略拒绝关联地址权限）和检测措施（AWS Config 规则检查弹性 IP 关联），并且能够自动通知安全团队。",
      "C": "虽然这个选项提供了定时检查和通知，但它依赖于定时函数，可能不会立即响应 IP 地址的关联，导致安全响应不够及时。",
      "D": "这个选项依赖于 Config 规则来执行权限检查，但它没有明确阻止开发人员关联 IP 地址，而是在事后进行检查，这可能导致安全风险。"
    },
    "service": [
      "IAM",
      "AWS Config",
      "AWS Lambda",
      "Amazon Athena",
      "AWS CloudTrail"
    ],
    "reason": "6.2"
  },
  {
    "no": 154,
    "question": "一家公司正在使用 AWS Organizations 为其每个部门创建单独的 AWS 账户。该公司需要自动执行以下任务：• 定期更新 Linux AMI，并生成金镜像 • 如果有新版本的 Chef 代理可用，则在金镜像中安装新版本的 Chef 代理 • 向部门的账户提供新生成的 AMI。哪种解决方案在管理开销最小的情况下满足这些要求？",
    "choose": 1,
    "options": {
      "A": "编写脚本以从之前的金镜像启动 Amazon EC2 实例。应用补丁更新。安装新版本的 Chef 代理，生成新的金镜像，然后修改 AMI 权限，仅与部门的账户共享新镜像。",
      "B": "使用 Amazon EC2 Image Builder 创建包含基础 Linux AMI 和安装 Chef 代理的组件的镜像管道。使用 AWS Resource Access Manager 与部门的账户共享 EC2 Image Builder 镜像。",
      "C": "使用 AWS Systems Manager Automation 运行手册通过使用之前的镜像更新 Linux AMI。提供更新 Chef 代理的脚本 URL。使用 AWS Organizations 替换部门账户中的之前金镜像。",
      "D": "使用 Amazon EC2 Image Builder 创建包含基础 Linux AMI 和安装 Chef 代理的组件的镜像管道。在 AWS Systems Manager 参数存储中创建一个参数以存储新的 AMI ID，供部门的账户参考。"
    },
    "best": ["B"],
    "analysis": {
      "A": "这个选项需要手动编写脚本并管理多个步骤，这增加了管理开销。",
      "B": "这个选项使用 Amazon EC2 Image Builder 自动化镜像的创建和更新，同时使用 AWS Resource Access Manager 简化了镜像的共享，符合最小管理开销的要求。",
      "C": "这个选项虽然使用了自动化工具，但提供脚本 URL 并使用 AWS Organizations 替换镜像增加了复杂性。",
      "D": "这个选项虽然使用了 Image Builder，但在参数存储中管理 AMI ID 并不直接涉及到镜像的共享，可能需要额外的步骤来确保账户间的镜像可用性。"
    },
    "service": [
      "AWS Organizations",
      "Amazon EC2",
      "Amazon EC2 Image Builder",
      "AWS Resource Access Manager",
      "AWS Systems Manager"
    ],
    "reason": "2.3"
  },
  {
    "no": 156,
    "question": "一家公司有一个开发人员为自动化部署管道编写代码。该开发人员将每个项目的源代码存储在一个 Amazon S3 桶中。公司希望增加更多开发人员加入团队，但担心代码冲突和工作丢失。公司还希望建立一个测试环境来部署新版本的代码进行测试，并允许开发人员在代码库中更改代码时自动部署到这两个环境。最有效的方式是什么？",
    "choose": 1,
    "options": {
      "A": "为每个项目创建一个 AWS CodeCommit 仓库，使用主分支存放生产代码，并为测试中的代码创建一个测试分支。使用功能分支开发新功能，并使用拉取请求将代码合并到测试和主分支。",
      "B": "为每个项目创建另一个 S3 桶用于测试代码，并使用 AWS Lambda 函数在测试和生产桶之间推广代码更改。在所有桶上启用版本控制以防止代码冲突。",
      "C": "为每个项目创建一个 AWS CodeCommit 仓库，并使用主分支用于生产和测试代码，为每个环境使用不同的部署管道。使用功能分支开发新功能。",
      "D": "在每个 S3 桶上启用版本控制和分支，使用主分支存放生产代码，并为测试中的代码创建一个测试分支。让开发人员在每个环境中使用各自的分支进行开发。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用 AWS CodeCommit 作为源代码管理系统，支持分支和合并请求，这有助于管理多个开发人员的代码更改，避免冲突，并且可以为不同环境（生产和测试）维护不同的分支。",
      "B": "这个选项不是最佳的，因为虽然它提到了版本控制，但使用 S3 桶和 Lambda 函数来管理代码推广不如使用专门的源代码管理系统（如 CodeCommit）那样有效。",
      "C": "这个选项不是最佳的，因为它提到使用同一个分支（主分支）来处理生产和测试代码，这可能导致测试代码意外部署到生产环境。",
      "D": "这个选项不是最佳的，因为 S3 不支持真正的分支功能，这使得管理复杂的开发和部署流程变得困难。"
    },
    "service": ["AWS CodeCommit", "Amazon S3", "AWS Lambda"],
    "reason": "领域 1-SDLC 自动化"
  },
  {
    "no": 159,
    "question": "一家公司为应用团队管理 AWS 账户，使用 AWS Control Tower。各个应用团队负责保护其各自的 AWS 账户。一名 DevOps 工程师需要为尚未启用 Amazon GuardDuty 的所有 AWS 账户启用 Amazon GuardDuty。该 DevOps 工程师正在使用 AWS Control Tower 管理账户中的 AWS CloudFormation StackSets。DevOps 工程师应如何配置 CloudFormation 模板以防止 StackSets 部署期间失败？",
    "choose": 1,
    "options": {
      "A": "创建一个 CloudFormation 自定义资源，调用一个 AWS Lambda 函数。配置 Lambda 函数以有条件地启用 GuardDuty（如果尚未在账户中启用 GuardDuty）。",
      "B": "使用 CloudFormation 模板的 Conditions 部分在尚未启用 GuardDuty 的账户中启用 GuardDuty。",
      "C": "使用 CloudFormation Fn::GetAtt 内在函数检查是否已启用 GuardDuty。如果尚未启用 GuardDuty，请使用 CloudFormation 模板的 Resources 部分启用 GuardDuty。",
      "D": "手动发现尚未启用 GuardDuty 的 AWS 账户 ID 列表。使用 CloudFormation Fn::ImportValue 内在函数将账户 ID 列表导入 CloudFormation 模板以跳过列出的 AWS 账户的部署。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用 Lambda 函数来有条件地启用 GuardDuty，这样可以确保只在尚未启用的账户中启用 GuardDuty，避免部署失败。",
      "B": "这个选项不可行，因为 CloudFormation 的 Conditions 部分不支持运行时检查其他 AWS 服务的状态。",
      "C": "这个选项不可行，因为 Fn::GetAtt 不能用来检查服务如 GuardDuty 是否已经启用。",
      "D": "这个选项虽然可以避免在已启用 GuardDuty 的账户中重复部署，但它需要手动操作来维护账户列表，不够自动化，也容易出错。"
    },
    "service": [
      "AWS Control Tower",
      "AWS CloudFormation",
      "Amazon GuardDuty",
      "AWS Lambda"
    ],
    "reason": "2.2"
  },
  {
    "no": 155,
    "question": "一家公司在 AWS 上有一个任务关键型应用程序，使用自动缩放。公司希望部署生命周期满足以下参数：• 应用程序必须一次部署一个实例，以确保其余的舰队继续服务流量。• 该应用程序是 CPU 密集型的，必须进行密切监控。• 如果部署实例的 CPU 利用率超过 85%，部署必须自动回滚。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS CloudFormation 创建 AWS Step Functions 状态机和 Auto Scaling 生命周期钩子，一次将一个实例移动到等待状态。使用 AWS Systems Manager 自动化部署更新到每个实例，并使用心跳超时将其移回 Auto Scaling 组。",
      "B": "使用 AWS CodeDeploy 与 Amazon EC2 Auto Scaling 配置一个与 CPU 利用率指标相关联的警报。使用 CodeDeployDefault OneAtAtime 配置作为部署策略。在部署组中配置自动回滚，以在警报阈值被突破时回滚部署。",
      "C": "使用 AWS Elastic Beanstalk 进行负载均衡和 AWS Auto Scaling。配置一个与 CPU 利用率指标相关联的警报。配置固定批量大小为一个实例的滚动部署。启用增强健康监控部署状态，并根据先前创建的警报回滚。",
      "D": "使用 AWS Systems Manager 进行蓝/绿部署与 Amazon EC2 Auto Scaling。配置一个与 CPU 利用率指标相关联的警报。一次部署更新。在 Auto Scaling 组中配置自动回滚，以在警报阈值被突破时回滚部署。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然使用了 AWS CloudFormation 和 AWS Systems Manager，但没有明确提到如何处理 CPU 利用率超过 85% 的自动回滚。",
      "B": "这是最佳选项，因为它使用了 AWS CodeDeploy 和 Amazon EC2 Auto Scaling，并配置了与 CPU 利用率相关的警报，以及在警报阈值被突破时自动回滚的功能。",
      "C": "虽然提到了与 CPU 利用率相关的警报和回滚，但使用的是 AWS Elastic Beanstalk，这在处理单实例部署和精确控制方面可能不如 AWS CodeDeploy 灵活。",
      "D": "提到了蓝/绿部署和自动回滚，但没有明确说明如何确保一次只部署一个实例，可能不符合题目要求的部署策略。"
    },
    "service": [
      "AWS CloudFormation",
      "AWS Step Functions",
      "Auto Scaling",
      "AWS Systems Manager",
      "AWS CodeDeploy",
      "Amazon EC2",
      "AWS Elastic Beanstalk",
      "Amazon EC2 Auto Scaling"
    ],
    "reason": "1.4"
  },
  {
    "no": 158,
    "question": "一家电子商务公司使用大量的 Amazon Elastic Block Store (Amazon EBS) 支持的 Amazon EC2 实例。为了减少所有实例的手动工作，一名 DevOps 工程师被指派自动化当 EC2 实例退休事件被计划时的重启操作。这可以如何实现？",
    "choose": 1,
    "options": {
      "A": "创建一个计划的 Amazon EventBridge 规则，每周运行一次 AWS Systems Manager 自动化运行簿，检查是否有任何 EC2 实例计划退休。如果实例计划退休，运行簿将休眠实例。",
      "B": "在所有实例上启用 EC2 自动恢复。创建一个 AWS Config 规则，仅在维护窗口期间限制恢复。",
      "C": "在批准的维护窗口期间重启所有 EC2 实例，该窗口在标准工作时间之外。设置 Amazon CloudWatch 警报，以防任何实例未通过 EC2 实例状态检查时发送通知。",
      "D": "设置一个 AWS Health Amazon EventBridge 规则，当计划的退休事件发生时，运行 AWS Systems Manager 自动化运行簿以停止并启动 EC2 实例。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项提到了使用 EventBridge 规则和 Systems Manager 自动化运行簿，但是选择休眠实例并不是处理退休事件的最佳方式，因为休眠不等同于重启或替换实例。",
      "B": "虽然启用自动恢复是一个好的实践，但此选项限制了恢复只能在维护窗口期间发生，这可能不适用于紧急需要恢复的情况。",
      "C": "此选项提到了在维护窗口期间重启所有实例，但这是一个过于笼统和不精确的方法，可能导致不必要的中断。",
      "D": "这是最佳选项，因为它直接针对计划的退休事件使用 EventBridge 和 Systems Manager 自动化运行簿来停止并启动实例，确保实例可以被适当地管理和替换。"
    },
    "service": [
      "Amazon EC2",
      "Amazon EBS",
      "AWS Systems Manager",
      "Amazon EventBridge",
      "AWS Health"
    ],
    "reason": "2.3"
  },
  {
    "no": 160,
    "question": "一家公司拥有一个 AWS Control Tower 登陆区。公司的 DevOps 团队创建了一个工作负载 OU。在工作负载 OU 下嵌套了一个开发 OU 和一个生产 OU。公司授权用户完全访问公司的 AWS 账户以部署应用程序。DevOps 团队需要只允许特定的管理 IAM 角色管理仅生产 OU 中的任何 AWS 账户的 IAM 角色和策略。哪两个步骤的组合将满足这些要求？（选择两个。）",
    "choose": 2,
    "options": {
      "A": "为组织根创建一个 SCP，该 SCP 拒绝完全访问，并带有排除管理 IAM 角色的条件。",
      "B": "确保在组织根部应用 FullAWSAccess SCP。",
      "C": "创建一个允许 IAM 相关操作的 SCP。将 SCP 附加到开发 OU。",
      "D": "创建一个拒绝 IAM 相关操作的 SCP，并带有排除管理 IAM 角色的条件。将 SCP 附加到工作负载 OU。",
      "E": "创建一个拒绝 IAM 相关操作的 SCP，并带有排除管理 IAM 角色的条件。将 SCP 附加到生产 OU。"
    },
    "best": ["A", "E"],
    "analysis": {
      "A": "这是最佳选项之一，因为它通过创建一个 SCP 来拒绝所有用户的完全访问权限，但排除了管理 IAM 角色，从而允许该角色管理 IAM 资源。",
      "B": "这个选项不是最佳选项，因为 FullAWSAccess SCP 允许所有操作，不提供限制或区分不同用户或角色的功能。",
      "C": "这个选项不是最佳选项，因为它将 SCP 附加到开发 OU，而不是生产 OU，这与需求不符。",
      "D": "这个选项不是最佳选项，因为它将 SCP 附加到工作负载 OU，而不是直接附加到生产 OU，可能会影响到开发 OU 中的账户。",
      "E": "这是最佳选项之一，因为它直接在生产 OU 上设置了一个 SCP，拒绝 IAM 相关操作，但排除了管理 IAM 角色，符合需求。"
    },
    "service": ["AWS Control Tower", "IAM", "SCP"],
    "reason": "2.2"
  },
  {
    "no": 157,
    "question": "一名 DevOps 工程师注意到在自动扩展组中的所有 Amazon EC2 实例在应用程序负载均衡器后面运行都无法响应用户请求。EC2 实例也未能通过目标组的 HTTP 健康检查。在检查后，工程师注意到任何 EC2 实例中都没有运行应用程序进程。系统日志中有大量内存不足的消息。工程师需要提高应用程序的弹性，以应对潜在的应用程序内存泄漏。应启用监控和通知，以在出现问题时发出警报。哪两项组合的操作可以满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "更改自动扩展配置，以在实例未通过负载均衡器的健康检查时替换实例。",
      "B": "更改目标组健康检查 HealthCheckIntervalSeconds 参数以减少健康检查之间的间隔。",
      "C": "将目标组健康检查从 HTTP 更改为 TCP，以检查应用程序正在监听的端口是否可达。",
      "D": "在 Amazon CloudWatch 仪表板中为整个自动扩展组启用可用内存消耗指标。创建一个内存利用率高的警报。关联一个 Amazon SNS 主题以在警报触发时接收通知。",
      "E": "使用 Amazon CloudWatch 代理收集自动扩展组中 EC2 实例的内存利用率。创建一个内存利用率高的警报并关联一个 Amazon SNS 主题以接收通知。"
    },
    "best": ["D", "E"],
    "analysis": {
      "A": "虽然替换失败的实例可以临时解决问题，但它并不解决内存泄漏的根本原因，因此不是最佳选择。",
      "B": "减少健康检查间隔不会解决内存泄漏问题，只会更频繁地检测到实例失败。",
      "C": "更改为 TCP 健康检查只是检查端口可达性，并不能检测内存泄漏或应用程序是否正常运行。",
      "D": "监控内存消耗并在内存使用过高时发出警报是一种有效的方法，可以及时发现潜在的内存泄漏问题。",
      "E": "使用 CloudWatch 代理监控内存利用率并在达到高水平时发出警报，可以帮助及时识别和处理内存泄漏问题。"
    },
    "service": [
      "Amazon EC2",
      "Application Load Balancer",
      "Auto Scaling",
      "Amazon CloudWatch",
      "Amazon SNS"
    ],
    "reason": "3.1"
  },
  {
    "no": 162,
    "question": "一家公司在 Amazon Elastic Kubernetes Service (Amazon EKS) 集群中运行应用程序。EKS 集群使用应用程序负载均衡器来路由到集群中运行的应用程序的流量。新迁移至 EKS 集群的应用程序性能表现不佳。集群中的所有其他应用程序都保持适当的运行。新应用程序在部署后立即水平扩展到预配置的最大数量的 pod，而在此之前没有任何用户流量路由到该 Web 应用程序。哪种解决方案将解决 EKS 集群中 Web 应用程序的扩展行为？",
    "choose": 1,
    "options": {
      "A": "在 EKS 集群中实施水平 Pod 自动扩缩。",
      "B": "在 EKS 集群中实施垂直 Pod 自动扩缩。",
      "C": "实施集群自动扩缩。",
      "D": "在 EKS 集群中实施 AWS 负载均衡控制器。"
    },
    "best": ["A"],
    "analysis": {
      "A": "水平 Pod 自动扩缩 (HPA) 根据 CPU 使用率或其他指标自动调整 Pod 数量，适合解决应用程序在部署前就达到最大 Pod 数的问题。",
      "B": "垂直 Pod 自动扩缩 (VPA) 调整 Pod 的 CPU 和内存资源，不适合解决 Pod 数量过多的问题。",
      "C": "集群自动扩缩主要用于根据需要自动调整集群的节点数，不直接解决单个应用的扩展问题。",
      "D": "AWS 负载均衡控制器主要管理入口流量和路由，不直接解决应用的自动扩展问题。"
    },
    "service": [
      "Amazon EKS",
      "Application Load Balancer",
      "Horizontal Pod Autoscaler",
      "Vertical Pod Autoscaler",
      "Cluster Autoscaler",
      "AWS Load Balancer Controller"
    ],
    "reason": "3.2"
  },
  {
    "no": 161,
    "question": "一家公司雇佣了一名渗透测试员来模拟内部安全漏洞。测试员对公司的 Amazon EC2 实例执行了端口扫描。公司的安全措施未能检测到端口扫描。公司需要一种解决方案，当对 EC2 实例执行端口扫描时，能自动提供通知。公司创建并订阅了一个 Amazon Simple Notification Service (Amazon SNS) 主题。公司接下来应该做什么来满足这一需求？",
    "choose": 1,
    "options": {
      "A": "确保启用了 Amazon GuardDuty。为检测到的 EC2 和端口扫描发现创建一个 Amazon CloudWatch 警报。将警报连接到 SNS 主题。",
      "B": "确保启用了 Amazon Inspector。为检测到的网络可达性发现创建一个 Amazon EventBridge 事件，表明进行了端口扫描。将事件连接到 SNS 主题。",
      "C": "确保启用了 Amazon Inspector。为检测到的 CVEs 创建一个 Amazon EventBridge 事件，这些 CVEs 导致了开放端口漏洞。将事件连接到 SNS 主题。",
      "D": "确保启用了 AWS CloudTrail。创建一个 AWS Lambda 函数来分析 CloudTrail 日志中来自 IP 地址范围的异常流量量。将 Lambda 函数连接到 SNS 主题。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为 Amazon GuardDuty 是一种威胁检测服务，能自动检测和生成有关恶意或未经授权行为的警报。通过创建 CloudWatch 警报并连接到 SNS 主题，可以实现对端口扫描的自动通知。",
      "B": "这个选项不是最佳选项，因为 Amazon Inspector 主要用于应用程序安全性和合规性的评估，而不是实时的威胁检测。",
      "C": "这个选项不是最佳选项，因为它关注的是 CVEs 导致的开放端口漏洞，而不是端口扫描活动本身。",
      "D": "这个选项不是最佳选项，因为虽然 AWS CloudTrail 可以记录 API 调用和相关事件，但它不是专门用于检测端口扫描的。此外，创建和维护 Lambda 函数来分析日志可能需要更多的管理和配置工作。"
    },
    "service": [
      "Amazon EC2",
      "Amazon SNS",
      "Amazon GuardDuty",
      "Amazon CloudWatch",
      "Amazon Inspector",
      "AWS CloudTrail",
      "AWS Lambda"
    ],
    "reason": "6.3"
  },
  {
    "no": 164,
    "question": "一家公司在 Amazon EC2 实例上运行工作负载。该公司需要一个控制措施，要求在 AWS 账户中的所有 EC2 实例上使用实例元数据服务版本 2（IMDSv2）。如果 EC2 实例未阻止使用实例元数据服务版本 1（IMDSv1），则必须终止 EC2 实例。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在账户中设置 AWS Config。使用托管规则检查 EC2 实例。配置规则以使用 AWS Systems Manager 自动化来修正发现的问题，终止实例。",
      "B": "创建一个权限边界，阻止如果没有设置 ec2:MetadataHttpTokens 条件键为 required 的值，则阻止 ec2:RunInstance 操作。将权限边界附加到用于启动实例的 IAM 角色。",
      "C": "在账户中设置 Amazon Inspector。配置 Amazon Inspector 激活 EC2 实例的深度检查。为 Inspector2 发现创建一个 Amazon EventBridge 规则。设置一个 AWS Lambda 函数作为目标来终止实例。",
      "D": "为 EC2 实例启动成功事件创建一个 Amazon EventBridge 规则。将事件发送到一个 AWS Lambda 函数以检查 EC2 元数据并终止实例。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为 AWS Config 可以监控和评估 AWS 资源的配置，以确保它们符合预期的配置基线。通过使用 AWS Systems Manager 自动化，可以自动执行修正操作，如终止不符合要求的实例。",
      "B": "此选项不是最佳选项，因为它只在创建实例时阻止不符合条件的实例启动，但不处理已经运行的实例。",
      "C": "此选项不是最佳选项，因为 Amazon Inspector 主要用于安全漏洞扫描，而不是用于实施和强制执行配置管理。",
      "D": "此选项不是最佳选项，因为它依赖于编写 Lambda 函数来检查和终止实例，这增加了复杂性和潜在的错误点。"
    },
    "service": [
      "AWS Config",
      "AWS Systems Manager",
      "Amazon Inspector",
      "Amazon EventBridge",
      "AWS Lambda"
    ],
    "reason": "2.3"
  },
  {
    "no": 163,
    "question": "一家公司拥有一个管理其在 AWS Organizations 中组织的 AWS Control Tower 登陆区。该公司根据公司的要求创建了一个 OU 结构。公司的 DevOps 团队已经为解决方案建立了核心账户，并为所有集中的 AWS CloudFormation 和 AWS Service Catalog 解决方案建立了一个账户。公司希望通过 AWS Control Tower 提供一系列账户可以请求的自定义。哪些步骤的组合将满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "通过使用服务管理权限，为 CloudFormation 与 Organizations 启用受信任的访问。",
      "B": "创建一个名为 AWSControlTowerBlueprintAccess 的 IAM 角色。配置该角色的信任策略，允许管理账户中的 AWSControlTowerAdmin 角色扮演该角色。将 AWSServiceCatalogAdminFullAccess IAM 策略附加到 AWSControlTowerBlueprintAccess 角色。",
      "C": "为每个 CloudFormation 模板创建一个 Service Catalog 产品。",
      "D": "为每个 CloudFormation 模板创建一个 CloudFormation 堆栈集。为每个堆栈集启用自动部署。创建一个针对特定 OU 的 CloudFormation 堆栈实例。",
      "E": "部署 Customizations for AWS Control Tower (CfCT) CloudFormation 堆栈。",
      "F": "创建一个包含每个自定义资源的 CloudFormation 模板。"
    },
    "best": ["B", "D", "E"],
    "analysis": {
      "A": "虽然启用受信任的访问对于集成服务很重要，但这一步骤并不直接涉及到通过 AWS Control Tower 提供自定义。",
      "B": "这是最佳选项之一，因为它涉及到创建一个可以由管理账户中的 AWSControlTowerAdmin 角色扮演的 IAM 角色，这对于管理和部署自定义至关重要。",
      "C": "创建 Service Catalog 产品是一个好的实践，但它并不是直接通过 AWS Control Tower 提供自定义的必要步骤。",
      "D": "这是最佳选项之一，因为它涉及到为每个模板创建堆栈集并针对特定 OU 实现自动部署，这是在多个 OU 中实现自定义的有效方式。",
      "E": "这是最佳选项之一，因为部署 Customizations for AWS Control Tower (CfCT) CloudFormation 堆栈是实现和管理自定义的标准方法。",
      "F": "虽然创建包含自定义资源的模板是一个重要步骤，但它本身并不足以满足通过 AWS Control Tower 提供自定义的需求。"
    },
    "service": [
      "AWS Control Tower",
      "AWS Organizations",
      "IAM",
      "AWS CloudFormation",
      "AWS Service Catalog"
    ],
    "reason": "2.2"
  },
  {
    "no": 165,
    "question": "一家公司构建了一个应用程序，该应用程序在位于自动扩展组中的 Amazon EC2 实例前使用应用程序负载均衡器。该应用程序是无状态的。自动扩展组使用完全预构建的自定义 AMI。EC2 实例没有自定义引导过程。自动扩展组使用的 AMI 最近被删除。自动扩展组的扩展活动显示失败，因为 AMI ID 不存在。DevOps 工程师应采取哪些步骤组合来满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "创建一个使用新 AMI 的新启动模板。",
      "B": "更新自动扩展组以使用新的启动模板。",
      "C": "将自动扩展组的期望容量减少到 0。",
      "D": "将自动扩展组的期望容量增加 1。",
      "E": "从自动扩展组中运行的 EC2 实例创建新的 AMI。",
      "F": "通过复制 EC2 实例使用的操作系统的最新公共 AMI 来创建新的 AMI。"
    },
    "best": ["A", "B", "E"],
    "analysis": {
      "A": "创建一个使用新 AMI 的新启动模板是必要的，因为原 AMI 已被删除，需要替换。",
      "B": "更新自动扩展组以使用新的启动模板是必要的，以确保新实例可以使用新的 AMI 正确启动。",
      "C": "将自动扩展组的期望容量减少到 0 不是必要的，因为这会停止所有实例，而不是解决 AMI 问题。",
      "D": "仅增加自动扩展组的期望容量并不能解决 AMI 不存在的问题。",
      "E": "从自动扩展组中运行的 EC2 实例创建新的 AMI 是一个有效的解决方案，可以确保新的 AMI 包含所需的配置和应用程序。",
      "F": "复制操作系统的最新公共 AMI 可能不包含所需的特定配置或应用程序，因此不是最佳选择。"
    },
    "service": [
      "Amazon EC2",
      "Auto Scaling",
      "Application Load Balancer",
      "AMI"
    ],
    "reason": "3.2"
  },
  {
    "no": 168,
    "question": "一位 DevOps 工程师正在构建一个解决方案，该解决方案使用 Amazon Simple Queue Service (Amazon SQS) 标准队列。该解决方案还包括一个 AWS Lambda 函数和一个 Amazon DynamoDB 表。Lambda 函数从 SQS 队列事件源拉取内容并将内容写入 DynamoDB 表。该解决方案必须最大化 Lambda 的可扩展性，并且必须防止成功处理的 SQS 消息被多次处理。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在配置 Lambda 函数的事件源映射时，将批处理窗口减少到 1 秒。",
      "B": "在配置 Lambda 函数的事件源映射时，将批处理大小减少到 1。",
      "C": "在 Lambda 函数的事件源映射中的 FunctionResponseTypes 列表中包含 ReportBatchItemFailures 值。",
      "D": "设置 Lambda 函数的事件源映射上的队列可见性超时，以考虑 Lambda 函数的调用限制。"
    },
    "best": ["D"],
    "analysis": {
      "A": "减少批处理窗口到 1 秒可能会增加 Lambda 函数的调用频率，但不会直接防止消息被多次处理。",
      "B": "减少批处理大小到 1 可以减少一次处理的消息数量，但这会降低处理效率并可能增加成本，同时也不保证防止消息重复处理。",
      "C": "包含 ReportBatchItemFailures 值允许 Lambda 函数报告批处理中的单个项目失败，这有助于错误处理，但不直接解决消息的重复处理问题。",
      "D": "设置队列的可见性超时以考虑 Lambda 函数的调用限制可以确保在 Lambda 函数处理消息期间，这些消息不会被再次发送到其他 Lambda 函数，从而防止消息被多次处理。这是最佳选项，因为它直接解决了问题的核心——防止消息重复处理。"
    },
    "service": ["Amazon SQS", "AWS Lambda", "Amazon DynamoDB"],
    "reason": "3.2"
  },
  {
    "no": 167,
    "question": "一家公司使用 AWS Organizations 中的组织来管理其 AWS 账户。该公司的自动化账户包含一个 CI/CD 管道，用于创建和配置新的 AWS 账户。该公司有一组内部服务团队，为组织中的账户提供服务。服务团队在一组服务账户中运营。服务团队希望在 CreateAccount API 调用创建新账户时，在其服务账户中接收 AWS CloudTrail 事件。该公司应如何与服务账户共享此 CloudTrail 事件？",
    "choose": 1,
    "options": {
      "A": "在自动化账户中创建一个 Amazon EventBridge 规则，将账户创建事件发送到服务账户中的默认事件总线。更新服务账户中的默认事件总线，允许来自自动化账户的事件。",
      "B": "在服务账户中创建一个自定义 Amazon EventBridge 事件总线。更新自定义事件总线以允许来自自动化账户的事件。在服务账户中创建一个直接监听自动化账户的 CloudTrail 事件的 EventBridge 规则。",
      "C": "在自动化账户和服务账户中创建一个自定义 Amazon EventBridge 事件总线。创建一个 EventBridge 规则和策略，连接自动化账户和服务账户中的自定义事件总线。",
      "D": "在自动化账户中创建一个自定义 Amazon EventBridge 事件总线。创建一个 EventBridge 规则和策略，将自定义事件总线连接到服务账户中的默认事件总线。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最优选项，因为它直接使用 EventBridge 规则将事件从自动化账户的默认事件总线发送到服务账户的默认事件总线，并更新权限以允许此类事件流动。",
      "B": "这个选项不是最优的，因为它涉及创建额外的自定义事件总线和额外的配置，这增加了复杂性且不是必需的。",
      "C": "这个选项不是最优的，因为它创建了不必要的自定义事件总线，并且在两个账户之间建立连接更加复杂。",
      "D": "这个选项不是最优的，因为它只在自动化账户中创建了自定义事件总线，而没有在服务账户中创建，这可能导致事件传递不成功。"
    },
    "service": [
      "AWS Organizations",
      "CI/CD",
      "AWS CloudTrail",
      "Amazon EventBridge"
    ],
    "reason": "2.2"
  },
  {
    "no": 170,
    "question": "一家公司使用 AWS Organizations 管理其 AWS 账户。该公司最近收购了另一家拥有独立 AWS 账户的公司。收购公司的 DevOps 团队需要整合两家公司的 AWS 账户管理，并保留对账户的完全管理控制权。DevOps 团队还需要收集和分组所有账户的发现，以实施和维护安全姿态。DevOps 团队应采取哪两项措施来满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "邀请被收购公司的 AWS 账户加入组织。创建具有完全管理权限的 SCP。将 SCP 附加到管理账户。",
      "B": "邀请被收购公司的 AWS 账户加入组织。在被邀请账户中创建 OrganizationAccountAccessRole IAM 角色。授予管理账户扮演该角色的权限。",
      "C": "使用 AWS Security Hub 收集和分组所有账户的发现。使用 Security Hub 自动检测账户加入组织时的新账户。",
      "D": "使用 AWS Firewall Manager 收集和分组所有账户的发现。为组织启用所有功能。指定组织中的一个账户作为 Firewall Manager 的委派管理员账户。",
      "E": "使用 Amazon Inspector 收集和分组所有账户的发现。指定组织中的一个账户作为 Amazon Inspector 的委派管理员账户。"
    },
    "best": ["B", "C"],
    "analysis": {
      "A": "虽然这个选项提到了将账户加入组织并创建具有完全管理权限的 SCP，但它没有提到如何在账户间实现角色扮演，这对于管理和安全实践是必要的。",
      "B": "这是一个最佳选项，因为它不仅涉及将账户加入组织，还包括在被邀请账户中创建 IAM 角色并授予管理账户扮演该角色的权限，这有助于集中管理和控制。",
      "C": "这也是一个最佳选项，因为使用 AWS Security Hub 可以有效地收集和分组所有账户的安全发现，并自动检测新加入的账户，有助于维护整体的安全姿态。",
      "D": "虽然使用 AWS Firewall Manager 可以帮助管理安全策略，但它主要关注网络安全，不涉及账户管理或角色扮演，因此不是最佳选项。",
      "E": "Amazon Inspector 主要用于安全评估，而不是账户管理或整合，因此不是最佳选项。"
    },
    "service": [
      "AWS Organizations",
      "AWS Security Hub",
      "IAM",
      "AWS Firewall Manager",
      "Amazon Inspector"
    ],
    "reason": "2.2"
  },
  {
    "no": 169,
    "question": "一家公司拥有一个新的 AWS 账户，团队将使用该账户部署各种应用程序。团队将为特定应用程序目的和存储 AWS CloudTrail 日志创建许多 Amazon S3 存储桶。公司已为该账户启用 Amazon Macie。一名 DevOps 工程师需要优化该账户的 Macie 成本，同时不影响账户的功能。以下哪些解决方案能满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "从自动发现中排除包含 CloudTrail 日志的 S3 存储桶。",
      "B": "从自动发现中排除具有公共读取访问权限的 S3 存储桶。",
      "C": "为账户中的所有 S3 存储桶配置每日定时发现作业。",
      "D": "配置发现作业以包括基于最后修改标准的 S3 对象。",
      "E": "配置发现作业以仅包括标记为生产的 S3 对象。"
    },
    "best": ["A", "E"],
    "analysis": {
      "A": "排除包含 CloudTrail 日志的 S3 存储桶可以减少不必要的 Macie 扫描，因为这些日志通常不包含敏感数据，这是一个成本效益高的选择。",
      "B": "排除具有公共读取访问权限的 S3 存储桶可能不是最佳选择，因为公共存储桶可能包含敏感数据，应该被 Macie 扫描以确保安全。",
      "C": "配置每日定时发现作业可能会增加不必要的成本，因为它不区分存储桶的重要性或内容。",
      "D": "包括基于最后修改标准的 S3 对象可能导致频繁的扫描，增加成本，而不一定提供额外的安全性。",
      "E": "仅包括标记为生产的 S3 对象可以确保 Macie 扫描集中在最关键的数据上，从而优化成本和效率。"
    },
    "service": ["Amazon S3", "AWS CloudTrail", "Amazon Macie"],
    "reason": "6.2"
  },
  {
    "no": 166,
    "question": "一家公司在 Application Load Balancer (ALB) 后面的 Amazon EC2 实例上部署了一个 Web 应用程序。该公司将应用程序代码存储在 AWS CodeCommit 仓库中。当代码合并到主分支时，AWS Lambda 函数调用 AWS CodeBuild 项目。CodeBuild 项目打包代码，将打包后的代码存储在 AWS CodeArtifact 中，并调用 AWS Systems Manager Run Command 将打包代码部署到 EC2 实例。以前的部署导致了缺陷，EC2 实例未运行最新版本的打包代码，以及实例之间的不一致。DevOps 工程师应采取哪些组合措施来实现更可靠的部署解决方案？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "在 AWS CodePipeline 中创建一个管道，使用 CodeCommit 仓库作为源提供者。配置管道阶段，以并行运行 CodeBuild 项目来构建和测试应用程序。在管道中，将 CodeBuild 项目的输出构件传递给 AWS CodeDeploy 操作。",
      "B": "在 AWS CodePipeline 中创建一个管道，使用 CodeCommit 仓库作为源提供者。创建分开的管道阶段，运行 CodeBuild 项目来构建然后测试应用程序。在管道中，将 CodeBuild 项目的输出构件传递给 AWS CodeDeploy 操作。",
      "C": "创建一个 AWS CodeDeploy 应用程序和一个部署组，以部署打包代码到 EC2 实例。为部署组配置 ALB。",
      "D": "创建单独的 Lambda 函数，使用 AWS CodeDeploy 而不是 Systems Manager 来运行构建、测试和部署操作。",
      "E": "创建一个 Amazon S3 存储桶。修改 CodeBuild 项目，将包存储在 S3 存储桶中而不是在 CodeArtifact 中。使用 CodeDeploy 中的部署操作将构件部署到 EC2 实例。"
    },
    "best": ["B", "C"],
    "analysis": {
      "A": "虽然这个选项提出了使用 CodePipeline 和 CodeDeploy，但并行构建和测试可能导致依赖问题和测试的不准确。",
      "B": "这个选项通过分开的阶段来构建和测试，确保了测试的准确性，并且使用 CodeDeploy 可以更好地管理部署过程，确保所有实例都运行最新的代码。",
      "C": "这个选项通过创建 CodeDeploy 应用程序和部署组，确保了部署的一致性和可靠性，同时配置 ALB 支持负载均衡和故障转移。",
      "D": "使用多个 Lambda 函数可能会增加管理复杂性，并且不如集中管理的 CodePipeline 和 CodeDeploy 方案可靠。",
      "E": "虽然使用 S3 作为存储可能简化存储过程，但不提供 CodeArtifact 的一些安全和管理功能，且这个选项没有明确改善部署的可靠性。"
    },
    "service": [
      "AWS CodeCommit",
      "AWS Lambda",
      "AWS CodeBuild",
      "AWS CodeArtifact",
      "AWS Systems Manager",
      "Amazon EC2",
      "Application Load Balancer",
      "AWS CodeDeploy",
      "Amazon S3"
    ],
    "reason": "1.4"
  },
  {
    "no": 171,
    "question": "一家公司有一个应用程序和一个CI/CD管道。CI/CD管道由一个AWS CodePipeline管道和一个AWS CodeBuild项目组成。CodeBuild项目在构建过程中对应用程序运行测试并输出测试报告。公司必须保留测试报告90天。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在包含CodeBuild项目的阶段之后的CodePipeline管道中添加一个新阶段。创建一个Amazon S3存储桶来存储报告。在新的CodePipeline阶段中配置一个S3部署操作类型，具有适当的报告路径和格式。",
      "B": "在CodeBuild项目的buildspec文件中添加一个报告组，具有适当的报告路径和格式。创建一个Amazon S3存储桶来存储报告。配置一个Amazon EventBridge规则，当构建完成时调用一个AWS Lambda函数将报告复制到S3存储桶。创建一个S3生命周期规则在90天后过期对象。",
      "C": "在CodePipeline管道中添加一个新阶段。配置一个测试操作类型，具有适当的报告路径和格式。在CodeBuild项目的buildspec文件中配置报告过期时间为90天。",
      "D": "在CodeBuild项目的buildspec文件中添加一个报告组，具有适当的报告路径和格式。创建一个Amazon S3存储桶来存储报告。将报告组配置为CodeBuild项目buildspec文件中的一个工件。将S3存储桶配置为工件目的地。设置对象过期为90天。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项没有提到如何自动管理报告的生命周期，即在90天后自动删除报告。",
      "B": "此选项虽然提供了自动删除报告的方法，但是使用EventBridge和Lambda增加了额外的复杂性和潜在的错误点。",
      "C": "此选项没有提到如何将报告存储到S3，且没有提供自动删除报告的方法。",
      "D": "此选项直接在CodeBuild的buildspec文件中配置报告组和S3存储桶，简化了流程。同时，通过设置S3对象的过期时间为90天，自动管理了报告的生命周期。因此，这是最优选项。"
    },
    "service": [
      "AWS CodePipeline",
      "AWS CodeBuild",
      "Amazon S3",
      "AWS Lambda",
      "Amazon EventBridge"
    ],
    "reason": "1.2"
  },
  {
    "no": 174,
    "question": "一家公司使用 AWS Organizations 管理其 AWS 账户。该公司有一个根 OU，它有一个子 OU。根 OU 有一个 SCP，允许对所有资源进行所有操作。子 OU 有一个 SCP，允许对 Amazon DynamoDB 和 AWS Lambda 进行所有操作，并拒绝所有其他操作。该公司有一个名为 vendor-data 的 AWS 账户位于子 OU 中。一位 DevOps 工程师在 vendor-data 账户中附加了 Administrator Access IAM 策略的 IAM 用户。DevOps 工程师尝试在 vendor-data 账户中启动 Amazon EC2 实例，但收到访问被拒绝错误。DevOps 工程师应该做哪些更改才能在 vendor-data 账户中启动 EC2 实例？",
    "choose": 1,
    "options": {
      "A": "将 AmazonEC2FullAccess IAM 策略附加到 IAM 用户。",
      "B": "创建一个允许 Amazon EC2 所有操作的新 SCP。将 SCP 附加到 vendor-data 账户。",
      "C": "更新子 OU 中的 SCP 以允许 Amazon EC2 的所有操作。",
      "D": "创建一个允许 Amazon EC2 所有操作的新 SCP。将 SCP 附加到根 OU。"
    },
    "best": ["C"],
    "analysis": {
      "A": "仅附加 IAM 策略不足以覆盖 SCP 的限制，因此这不是正确的解决方案。",
      "B": "SCP 不能直接附加到单个账户，它们必须附加到 OU 或根级别。",
      "C": "这是正确的解决方案，因为更新子 OU 中的 SCP 允许 EC2 操作将覆盖现有的限制，允许 DevOps 工程师启动 EC2 实例。",
      "D": "将 SCP 附加到根 OU 不会影响子 OU 中已经明确拒绝的操作。"
    },
    "service": [
      "AWS Organizations",
      "Amazon DynamoDB",
      "AWS Lambda",
      "Amazon EC2",
      "IAM"
    ],
    "reason": "2.2"
  },
  {
    "no": 172,
    "question": "一家公司使用 Amazon API Gateway 区域性 REST API 来托管其应用程序 API。REST API 有一个自定义域名。REST API 的默认端点已被停用。公司的内部团队使用该 API。公司希望在 API 和内部团队之间使用相互 TLS 作为额外的身份验证层。哪两个步骤的组合将满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "使用 AWS 证书管理器 (ACM) 创建一个私有证书颁发机构 (CA)。提供由私有 CA 签名的客户端证书。",
      "B": "提供由公共证书颁发机构 (CA) 签名的客户端证书。将证书导入 AWS 证书管理器 (ACM)。",
      "C": "将提供的客户端证书上传到 Amazon S3 存储桶。配置 API Gateway 相互 TLS 以使用存储在 S3 存储桶中的客户端证书作为信任存储。",
      "D": "将提供的客户端证书私钥上传到 Amazon S3 存储桶。配置 API Gateway 相互 TLS 以使用存储在 S3 存储桶中的私钥作为信任存储。",
      "E": "将根私有证书颁发机构 (CA) 证书上传到 Amazon S3 存储桶。配置 API Gateway 相互 TLS 以使用存储在 S3 存储桶中的私有 CA 证书作为信任存储。"
    },
    "best": ["A", "E"],
    "analysis": {
      "A": "这是最佳选项之一，因为创建私有 CA 并使用其签名的客户端证书可以确保 API 和内部团队之间的通信安全和身份验证。",
      "B": "这不是最佳选项，因为虽然使用公共 CA 签名的证书可以提供身份验证，但在内部使用时，使用私有 CA 更为安全和适合。",
      "C": "这不是最佳选项，因为将客户端证书存储在 S3 并不符合最佳安全实践，且 API Gateway 的相互 TLS 配置通常不使用客户端证书作为信任存储。",
      "D": "这不是最佳选项，因为将私钥上传到 S3 是不安全的，且不符合 API Gateway 相互 TLS 的配置要求。",
      "E": "这是最佳选项之一，因为上传根 CA 证书到 S3 并在 API Gateway 中配置使用这个证书作为信任存储，可以确保只有受信任的客户端可以访问 API。"
    },
    "service": ["Amazon API Gateway", "AWS Certificate Manager", "Amazon S3"],
    "reason": "6.2"
  },
  {
    "no": 175,
    "question": "一家公司的安全政策要求在生产环境中使用安全加固的 AMI。一位 DevOps 工程师使用 EC2 Image Builder 创建了一个定期构建 AMI 的管道。DevOps 工程师需要更新公司的 Auto Scaling 组的启动模板。Auto Scaling 组在启动 Amazon EC2 实例时必须使用最新的 AMI。哪种解决方案在操作效率最高的情况下满足这些要求？",
    "choose": 1,
    "options": {
      "A": "配置一个 Amazon EventBridge 规则以接收来自 Image Builder 的新 AMI 事件。目标是一个 AWS Systems Manager Run Command 文档，该文档更新 Auto Scaling 组的启动模板以使用最新的 AMI ID。",
      "B": "配置一个 Amazon EventBridge 规则以接收来自 Image Builder 的新 AMI 事件。目标是一个 AWS Lambda 函数，该函数更新 Auto Scaling 组的启动模板以使用最新的 AMI ID。",
      "C": "配置启动模板以使用来自 AWS Systems Manager 参数存储的 AMI ID 值。配置 Image Builder 管道以使用最新的 AMI ID 更新参数存储值。",
      "D": "配置 Image Builder 分发设置以更新启动模板以使用最新的 AMI ID。配置 Auto Scaling 组以使用启动模板的最新版本。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然这种方法可以实现自动更新，但使用 Run Command 文档可能会增加操作复杂性和执行时间。",
      "B": "使用 Lambda 函数是一个有效的自动化方法，但与选项 C 相比，它可能需要更多的自定义代码和维护。",
      "C": "这种方法通过直接在参数存储中更新 AMI ID，并让启动模板引用这个值，实现了高效的自动更新，减少了操作复杂性，是最优解。",
      "D": "这个选项描述不完整且逻辑上存在错误，因为 Image Builder 本身不直接更新启动模板。"
    },
    "service": [
      "EC2 Image Builder",
      "Amazon EventBridge",
      "AWS Systems Manager",
      "AWS Lambda",
      "Auto Scaling"
    ],
    "reason": "1.4"
  },
  {
    "no": 176,
    "question": "一家公司在 AWS Lambda 函数上配置了一个 Amazon S3 事件源。该公司需要在特定 S3 存储桶中创建新对象或修改现有对象时运行 Lambda 函数。Lambda 函数将使用传入事件的 S3 存储桶名称和 S3 对象键来读取已创建或修改的 S3 对象的内容。Lambda 函数将解析内容并将解析后的内容保存到 Amazon DynamoDB 表中。Lambda 函数的执行角色具有从 S3 存储桶读取和写入 DynamoDB 表的权限。在测试期间，DevOps 工程师发现当向 S3 存储桶添加对象或修改现有对象时，Lambda 函数不运行。哪种解决方案将解决此问题？",
    "choose": 1,
    "options": {
      "A": "增加 Lambda 函数的内存，以赋予函数处理 S3 存储桶中的大文件的能力。",
      "B": "在 Lambda 函数上创建资源策略，授权 Amazon S3 调用 S3 存储桶的 Lambda 函数。",
      "C": "将 Amazon Simple Queue Service (Amazon SQS) 队列配置为 Lambda 函数的 OnFailure 目的地。",
      "D": "在 Lambda 函数的 /tmp 文件夹中预留空间，以赋予函数处理 S3 存储桶中的大文件的能力。"
    },
    "best": ["B"],
    "analysis": {
      "A": "增加内存并不能解决 Lambda 函数未被触发的问题，因为这与内存大小无关。",
      "B": "创建资源策略授权 S3 调用 Lambda 函数是正确的解决方案，因为 Lambda 函数需要适当的权限才能被 S3 事件触发。",
      "C": "配置 SQS 队列作为失败目的地并不解决 Lambda 函数未被触发的问题，这只是处理失败情况的一种方式。",
      "D": "预留 /tmp 文件夹空间同样不解决触发问题，这只是处理大文件的一种方式。"
    },
    "service": ["AWS Lambda", "Amazon S3", "Amazon DynamoDB", "Amazon SQS"],
    "reason": "5.1"
  },
  {
    "no": 173,
    "question": "一家公司使用 AWS Directory Service for Microsoft Active Directory 作为其身份提供商 (IdP)。该公司要求所有基础设施由 AWS CloudFormation 定义和部署。一位 DevOps 工程师需要创建一组基于 Windows 的 Amazon EC2 实例来托管应用程序。DevOps 工程师已创建一个包含 EC2 启动模板、IAM 角色、EC2 安全组和 EC2 Auto Scaling 组的 CloudFormation 模板。DevOps 工程师必须实施一个解决方案，将所有 EC2 实例加入到 AWS 托管的 Microsoft AD 目录的域中。哪种解决方案能以最高的操作效率满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在 CloudFormation 模板中，创建一个 AWS::SSM::Document 资源，使用现有目录的参数将 EC2 实例加入到 AWS 托管的 Microsoft AD 域。更新启动模板以包括使用新的 SSM 文档的 SSMAssociation 属性。将 AmazonSSMManagedInstanceCore 和 AmazonSSMDirectoryServiceAccess AWS 托管策略附加到 EC2 实例使用的 IAM 角色。",
      "B": "在 CloudFormation 模板中，更新启动模板以包括在启动时传播的特定标签。创建一个 AWS::SSM::Association 资源，将 AWS-JoinDirectoryServiceDomain 自动化运行手册与具有指定标签的 EC2 实例关联。定义加入 AWS 托管的 Microsoft AD 目录所需的参数。将 AmazonSSMManagedInstanceCore 和 AmazonSSMDirectoryServiceAccess AWS 托管策略附加到 EC2 实例使用的 IAM 角色。",
      "C": "将现有的 AWS 托管 Microsoft AD 域连接详细信息存储在 AWS Secrets Manager 中。在 CloudFormation 模板中，创建一个 AWS::SSM::Association 资源，将 AWS-CreateManagedWindowsInstanceWithApproval 自动化运行手册与 EC2 Auto Scaling 组关联。传递来自 Secrets Manager 的参数 ARNs 以加入域。将 AmazonSSMDirectoryServiceAccess 和 SecretsManagerReadWrite AWS 托管策略附加到 EC2 实例使用的 IAM 角色。",
      "D": "将现有的 AWS 托管 Microsoft AD 域管理员凭据存储在 AWS Secrets Manager 中。在 CloudFormation 模板中，更新 EC2 启动模板以包括用户数据。配置用户数据以从 Secrets Manager 拉取管理员凭据并加入 AWS 托管的 Microsoft AD 域。将 AmazonSSMManagedInstanceCore 和 SecretsManagerReadWrite AWS 托管策略附加到 EC2 实例使用的 IAM 角色。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项通过创建 SSM 文档和更新启动模板来加入域，但它不如使用标签和自动化运行手册的方法灵活和易于管理。",
      "B": "此选项通过使用标签和 AWS-JoinDirectoryServiceDomain 自动化运行手册，以及附加必要的 AWS 托管策略，提供了一个高效且易于管理的解决方案，是最佳选择。",
      "C": "此选项涉及使用 Secrets Manager 存储域连接详细信息，这增加了复杂性，并且不如选项 B 中的方法操作效率高。",
      "D": "此选项通过使用用户数据和 Secrets Manager 来加入域，但这种方法比选项 B 更复杂，且操作效率较低。"
    },
    "service": [
      "AWS Directory Service",
      "AWS CloudFormation",
      "Amazon EC2",
      "IAM",
      "AWS::SSM::Document",
      "AWS::SSM::Association",
      "AWS Secrets Manager"
    ],
    "reason": "2.1"
  },
  {
    "no": 180,
    "question": "一家公司正在使用 AWS CodePipeline 部署应用程序。根据新的指导方针，公司的安全团队的一名成员必须在将更改部署到生产环境之前对任何应用程序更改进行签名。批准必须被记录并保留。哪两项组合的操作能满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "配置 CodePipeline 将操作写入 Amazon CloudWatch 日志。",
      "B": "在每个管道阶段结束时配置 CodePipeline 将操作写入 Amazon S3 存储桶。",
      "C": "创建一个 AWS CloudTrail 跟踪，将日志交付到 Amazon S3。",
      "D": "创建一个 CodePipeline 自定义操作以调用 AWS Lambda 函数进行批准。创建一个策略，授权安全团队管理 CodePipeline 自定义操作。",
      "E": "在部署步骤之前创建一个 CodePipeline 手动批准操作。创建一个策略，授权安全团队批准手动批准阶段。"
    },
    "best": ["D", "E"],
    "analysis": {
      "A": "虽然将操作写入 CloudWatch 日志可以记录操作，但它不提供批准机制。",
      "B": "将操作写入 S3 存储桶可以保留记录，但同样不提供批准机制。",
      "C": "CloudTrail 提供审计跟踪，但主要用于记录 API 调用，不直接用于批准更改。",
      "D": "创建自定义操作调用 Lambda 函数可以实现批准流程，并通过策略控制安全团队的访问权限，满足需求。",
      "E": "手动批准操作允许安全团队在部署前进行批准，符合新指导方针的要求。"
    },
    "service": [
      "AWS CodePipeline",
      "Amazon CloudWatch",
      "Amazon S3",
      "AWS CloudTrail",
      "AWS Lambda"
    ],
    "reason": "领域 1-SDLC 自动化"
  },
  {
    "no": 177,
    "question": "一家公司在两个 AWS 区域部署了一个关键应用程序。该应用程序在两个区域都使用了应用程序负载均衡器（ALB）。该公司为两个 ALB 设置了 Amazon Route 53 别名 DNS 记录。该公司使用 Amazon Route 53 应用程序恢复控制器确保应用程序可以在两个区域之间故障转移。Route 53 ARC 配置包括两个区域的路由控制。该公司使用 Route 53 ARC 进行季度灾难恢复（DR）测试。在最近的 DR 测试中，一名 DevOps 工程师意外关闭了两个路由控制。该公司需要确保至少有一个路由控制始终处于开启状态。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在 Route 53 ARC 中创建一个新的断言安全规则。将断言安全规则应用于两个路由控制。将规则配置为 ATLEAST 类型，阈值为 1。",
      "B": "在 Route 53 ARC 中创建一个新的门控安全规则。将断言安全规则应用于两个路由控制。将规则配置为 OR 类型，阈值为 1。",
      "C": "在 Route 53 ARC 中创建一个新的资源集。将资源集配置为 AWS::Route53::HealthCheck 资源类型。指定两个路由控制的 ARN 作为目标资源。为资源集创建一个新的就绪检查。",
      "D": "在 Route 53 ARC 中创建一个新的资源集。将资源集配置为 AWS::Route53RecoveryReadiness::DNSTargetResource 资源类型。添加两个 Route 53 别名 DNS 记录的域名作为目标资源。为资源集创建一个新的就绪检查。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为断言安全规则可以确保至少有一个路由控制始终处于开启状态，符合公司的需求。",
      "B": "这个选项不正确，因为它提到了门控安全规则，但实际上应用的是断言安全规则，且 OR 类型和阈值的设置不符合要求。",
      "C": "这个选项不正确，因为它涉及到创建资源集和健康检查，这与确保至少一个路由控制始终开启的需求不相关。",
      "D": "这个选项不正确，因为它涉及到创建资源集和就绪检查，这与确保至少一个路由控制始终开启的需求不相关。"
    },
    "service": [
      "Amazon Route 53",
      "Amazon Route 53 Application Recovery Controller"
    ],
    "reason": "3.3"
  },
  {
    "no": 181,
    "question": "一家公司要求其内部业务团队仅通过预先批准的 AWS CloudFormation 模板启动资源。安全团队要求在资源偏离其预期状态时进行自动监控。应使用哪种策略来满足这些要求？",
    "choose": 1,
    "options": {
      "A": "仅允许用户使用 CloudFormation 服务角色部署 CloudFormation 堆栈。使用 CloudFormation 偏移检测来检测资源是否已从其预期状态偏移。",
      "B": "仅允许用户使用 CloudFormation 服务角色部署 CloudFormation 堆栈。使用 AWS Config 规则来检测资源是否已从其预期状态偏移。",
      "C": "仅允许用户使用 AWS Service Catalog 部署 CloudFormation 堆栈。强制使用启动约束。使用 AWS Config 规则来检测资源是否已从其预期状态偏移。",
      "D": "仅允许用户使用 AWS Service Catalog 部署 CloudFormation 堆栈。强制使用模板约束。使用 Amazon EventBridge 通知来检测资源是否已从其预期状态偏移。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然使用 CloudFormation 偏移检测可以检测资源状态的偏移，但这个选项没有限制用户只能使用预批准的模板。",
      "B": "使用 AWS Config 规则可以有效监控资源状态，但同样没有限制用户只能使用预批准的模板。",
      "C": "这个选项不仅限制了用户只能使用预批准的模板（通过 AWS Service Catalog），还使用了 AWS Config 规则进行资源状态监控，完全符合题目要求。",
      "D": "虽然限制了用户只能使用预批准的模板，但使用 Amazon EventBridge 通知可能不如 AWS Config 规则直接和有效地监控资源状态。"
    },
    "service": [
      "AWS CloudFormation",
      "AWS Service Catalog",
      "AWS Config",
      "Amazon EventBridge"
    ],
    "reason": "2.1"
  },
  {
    "no": 179,
    "question": "一位 DevOps 工程师正在计划将基于 Ruby 的应用程序部署到生产环境。该应用程序需要与 Amazon RDS for MySQL 数据库进行交互，并且应具有自动缩放和高可用性。数据库中存储的数据至关重要，无论应用程序堆栈的状态如何，都应保持持久性。DevOps 工程师需要为应用程序设置自动化部署策略，并具有自动回滚功能。该解决方案还必须在部署失败时提醒应用程序团队。哪种步骤组合能满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "在 AWS Elastic Beanstalk 上部署应用程序。将 Amazon RDS for MySQL DB 实例作为 Elastic Beanstalk 配置的一部分进行部署。",
      "B": "在 AWS Elastic Beanstalk 上部署应用程序。在 Elastic Beanstalk 外部单独部署 Amazon RDS for MySQL DB 实例。",
      "C": "在 AWS Elastic Beanstalk 配置中配置通知电子邮件地址，以提醒应用程序团队。",
      "D": "配置 Amazon EventBridge 规则以监控 AWS 健康事件。使用 Amazon Simple Notification Service (Amazon SNS) 主题作为目标，以提醒应用程序团队。",
      "E": "使用不可变部署方法部署新的应用程序版本。",
      "F": "使用滚动部署方法部署新的应用程序版本。"
    },
    "best": ["B", "D", "E"],
    "analysis": {
      "A": "将数据库与 Elastic Beanstalk 环境一起部署可能会导致数据库与应用程序生命周期紧密耦合，这不利于数据的持久性和独立管理。",
      "B": "将数据库实例与 Elastic Beanstalk 环境分开部署可以确保数据库的独立性和持久性，符合题目要求。",
      "C": "虽然这种配置可以提供基本的通知功能，但使用 Amazon SNS 通过 EventBridge 提供更复杂的监控和通知机制更为合适。",
      "D": "EventBridge 和 SNS 的组合提供了强大的监控和通知功能，可以有效地在部署失败时通知应用程序团队。",
      "E": "不可变部署提供了一种安全的部署方式，可以在新版本部署时保持现有应用的稳定性，并且易于自动回滚，符合题目要求。",
      "F": "滚动部署虽然可以逐步更新应用版本，但在出现问题时回滚较为复杂，不如不可变部署方法稳定和安全。"
    },
    "service": [
      "AWS Elastic Beanstalk",
      "Amazon RDS for MySQL",
      "Amazon EventBridge",
      "Amazon Simple Notification Service (Amazon SNS)"
    ],
    "reason": "1.4"
  },
  {
    "no": 178,
    "question": "一家医疗服务公司担心监测患者健康的应用程序的软件许可成本不断增加。该公司希望建立一个审计流程，确保该应用程序仅在 Amazon EC2 Dedicated Hosts 上运行。一名 DevOps 工程师必须创建一个工作流程来审计该应用程序以确保合规性。工程师应采取哪些步骤以最小的管理开销满足此要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS Systems Manager Configuration Compliance。使用 put-compliance-items API 动作的调用来扫描并构建一个基于宿主放置配置的不合规 EC2 实例的数据库。使用 Amazon DynamoDB 表来存储这些实例 ID 以便快速访问。通过调用 list-compliance-summaries API 动作在 Systems Manager 中生成报告。",
      "B": "使用在 EC2 实例上运行的自定义 Java 代码。根据需要检查的实例数量设置 EC2 Auto Scaling。将不合规的 EC2 实例 ID 列表发送到 Amazon SQS 队列。设置另一个工作实例从 SQS 队列处理实例 ID 并将它们写入 Amazon DynamoDB。使用 AWS Lambda 函数终止从队列获得的不合规实例 ID，并将它们发送到 Amazon SNS 电子邮件主题进行分发。",
      "C": "使用 AWS Config。通过启用对该地区所有 Amazon EC2 资源的 Config 记录来识别所有要审计的 EC2 实例。创建一个自定义 AWS Config 规则，该规则触发一个使用“config-rule-change-triggered”蓝图的 AWS Lambda 函数。修改 Lambda 的 evaluateCompliance() 函数以验证宿主放置，如果实例未在 EC2 Dedicated Host 上运行，则返回 NON_COMPLIANT 结果。使用 AWS Config 报告来处理不合规实例。",
      "D": "使用 AWS CloudTrail。通过分析所有对 EC2 RunCommand API 动作的调用来识别所有要审计的 EC2 实例。调用一个 AWS Lambda 函数来分析实例的宿主放置。将不合规资源的 EC2 实例 ID 存储在 Amazon RDS for MySQL DB 实例中。通过查询 RDS 实例并将查询结果导出为 CSV 文本文件来生成报告。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然使用 AWS Systems Manager Configuration Compliance 可以实现合规性检查，但这需要额外的步骤来构建和维护数据库，增加了管理开销。",
      "B": "这个选项涉及编写自定义代码和管理多个组件，如 EC2 Auto Scaling 和 SQS，这增加了复杂性和管理负担。",
      "C": "这是最佳选项，因为 AWS Config 可以直接监控 EC2 实例并评估其合规性状态，使用 Lambda 函数自动处理不合规实例，减少了管理开销。",
      "D": "虽然使用 AWS CloudTrail 可以追踪 API 调用，但这种方法需要额外的步骤来分析和存储数据，增加了管理开销。"
    },
    "service": [
      "AWS Config",
      "AWS Lambda",
      "AWS Systems Manager",
      "Amazon DynamoDB",
      "Amazon SQS",
      "Amazon SNS",
      "AWS CloudTrail",
      "Amazon RDS for MySQL"
    ],
    "reason": "2.3"
  },
  {
    "no": 183,
    "question": "一位 DevOps 工程师正在设置基于容器的架构。工程师决定使用 AWS CloudFormation 自动配置 Amazon ECS 集群和一个 Amazon EC2 Auto Scaling 组来启动 EC2 容器实例。在成功创建 CloudFormation 堆栈后，工程师注意到，尽管 ECS 集群和 EC2 实例已成功创建且堆栈完成创建，但 EC2 实例却与不同的集群关联。DevOps 工程师应如何更新 CloudFormation 模板以解决此问题？",
    "choose": 1,
    "options": {
      "A": "在 AWS::ECS::Cluster 资源中引用 EC2 实例，并在 AWS::ECS::Service 资源中引用 ECS 集群。",
      "B": "在 AWS::AutoScaling::LaunchConfiguration 资源的 UserData 属性中引用 ECS 集群。",
      "C": "在 AWS::EC2::Instance 资源的 UserData 属性中引用 ECS 集群。",
      "D": "在 AWS::CloudFormation::CustomResource 资源中引用 ECS 集群，以触发一个 AWS Lambda 函数，该函数将 EC2 实例注册到适当的 ECS 集群。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项不正确，因为 AWS::ECS::Cluster 和 AWS::ECS::Service 资源不用于直接关联 EC2 实例和 ECS 集群。",
      "B": "此选项正确，因为通过在 Auto Scaling 的 LaunchConfiguration 中的 UserData 引用 ECS 集群，可以确保启动的 EC2 实例自动注册到正确的 ECS 集群。",
      "C": "此选项不正确，因为 AWS::EC2::Instance 资源通常不用于与 ECS 集群的直接关联，特别是在使用 Auto Scaling 时。",
      "D": "此选项虽然理论上可行，但过于复杂且不是最直接的方法。通常不推荐使用自定义资源来处理这种基础的配置问题。"
    },
    "service": [
      "AWS CloudFormation",
      "Amazon ECS",
      "Amazon EC2",
      "Auto Scaling"
    ],
    "reason": "2.1"
  },
  {
    "no": 182,
    "question": "一家公司有多个开发组在一个共享的AWS账户中工作。这些组的高级经理希望在资源创建接近账户的服务限制时通过第三方API调用进行警报。哪种解决方案能以最少的开发工作量实现这一目标？",
    "choose": 1,
    "options": {
      "A": "创建一个Amazon EventBridge规则，定期运行并定位一个AWS Lambda函数。在Lambda函数中，评估AWS环境的当前状态并将部署的资源值与账户的资源限制进行比较。如果账户接近服务限制，则通知高级经理。",
      "B": "部署一个AWS Lambda函数，刷新AWS Trusted Advisor检查，并配置一个Amazon EventBridge规则定期运行Lambda函数。创建另一个EventBridge规则，其事件模式匹配Trusted Advisor事件和一个目标Lambda函数。在目标Lambda函数中，通知高级经理。",
      "C": "部署一个AWS Lambda函数，刷新AWS Health Dashboard检查，并配置一个Amazon EventBridge规则定期运行Lambda函数。创建另一个EventBridge规则，其事件模式匹配Health Dashboard事件和一个目标Lambda函数。在目标Lambda函数中，通知高级经理。",
      "D": "添加一个AWS Config自定义规则，定期运行，检查AWS服务限制状态，并将通知流式传输到一个Amazon Simple Notification Service（Amazon SNS）主题。部署一个AWS Lambda函数来通知高级经理，并订阅Lambda函数到SNS主题。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然这个选项使用了Lambda和EventBridge，但它需要手动评估资源状态和限制，这可能会增加开发和维护的复杂性。",
      "B": "这个选项利用了AWS Trusted Advisor的自动检查功能，可以有效地监控服务限制，并通过EventBridge和Lambda自动处理通知，减少了开发和维护工作。",
      "C": "AWS Health Dashboard主要用于健康事件和维护通知，并不专注于服务限制，因此这不是最佳选项。",
      "D": "虽然使用了AWS Config和SNS，但这需要额外配置和管理自定义规则，可能不如使用Trusted Advisor那样直接有效。"
    },
    "service": [
      "AWS Lambda",
      "Amazon EventBridge",
      "AWS Trusted Advisor",
      "AWS Health Dashboard",
      "AWS Config",
      "Amazon SNS"
    ],
    "reason": "5.1"
  },
  {
    "no": 189,
    "question": "一家公司需要确保所有现有和新的 VPC 在其 AWS 账户中始终配置流日志。该公司使用 AWS CloudFormation 堆栈来管理其 VPC。公司需要一种解决方案，适用于任何 IAM 用户创建的任何 VPC。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "将 AWS::EC2::FlowLog 资源添加到创建 VPC 的 CloudFormation 堆栈中。",
      "B": "在 AWS Organizations 中创建一个组织。将公司的 AWS 账户添加到该组织中。创建一个 SCP 以防止用户修改 VPC 流日志。",
      "C": "开启 AWS Config。创建一个 AWS Config 规则来检查是否开启了 VPC 流日志。配置自动修正以开启 VPC 流日志。",
      "D": "创建一个 IAM 策略来拒绝使用 VPC 流日志的 API 调用。将 IAM 策略附加到所有 IAM 用户。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然这种方法可以确保通过 CloudFormation 创建的 VPC 配置流日志，但它不适用于不通过 CloudFormation 创建的 VPC。",
      "B": "此方法通过组织级别的策略防止用户修改流日志，但不确保流日志始终被启用。",
      "C": "这种方法通过 AWS Config 自动检查和修正确保所有 VPC，无论它们是如何创建的，都启用了流日志，满足题目要求。",
      "D": "这种方法通过拒绝 API 调用防止用户操作流日志，但不确保流日志的启用。"
    },
    "service": ["AWS CloudFormation", "AWS Organizations", "AWS Config", "IAM"],
    "reason": "2.1"
  },
  {
    "no": 184,
    "question": "一名 DevOps 工程师正在为一家要求其基础设施必须位于美国境内的公司实施治理控制。工程师必须限制可以使用的 AWS 区域，并确保一旦发生任何违反治理政策的活动，尽快发送警报。这些控制应该自动启用在美国（US）之外的任何新区域。哪两项组合的操作可以满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "创建一个 AWS Organizations SCP，拒绝访问所有非美国区域的所有非全球服务。将策略附加到组织的根部。",
      "B": "配置 AWS CloudTrail 将日志发送到 Amazon CloudWatch Logs，并为所有区域启用。使用 CloudWatch Logs 指标过滤器在非美国区域的任何服务活动发生时发送警报。",
      "C": "使用 AWS Lambda 函数检查 AWS 服务活动，并将其部署到所有区域。编写一个 Amazon EventBridge 规则，每小时运行一次 Lambda 函数，如果在非美国区域发现活动，则发送警报。",
      "D": "使用 AWS Lambda 函数查询 Amazon Inspector 以查找非美国区域的服务活动，并在发现任何活动时发送警报。",
      "E": "使用 aws:RequestedRegion 条件键编写 SCP，限制访问美国区域。将策略应用于所有用户、组和角色。"
    },
    "best": ["A", "B"],
    "analysis": {
      "A": "这是最佳选项之一，因为它通过 AWS Organizations SCP 直接限制对非美国区域的访问，符合题目要求的自动化和治理控制。",
      "B": "这是最佳选项之一，因为它通过监控所有区域的 AWS CloudTrail 日志并使用 CloudWatch Logs 指标过滤器来实时警报任何非美国区域的活动，符合题目要求的监控和警报。",
      "C": "虽然这个选项提供了监控非美国区域的方法，但每小时运行一次可能无法尽快警报，不如选项 B 的实时监控。",
      "D": "这个选项依赖于 Amazon Inspector，但 Inspector 主要用于安全评估和漏洞扫描，并不适合用于实时监控区域活动。",
      "E": "虽然这个选项限制了对非美国区域的访问，但它不提供任何监控或警报机制，因此不符合题目要求的“尽快发送警报”的部分。"
    },
    "service": [
      "AWS Organizations",
      "AWS CloudTrail",
      "Amazon CloudWatch Logs",
      "AWS Lambda",
      "Amazon EventBridge",
      "Amazon Inspector"
    ],
    "reason": "6.1"
  },
  {
    "no": 185,
    "question": "一家公司通过电子商务Web应用程序销售产品。该公司希望建立一个仪表板，显示产品交易详情的饼图。公司希望将仪表板与公司现有的Amazon CloudWatch仪表板集成。哪种解决方案在最大的操作效率下满足这些要求？",
    "choose": 1,
    "options": {
      "A": "更新电子商务应用程序，使其为每个处理的交易向CloudWatch日志组发出一个JSON对象。使用CloudWatch Logs Insights查询日志组，并将结果以饼图格式可视化。将结果附加到所需的CloudWatch仪表板上。",
      "B": "更新电子商务应用程序，使其为每个处理的交易向Amazon S3存储桶发出一个JSON对象。使用Amazon Athena查询S3存储桶，并将结果以饼图格式可视化。从Athena导出结果。将结果附加到所需的CloudWatch仪表板上。",
      "C": "更新电子商务应用程序以使用AWS X-Ray进行检测。创建一个新的X-Ray子段。为每个处理的交易添加注释。使用X-Ray追踪查询数据，并将结果以饼图格式可视化。将结果附加到所需的CloudWatch仪表板上。",
      "D": "更新电子商务应用程序，使其为每个处理的交易向CloudWatch日志组发出一个JSON对象。创建一个AWS Lambda函数来聚合并将结果写入Amazon DynamoDB。为日志文件创建一个Lambda订阅过滤器。将结果附加到所需的CloudWatch仪表板上。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最优选项，因为它直接使用CloudWatch Logs和CloudWatch Logs Insights来查询和可视化数据，这样可以无缝集成到现有的CloudWatch仪表板中，操作效率高。",
      "B": "这个选项不是最优的，因为它涉及到使用Amazon S3和Amazon Athena，这增加了操作的复杂性，并且需要从Athena导出数据再导入CloudWatch，效率较低。",
      "C": "这个选项不是最优的，因为虽然AWS X-Ray提供了强大的追踪功能，但其主要用于性能调试和分析，而不是直接用于数据可视化和仪表板集成。",
      "D": "这个选项不是最优的，因为它涉及创建额外的AWS Lambda函数和使用DynamoDB，这增加了系统的复杂性和操作成本。"
    },
    "service": [
      "Amazon CloudWatch",
      "CloudWatch Logs",
      "CloudWatch Logs Insights",
      "Amazon S3",
      "Amazon Athena",
      "AWS X-Ray",
      "AWS Lambda",
      "Amazon DynamoDB"
    ],
    "reason": "4.1"
  },
  {
    "no": 186,
    "question": "一家公司正在启动一个应用程序。该应用程序必须只使用经批准的AWS服务。运行该应用程序的账户创建不到1年，并被分配到AWS组织的一个OU中。公司需要创建一个新的组织账户结构。账户结构必须具有适当的SCP，以支持仅使用当前在AWS账户中活跃的服务。公司将在解决方案中使用AWS身份和访问管理（IAM）访问分析器。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个SCP，允许IAM访问分析器识别的服务。为账户创建一个OU。将账户移动到新的OU。将新的SCP附加到新的OU。从新的OU分离默认的FullAWSAccess SCP。",
      "B": "创建一个SCP，拒绝IAM访问分析器识别的服务。为账户创建一个OU。将账户移动到新的OU。将新的SCP附加到新的OU。",
      "C": "创建一个SCP，允许IAM访问分析器识别的服务。将新的SCP附加到组织的根。",
      "D": "创建一个SCP，允许IAM访问分析器识别的服务。为账户创建一个OU。将账户移动到新的OU。将新的SCP附加到管理账户。从新的OU分离默认的FullAWSAccess SCP。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它创建了一个SCP来允许仅使用IAM访问分析器识别的服务，确保了只使用批准的服务。此外，它还涉及创建一个新的OU并将账户移动到该OU，然后将SCP附加到新的OU，并从新的OU中分离默认的FullAWSAccess SCP，这有助于确保更精细的权限控制。",
      "B": "这个选项不是最佳的，因为它创建了一个SCP来拒绝IAM访问分析器识别的服务，这可能会不必要地限制使用某些需要的服务。",
      "C": "这个选项不是最佳的，因为它没有涉及创建新的OU或移动账户，这可能会导致权限管理不够精细。",
      "D": "这个选项不是最佳的，因为它提到将SCP附加到管理账户，而不是新的OU，这可能会导致权限应用范围不正确。"
    },
    "service": ["AWS Organizations", "IAM Access Analyzer", "SCP"],
    "reason": "2.2"
  },
  {
    "no": 187,
    "question": "一家公司有多个开发团队在不同的业务单元工作，这些团队在一个共享的单一AWS账户中工作。在账户中创建的所有Amazon EC2资源都必须包括指定创建资源的人的标签。标签必须在资源创建后的第一个小时内完成。一名DevOps工程师需要添加标签到创建的资源，这些标签包括创建资源的用户ID和成本中心ID。DevOps工程师配置了一个AWS Lambda函数，带有成本中心映射来标记资源。DevOps工程师还在AWS账户中设置了AWS CloudTrail。一个Amazon S3桶存储CloudTrail事件日志。哪种解决方案能满足标签要求？",
    "choose": 1,
    "options": {
      "A": "在S3桶上创建一个S3事件通知，以调用Lambda函数处理s3:ObjectTagging:Put事件。在S3桶上启用版本控制。",
      "B": "在S3桶上启用服务器访问日志。在S3桶上创建一个S3事件通知，用于s3:ObjectTagging:*事件。",
      "C": "创建一个定时的每小时Amazon EventBridge规则，调用Lambda函数。修改Lambda函数以从S3桶读取日志。",
      "D": "创建一个Amazon EventBridge规则，使用Amazon EC2作为事件源。配置规则以匹配由CloudTrail传递的事件。配置规则以目标Lambda函数。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它依赖于S3对象标签事件，这与CloudTrail日志和EC2资源创建无直接关联。",
      "B": "此选项不是最佳选择，因为它依赖于服务器访问日志，这与EC2资源创建和CloudTrail事件日志无直接关联。",
      "C": "此选项不是最佳选择，因为它依赖于定时任务读取日志，这可能导致延迟，并且不保证在资源创建后的第一个小时内完成标签添加。",
      "D": "此选项是最佳选择，因为它直接使用CloudTrail事件触发Lambda函数，可以确保在EC2资源创建后立即添加标签，满足题目要求。"
    },
    "service": [
      "AWS Lambda",
      "AWS CloudTrail",
      "Amazon S3",
      "Amazon EC2",
      "Amazon EventBridge"
    ],
    "reason": "2.3"
  },
  {
    "no": 192,
    "question": "一个软件团队正在使用 AWS CodePipeline 自动化其 Java 应用程序的发布管道。该管道由源阶段、构建阶段和部署阶段组成。每个阶段包含一个 runOrder 值为 1 的单一动作。团队希望将单元测试集成到现有的发布管道中。团队需要一个解决方案，只部署通过所有单元测试的代码更改。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "修改构建阶段。添加一个 runOrder 值为 1 的测试动作。使用 AWS CodeDeploy 作为动作提供者来运行单元测试。",
      "B": "修改构建阶段。添加一个 runOrder 值为 2 的测试动作。使用 AWS CodeBuild 作为动作提供者来运行单元测试。",
      "C": "修改部署阶段。添加一个 runOrder 值为 1 的测试动作。使用 AWS CodeDeploy 作为动作提供者来运行单元测试。",
      "D": "修改部署阶段。添加一个 runOrder 值为 2 的测试动作。使用 AWS CodeBuild 作为动作提供者来运行单元测试。"
    },
    "best": ["B"],
    "analysis": {
      "A": "不正确，因为 AWS CodeDeploy 用于部署而不是运行测试。",
      "B": "正确，因为 AWS CodeBuild 可以用于运行单元测试，并且将测试动作的 runOrder 设置为 2 可以确保在构建后运行测试。",
      "C": "不正确，因为测试应该在部署之前完成，而且 AWS CodeDeploy 用于部署而不是测试。",
      "D": "不正确，虽然 AWS CodeBuild 是正确的选择来运行测试，但测试应该在构建阶段而不是部署阶段进行。"
    },
    "service": ["AWS CodePipeline", "AWS CodeBuild", "AWS CodeDeploy"],
    "reason": "1.2"
  },
  {
    "no": 193,
    "question": "一家公司使用 AWS Organizations 中的组织来管理公司开发人员使用的几个 AWS 账户。该公司要求所有数据在传输中加密。在开发人员账户中创建的多个 Amazon S3 存储桶允许未加密的连接。DevOps 工程师必须强制对组织中账户创建的所有现有 S3 存储桶的数据传输进行加密。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS CloudFormation StackSets 向每个账户部署 AWS Network Firewall 防火墙。将所有出站请求从 AWS 环境路由通过防火墙。部署策略以阻止所有出站请求访问 80 端口。",
      "B": "使用 AWS CloudFormation StackSets 向每个账户部署 AWS Network Firewall 防火墙。将所有入站请求路由到 AWS 环境通过防火墙。部署策略以阻止所有入站请求访问 80 端口。",
      "C": "为组织开启 AWS Config。部署一个使用 s3-bucket-ssl-requests-only 管理规则的合规性包和一个 AWS Systems Manager Automation 运行手册。使用一个运行手册，当 aws:SecureTransport 条件键的值为 false 时，添加一个存储桶策略语句来拒绝访问 S3 存储桶。",
      "D": "为组织开启 AWS Config。部署一个使用 s3-bucket-ssl-requests-only 管理规则的合规性包和一个 AWS Systems Manager Automation 运行手册。使用一个运行手册，当 s3:x-amz-server-side-encryption-aws-kms-key-id 条件键的值为 null 时，添加一个存储桶策略语句来拒绝访问 S3 存储桶。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项通过防火墙阻止出站请求访问 80 端口，但不直接解决 S3 存储桶的数据传输加密问题。",
      "B": "此选项通过防火墙阻止入站请求访问 80 端口，但不直接解决 S3 存储桶的数据传输加密问题。",
      "C": "此选项通过 AWS Config 和 AWS Systems Manager Automation 运行手册强制 S3 存储桶只接受通过 SSL 加密的请求，直接满足题目要求。",
      "D": "此选项关注于服务器端加密的 KMS 密钥，而不是数据传输中的加密，因此不满足题目要求。"
    },
    "service": [
      "AWS Organizations",
      "Amazon S3",
      "AWS CloudFormation",
      "AWS Network Firewall",
      "AWS Config",
      "AWS Systems Manager"
    ],
    "reason": "2.1"
  },
  {
    "no": 188,
    "question": "一家公司在单个 AWS 账户中为多个环境运行一个应用程序。一个 AWS CodePipeline 管道使用开发环境的 Amazon Elastic Container Service (Amazon ECS) 集群来测试来自 Amazon Elastic Container Registry (Amazon ECR) 仓库的应用程序映像。管道将映像推广到生产环境的 ECS 集群。公司需要将生产集群移动到同一 AWS 区域的另一个 AWS 账户中。生产集群必须能够通过私有连接下载映像。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 Amazon ECR VPC 终端节点和 Amazon S3 网关终端节点。在单独的 AWS 账户中创建一个 ECR 仓库。设置仓库策略以允许生产 ECS 任务从主 AWS 账户拉取映像。配置生产 ECS 任务执行角色以获得从 ECR 仓库下载映像的权限。",
      "B": "在主 AWS 账户的生产 ECR 仓库上设置仓库策略。配置仓库策略以允许单独 AWS 账户中的生产 ECS 任务从主账户拉取映像。配置生产 ECS 任务执行角色以获得从 ECR 仓库下载映像的权限。",
      "C": "在主 AWS 账户中配置 ECR 私有映像复制。激活跨账户复制。定义单独 AWS 账户的目标账户 ID。",
      "D": "使用 Amazon ECR VPC 终端节点和 Amazon S3 网关终端节点。在主 AWS 账户的生产 ECR 仓库上设置仓库策略。配置仓库策略以允许单独 AWS 账户中的生产 ECS 任务从主账户拉取映像。配置生产 ECS 任务执行角色以获得从 ECR 仓库下载映像的权限。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它提到在单独的 AWS 账户中创建一个新的 ECR 仓库，这不是必要的，也增加了管理复杂性。",
      "B": "此选项不是最佳选择，因为它没有提到使用 VPC 终端节点，这是确保私有连接的重要组成部分。",
      "C": "此选项不是最佳选择，因为它只提到了映像复制，没有涉及如何确保生产 ECS 任务可以访问这些映像。",
      "D": "这是最佳选项，因为它涵盖了使用 VPC 终端节点确保私有连接，同时设置仓库策略允许跨账户访问，并确保生产 ECS 任务有适当的权限下载映像。"
    },
    "service": ["AWS CodePipeline", "Amazon ECS", "Amazon ECR"],
    "reason": "1.4"
  },
  {
    "no": 191,
    "question": "一家公司使用 AWS WAF 保护其云基础设施。一名 DevOps 工程师需要给运营团队提供分析 AWS WAF 日志消息的能力。运营团队需要能够为日志输出中的特定模式创建警报。哪种解决方案在最小的操作开销下满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 Amazon CloudWatch Logs 日志组。配置适当的 AWS WAF 网络 ACL 以将日志消息发送到日志组。指导运营团队创建 CloudWatch 指标过滤器。",
      "B": "创建一个 Amazon OpenSearch Service 集群和适当的索引。配置一个 Amazon Kinesis Data Firehose 传输流以将日志数据流式传输到索引。使用 OpenSearch Dashboards 创建过滤器和小部件。",
      "C": "创建一个 Amazon S3 存储桶用于日志输出。配置 AWS WAF 将日志输出发送到 S3 存储桶。指导运营团队创建 AWS Lambda 函数以检测每个所需的日志消息模式。配置 Lambda 函数以发布到 Amazon Simple Notification Service (Amazon SNS) 主题。",
      "D": "创建一个 Amazon S3 存储桶用于日志输出。配置 AWS WAF 将日志输出发送到 S3 存储桶。使用 Amazon Athena 创建一个外部表定义以适应日志消息模式。指导运营团队编写 SQL 查询并为 Athena 查询创建 Amazon CloudWatch 指标过滤器。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最优选项，因为它直接使用 CloudWatch Logs 和 CloudWatch 指标过滤器，可以简单快速地设置并且操作开销小。",
      "B": "虽然这个选项可以实现功能，但是设置和维护 OpenSearch Service 集群和 Kinesis Data Firehose 传输流的复杂性和成本较高。",
      "C": "这个选项涉及到使用 S3 和 Lambda，这增加了操作复杂性，并且可能会导致更高的成本和延迟。",
      "D": "使用 Athena 进行查询虽然功能强大，但是对于简单的日志分析和警报创建来说，操作过于复杂且成本较高。"
    },
    "service": [
      "AWS WAF",
      "Amazon CloudWatch Logs",
      "CloudWatch",
      "Amazon OpenSearch Service",
      "Amazon Kinesis Data Firehose",
      "Amazon S3",
      "AWS Lambda",
      "Amazon Simple Notification Service (Amazon SNS)",
      "Amazon Athena"
    ],
    "reason": "4.1"
  },
  {
    "no": 190,
    "question": "一家公司的应用团队使用 AWS CodeCommit 仓库来管理他们的应用程序。应用团队在多个 AWS 账户中拥有仓库。所有账户都在 AWS Organizations 的组织中。每个应用团队使用配置了外部 IdP 的 AWS IAM Identity Center (AWS Single Sign-On) 来扮演开发者 IAM 角色。开发者角色允许应用团队使用 Git 来处理仓库中的代码。安全审计显示，应用团队可以修改任何仓库的主分支。一位 DevOps 工程师必须实施一个解决方案，允许应用团队只修改他们管理的仓库的主分支。哪三个步骤的组合将满足这些要求？（选择三个。）",
    "choose": 3,
    "options": {
      "A": "更新 SAML 断言以传递用户的团队名称。更新 IAM 角色的信任策略以添加具有团队名称的 access-team 会话标签。",
      "B": "在组织管理账户中为每个团队创建一个审批规则模板。将模板与所有仓库关联。将开发者角色 ARN 添加为审批者。",
      "C": "为每个账户创建一个审批规则模板。将模板与所有仓库关联。在审批规则模板中添加“aws:ResourceTag/access-team”: “${aws:PrincipalTag/access-team}”条件。",
      "D": "为每个 CodeCommit 仓库添加一个 access-team 标签，其值设置为关联团队的名称。",
      "E": "在账户中附加一个 SCP。包括以下声明：",
      "F": "在每个账户中创建一个 IAM 权限边界。包括以下声明："
    },
    "best": ["A", "C", "D"],
    "analysis": {
      "A": "这是最优选项之一，因为通过更新 SAML 断言和 IAM 角色的信任策略，可以确保只有具有正确团队名称标签的用户才能访问特定资源。",
      "B": "这不是最优选项，因为虽然创建审批规则模板可以控制谁可以批准更改，但它不限制对主分支的修改权限。",
      "C": "这是最优选项之一，因为通过在审批规则模板中添加条件，可以确保只有标记与资源标记匹配的 IAM 实体才能修改仓库。",
      "D": "这是最优选项之一，因为为每个仓库添加特定团队的标签可以帮助实施基于标签的访问控制，确保只有相应团队可以修改他们的仓库。",
      "E": "这不是最优选项，因为仅附加 SCP 不足以限制对特定仓库的访问或修改。",
      "F": "这不是最优选项，因为权限边界虽然可以限制 IAM 角色的最大权限，但它不直接关联到特定仓库的访问控制。"
    },
    "service": [
      "AWS CodeCommit",
      "AWS IAM Identity Center",
      "AWS Organizations",
      "IAM",
      "SAML",
      "SCP"
    ],
    "reason": "6.1"
  },
  {
    "no": 194,
    "question": "一家公司正在审查其IAM策略。一项由DevOps工程师编写的策略被标记为过于宽松。该策略被用于一个AWS Lambda函数，该函数在周末向标记为Environment: NonProduction的Amazon EC2实例发出停止命令。当前的策略是：工程师应该做哪些更改以实现最小权限策略？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "添加以下条件表达式：",
      "B": "将\"Resource\": \"*\"更改为\"Resource\": \"arn:aws:ec2:*:*:instance/*\"",
      "C": "添加以下条件表达式：",
      "D": "添加以下条件表达式：",
      "E": "将\"Action\": \"ec2:*\"更改为\"Action\": \"ec2:StopInstances\"",
      "F": "添加以下条件表达式："
    },
    "best": ["B", "E", "F"],
    "analysis": {
      "A": "虽然添加条件表达式可以增加限制，但没有具体信息说明这个条件表达式是什么，因此无法判断其有效性。",
      "B": "将资源从所有实例更改为特定的ARN模式，这是实现最小权限的一个很好的实践，因为它限制了策略的作用范围。",
      "C": "同A，缺乏具体的条件表达式内容，无法评估其对最小权限策略的贡献。",
      "D": "同A和C，没有具体的条件表达式，无法确定其有效性。",
      "E": "将操作从所有EC2操作更改为仅StopInstances，这显著减少了权限范围，符合最小权限原则。",
      "F": "如果条件表达式正确指定了非生产环境的标签，这将是一个有效的选择，因为它确保了策略只在符合特定条件的实例上执行。"
    },
    "service": ["IAM", "AWS Lambda", "Amazon EC2"],
    "reason": "6.1"
  },
  {
    "no": 195,
    "question": "一家公司正在开发一个应用程序，该应用程序将生成日志事件。日志事件每十分之一秒包含五个不同的指标，并产生大量数据。公司需要配置应用程序将日志写入 Amazon Timestream。公司将配置针对 Timestream 表的每日查询。哪种步骤组合将以最快的查询性能满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "使用批量写入在单个写操作中写入多个日志事件。",
      "B": "将每个日志事件作为单个写操作写入。",
      "C": "将每个日志视为单一测量记录。",
      "D": "将每个日志视为多测量记录。",
      "E": "将内存存储保留期配置为比磁性存储保留期更长。",
      "F": "将内存存储保留期配置为比磁性存储保留期更短。"
    },
    "best": ["A", "D", "F"],
    "analysis": {
      "A": "使用批量写入可以减少写入操作的次数，从而提高写入效率和查询性能。",
      "B": "将每个日志事件作为单个写操作写入会增加写入操作的次数，降低效率。",
      "C": "将每个日志视为单一测量记录可能不适合处理包含多个指标的日志事件。",
      "D": "将每个日志视为多测量记录可以更有效地组织数据，提高查询性能。",
      "E": "将内存存储保留期配置为比磁性存储保留期更长可能会导致不必要的成本增加，且不利于快速查询性能。",
      "F": "将内存存储保留期配置为比磁性存储保留期更短可以确保数据更快地转移到磁性存储，从而优化查询性能。"
    },
    "service": ["Amazon Timestream"],
    "reason": "4.1"
  },
  {
    "no": 196,
    "question": "一位 DevOps 工程师创建了一个 AWS CloudFormation 模板，该模板在 Amazon EC2 实例上部署应用程序。EC2 实例运行 Amazon Linux。应用程序通过包含用户数据的 shell 脚本部署到 EC2 实例上。EC2 实例具有一个 IAM 实例配置文件，该配置文件具有一个附加了 AmazonSSMManagedinstanceCore 托管策略的 IAM 角色。DevOps 工程师修改了 CloudFormation 模板中的用户数据以安装应用程序的新版本。工程师还应用了堆栈更新。然而，运行中的 EC2 实例上没有更新应用程序。工程师需要确保对运行中的 EC2 实例进行应用程序更改的安装。哪两个步骤的组合将满足这些要求？（选择两个。）",
    "choose": 2,
    "options": {
      "A": "将用户数据内容配置为使用多用途互联网邮件扩展（MIME）多部分格式。在 text/cloud-config 部分将 scripts-user 参数设置为 always。",
      "B": "将用户数据命令重构为使用 cfn-init 帮助脚本。更新用户数据以安装和配置 cfn-hup 和 cfn-init 帮助脚本以监视和应用元数据更改。",
      "C": "为 EC2 实例配置一个 EC2 启动模板。创建一个新的 EC2 Auto Scaling 组。将 Auto Scaling 组与 EC2 启动模板关联。对 Auto Scaling 组使用 AutoScalingScheduledAction 更新策略。",
      "D": "将用户数据命令重构为使用 AWS Systems Manager 文档（SSM 文档）。在用户数据中添加一个 AWS CLI 命令，使用 Systems Manager Run Command 将 SSM 文档应用于 EC2 实例。",
      "E": "将用户数据命令重构为使用 AWS Systems Manager 文档（SSM 文档）。使用 Systems Manager State Manager 在 SSM 文档和 EC2 实例之间创建关联。"
    },
    "best": ["B", "E"],
    "analysis": {
      "A": "虽然使用 MIME 多部分格式可以更灵活地处理用户数据，但仅设置 scripts-user 参数为 always 并不足以确保应用程序更新，因为它不处理元数据或配置的动态更新。",
      "B": "使用 cfn-init 和 cfn-hup 脚本可以有效地管理和应用 CloudFormation 元数据的更改，这对于确保应用程序更新被正确应用至 EC2 实例是必要的。",
      "C": "虽然使用 EC2 Auto Scaling 和启动模板可以部署新实例，但这并不直接影响已经运行的实例上的应用程序更新。",
      "D": "使用 SSM 文档和 Run Command 可以远程执行配置更改，但这需要额外的步骤来确保文档适用于应用程序更新，且不如 State Manager 直接。",
      "E": "使用 Systems Manager State Manager 创建 SSM 文档和 EC2 实例之间的关联是一种有效的方法，可以确保所有目标实例都定期接收和应用配置更新，包括应用程序的新版本。"
    },
    "service": [
      "AWS CloudFormation",
      "Amazon EC2",
      "IAM",
      "AWS Systems Manager"
    ],
    "reason": "2.1"
  },
  {
    "no": 197,
    "question": "一家公司正在重构应用程序以使用 AWS。该公司确定了一个内部 Web 应用程序，需要在特定的 AWS 账户中进行 Amazon S3 API 调用。公司希望使用其现有的身份提供商 (IdP) auth.company.com 进行身份验证。该 IdP 仅支持 OpenID Connect (OIDC)。一名 DevOps 工程师需要保护 Web 应用程序对 AWS 账户的访问。哪种步骤组合将满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "配置 AWS IAM 身份中心（AWS 单点登录）。配置一个 IdP。上传现有 IdP 的 IdP 元数据。",
      "B": "使用现有 IP 的提供者 URL、受众和签名创建一个 IAM IdP。",
      "C": "创建一个 IAM 角色，该角色具有允许必要的 S3 操作的策略。配置角色的信任策略，以允许 OIDC IP 在 sts.amazon.com:aud 上下文键为 appid_from_idp 时扮演角色。",
      "D": "创建一个 IAM 角色，该角色具有允许必要的 S3 操作的策略。配置角色的信任策略，以允许 OIDC IP 在 auth.company.com:aud 上下文键为 appid_from_idp 时扮演角色。",
      "E": "配置 Web 应用程序以使用 AssumeRoleWithWebIdentity API 操作检索临时凭证。使用临时凭证进行 S3 API 调用。",
      "F": "配置 Web 应用程序以使用 GetFederationToken API 操作检索临时凭证。使用临时凭证进行 S3 API 调用。"
    },
    "best": ["B", "D", "E"],
    "analysis": {
      "A": "此选项不是最佳选择，因为 AWS IAM Identity Center (AWS Single Sign-On) 不支持 OIDC，而是用于 SAML 2.0。",
      "B": "此选项是最佳选择之一，因为它涉及使用现有的 OIDC IdP 创建 IAM 身份提供商，这是连接现有身份系统与 AWS 的标准方法。",
      "C": "此选项不是最佳选择，因为它错误地引用了 sts.amazon.com 作为受众，这不符合题目中提到的 auth.company.com。",
      "D": "此选项是最佳选择之一，因为它正确地设置了 IAM 角色和信任策略，以允许从 OIDC IdP auth.company.com 扮演角色。",
      "E": "此选项是最佳选择之一，因为它涉及使用 AssumeRoleWithWebIdentity，这是一个适用于 OIDC 提供商的 API，用于获取访问 S3 所需的临时凭证。",
      "F": "此选项不是最佳选择，因为 GetFederationToken 主要用于 AWS 账户内的联合用户身份，而不是 OIDC 方案。"
    },
    "service": [
      "IAM",
      "Amazon S3",
      "AWS IAM Identity Center",
      "AssumeRoleWithWebIdentity",
      "GetFederationToken"
    ],
    "reason": "6.1"
  },
  {
    "no": 199,
    "question": "一家公司正在从其本地数据中心迁移到 AWS。该公司目前使用自定义的本地 CI/CD 管道解决方案来构建和打包软件。公司希望其软件包和依赖的公共存储库在 AWS CodeArtifact 中可用，以便于创建特定于应用程序的管道。公司应采取哪些步骤组合来更新 CI/CD 管道解决方案并配置 CodeArtifact，以实现最小的操作开销？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "更新 CI/CD 管道以创建包含新打包软件的 VM 映像。使用 AWS Import/Export 使 VM 映像作为 Amazon EC2 AMI 可用。启动带有允许 CodeArtifact 操作的 IAM 实例配置文件的 AMI。使用 AWS CLI 命令将包发布到 CodeArtifact 存储库。",
      "B": "创建一个 AWS 身份和访问管理角色任何地方的信任锚。创建一个允许 CodeArtifact 操作并具有信任锚信任关系的 IAM 角色。更新本地 CI/CD 管道以假设新的 IAM 角色并将包发布到 CodeArtifact。",
      "C": "创建一个新的 Amazon S3 存储桶。生成允许 PutObject 请求的预签名 URL。更新本地 CI/CD 管道以使用预签名 URL 从本地位置发布包到 S3 存储桶。创建一个在存储桶中通过 put 命令创建包时运行的 AWS Lambda 函数。配置 Lambda 函数以将包发布到 CodeArtifact。",
      "D": "为每个公共存储库创建一个配置有外部连接的 CodeArtifact 存储库。将依赖存储库配置为上游公共存储库。",
      "E": "创建一个配置有一组外部连接到公共存储库的 CodeArtifact 存储库。将外部连接配置为存储库的下游。"
    },
    "best": ["B", "E"],
    "analysis": {
      "A": "此选项涉及创建 VM 映像和使用 Import/Export，这增加了操作复杂性和开销，不是最佳选择。",
      "B": "此选项通过创建 IAM 角色和信任关系，允许本地 CI/CD 管道直接与 AWS CodeArtifact 交互，减少了操作开销，是最佳选择之一。",
      "C": "此选项涉及使用 S3 和 Lambda，虽然可行，但相比直接使用 IAM 角色和 CodeArtifact，操作更为复杂。",
      "D": "此选项主要关注配置存储库与公共存储库的连接，而不直接涉及 CI/CD 管道的更新，因此不是最佳选择。",
      "E": "此选项通过配置 CodeArtifact 存储库与公共存储库的连接，简化了依赖管理，是最佳选择之一。"
    },
    "service": [
      "AWS CodeArtifact",
      "IAM",
      "Amazon S3",
      "AWS Lambda",
      "AWS CLI",
      "AWS Import/Export"
    ],
    "reason": "1.1"
  },
  {
    "no": 204,
    "question": "一家公司有一个AWS CodeDeploy应用程序。该应用程序有一个部署组，使用单个标签组来识别部署应用程序的实例。单个标签组配置识别具有Environment=Production和Name=ApplicationA标签的实例，用于部署ApplicationA。公司启动了一个额外的Amazon EC2实例，带有Department=Marketing, Environment=Production和Name=ApplicationB标签。在下一次CodeDeploy部署应用程序时，额外的实例上安装了ApplicationA。DevOps工程师需要配置现有的部署组，以防止在额外的实例上安装ApplicationA。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "将当前单个标签组更改为仅包含Environment=Production标签。添加另一个单个标签组，仅包含Name=ApplicationA标签。",
      "B": "将当前单个标签组更改为包含Department=Marketing, Environment=production和Name=ApplicationA标签。",
      "C": "添加另一个单个标签组，仅包含Department=Marketing标签。保持当前单个标签组的Environment=Production和Name=ApplicationA标签。",
      "D": "将当前单个标签组更改为仅包含Environment=Production标签。添加另一个单个标签组，仅包含Department=Marketing标签。"
    },
    "best": ["B"],
    "analysis": {
      "A": "这个选项不会阻止额外的实例部署ApplicationA，因为它没有考虑Department标签。",
      "B": "这个选项通过确保只有具有正确Department、Environment和Name标签的实例才能部署ApplicationA，从而满足需求。",
      "C": "这个选项不会阻止额外的实例部署ApplicationA，因为它没有正确限制Name标签。",
      "D": "这个选项不会阻止额外的实例部署ApplicationA，因为它没有考虑Name标签。"
    },
    "service": ["AWS CodeDeploy", "Amazon EC2"],
    "reason": "1.4"
  },
  {
    "no": 201,
    "question": "一家公司最近在 AWS 上部署了其 Web 应用程序。该公司正在为大规模销售活动做准备，并必须确保 Web 应用程序可以扩展以满足需求。应用程序的前端基础设施包括一个 Amazon CloudFront 分发，其源是一个 Amazon S3 存储桶。后端基础设施包括一个 Amazon API Gateway API、几个 AWS Lambda 函数和一个 Amazon Aurora DB 集群。公司的 DevOps 工程师进行了负载测试，并确定 Lambda 函数可以满足请求的峰值数量。然而，DevOps 工程师注意到在请求的初始突发期间存在请求延迟。大多数对 Lambda 函数的请求都会产生对数据库的查询。大部分调用时间用于建立数据库连接。哪种步骤组合将为应用程序提供所需的可扩展性？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "为 Lambda 函数配置更高的保留并发。",
      "B": "为 Lambda 函数配置更高的预置并发。",
      "C": "将 DB 集群转换为 Aurora 全球数据库。在基于公司客户所在位置的 AWS 区域中添加额外的 Aurora 副本。",
      "D": "重构 Lambda 函数。将初始化数据库连接的代码块移动到函数处理程序中。",
      "F": "使用 Amazon RDS Proxy 为 Aurora 数据库创建一个代理。更新 Lambda 函数以使用代理端点进行数据库连接。"
    },
    "best": ["B", "C", "F"],
    "analysis": {
      "A": "虽然增加保留并发可以提高 Lambda 函数的处理能力，但它并不直接解决数据库连接初始化的问题。",
      "B": "预置并发可以立即提供预热的实例，减少启动延迟，有助于处理初始请求突发。",
      "C": "使用 Aurora 全球数据库和在多个区域添加副本可以提高数据库的读取性能和可用性，减少延迟。",
      "D": "仅将数据库连接初始化移动到函数处理程序中并不能解决连接初始化所需时间的问题，可能还会增加每次调用的延迟。",
      "F": "使用 RDS Proxy 可以有效管理数据库连接，减少需要建立的连接数，从而减少延迟并提高扩展性。"
    },
    "service": [
      "Amazon CloudFront",
      "Amazon S3",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon Aurora",
      "Amazon RDS Proxy"
    ],
    "reason": "3.2"
  },
  {
    "no": 203,
    "question": "一家公司的应用程序运行在 Amazon EC2 实例上。该应用程序将登录信息写入日志文件，记录用户名、日期、时间和源 IP 地址。日志发布到 Amazon CloudWatch Logs 的日志组中。公司正在对前一天发生的事件进行根本原因分析。公司需要知道过去 7 天内特定用户的登录次数。哪种解决方案可以提供这些信息？",
    "choose": 1,
    "options": {
      "A": "在日志组上创建一个 CloudWatch Logs 指标过滤器。使用与用户名匹配的过滤模式。发布一个 CloudWatch 指标，汇总过去 7 天的登录次数。",
      "B": "在日志组上创建一个 CloudWatch Logs 订阅。使用与用户名匹配的过滤模式。发布一个 CloudWatch 指标，汇总过去 7 天的登录次数。",
      "C": "创建一个 CloudWatch Logs Insights 查询，使用聚合函数计算过去 7 天内该用户名的登录次数。在日志组上运行查询。",
      "D": "创建一个 CloudWatch 仪表板。添加一个数字小部件，该小部件有一个过滤模式，直接从日志组中计算过去 7 天内该用户名的登录次数。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然指标过滤器可以用于创建基于日志数据的自定义指标，但它们主要用于实时监控而不是进行历史数据分析。",
      "B": "订阅用于将日志数据实时流式传输到其他服务，例如 Lambda 或 Kinesis，不适用于直接的日志数据分析。",
      "C": "CloudWatch Logs Insights 提供了强大的日志查询和分析功能，可以直接在日志数据上运行复杂的查询，非常适合进行历史数据分析和根本原因分析。",
      "D": "虽然 CloudWatch 仪表板可以显示实时和历史数据，但它不支持直接在日志数据上运行复杂的查询，其功能更侧重于监控而不是深入分析。"
    },
    "service": [
      "Amazon EC2",
      "Amazon CloudWatch Logs",
      "CloudWatch Logs Insights"
    ],
    "reason": "4.1"
  },
  {
    "no": 198,
    "question": "一家公司在其 AWS 账户中使用 Amazon RDS 用于所有数据库。该公司使用 AWS Control Tower 构建了一个具有审计和日志记录账户的登陆区。出于合规性原因，所有数据库都必须在静止状态下进行加密。公司的安全工程师需要接收到公司账户中任何不合规数据库的通知。哪种解决方案在最大程度上满足这些要求并具有最高的操作效率？",
    "choose": 1,
    "options": {
      "A": "使用 AWS Control Tower 激活可选的侦探控制（护栏）以确定 RDS 存储是否加密。在公司的审计账户中创建一个 Amazon Simple Notification Service（Amazon SNS）主题。创建一个 Amazon EventBridge 规则来过滤来自 AWS Control Tower 控制（护栏）的不合规事件以通知 SNS 主题。订阅安全工程师的电子邮件地址到 SNS 主题。",
      "B": "使用 AWS CloudFormation StackSets 在每个账户中部署 AWS Lambda 函数。编写 Lambda 函数代码以确定部署到的账户中的 RDS 存储是否加密。将发现作为 Amazon CloudWatch 指标发送到管理账户。创建一个 Amazon Simple Notification Service（Amazon SNS）主题。创建一个 CloudWatch 警报，当达到指标阈值时通知 SNS 主题。订阅安全工程师的电子邮件地址到 SNS 主题。",
      "C": "在每个账户中创建一个自定义 AWS Config 规则以确定 RDS 存储是否加密。在审计账户中创建一个 Amazon Simple Notification Service（Amazon SNS）主题。创建一个 Amazon EventBridge 规则来过滤来自 AWS Control Tower 控制（护栏）的不合规事件以通知 SNS 主题。订阅安全工程师的电子邮件地址到 SNS 主题。",
      "D": "启动一个 Amazon EC2 实例。使用 AWS CLI 运行一个每小时的 cron 作业以确定每个 AWS 账户中的 RDS 存储是否加密。将结果存储在 RDS 数据库中。在检测到不合规时通过 EC2 实例发送电子邮件通知安全工程师"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它利用了 AWS Control Tower 的护栏功能来自动检测 RDS 存储是否加密，并通过 EventBridge 和 SNS 实现自动通知，这样可以提高操作效率并减少手动干预。",
      "B": "这个选项虽然可以实现功能，但是需要在每个账户中部署和维护 Lambda 函数，这增加了操作复杂性和成本。",
      "C": "这个选项提到了在每个账户中创建 AWS Config 规则，但是它错误地提到了使用 AWS Control Tower 的护栏来通知，这在技术上是不可行的，因为 AWS Config 和 Control Tower 的护栏是两种不同的控制机制。",
      "D": "这个选项涉及手动管理 EC2 实例和编写 cron 作业，这不仅操作复杂，而且效率低下，容易出错。"
    },
    "service": [
      "AWS Control Tower",
      "Amazon RDS",
      "Amazon SNS",
      "Amazon EventBridge",
      "AWS CloudFormation",
      "AWS Lambda",
      "Amazon CloudWatch",
      "AWS Config",
      "Amazon EC2"
    ],
    "reason": "6.3"
  },
  {
    "no": 202,
    "question": "一家公司运行一个跨多个可用区的Web应用程序。该公司使用应用程序负载均衡器（ALB）进行路由，使用AWS Fargate运行应用程序，并使用Amazon Aurora存储应用程序数据。该公司使用AWS CloudFormation模板部署应用程序。该公司将所有Docker镜像存储在同一AWS账户和AWS区域的Amazon弹性容器注册表（Amazon ECR）仓库中。一位DevOps工程师需要在另一个区域建立灾难恢复（DR）流程。解决方案必须满足8小时的恢复点目标（RPO）和2小时的恢复时间目标（RTO）。公司有时需要超过2小时来构建Docker镜像。哪种解决方案最能以成本效益的方式满足RTO和RPO要求？",
    "choose": 1,
    "options": {
      "A": "将CloudFormation模板和Dockerfile复制到DR区域的Amazon S3存储桶中。使用AWS Backup配置自动Aurora跨区域每小时快照。在DR情况下，构建最新的Docker镜像并将Docker镜像上传到DR区域的ECR仓库。使用具有最新Aurora快照和ECR仓库中的Docker镜像的CloudFormation模板启动新的CloudFormation堆栈。更新应用程序DNS记录以指向新的ALB。",
      "B": "将CloudFormation模板复制到DR区域的Amazon S3存储桶中。配置Aurora自动备份跨区域复制。配置ECR跨区域复制。在DR情况下，使用具有最新Aurora快照和本地ECR仓库中的Docker镜像的CloudFormation模板启动新的CloudFormation堆栈。更新应用程序DNS记录以指向新的ALB。",
      "C": "将CloudFormation模板复制到DR区域的Amazon S3存储桶中。使用Amazon EventBridge安排AWS Lambda函数每小时对Aurora数据库和ECR仓库中最新的Docker镜像进行快照。将快照和Docker镜像复制到DR区域。在DR情况下，使用具有最新Aurora快照和本地ECR仓库中的Docker镜像的CloudFormation模板启动新的CloudFormation堆栈。",
      "D": "将CloudFormation模板复制到DR区域的Amazon S3存储桶中。在DR区域部署第二个应用程序CloudFormation堆栈。重新配置Aurora为全球数据库。在当前区域需要新的应用程序发布时更新两个CloudFormation堆栈。在DR情况下，更新应用程序DNS记录以指向新的ALB。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它涉及在灾难恢复时重新构建Docker镜像，这可能超过2小时的RTO。",
      "B": "此选项是最佳选择，因为它通过配置Aurora和ECR的跨区域复制，确保了在另一个区域有最新的数据和镜像备份，从而可以快速恢复服务。",
      "C": "此选项不是最佳选择，因为它依赖于定时的Lambda函数来创建快照，这可能导致在灾难发生时数据不是最新的。",
      "D": "此选项不是最佳选择，因为它涉及维护两个CloudFormation堆栈，这可能增加成本和复杂性，而且全球数据库的配置可能不是最成本效益的选择。"
    },
    "service": [
      "AWS CloudFormation",
      "Amazon S3",
      "AWS Backup",
      "Amazon Aurora",
      "Amazon ECR",
      "Application Load Balancer",
      "AWS Fargate",
      "Amazon EventBridge",
      "AWS Lambda"
    ],
    "reason": "3.3"
  },
  {
    "no": 205,
    "question": "一家公司正在启动一个应用程序，该应用程序在 Amazon S3 存储桶中存储原始数据。三个应用程序需要访问数据以生成报告。在应用程序可以访问数据之前，必须以不同的方式对数据进行编辑。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "为每个应用程序创建一个 S3 存储桶。配置 S3 同区域复制（SRR）从原始数据的 S3 存储桶到每个应用程序的 S3 存储桶。配置每个应用程序从其自己的 S3 存储桶中获取数据。",
      "B": "创建一个 Amazon Kinesis 数据流。创建一个 AWS Lambda 函数，该函数由原始数据的 S3 存储桶中的对象创建事件触发。为每个应用程序编程 Lambda 函数以编辑数据。在 Kinesis 数据流上发布数据。配置每个应用程序从 Kinesis 数据流中获取数据。",
      "C": "为每个应用程序创建一个 S3 访问点，使用原始数据的 S3 存储桶作为目的地。创建一个 AWS Lambda 函数，该函数由原始数据的 S3 存储桶中的对象创建事件触发。为每个应用程序编程 Lambda 函数以编辑数据。将数据存储在每个应用程序的 S3 访问点中。配置每个应用程序从其自己的 S3 访问点中获取数据。",
      "D": "创建一个 S3 访问点，使用原始数据的 S3 存储桶作为目的地。为每个应用程序创建一个 S3 对象 Lambda 访问点，使用 S3 访问点。为每个 S3 对象 Lambda 访问点配置 AWS Lambda 函数以在检索对象时编辑数据。配置每个应用程序从其自己的 S3 对象 Lambda 访问点中获取数据"
    },
    "best": ["D"],
    "analysis": {
      "A": "这个选项不是最佳选择，因为它涉及到数据的多次复制和存储，这不仅增加了成本，还可能导致数据一致性问题。",
      "B": "这个选项不是最佳选择，因为虽然它使用了 Lambda 函数来处理数据，但是所有应用程序都从同一个 Kinesis 数据流中读取数据，这可能导致数据隐私和安全问题。",
      "C": "这个选项不是最佳选择，因为它涉及到为每个应用程序创建单独的访问点和存储，这增加了管理的复杂性和成本。",
      "D": "这是最佳选项，因为它使用 S3 对象 Lambda 访问点来动态处理数据，这样每个应用程序都可以在检索数据时获得特定于其需要的编辑数据，这样做既节省了存储空间，也提高了效率和安全性。"
    },
    "service": [
      "Amazon S3",
      "AWS Lambda",
      "Amazon Kinesis",
      "S3 Object Lambda"
    ],
    "reason": "3.2"
  },
  {
    "no": 206,
    "question": "一家公司使用 AWS Control Tower 和 AWS CloudFormation 管理其 AWS 账户并创建 AWS 资源。该公司要求在 CloudFormation 堆栈中创建 Amazon S3 存储桶时，必须使用 AWS Key Management Service (AWS KMS) 加密 S3 存储桶。哪种解决方案能满足这一要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS Organizations。附加一个 SCP，如果请求不包括请求使用 AWS KMS 密钥（SSE-KMS）的服务器端加密的 x-amz-server-side-encryption 标头，则拒绝 s3:PutObject 权限。",
      "B": "使用具有多账户环境的 AWS Control Tower。在所有 OU 上配置并启用主动的 AWS Control Tower 控制与 CloudFormation 钩子。",
      "C": "使用具有多账户环境的 AWS Control Tower。在所有 OU 上配置并启用侦探性的 AWS Control Tower 控制与 CloudFormation 钩子。",
      "D": "使用 AWS Organizations。创建一个 AWS Config 组织规则，检查所有 S3 存储桶是否启用了 KMS 加密密钥。部署规则。创建并应用一个 SCP，以防止用户在所有 AWS 账户中停止和删除 AWS Config。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项通过 SCP 策略确保 S3 存储桶在创建时使用 KMS 加密，但它依赖于拒绝策略而不是主动确保加密，因此不是最佳选择。",
      "B": "此选项通过在 AWS Control Tower 中使用 CloudFormation 钩子主动确保所有新创建的 S3 存储桶都使用 KMS 加密，符合题目要求。",
      "C": "侦探性控制主要用于监控和报告，而不是主动强制执行策略，因此不适合确保加密要求。",
      "D": "此选项虽然涉及检查 S3 存储桶的 KMS 加密状态，但它是事后的检查，不保证在创建时强制加密。"
    },
    "service": [
      "AWS Control Tower",
      "AWS CloudFormation",
      "AWS Organizations",
      "AWS Key Management Service (AWS KMS)",
      "AWS Config"
    ],
    "reason": "2.2"
  },
  {
    "no": 200,
    "question": "一个 DevOps 团队使用 AWS CodePipeline、AWS CodeBuild 和 AWS CodeDeploy 部署应用程序。该应用程序是一个使用 AWS Lambda 函数和 Amazon API Gateway 的 REST API。最近的部署引入了错误，影响了许多客户。DevOps 团队需要一种解决方案，在检测到错误时恢复到应用程序的最新稳定版本。该解决方案必须影响尽可能少的客户。哪种解决方案在操作效率最高的情况下满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在 CodeDeploy 中设置部署配置为 LambdaAllAtOnce。在部署组上配置自动回滚。创建一个 Amazon CloudWatch 报警，用于检测 API Gateway 上的 HTTP Bad Gateway 错误。配置部署组在报警数量达到报警阈值时回滚。",
      "B": "在 CodeDeploy 中设置部署配置为 LambdaCanary10Percent10Minutes。在部署组上配置自动回滚。创建一个 Amazon CloudWatch 报警，用于检测 API Gateway 上的 HTTP Bad Gateway 错误。配置部署组在报警数量达到报警阈值时回滚。",
      "C": "在 CodeDeploy 中设置部署配置为 LambdaAllAtOnce。在部署组上配置手动回滚。创建一个 Amazon Simple Notification Service (Amazon SNS) 主题，以在每次部署失败时发送通知。配置 SNS 主题以调用一个新的 Lambda 函数，该函数停止当前部署并启动最近成功的部署。",
      "D": "在 CodeDeploy 中设置部署配置为 LambdaCanary10Percent10Minutes。在部署组上配置手动回滚。创建一个 Amazon CloudWatch 日志组的度量过滤器，用于监控 API Gateway 上的 HTTP Bad Gateway 错误。配置度量过滤器以调用一个新的 Lambda 函数，该函数停止当前部署并启动最近成功的部署。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然这个选项提供了自动回滚和错误检测，但是使用 LambdaAllAtOnce 部署配置会同时更新所有函数，这可能会影响更多的客户。",
      "B": "这个选项使用 LambdaCanary10Percent10Minutes 部署配置，这意味着只有 10% 的流量会被新版本影响，如果出现错误，它会自动回滚，从而最小化影响客户的数量。此外，它还包括自动回滚和错误检测，使其成为最佳选择。",
      "C": "这个选项虽然提供了错误处理机制，但是使用 LambdaAllAtOnce 部署配置和手动回滚可能会导致更多客户受到影响，操作效率也较低。",
      "D": "这个选项使用了 LambdaCanary10Percent10Minutes 部署配置，但是它依赖于手动回滚，这可能会导致在错误检测和响应过程中延迟，从而影响更多的客户。"
    },
    "service": [
      "AWS CodePipeline",
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "AWS Lambda",
      "Amazon API Gateway",
      "Amazon CloudWatch",
      "Amazon SNS"
    ],
    "reason": "1.4"
  },
  {
    "no": 210,
    "question": "一家公司拥有一批在单个AWS账户中运行Linux的Amazon EC2实例。该公司正在跨EC2实例使用AWS系统管理器自动化任务。在最近的补丁周期中，由于可用磁盘空间不足，几个EC2实例进入了错误状态。一位DevOps工程师需要确保在未来的补丁过程中EC2实例有足够的可用磁盘空间。哪两个步骤的组合可以满足这些要求？（选择两个。）",
    "choose": 2,
    "options": {
      "A": "确保所有EC2实例上都安装了Amazon CloudWatch代理。",
      "B": "在每个EC2实例上创建一个cron作业，定期删除临时文件。",
      "C": "为EC2实例创建一个Amazon CloudWatch日志组。配置一个在每个EC2实例上安装的cron作业，将可用磁盘空间写入相关EC2实例的CloudWatch日志流。",
      "D": "创建一个Amazon CloudWatch警报，以监控所有EC2实例上的可用磁盘空间。将警报作为安全控制添加到系统管理器自动化任务中。",
      "E": "创建一个AWS Lambda函数，定期检查所有EC2实例上是否有足够的可用磁盘空间，通过评估每个EC2实例各自的Amazon CloudWatch日志流。"
    },
    "best": ["D", "E"],
    "analysis": {
      "A": "虽然安装CloudWatch代理可以帮助收集指标和日志，但它本身并不直接解决磁盘空间不足的问题。",
      "B": "定期删除临时文件可以帮助释放磁盘空间，但这种方法不够灵活，也可能无法及时响应磁盘空间紧张的情况。",
      "C": "仅仅记录磁盘空间的使用情况并不能自动处理空间不足的问题。",
      "D": "监控磁盘空间并在达到阈值时触发警报，可以及时通知管理员或触发自动化任务处理磁盘空间问题，是一种有效的预防措施。",
      "E": "通过Lambda函数定期检查并评估磁盘空间，可以动态管理磁盘使用，确保在补丁应用前磁盘空间充足，是一种主动的解决方案。"
    },
    "service": [
      "Amazon EC2",
      "AWS Systems Manager",
      "Amazon CloudWatch",
      "AWS Lambda"
    ],
    "reason": "2.3"
  },
  {
    "no": 211,
    "question": "一位 DevOps 工程师正在构建一个应用程序，该应用程序使用 AWS Lambda 函数查询 Amazon Aurora MySQL DB 集群。Lambda 函数仅执行读取查询。Amazon EventBridge 事件触发 Lambda 函数。随着越来越多的事件每秒触发 Lambda 函数，数据库的延迟增加，数据库的吞吐量减少。DevOps 工程师需要提高应用程序的性能。哪种步骤组合将满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "使用 Amazon RDS Proxy 创建一个代理。将代理连接到 Aurora 集群的读取器端点。在代理上设置最大连接百分比。",
      "B": "在 Lambda 代码中实现数据库连接池。在数据库连接池上设置最大连接数。",
      "C": "在 Lambda 事件处理程序代码之外实现数据库连接打开。",
      "D": "在 Lambda 事件处理程序代码内部实现数据库连接的打开和关闭。",
      "E": "从 Lambda 函数连接到代理端点。",
      "F": "从 Lambda 函数连接到 Aurora 集群端点。"
    },
    "best": ["A", "E", "C"],
    "analysis": {
      "A": "使用 Amazon RDS Proxy 可以有效管理数据库连接，减少每次 Lambda 函数触发时创建和销毁连接的开销，提高数据库性能。",
      "B": "虽然实现数据库连接池可以提高性能，但在无服务器环境中，如 Lambda，连接池可能不会持久化，因此不是最佳选择。",
      "C": "将数据库连接打开放在 Lambda 事件处理程序代码之外可以减少每次事件触发时的连接开销，提高性能。",
      "D": "在事件处理程序内部打开和关闭数据库连接会增加延迟，因为每次事件触发都需要重新建立连接。",
      "E": "连接到通过 RDS Proxy 设置的代理端点可以进一步优化连接管理和性能。",
      "F": "直接连接到 Aurora 集群端点可能导致连接过多和资源竞争，不推荐此方法。"
    },
    "service": [
      "AWS Lambda",
      "Amazon Aurora",
      "Amazon EventBridge",
      "Amazon RDS Proxy"
    ],
    "reason": "3.2"
  },
  {
    "no": 208,
    "question": "一家公司在 AWS 上部署了一个复杂的基于容器的工作负载。该工作负载使用 Amazon Managed Service for Prometheus 进行监控。工作负载在同一个 AWS 账户中的 Amazon Elastic Kubernetes Service (Amazon EKS) 集群中运行。公司的 DevOps 团队希望使用公司的 Amazon Simple Notification Service (Amazon SNS) 主题接收工作负载警报。SNS 主题与 EKS 集群在同一个 AWS 账户中。哪种步骤组合可以满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "使用 Amazon Managed Service for Prometheus 远程写入 URL 将警报发送到 SNS 主题",
      "B": "创建一个检查每个工作负载容器可用性的警报规则。",
      "C": "为 SNS 主题创建一个警报管理器配置。",
      "D": "修改 SNS 主题的访问策略。授予 aps.amazonaws.com 服务主体 sns:Publish 权限和 sns:GetTopicAttributes 权限。",
      "E": "修改 Amazon Managed Service for Prometheus 使用的 IAM 角色。授予该角色 sns:Publish 权限和 sns:GetTopicAttributes 权限。",
      "F": "为 EKS 集群创建一个 OpenID Connect (OIDC) 提供者。创建一个集群服务账户。使用 IAM 角色授予账户 sns:Publish 权限和 sns:GetTopicAttributes 权限。"
    },
    "best": ["C", "D", "E"],
    "analysis": {
      "A": "此选项不正确，因为 Amazon Managed Service for Prometheus 不支持直接通过远程写入 URL 将警报发送到 SNS 主题。",
      "B": "此选项不正确，因为它只是创建了一个检查容器可用性的警报规则，但没有涉及如何将警报发送到 SNS 主题。",
      "C": "此选项正确，因为创建警报管理器配置是将 Prometheus 警报与 SNS 主题集成的关键步骤。",
      "D": "此选项正确，因为修改 SNS 主题的访问策略以允许 Prometheus 服务发送警报是必要的。",
      "E": "此选项正确，因为修改 Prometheus 使用的 IAM 角色以包括对 SNS 主题的访问权限是实现警报功能的关键。",
      "F": "此选项不正确，因为它涉及到为 EKS 集群创建 OIDC 提供者和服务账户，这与 Prometheus 直接发送警报到 SNS 主题无关。"
    },
    "service": [
      "Amazon Managed Service for Prometheus",
      "Amazon Elastic Kubernetes Service",
      "Amazon Simple Notification Service"
    ],
    "reason": "4.3"
  },
  {
    "no": 212,
    "question": "一家公司在单个 AWS 账户中部署了一个 AWS CloudFormation 堆栈。该公司已配置堆栈以将事件通知发送到 Amazon Simple Notification Service (Amazon SNS) 主题。DevOps 工程师必须实施一个自动化解决方案，仅在成功更新堆栈后为特定的 CloudFormation 堆栈实例应用标签。DevOps 工程师已创建一个 AWS Lambda 函数，用于为特定堆栈实例应用和更新此标签。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "当系统管理器检测到 CloudFormation 堆栈的实例状态为 UPDATE_COMPLETE 事件时，运行 AWS-UpdateCloudFormationStack AWS 系统管理器自动化运行手册。配置运行手册以调用 Lambda 函数。",
      "B": "创建一个自定义 AWS Config 规则，如果 CloudFormation 堆栈具有 UPDATE_COMPLETE 实例状态，则生成一个合规性变更事件。配置 AWS Config 以直接调用 Lambda 函数以自动修正更改事件。",
      "C": "创建一个 Amazon EventBridge 规则，该规则匹配 CloudFormation 堆栈的实例状态为 UPDATE_COMPLETE 的事件模式。配置规则以调用 Lambda 函数。",
      "D": "调整 CloudFormation 堆栈的配置，仅在实例状态事件为 UPDATE_COMPLETE 时发送通知到 SNS 主题。订阅 Lambda 函数到 SNS 主题。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项涉及使用 AWS Systems Manager 自动化运行手册，但这通常用于管理和自动化基础设施，而不是直接用于响应 CloudFormation 事件。",
      "B": "AWS Config 主要用于配置合规性和审核，而不是用于实时事件响应或自动化标签应用。",
      "C": "此选项直接使用 Amazon EventBridge 来捕捉 CloudFormation 的 UPDATE_COMPLETE 事件，并触发 Lambda 函数，这是一个直接且高效的方法来实现需求。",
      "D": "虽然此选项使用了 SNS 来触发 Lambda 函数，但它增加了额外的步骤和复杂性，因为需要管理 SNS 订阅。EventBridge 提供了更直接的事件处理方式。"
    },
    "service": [
      "AWS CloudFormation",
      "Amazon SNS",
      "AWS Lambda",
      "AWS Systems Manager",
      "AWS Config",
      "Amazon EventBridge"
    ],
    "reason": "2.3"
  },
  {
    "no": 207,
    "question": "一位 DevOps 工程师开发了一个 AWS Lambda 函数。该 Lambda 函数启动针对特定 CloudFormation 堆栈的所有支持资源的 AWS CloudFormation 偏移检测操作。然后，Lambda 函数退出其调用。DevOps 工程师创建了一个 Amazon EventBridge 定时规则，每小时调用一次 Lambda 函数。AWS 账户中已经存在一个 Amazon Simple Notification Service (Amazon SNS) 主题。DevOps 工程师已订阅 SNS 主题以接收通知。DevOps 工程师需要尽快收到有关此特定堆栈配置中检测到的偏移的通知。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "将现有的 EventBridge 规则配置为同时针对 SNS 主题。配置 SNS 订阅过滤策略以匹配 CloudFormation 堆栈。将订阅过滤策略附加到 SNS 主题。",
      "B": "创建第二个 Lambda 函数来查询 CloudFormation API 以获取堆栈的偏移检测结果。如果检测到偏移，配置第二个 Lambda 函数以将消息发布到 SNS 主题。调整现有的 EventBridge 规则以同时针对第二个 Lambda 函数。",
      "C": "在帐户中配置 Amazon GuardDuty，对所有 CloudFormation 堆栈进行偏移检测。创建第二个 EventBridge 规则，该规则对特定 CloudFormation 堆栈的 GuardDuty 偏移检测事件发现做出反应。将 SNS 主题配置为第二个 EventBridge 规则的目标。",
      "D": "在帐户中配置 AWS Config。使用 cloudformation-stack-drift-detection-check 管理规则。创建第二个 EventBridge 规则，该规则对 CloudFormation 堆栈的合规性变更事件做出反应。将 SNS 主题配置为第二个 EventBridge 规则的目标。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它没有提到如何处理偏移检测结果，只是简单地将 EventBridge 规则与 SNS 主题关联。",
      "B": "此选项不是最佳选择，因为它需要创建额外的 Lambda 函数来处理偏移检测结果，这增加了复杂性和潜在的延迟。",
      "C": "此选项不是最佳选择，因为 GuardDuty 主要用于威胁检测和持续监控，而不是专门用于 CloudFormation 堆栈的偏移检测。",
      "D": "这是最佳选择，因为 AWS Config 可以直接监控 CloudFormation 堆栈的偏移，并且可以配置 EventBridge 规则来响应合规性变更事件，从而实现快速通知。"
    },
    "service": [
      "AWS Lambda",
      "AWS CloudFormation",
      "Amazon EventBridge",
      "Amazon SNS",
      "AWS Config"
    ],
    "reason": "2.1"
  },
  {
    "no": 209,
    "question": "一家公司的 AWS Organizations 中的组织有一个单一的 OU。该公司在 OU 账户中运行 Amazon EC2 实例。公司需要限制每个 EC2 实例的凭证仅用于该凭证分配给的特定 EC2 实例。一位 DevOps 工程师必须为 EC2 实例配置安全性。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 SCP，指定 VPC CIDR 块。配置 SCP 以检查 aws:VpcSourcelp 条件键的值是否在指定的块中。在同一个 SCP 检查中，检查 aws:EC2InstanceSourcePrivatelPv4 和 aws:SourceVpc 条件键的值是否相同。如果任一条件为假，则拒绝访问。将 SCP 应用于 OU。",
      "B": "创建一个 SCP，检查 aws:EC2InstanceSourceVPC 和 aws:SourceVpc 条件键的值是否相同。如果值不同，则拒绝访问。在同一个 SCP 检查中，检查 aws:EC2InstanceSourcePrivateIPv4 和 aws:VpcSourceIp 条件键的值是否相同。如果值不同，则拒绝访问。将 SCP 应用于 OU。",
      "C": "创建一个 SCP，包括一个可接受的 VPC 值列表，并检查 aws:SourceVpc 条件键的值是否在列表中。在同一个 SCP 检查中，定义一个可接受的 IP 地址值列表，并检查 aws:VpcSourceIp 条件键的值是否在列表中。如果任一条件为假，则拒绝访问。将 SCP 应用于组织中的每个账户。",
      "D": "创建一个 SCP，检查 aws:EC2InstanceSourceVPC 和 aws:VpcSourceIp 条件键的值是否相同。如果值不同，则拒绝访问。在同一个 SCP 检查中，检查 aws:EC2InstanceSourcePrivateIPv4 和 aws:SourceVpc 条件键的值是否相同。如果值不同，则拒绝访问。将 SCP 应用于组织中的每个账户。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项尝试通过检查 IP 地址和 VPC 来限制访问，但它没有明确地将凭证限制在特定的 EC2 实例上。",
      "B": "此选项通过确保 EC2 实例的源 VPC 和 IP 地址与访问请求中的相应值匹配，有效地限制了凭证的使用，确保了凭证仅在其分配的实例上使用。",
      "C": "此选项提供了一个列表来限制 VPC 和 IP 地址，但它应用于每个账户而不是特定的 OU，这可能不符合公司的要求。",
      "D": "此选项与选项 B 类似，但它应用于每个账户而不是特定的 OU，这可能不符合公司的要求。"
    },
    "service": ["AWS Organizations", "Amazon EC2", "SCP"],
    "reason": "6.1"
  },
  {
    "no": 213,
    "question": "一家公司将应用程序部署到两个 AWS 区域。该应用程序在与应用程序相同的区域中的 Amazon S3 存储桶中创建并存储对象。两个部署的应用程序都需要访问来自两个区域的所有对象及其元数据。公司已在 S3 存储桶之间配置了双向复制，并在每个 S3 存储桶上启用了 S3 复制指标。DevOps 工程师需要实施一种解决方案，如果对象复制失败，则重试复制过程。哪种解决方案将满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 Amazon EventBridge 规则，该规则监听 S3 事件通知以获取失败的复制事件。创建一个 AWS Lambda 函数，用于下载失败的复制对象，然后对目标存储桶中的对象执行 PutObject 命令。配置 EventBridge 规则以调用 Lambda 函数处理复制失败的对象。",
      "B": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。配置 S3 事件通知以将失败的复制通知发送到 SQS 队列。创建一个 AWS Lambda 函数，用于下载失败的复制对象，然后对目标存储桶中的对象执行 PutObject 命令。配置 Lambda 函数以轮询队列以处理通知。",
      "C": "创建一个 Amazon EventBridge 规则，该规则监听 S3 事件通知以获取失败的复制。创建一个 AWS Lambda 函数，用于下载失败的复制对象，然后对目标存储桶中的对象执行 PutObject 命令。",
      "D": "创建一个 AWS Lambda 函数，该函数将使用 S3 批量操作重试现有对象的复制失败。配置 S3 事件通知以将失败的复制通知发送到 Lambda 函数。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项考虑了使用 EventBridge 规则和 Lambda 函数来处理失败的复制，但没有提到如何管理和优化处理失败事件的队列。",
      "B": "此选项通过创建 SQS 队列来有效管理和优化处理失败复制的事件，使用 Lambda 函数进行处理，这是一种更可靠和可扩展的方法来处理可能的高复制失败率。",
      "C": "此选项与选项 A 类似，但缺少了对 EventBridge 规则的具体配置说明，使其不如选项 A 和 B 完整。",
      "D": "此选项提到了使用 S3 批量操作，但在处理大量失败的复制时可能不如基于队列的解决方案灵活和有效。"
    },
    "service": ["Amazon S3", "AWS Lambda", "Amazon EventBridge", "Amazon SQS"],
    "reason": "3.1"
  },
  {
    "no": 215,
    "question": "一个云团队使用 AWS Organizations 和 AWS IAM Identity Center (AWS Single Sign-On) 来管理公司的 AWS 账户。公司最近成立了一个研究团队。研究团队需要能够完全管理其账户中的资源。研究团队不得创建 IAM 用户。云团队为研究团队创建了 IAM Identity Center 中的研究管理员权限集，权限集附加了 AdministratorAccess AWS 管理策略。云团队必须确保研究团队的任何人都不能创建 IAM 用户。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 IAM 策略，拒绝 iam:CreateUser 动作。将 IAM 策略附加到研究管理员权限集。",
      "B": "创建一个 IAM 策略，允许除 iam:CreateUser 动作之外的所有动作。使用 IAM 策略设置研究管理员权限集的权限边界。",
      "C": "创建一个 SCP，拒绝 iam:CreateUser 动作。将 SCP 附加到研究团队的 AWS 账户。",
      "D": "创建一个 AWS Lambda 函数来删除 IAM 用户。创建一个 Amazon EventBridge 规则来检测 IAM CreateUser 事件。配置规则以调用 Lambda 函数。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然这个选项可以直接拒绝创建用户的操作，但它不是最优的，因为它需要在每个 IAM 用户或角色上单独设置，而不是账户级别。",
      "B": "这个选项设置了权限边界，但权限边界用于限制可以授予 IAM 实体的最大权限，并不直接拒绝操作。",
      "C": "这是最优选项，因为 SCP（服务控制策略）可以在账户级别设置，直接拒绝研究团队的所有成员创建 IAM 用户的能力。",
      "D": "这个选项通过检测和响应来处理问题，而不是预防问题的发生，因此不是最优的解决方案。"
    },
    "service": [
      "AWS Organizations",
      "AWS IAM Identity Center",
      "IAM",
      "SCP",
      "AWS Lambda",
      "Amazon EventBridge"
    ],
    "reason": "6.1"
  },
  {
    "no": 218,
    "question": "一家公司在 AWS Organizations 中的公司组织账户中运营敏感工作负载。该公司使用一个 IP 地址范围来委派 Amazon VPC CIDR 块和所有非云硬件的 IP 地址。公司需要一种解决方案，防止不在公司 IP 地址范围内的主体在组织的账户中执行 AWS 操作。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "为组织配置 AWS Firewall Manager。创建一个仅允许来自公司 IP 地址范围的源流量的 AWS Network Firewall 策略。将策略范围设置为组织中的所有账户。",
      "B": "在 Organizations 中创建一个 SCP，拒绝不在公司 IP 地址范围内的源 IP 地址。将 SCP 附加到组织的根。",
      "C": "为组织配置 Amazon GuardDuty。为公司的 IP 范围创建一个 GuardDuty 可信 IP 地址列表。为组织激活可信 IP 列表。",
      "D": "在 Organizations 中创建一个 SCP，允许在公司 IP 地址范围内的源 IP 地址。将 SCP 附加到组织的根。"
    },
    "best": ["B"],
    "analysis": {
      "A": "AWS Firewall Manager 和 AWS Network Firewall 主要用于网络流量的监控和控制，而不是用于基于 IP 地址限制 AWS 操作。",
      "B": "这是最佳选项，因为使用 SCP（服务控制策略）可以直接在 AWS Organizations 层面上限制不在特定 IP 地址范围内的 AWS 操作。",
      "C": "Amazon GuardDuty 是一种威胁检测服务，它可以帮助识别可疑活动，但它不用于阻止特定 IP 地址范围外的操作。",
      "D": "此选项虽然使用了 SCP，但它是允许而不是拒绝策略，这可能不足以防止外部 IP 地址的访问，因为它不明确拒绝不在 IP 范围内的地址。"
    },
    "service": ["AWS Organizations", "SCP"],
    "reason": "6.1"
  },
  {
    "no": 217,
    "question": "一家公司有一个在 AWS Lambda 上运行的应用程序，该应用程序将日志发送到 Amazon CloudWatch Logs。一个 Amazon Kinesis 数据流订阅了 CloudWatch Logs 中的日志组。一个单一的消费者 Lambda 函数处理来自数据流的日志，并将日志存储在 Amazon S3 存储桶中。公司的 DevOps 团队注意到在处理和摄取某些日志时存在高延迟。哪种步骤组合将减少延迟？（选择三个。）",
    "choose": 3,
    "options": {
      "A": "创建具有增强型扇出的数据流消费者。将处理日志的 Lambda 函数设置为消费者。",
      "B": "增加 Lambda 事件源映射中的 ParallelizationFactor 设置。",
      "C": "为处理日志的 Lambda 函数配置保留并发。",
      "D": "增加 Kinesis 数据流中的批处理大小。",
      "E": "关闭 Lambda 事件源映射中的 ReportBatchItemFailures 设置。",
      "F": "增加 Kinesis 数据流中的分片数量。"
    },
    "best": ["A", "B", "F"],
    "analysis": {
      "A": "增强型扇出可以为每个消费者提供专用的吞吐量，从而减少延迟，是一个优选。",
      "B": "增加 ParallelizationFactor 可以允许 Lambda 函数并行处理更多记录，提高处理效率，是一个优选。",
      "C": "配置保留并发可以确保 Lambda 函数有足够的并发执行实例，但不直接影响处理延迟。",
      "D": "增加批处理大小可能会增加单个批处理的处理时间，反而可能增加延迟。",
      "E": "关闭 ReportBatchItemFailures 可能会减少错误处理的开销，但对于减少处理日志的延迟帮助不大。",
      "F": "增加分片数量可以提高数据流的并行处理能力，减少延迟，是一个优选。"
    },
    "service": [
      "AWS Lambda",
      "Amazon CloudWatch Logs",
      "Amazon Kinesis",
      "Amazon S3"
    ],
    "reason": "4.1"
  },
  {
    "no": 214,
    "question": "一家公司需要为其应用程序实现故障转移。该应用程序包括一个Amazon CloudFront分发和一个位于AWS区域的公共应用程序负载均衡器（ALB）。公司已将ALB配置为分发的默认源。在最近一些应用程序中断后，公司希望实现零秒的恢复时间目标（RTO）。公司在一个次要区域以温备用配置部署了应用程序。一位DevOps工程师需要自动化应用程序到次要区域的故障转移，以便HTTP GET请求满足所需的RTO。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建第二个CloudFront分发，将次要ALB设置为默认源。创建Amazon Route 53别名记录，为两个CloudFront分发设置故障转移策略和评估目标健康设置为是。更新应用程序以使用新的记录集。",
      "B": "在分发中创建一个新的源，为次要ALB创建一个新的源组。将原始ALB设置为主源。配置源组以针对HTTP 5xx状态代码进行故障转移。更新默认行为以使用源组。",
      "C": "创建Amazon Route 53别名记录，为两个ALB设置故障转移策略和评估目标健康设置为是。将两个记录的TTL设置为0。更新分发的源以使用新的记录集。",
      "D": "创建一个CloudFront函数，用于检测HTTP 5xx状态代码。如果函数检测到5xx状态代码，配置函数返回到次要ALB的307临时重定向错误响应。更新分发的默认行为以将源响应发送到函数。"
    },
    "best": ["C"],
    "analysis": {
      "A": "这个选项虽然考虑了使用Route 53进行故障转移，但创建第二个CloudFront分发可能导致额外的复杂性和成本。",
      "B": "这个选项使用了源组来管理故障转移，但它依赖于HTTP 5xx状态代码来触发，这可能不会覆盖所有故障场景。",
      "C": "这个选项通过设置Route 53的故障转移策略和评估目标健康，以及将TTL设置为0来实现即时故障转移，符合零秒RTO的要求。",
      "D": "这个选项依赖于CloudFront函数来处理故障转移，但这种方法可能会增加延迟，并且对于非5xx错误不会触发故障转移。"
    },
    "service": [
      "Amazon CloudFront",
      "Application Load Balancer",
      "Amazon Route 53"
    ],
    "reason": "3.3"
  },
  {
    "no": 216,
    "question": "一家公司在新的 AWS 账户中发布了一个新应用程序。该应用程序包括一个 AWS Lambda 函数，该函数处理来自 Amazon Simple Queue Service (Amazon SQS) 标准队列的消息。Lambda 函数将结果存储在 Amazon S3 存储桶中，以供进一步的下游处理。Lambda 函数需要在发布消息后的特定时间段内处理消息。Lambda 函数的批处理大小为 10 条消息，并且处理一批消息需要几秒钟。随着应用程序首日服务负载的增加，队列中的消息积累速度超过了 Lambda 函数处理消息的速度。一些消息错过了所需的处理时间。日志显示队列中的许多消息数据无效。公司需要满足具有有效数据的消息的时间要求。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "增加 Lambda 函数的批处理大小。将 SQS 标准队列更改为 SQS FIFO 队列。在 AWS 区域请求增加 Lambda 并发。",
      "B": "减少 Lambda 函数的批处理大小。增加 SQS 消息吞吐量配额。在 AWS 区域请求增加 Lambda 并发。",
      "C": "增加 Lambda 函数的批处理大小。在 S3 存储桶上配置 S3 传输加速。配置 SQS 死信队列。",
      "D": "保持 Lambda 函数的批处理大小不变。配置 Lambda 函数报告失败的批处理项。配置 SQS 死信队列。"
    },
    "best": ["D"],
    "analysis": {
      "A": "增加批处理大小可能会导致单个 Lambda 函数处理时间过长，而更改为 FIFO 队列虽然可以保证顺序，但不会解决无效数据问题。",
      "B": "减少批处理大小可能会增加处理速度，但不会直接解决无效数据问题。",
      "C": "增加批处理大小可能导致处理延迟，而 S3 传输加速对处理 SQS 消息并无直接帮助。",
      "D": "保持批处理大小不变并报告失败的批处理项可以帮助快速识别和处理无效数据，配置死信队列可以处理无法成功处理的消息，从而优化处理流程。"
    },
    "service": ["AWS Lambda", "Amazon SQS", "Amazon S3"],
    "reason": "3.2"
  },
  {
    "no": 220,
    "question": "一家公司使用 AWS Organizations 管理多个 AWS 账户。该公司需要在所有 AWS 账户中实现一个自动化过程，以隔离在实例接收到特定标签时被认为是受损的 Amazon EC2 实例。哪两个步骤的组合将满足这些要求？（选择两个。）",
    "choose": 2,
    "options": {
      "A": "使用 AWS CloudFormation StackSets 在所有 AWS 账户中部署 CloudFormation 堆栈。",
      "B": "创建一个 SCP，其中包含一个对 ec2:* 操作的拒绝声明，条件为“aws:RequestTag/isolation”: false。",
      "C": "将 SCP 附加到组织的根部。",
      "D": "创建一个 AWS CloudFormation 模板，该模板创建一个没有附加 IAM 策略的 EC2 实例角色。配置模板以具有一个明确拒绝所有流量的安全组。使用 CloudFormation 模板创建一个 AWS Lambda 函数，该函数将 IAM 角色附加到实例。配置 Lambda 函数以添加网络 ACL。设置一个 Amazon EventBridge 规则以在将特定标签应用于受损 EC2 实例时调用 Lambda 函数。",
      "E": "创建一个 AWS CloudFormation 模板，该模板创建一个没有附加 IAM 策略的 EC2 实例角色。配置模板以具有没有入站规则或出站规则的安全组。使用 CloudFormation 模板创建一个 AWS Lambda 函数，该函数将 IAM 角色附加到实例。配置 Lambda 函数以替换任何现有的安全组。设置一个 Amazon EventBridge 规则以在将特定标签应用于受损 EC2 实例时调用 Lambda 函数。"
    },
    "best": ["D", "E"],
    "analysis": {
      "A": "虽然 AWS CloudFormation StackSets 可以跨账户部署资源，但它本身并不提供隔离受损 EC2 实例的功能。",
      "B": "SCP 用于限制 AWS 账户中的权限，但它不能直接用于隔离 EC2 实例。",
      "C": "将 SCP 附加到组织的根部可以实施策略，但这并不直接涉及隔离 EC2 实例。",
      "D": "这个选项通过创建一个 Lambda 函数来隔离 EC2 实例，并通过 EventBridge 规则触发，这符合题目要求。",
      "E": "这个选项通过创建一个 Lambda 函数来隔离 EC2 实例，并通过 EventBridge 规则触发，这符合题目要求。"
    },
    "service": [
      "AWS Organizations",
      "Amazon EC2",
      "AWS CloudFormation",
      "AWS Lambda",
      "Amazon EventBridge"
    ],
    "reason": "2.3"
  },
  {
    "no": 221,
    "question": "一家公司通过使用 AWS Organizations 并为不同的业务部门使用 OU 来管理多个 AWS 账户。该公司正在更新其企业网络以使用新的 IP 地址范围。该公司在不同的 AWS 账户中有 10 个 Amazon S3 存储桶。S3 存储桶存储不同部门的报告。S3 存储桶配置仅允许私有企业网络 IP 地址访问 S3 存储桶。一名 DevOps 工程师需要更改有权访问 S3 存储桶内容的 IP 地址范围。DevOps 工程师还需要撤销公司中两个 OU 的权限。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个新的 SCP，其中包含两个声明，一个允许所有 S3 存储桶访问新的 IP 地址范围，另一个拒绝所有 S3 存储桶访问旧的 IP 地址范围。为两个 OU 中的 OrganizationAccountAccessRole 角色设置权限边界，以拒绝访问 S3 存储桶。",
      "B": "创建一个新的 SCP，其中包含一个声明，仅允许新的 IP 地址范围访问 S3 存储桶。创建另一个 SCP 拒绝访问 S3 存储桶。将第二个 SCP 附加到两个 OU。",
      "C": "在所有 S3 存储桶上配置基于资源的策略，仅允许新的 IP 地址范围访问 S3 存储桶。创建一个新的 SCP 拒绝访问 S3 存储桶。将 SCP 附加到两个 OU。",
      "D": "在所有 S3 存储桶上配置基于资源的策略，仅允许新的 IP 地址范围访问 S3 存储桶。为两个 OU 中的 OrganizationAccountAccessRole 角色设置权限边界，以拒绝访问 S3 存储桶。"
    },
    "best": ["D"],
    "analysis": {
      "A": "这个选项虽然考虑到了更新 IP 地址范围，但是使用 SCP 来控制 IP 访问不是最佳实践，因为 SCP 更适合管理账户级别的权限而不是特定服务的访问。",
      "B": "这个选项没有考虑到如何有效地更新 IP 地址范围，仅仅是创建了拒绝访问的 SCP，没有提供一个平滑的过渡方案。",
      "C": "虽然这个选项考虑到了基于资源的策略来限制 IP 地址，但是它没有考虑到如何在 OU 级别撤销权限，仅仅是附加了一个拒绝访问的 SCP。",
      "D": "这个选项不仅考虑到了使用基于资源的策略来更新 IP 地址范围，还考虑到了在 OU 级别设置权限边界来撤销访问权限，是一个全面的解决方案。"
    },
    "service": ["AWS Organizations", "Amazon S3", "SCP"],
    "reason": "2.2"
  },
  {
    "no": 219,
    "question": "一家公司在两个 AWS 区域部署了一个应用程序。该应用程序目前在主要区域使用 Amazon S3 存储桶存储数据。DevOps 工程师需要确保该应用程序在两个区域都具有高可用性。DevOps 工程师在辅助区域创建了一个新的 S3 存储桶。所有现有和新对象都必须在两个 S3 存储桶中。应用程序必须在区域之间进行故障转移，且没有数据丢失。哪种步骤组合可以在最大操作效率下满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "创建一个新的 IAM 角色，允许 Amazon S3 和 S3 批量操作服务主体承担具有必要权限的 S3 复制的角色。",
      "B": "创建一个新的 IAM 角色，允许 AWS 批量服务主体承担具有必要权限的 S3 复制的角色。",
      "C": "在源 S3 存储桶上创建一个 S3 跨区域复制（CRR）规则。配置规则以使用 Amazon S3 的 IAM 角色复制到目标 S3 存储桶。",
      "D": "在源 S3 存储桶上创建一个双向复制规则。配置规则以使用 Amazon S3 的 IAM 角色复制到目标 S3 存储桶。",
      "E": "创建一个具有 AWS Fargate 编排类型的 AWS 批量作业。配置作业以使用 AWS 批量的 IAM 角色。指定一个 Bash 命令使用 AWS CLI 同步源 S3 存储桶和目标 S3 存储桶的内容",
      "F": "在 S3 批量操作中创建一个操作以复制源 S3 存储桶的内容到目标 S3 存储桶。配置操作以使用 Amazon S3 的 IAM 角色。"
    },
    "best": ["A", "C", "F"],
    "analysis": {
      "A": "这是最佳选项之一，因为它提供了一个 IAM 角色，该角色允许 Amazon S3 和 S3 批量操作服务主体进行必要的 S3 复制，这是实现高效操作的关键。",
      "B": "这不是最佳选项，因为它提到了 AWS 批量服务，这与 S3 复制不直接相关。",
      "C": "这是最佳选项之一，因为它直接涉及到在源 S3 存储桶上设置跨区域复制规则，这是确保两个区域数据一致性的有效方式。",
      "D": "这不是最佳选项，因为 S3 不支持双向复制，这可能导致复制配置错误。",
      "E": "这不是最佳选项，因为使用 AWS Batch 和 Fargate 进行数据同步不如使用 S3 内置的复制功能高效。",
      "F": "这是最佳选项之一，因为它使用 S3 批量操作来复制数据，这是一个高效的方式来确保数据在两个存储桶之间同步。"
    },
    "service": ["Amazon S3", "IAM", "AWS Batch", "AWS Fargate"],
    "reason": "3.1"
  },
  {
    "no": 222,
    "question": "一家公司开始在多个团队中使用 AWS。每个团队都有多个账户和独特的安全配置文件。该公司在 AWS Organizations 中管理这些账户。每个账户都有自己的配置和安全控制。公司的 DevOps 团队希望使用预防和侦测控制来管理所有账户。DevOps 团队需要确保现在和将来随着公司在组织中创建新账户时账户的安全。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 Organizations 创建具有适当 SCPs 的 OUs，为每个团队附加适当的 SCPs。将团队账户放置在适当的 OUs 中以应用安全控制。在适当的 OUs 中创建任何新的团队账户。",
      "B": "创建一个 AWS Control Tower 登陆区。在 AWS Control Tower 中为现有团队配置 OUs 和适当的控制。配置 AWS Control Tower 的受信任访问。将现有账户注册到匹配每个团队适当安全策略的相应 OUs 中。使用 AWS Control Tower 预置任何新账户。",
      "C": "在组织的管理账户中创建 AWS CloudFormation 堆栈集。配置一个堆栈集，将 AWS Config 与所有控制的配置规则和补救措施部署到组织中的每个账户。随着账户的创建，更新堆栈集以部署到新账户。",
      "D": "配置 AWS Config 来管理组织中所有 AWS 账户的 AWS Config 规则。部署符合性包，提供组织中的 AWS Config 规则和补救措施。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然使用 AWS Organizations 创建 OUs 并附加 SCPs 是一种有效的安全控制方法，但它主要提供权限管理而不涵盖所有安全和合规性需求。",
      "B": "AWS Control Tower 提供了一个集成的解决方案，用于管理多账户环境中的安全性、合规性和操作。它自动化了账户的创建、设置和管理，提供了集中的监控和自动化合规性检查，是最全面的解决方案。",
      "C": "使用 AWS CloudFormation 堆栈集可以自动化配置管理，但它主要关注资源部署和配置，而不是全面的安全性和合规性管理。",
      "D": "配置 AWS Config 和部署符合性包是一种有效的监控和合规性策略，但它不提供账户创建和预配置的自动化管理。"
    },
    "service": [
      "AWS Organizations",
      "AWS Control Tower",
      "AWS CloudFormation",
      "AWS Config"
    ],
    "reason": "2.2"
  },
  {
    "no": 224,
    "question": "一位 DevOps 工程师管理着一家公司的 Amazon Elastic Container Service (Amazon ECS) 集群。该集群在多个 Amazon EC2 实例上运行，这些实例位于一个自动扩展组中。DevOps 工程师必须实施一个解决方案，用于记录和审查所有已停止任务的错误。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 Amazon EventBridge 规则来捕获任务状态变化。将事件发送到 Amazon CloudWatch 日志。使用 CloudWatch 日志洞察来调查已停止的任务。",
      "B": "配置任务以在嵌入式度量格式中写入日志数据。将日志存储在 Amazon CloudWatch 日志中。监控 ContainerInstanceCount 指标的变化。",
      "C": "配置 EC2 实例以将日志存储在 Amazon CloudWatch 日志中。创建一个 CloudWatch 贡献者洞察规则，使用 EC2 实例日志数据。使用贡献者洞察规则来调查已停止的任务。",
      "D": "为 EC2_INSTANCE_TERMINATING 缩减事件配置一个 EC2 自动扩展生命周期钩子。将 SystemEventLog 文件写入 Amazon S3。使用 Amazon Athena 查询日志文件中的错误。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用 Amazon EventBridge 来捕获任务状态变化，并将事件发送到 CloudWatch 日志，然后使用 CloudWatch Logs Insights 来调查已停止的任务，这符合需求。",
      "B": "此选项不适用，因为它关注于监控 ContainerInstanceCount 指标的变化，而不是直接调查已停止任务的错误。",
      "C": "此选项不适用，因为它侧重于使用 EC2 实例日志数据，而不是直接从 ECS 任务本身捕获和调查错误。",
      "D": "此选项不适用，因为它涉及到在 EC2 实例终止时处理日志，而不是专注于 ECS 任务的错误分析。"
    },
    "service": [
      "Amazon ECS",
      "Amazon EC2",
      "Amazon EventBridge",
      "Amazon CloudWatch Logs",
      "CloudWatch Logs Insights",
      "Amazon S3",
      "Amazon Athena"
    ],
    "reason": "4.2"
  },
  {
    "no": 223,
    "question": "一家公司使用 AWS CodeCommit 仓库来存储其源代码和相应的单元测试。该公司配置了一个包括 AWS CodeBuild 项目的 AWS CodePipeline 管道，该项目在代码合并到仓库的主分支时运行。公司希望 CodeBuild 项目运行单元测试。如果单元测试通过，CodeBuild 项目必须标记最近的提交。公司应如何配置 CodeBuild 项目以满足这些要求？",
    "choose": 1,
    "options": {
      "A": "配置 CodeBuild 项目使用原生 Git 克隆 CodeCommit 仓库。配置项目运行单元测试。如果代码通过单元测试，配置项目使用原生 Git 创建标签并将 Git 标签推送到仓库。",
      "B": "配置 CodeBuild 项目使用原生 Git 克隆 CodeCommit 仓库。配置项目运行单元测试。如果代码通过单元测试，配置项目使用 AWS CLI 命令在仓库中创建新的仓库标签。",
      "C": "配置 CodeBuild 项目使用 AWS CLI 命令从 CodeCommit 仓库复制代码。配置项目运行单元测试。如果代码通过单元测试，配置项目使用 AWS CLI 命令在仓库中创建新的 Git 标签。",
      "D": "配置 CodeBuild 项目使用 AWS CLI 命令从 CodeCommit 仓库复制代码。配置项目运行单元测试。如果代码通过单元测试，配置项目使用 AWS CLI 命令在仓库中创建新的仓库标签。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用原生 Git 命令直接与 CodeCommit 仓库交互，这是最直接和高效的方法来克隆仓库、运行测试并在测试通过后创建和推送标签。",
      "B": "此选项不是最佳选择，因为它提到使用 AWS CLI 创建仓库标签，这不是处理 Git 仓库标签的标准方法。",
      "C": "此选项不是最佳选择，因为它使用 AWS CLI 复制代码，这不是最有效的方法来处理 CodeCommit 仓库的代码。原生 Git 命令更适合与 Git 仓库交互。",
      "D": "此选项不是最佳选择，因为它同样使用 AWS CLI 复制代码并创建标签，这不是最有效的方法来处理 CodeCommit 仓库的代码。"
    },
    "service": ["AWS CodeCommit", "AWS CodeBuild", "AWS CodePipeline"],
    "reason": "1.2"
  },
  {
    "no": 225,
    "question": "一家公司希望在几百台 Amazon EC2 实例上部署工作负载。公司将使用启动模板在 Auto Scaling 组中配置 EC2 实例。工作负载将从 Amazon S3 存储桶中拉取文件，处理数据，并将结果放入另一个 S3 存储桶。EC2 实例必须具有最小权限权限，并且必须使用临时安全凭证。哪两个步骤的组合将满足这些要求？（选择两个。）",
    "choose": 2,
    "options": {
      "A": "创建具有适当 S3 存储桶权限的 IAM 角色，并将 IAM 角色添加到实例配置文件中。",
      "B": "更新启动模板以包含 IAM 实例配置文件。",
      "C": "创建具有适当 Amazon S3 权限的 IAM 用户，生成密钥和令牌。",
      "D": "创建信任锚和配置文件，并将 IAM 角色附加到配置文件。",
      "E": "更新启动模板，修改用户数据以使用新的密钥和令牌。"
    },
    "best": ["A", "B"],
    "analysis": {
      "A": "这是最佳选项之一，因为创建 IAM 角色并将其与实例配置文件关联是为 EC2 实例提供必要权限的标准方法，同时确保权限的最小化和安全性。",
      "B": "这也是最佳选项之一，因为更新启动模板以包含 IAM 实例配置文件确保所有自动扩展的 EC2 实例都自动具有正确的权限和配置。",
      "C": "这不是最佳选项，因为使用 IAM 用户和长期安全凭证不符合最小权限和使用临时凭证的要求。",
      "D": "这不是最佳选项，因为创建信任锚和配置文件不是标准的 AWS 实践，也不符合题目要求。",
      "E": "这不是最佳选项，因为修改用户数据以使用新的密钥和令牌会导致安全风险，且不符合使用临时安全凭证的要求。"
    },
    "service": ["Amazon EC2", "Amazon S3", "IAM", "Auto Scaling"],
    "reason": "6.1"
  },
  {
    "no": 226,
    "question": "一家公司正在使用 AWS CodeDeploy 来自动化软件部署。部署必须满足以下要求：• 在部署期间，必须有一定数量的实例可用于处理流量。流量必须在这些实例之间平衡，并且在发生故障时实例必须自动恢复。• 必须自动启动新的实例群来部署新的修订版，无需手动配置。• 流量必须重新路由到新环境的一半新实例。如果流量被重新路由到至少一半的实例，则部署应成功；否则，应失败。• 在将流量路由到新的实例群之前，必须删除部署过程中生成的临时文件。• 在成功部署后，应立即删除部署组中的原始实例以降低成本。DevOps 工程师如何满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用应用程序负载均衡器和就地部署。将自动扩展组与部署组关联。使用自动复制自动扩展组选项，并使用 CodeDeployDefault.OneAtAtime 作为部署配置。指示 AWS CodeDeploy 终止部署组中的原始实例，并在 appspec.yml 中使用 AllowTraffic 钩子删除临时文件。",
      "B": "使用应用程序负载均衡器和蓝/绿部署。将自动扩展组和应用程序负载均衡器目标组与部署组关联。使用自动复制自动扩展组选项，创建自定义部署配置，定义最小健康主机为 50%，并将配置分配给部署组。指示 AWS CodeDeploy 终止部署组中的原始实例，并在 appspec.yml 中使用 BeforeBlockTraffic 钩子删除临时文件。",
      "C": "使用应用程序负载均衡器和蓝/绿部署。将自动扩展组和应用程序负载均衡器目标组与部署组关联。使用自动复制自动扩展组选项，并使用 CodeDeployDefault.HalfAtAtime 作为部署配置。指示 AWS CodeDeploy 终止部署组中的原始实例，并在 appspec.yml 中使用 BeforeAllowTraffic 钩子删除临时文件。",
      "D": "使用应用程序负载均衡器和就地部署。将自动扩展组和应用程序负载均衡器目标组与部署组关联。使用自动复制自动扩展组选项，并使用 CodeDeployDefault.AllatOnce 作为部署配置。指示 AWS CodeDeploy 终止部署组中的原始实例，并在 appspec.yml 中使用 BlockTraffic 钩子删除临时文件。"
    },
    "best": ["C"],
    "analysis": {
      "A": "这个选项使用了就地部署，这不符合要求中提到的自动启动新的实例群来部署新的修订版。",
      "B": "这个选项虽然使用了蓝/绿部署，但是使用了 BeforeBlockTraffic 钩子，这不符合在流量路由之前删除临时文件的要求。",
      "C": "这个选项使用了蓝/绿部署，并且使用了 BeforeAllowTraffic 钩子来在流量路由之前删除临时文件，符合所有要求。",
      "D": "这个选项使用了就地部署，这不符合要求中提到的自动启动新的实例群来部署新的修订版。"
    },
    "service": [
      "AWS CodeDeploy",
      "Application Load Balancer",
      "Auto Scaling",
      "appspec.yml"
    ],
    "reason": "1.4"
  },
  {
    "no": 228,
    "question": "一个 DevOps 团队在 AWS Config 中创建了一个自定义 Lambda 规则。该规则监控 Amazon 弹性容器仓库（Amazon ECR）策略语句中的 ecr:* 操作。当检测到不合规的仓库时，Amazon EventBridge 使用 Amazon Simple Notification Service (Amazon SNS) 将通知路由到安全团队。当评估自定义 AWS Config 规则时，AWS Lambda 函数无法运行。哪种解决方案将解决这个问题？",
    "choose": 1,
    "options": {
      "A": "修改 Lambda 函数的资源策略，授予 AWS Config 权限以调用该函数。",
      "B": "修改 SNS 主题策略，包括 EventBridge 发布到 SNS 主题的配置更改。",
      "C": "修改 Lambda 函数的执行角色，包括自定义 AWS Config 规则的配置更改。",
      "D": "修改所有 ECR 仓库策略，授予 AWS Config 访问必要的 ECR API 操作的权限。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为如果 AWS Config 规则无法触发 Lambda 函数，通常是因为 Lambda 函数的资源策略没有正确授权 AWS Config 调用该函数。",
      "B": "这个选项不正确，因为问题描述中 EventBridge 已经能够使用 SNS 发送通知，所以 SNS 主题策略不是问题所在。",
      "C": "这个选项不正确，因为执行角色通常用于控制 Lambda 函数可以执行哪些 AWS 服务，而不是控制哪些服务可以触发 Lambda 函数。",
      "D": "这个选项不正确，因为问题描述中没有提到 AWS Config 无法访问 ECR，而是 Lambda 函数无法被触发。"
    },
    "service": [
      "AWS Config",
      "AWS Lambda",
      "Amazon EventBridge",
      "Amazon SNS",
      "Amazon ECR"
    ],
    "reason": "2.3"
  },
  {
    "no": 227,
    "question": "一家公司需要采用多账户策略来部署其应用程序及相关的 CI/CD 基础设施。该公司已在 AWS Organizations 中创建了一个启用了所有功能的组织。公司已配置 AWS Control Tower 并已建立了一个登陆区。公司需要在组织中的所有 AWS 账户中使用 AWS Control Tower 控制（防护栏）。公司必须为多环境应用程序创建账户，并且必须确保所有账户都配置到初始基线。哪种解决方案能在最小的操作开销下满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 AWS Control Tower Account Factory Customization (AFC) 蓝图，使用基线配置。使用 AWS Control Tower Account Factory 为每个环境配置一个专用的 AWS 账户和一个 CI/CD 账户，使用该蓝图。",
      "B": "使用 AWS Control Tower Account Factory 为每个环境和一个 CI/CD 账户配置一个专用的 AWS 账户。使用 AWS CloudFormation StackSets 将基线配置应用到新账户。",
      "C": "使用 Organizations 为多环境 AWS 账户和一个 CI/CD 账户配置账户。在 Organizations 管理账户中，创建一个 AWS Lambda 函数，该函数假设 Organizations 访问角色以将基线配置应用到新账户。",
      "D": "使用 Organizations 为每个环境、一个审计账户和一个 CI/CD 账户配置专用的 AWS 账户。使用 AWS CloudFormation StackSets 将基线配置应用到新账户。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用 AWS Control Tower 的 Account Factory Customization 蓝图来自动化账户的创建和配置，这样可以确保所有账户都符合公司的基线配置，同时减少了手动操作的需要。",
      "B": "这个选项虽然使用了 AWS Control Tower Account Factory 来创建账户，但是它依赖于 AWS CloudFormation StackSets 来应用基线配置，这增加了操作复杂性和潜在的错误点。",
      "C": "这个选项使用了 AWS Organizations 和 AWS Lambda，但是它需要手动创建和管理 Lambda 函数来应用配置，这增加了操作复杂性和维护负担。",
      "D": "这个选项使用了 Organizations 和 AWS CloudFormation StackSets，但是没有利用 AWS Control Tower 的功能，可能会导致配置不一致和管理上的复杂性。"
    },
    "service": [
      "AWS Organizations",
      "AWS Control Tower",
      "AWS Lambda",
      "AWS CloudFormation"
    ],
    "reason": "2.2"
  },
  {
    "no": 229,
    "question": "一位开发者正在为一款新的软件即服务（SaaS）应用创建概念验证。该应用位于一个共享的开发AWS账户中，该账户是AWS组织中的一部分。开发者需要为正在考虑用于概念验证的AWS服务创建服务链接的IAM角色。解决方案需要赋予开发者仅创建和配置服务链接角色的能力。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在组织的管理账户中为开发者创建一个IAM用户。在开发账户中配置一个跨账户角色供开发者使用。限制跨账户角色的范围为常见服务。",
      "B": "将开发者添加到一个IAM组中。将PowerUserAccess托管策略附加到IAM组。对用户账户强制执行多因素认证（MFA）。",
      "C": "在组织中的开发账户添加一个SCP。配置SCP，使用Deny规则对iam:*限制开发者的访问。",
      "D": "创建一个具有必要IAM访问权限的IAM角色，允许开发者创建策略和角色。创建并附加一个权限边界到角色。授权开发者承担该角色。"
    },
    "best": ["D"],
    "analysis": {
      "A": "这个选项不是最佳选择，因为它涉及到跨账户角色，这可能不是为单一开发者配置服务链接角色的最直接或最安全的方法。",
      "B": "这个选项不是最佳选择，因为PowerUserAccess策略提供了比创建和管理服务链接角色更广泛的权限，这可能会导致权限过度。",
      "C": "这个选项不是最佳选择，因为使用Deny规则对iam:*进行限制将完全阻止开发者创建或配置任何IAM角色，包括服务链接角色。",
      "D": "这是最佳选择，因为它直接允许开发者创建和管理IAM角色，并通过权限边界限制这些角色的权限，确保安全性和最小权限原则。"
    },
    "service": ["IAM", "AWS Organizations"],
    "reason": "6.1"
  },
  {
    "no": 235,
    "question": "一家公司开发了一个托管在 Amazon S3 存储桶上的静态网站。该网站使用 AWS CloudFormation 部署。CloudFormation 模板定义了一个 S3 存储桶和一个自定义资源，该资源从源位置将内容复制到存储桶中。公司决定需要将网站迁移到新位置，因此必须删除并重新创建现有的 CloudFormation 堆栈。然而，CloudFormation 报告堆栈无法干净地删除。最可能的原因是什么，DevOps 工程师如何缓解这个问题以及未来版本的网站？",
    "choose": 1,
    "options": {
      "A": "删除失败是因为 S3 存储桶具有活跃的网站配置。修改 CloudFormation 模板以从 S3 存储桶资源中删除 WebsiteConfiguration 属性。",
      "B": "删除失败是因为 S3 存储桶不为空。修改自定义资源的 AWS Lambda 函数代码，以便在 RequestType 为 Delete 时递归清空存储桶。",
      "C": "删除失败是因为自定义资源没有定义删除策略。向自定义资源定义中添加 DeletionPolicy 属性，其值为 RemoveOnDeletion。",
      "D": "删除失败是因为 S3 存储桶不为空。修改 CloudFormation 模板中的 S3 存储桶资源，添加 DeletionPolicy 属性，其值为 Empty。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然删除网站配置是一个必要步骤，但仅仅移除配置并不能解决存储桶中已有内容导致的删除失败问题。",
      "B": "虽然这种方法可以清空存储桶，但它需要修改 Lambda 函数代码，这可能不是最直接或最简单的解决方案。",
      "C": "添加删除策略是一个好主意，但 RemoveOnDeletion 不是 AWS 中的标准选项，这可能是一个错误的属性值。",
      "D": "这是最直接的解决方案，因为它直接在 CloudFormation 模板中处理存储桶不为空的问题，确保存储桶在删除堆栈时自动清空。"
    },
    "service": ["AWS CloudFormation", "Amazon S3", "AWS Lambda"],
    "reason": "2.1"
  },
  {
    "no": 231,
    "question": "一家公司使用 AWS Organizations 管理其 AWS 账户。一名 DevOps 工程师必须确保所有访问 AWS 管理控制台的用户通过公司的企业身份提供商（IdP）进行身份验证。哪两个步骤的组合可以满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "使用 Amazon GuardDuty 与委托管理员账户一起使用 GuardDuty 强制拒绝 IAM 用户登录。",
      "B": "使用 AWS IAM 身份中心配置与 SAML 2.0 的身份联合。",
      "C": "在 AWS IAM 身份中心创建权限边界以拒绝 IAM 用户的密码登录。",
      "D": "在组织管理账户中创建 IAM 组以为所有 IAM 用户应用一致的权限。",
      "E": "在组织中创建 SCP 以拒绝 IAM 用户的密码创建。"
    },
    "best": ["B", "E"],
    "analysis": {
      "A": "这个选项不是最佳选择，因为 GuardDuty 主要用于威胁检测和监控，而不是用于管理身份验证和联合身份。",
      "B": "这是一个最佳选择，因为 AWS IAM 身份中心（原 AWS Single Sign-On）支持通过 SAML 2.0 实现身份联合，可以与企业身份提供商集成。",
      "C": "这个选项不是最佳选择，因为权限边界用于限制 IAM 角色的最大权限，而不是直接管理身份验证方式。",
      "D": "这个选项不是最佳选择，因为虽然可以通过 IAM 组管理权限，但它不涉及与企业身份提供商的身份验证集成。",
      "E": "这是一个最佳选择，因为使用服务控制策略（SCP）可以在 AWS Organizations 级别拒绝或限制账户权限，包括创建密码，从而强制使用企业身份提供商的身份验证。"
    },
    "service": [
      "AWS Organizations",
      "Amazon GuardDuty",
      "AWS IAM Identity Center",
      "IAM",
      "SCP"
    ],
    "reason": "6.1"
  },
  {
    "no": 230,
    "question": "一家公司使用 AWS Organizations 管理其 AWS 账户。该公司希望其监控系统在根用户登录时接收到警报。公司还需要一个仪表板来显示根用户生成的任何日志活动。哪种步骤组合可以满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "启用 AWS Config 并配置多账户聚合器。配置日志转发到 Amazon CloudWatch Logs。",
      "B": "创建一个使用 Amazon CloudWatch Logs 查询的 Amazon QuickSight 仪表板。",
      "C": "创建一个 Amazon CloudWatch Logs 指标过滤器以匹配根用户登录事件。配置 CloudWatch 警报和 Amazon Simple Notification Service (Amazon SNS) 主题以向公司的监控系统发送警报。",
      "D": "创建一个 Amazon CloudWatch Logs 订阅过滤器以匹配根用户登录事件。配置过滤器将事件转发到 Amazon Simple Notification Service (Amazon SNS) 主题。配置 SNS 主题向公司的监控系统发送警报。",
      "E": "创建一个 AWS CloudTrail 组织跟踪。配置组织跟踪将事件发送到 Amazon CloudWatch Logs。",
      "F": "创建一个使用 CloudWatch Logs Insights 查询的 Amazon CloudWatch 仪表板。"
    },
    "best": ["C", "D", "E"],
    "analysis": {
      "A": "虽然启用 AWS Config 并配置日志转发到 CloudWatch Logs 是一个好的监控实践，但它不直接涉及到根用户登录事件的监控和警报。",
      "B": "Amazon QuickSight 仪表板可以用于可视化日志数据，但它不提供实时警报功能，因此不是最佳选择。",
      "C": "这是最佳选项之一，因为它直接涉及到创建针对根用户登录的指标过滤器，并配置警报和通知。",
      "D": "这也是最佳选项之一，因为它涉及到创建订阅过滤器来监控根用户登录事件，并配置通知。",
      "E": "这是最佳选项之一，因为 AWS CloudTrail 组织跟踪可以跟踪根用户活动，并将日志发送到 CloudWatch Logs，从而支持监控和警报。",
      "F": "虽然 CloudWatch 仪表板可以用于监控日志，但它主要用于数据可视化而不是实时警报，因此不是最佳选择。"
    },
    "service": [
      "AWS Organizations",
      "Amazon CloudWatch Logs",
      "Amazon SNS",
      "AWS Config",
      "Amazon QuickSight",
      "AWS CloudTrail",
      "Amazon CloudWatch"
    ],
    "reason": "4.1"
  },
  {
    "no": 237,
    "question": "一家公司有一个事件驱动的 JavaScript 应用程序。该应用程序使用解耦的 AWS 托管服务来发布、消费和路由事件。在应用程序测试期间，事件未按 Amazon EventBridge 规则指定的目标传递。DevOps 团队必须为应用程序测试人员提供额外的功能，以查看、排除故障并防止事件丢失，而无需重新部署应用程序。DevOps 团队应采取哪些步骤组合以满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "启动 AWS Device Farm，使用标准测试环境和项目运行应用程序的特定构建。",
      "B": "创建一个 Amazon S3 存储桶。启用 AWS CloudTrail。创建一个 CloudTrail 跟踪，指定 S3 存储桶作为存储位置。",
      "C": "将 EventBridge 规则配置为使用 Amazon Simple Queue Service (Amazon SQS) 标准队列作为死信队列。",
      "D": "将 EventBridge 规则配置为使用 Amazon Simple Queue Service (Amazon SQS) FIFO 队列作为死信队列。",
      "E": "在 Amazon CloudWatch Logs 中创建日志组，并将该日志组指定为 EventBridge 规则的额外目标。",
      "F": "更新应用程序代码库，使用 AWS X-Ray SDK 跟踪功能为代码添加支持 X-Amzn-Trace-Id 标头的工具。"
    },
    "best": ["C", "D", "E"],
    "analysis": {
      "A": "AWS Device Farm 主要用于应用程序测试，而不是用于事件查看、排除故障或防止事件丢失。",
      "B": "虽然 CloudTrail 可以用于审计和监控 AWS 账户的活动，但它并不直接帮助查看或排除 EventBridge 事件传递问题。",
      "C": "使用 SQS 标准队列作为死信队列可以帮助捕获无法成功处理的事件，从而防止事件丢失并帮助排除故障。",
      "D": "使用 SQS FIFO 队列作为死信队列可以确保事件的顺序，有助于排除事件处理问题。",
      "E": "将 CloudWatch Logs 作为额外的目标可以帮助记录和查看事件传递的详细信息，有助于排除故障。",
      "F": "虽然 AWS X-Ray 提供应用程序性能管理和排除故障的功能，但它主要用于性能分析，而不是直接用于事件查看或防止事件丢失。"
    },
    "service": [
      "AWS Device Farm",
      "AWS CloudTrail",
      "Amazon S3",
      "Amazon EventBridge",
      "Amazon SQS",
      "Amazon CloudWatch Logs",
      "AWS X-Ray"
    ],
    "reason": "5.1"
  },
  {
    "no": 236,
    "question": "一家公司使用 Amazon EC2 作为其主要计算平台。DevOps 团队希望审计公司的 EC2 实例，以检查是否安装了任何禁止的应用程序。哪种解决方案在最大程度上满足这些要求的操作效率？",
    "choose": 1,
    "options": {
      "A": "在每个实例上配置 AWS Systems Manager。使用 AWS Systems Manager Inventory。使用 Systems Manager 资源数据同步将发现结果同步并存储在 Amazon S3 存储桶中。创建一个在 S3 存储桶中添加新对象时运行的 AWS Lambda 函数。配置 Lambda 函数以识别禁止的应用程序。",
      "B": "在每个实例上配置 AWS Systems Manager。使用 Systems Manager Inventory 创建 AWS Config 规则，监控来自 Systems Manager Inventory 的更改以识别禁止的应用程序。",
      "C": "在每个实例上配置 AWS Systems Manager。使用 Systems Manager Inventory。在 AWS CloudTrail 中过滤 Systems Manager Inventory 事件的轨迹以识别禁止的应用程序。",
      "D": "指定 Amazon CloudWatch Logs 为所有应用程序实例的日志目的地。在所有实例上运行自动化脚本以创建已安装应用程序的清单。配置脚本将结果转发到 CloudWatch Logs。创建一个 CloudWatch 警报，使用过滤模式搜索日志数据以识别禁止的应用程序。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用 AWS Systems Manager 来管理和审计 EC2 实例，同时利用 Lambda 函数自动处理 S3 存储桶中的数据，从而提高操作效率。",
      "B": "此选项不是最佳选择，因为它依赖于 AWS Config 规则来监控更改，这可能不如选项 A 中的自动化 Lambda 函数处理高效。",
      "C": "此选项不是最佳选择，因为它依赖于手动过滤 CloudTrail 日志，这在操作效率上不如选项 A 中的自动化处理。",
      "D": "此选项不是最佳选择，因为它涉及手动配置脚本和 CloudWatch 警报，这在操作效率上不如选项 A 中的自动化和集成解决方案。"
    },
    "service": [
      "AWS Systems Manager",
      "AWS Lambda",
      "Amazon S3",
      "AWS Config",
      "AWS CloudTrail",
      "Amazon CloudWatch Logs"
    ],
    "reason": "2.3"
  },
  {
    "no": 234,
    "question": "一家公司希望减少开发新功能所需的时间。该公司使用 AWS CodeBuild 和 AWS CodeDeploy 构建和部署其应用程序。公司使用 AWS CodePipeline 为每个微服务部署各自的 CI/CD 管道。公司需要更多地了解发布新功能的平均时间和失败部署后恢复的平均时间。哪种解决方案将以最少的配置工作提供这种可见性？",
    "choose": 1,
    "options": {
      "A": "编程 AWS Lambda 函数，创建关于每个管道成功运行和失败运行的 Amazon CloudWatch 自定义指标。创建一个 Amazon EventBridge 规则，每 5 分钟调用一次 Lambda 函数。使用这些指标构建 CloudWatch 仪表板。",
      "B": "编程 AWS Lambda 函数，创建关于每个管道成功运行和失败运行的 Amazon CloudWatch 自定义指标。创建一个 Amazon EventBridge 规则，在每次成功运行和失败运行后调用 Lambda 函数。使用这些指标构建 CloudWatch 仪表板。",
      "C": "编程 AWS Lambda 函数，将关于成功运行和失败运行的信息写入 Amazon DynamoDB。创建一个 Amazon EventBridge 规则，在每次成功运行和失败运行后调用 Lambda 函数。构建一个 Amazon QuickSight 仪表板来显示来自 DynamoDB 的信息。",
      "D": "编程 AWS Lambda 函数，将关于成功运行和失败运行的信息写入 Amazon DynamoDB。创建一个 Amazon EventBridge 规则，每 5 分钟调用一次 Lambda 函数。构建一个 Amazon QuickSight 仪表板来显示来自 DynamoDB 的信息。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然这个选项使用了 CloudWatch 自定义指标和仪表板，但每 5 分钟调用一次可能不会及时反映实际的部署状态，导致数据延迟。",
      "B": "这个选项提供了最少的配置工作并且能够实时反映每次部署的成功或失败状态，是最优解。",
      "C": "虽然使用了 DynamoDB 和 QuickSight 仪表板，但这增加了额外的配置和管理负担，而且不如直接使用 CloudWatch 那样直接。",
      "D": "这个选项与选项 C 类似，但每 5 分钟调用一次会导致数据延迟，不适合需要实时数据的场景。"
    },
    "service": [
      "AWS Lambda",
      "Amazon CloudWatch",
      "Amazon EventBridge",
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "AWS CodePipeline",
      "Amazon DynamoDB",
      "Amazon QuickSight"
    ],
    "reason": "1.1"
  },
  {
    "no": 233,
    "question": "一家公司在 AWS Organizations 中的一个组织中将其 AWS 账户分组到 OUs 中。该公司在组织的一个账户中部署了一组 Amazon API Gateway API。这些 API 绑定到账户的 VPC 中，并且没有现有的身份验证机制。只有特定 OU 中的主体可以获得调用 API 的权限。公司对 API Gateway 接口 VPC 终端应用以下策略：公司还更新了 API Gateway 资源策略，以拒绝不通过接口 VPC 终端的调用。更新后，在尝试使用接口 VPC 终端 URL 调用 API 时出现以下错误消息：“用户：anonymous 未经授权。”哪两个步骤的组合将解决这个问题？（选择两个）",
    "choose": 2,
    "options": {
      "A": "通过将 AWS IAM 设置为授权方法，启用所有 API 方法的 IAM 身份验证。",
      "B": "创建一个基于令牌的 AWS Lambda 授权者，该授权者在承载令牌中传递调用者的身份。",
      "C": "创建一个基于请求参数的 AWS Lambda 授权者，该授权者在一组头部、查询字符串参数、阶段变量和 $context 变量的组合中传递调用者的身份。",
      "D": "使用 Amazon Cognito 用户池作为授权者来控制对 API 的访问。",
      "E": "通过使用 AWS 凭证对客户端请求进行签名，使用签名版本 4 验证请求者的身份。"
    },
    "best": ["A", "D"],
    "analysis": {
      "A": "启用 IAM 身份验证可以确保只有具有适当 IAM 策略的用户或角色才能调用 API，这符合只允许特定 OU 中的主体调用 API 的要求。",
      "B": "虽然 Lambda 授权者可以传递调用者的身份，但它不直接与 AWS IAM 集成，可能不足以满足特定 OU 中的主体的权限管理需求。",
      "C": "与选项 B 类似，这种方法也涉及 Lambda 授权者，但同样缺乏直接的 IAM 集成。",
      "D": "Amazon Cognito 用户池作为授权者提供了一个管理用户身份和权限的强大框架，可以很好地控制哪些用户可以访问 API。",
      "E": "虽然使用签名版本 4 可以验证请求者的身份，但它主要用于确保请求的完整性和来源，不直接控制访问权限。"
    },
    "service": [
      "AWS Organizations",
      "Amazon API Gateway",
      "IAM",
      "Amazon Cognito",
      "AWS Lambda"
    ],
    "reason": "6.1"
  },
  {
    "no": 239,
    "question": "一家公司使用 Amazon Elastic Kubernetes Service (Amazon EKS) 集群来部署其容器上的 Web 应用程序。Web 应用程序包含无法在没有特定凭据的情况下解密的机密数据。一位 DevOps 工程师已将凭据存储在 AWS Secrets Manager 中。Secrets 使用 AWS Key Management Service (AWS KMS) 客户管理的密钥进行加密。一个第三方工具的 Kubernetes 服务账户使应用程序可以访问这些密钥。服务账户承担了公司创建的 IAM 角色以访问密钥。服务账户在尝试从 Secrets Manager 检索密钥时收到 Access Denied (403 Forbidden) 错误。此问题的根本原因是什么？",
    "choose": 1,
    "options": {
      "A": "附加到 EKS 集群的 IAM 角色无权从 Secrets Manager 检索密钥。",
      "B": "客户管理的密钥的密钥策略不允许 Kubernetes 服务账户 IAM 角色使用该密钥。",
      "C": "客户管理的密钥的密钥策略不允许 EKS 集群 IAM 角色使用该密钥。",
      "D": "Kubernetes 服务账户承担的 IAM 角色没有权限访问 EKS 集群。"
    },
    "best": ["B"],
    "analysis": {
      "A": "此选项不正确，因为问题描述中并未提及 EKS 集群的 IAM 角色直接与 Secrets Manager 交互。",
      "B": "此选项正确，因为问题描述中提到服务账户承担的 IAM 角色尝试访问由 KMS 加密的密钥，如果 KMS 密钥策略不允许此 IAM 角色使用密钥，则会导致 403 Forbidden 错误。",
      "C": "此选项不正确，因为问题描述中提到的是服务账户的 IAM 角色，而不是 EKS 集群的 IAM 角色。",
      "D": "此选项不正确，因为问题描述中的错误是在访问 Secrets Manager 时发生的，而不是在访问 EKS 集群时。"
    },
    "service": ["Amazon EKS", "AWS Secrets Manager", "AWS KMS", "IAM"],
    "reason": "4.1"
  },
  {
    "no": 232,
    "question": "一家公司部署了一个在 Amazon Elastic Kubernetes Service (Amazon EKS) 上运行的新平台。该平台托管了用户经常更新的 Web 应用程序。应用程序开发人员为应用程序构建 Docker 镜像，并手动将 Docker 镜像部署到平台上。平台的使用量已增加到每天超过 500 名用户。频繁的更新、为应用程序构建更新的 Docker 镜像以及手动在平台上部署 Docker 镜像都变得难以管理。公司需要在 Docker 镜像扫描返回任何针对操作系统或编程语言包的高危或严重漏洞时接收 Amazon Simple Notification Service (Amazon SNS) 通知。哪两个步骤的组合将满足这些要求？（选择两个。）",
    "choose": 2,
    "options": {
      "A": "创建一个 AWS CodeCommit 仓库来存储 Dockerfile 和 Kubernetes 部署文件。在 AWS CodePipeline 中创建一个管道。使用 Amazon S3 事件来调用管道，当提交了 Dockerfile 的新版本时。添加一个步骤到管道中以启动 AWS CodeBuild 项目。",
      "B": "创建一个 AWS CodeCommit 仓库来存储 Dockerfile 和 Kubernetes 部署文件。在 AWS CodePipeline 中创建一个管道。使用 Amazon EventBridge 事件来调用管道，当提交了 Dockerfile 的新版本时。添加一个步骤到管道中以启动 AWS CodeBuild 项目。",
      "C": "创建一个 AWS CodeBuild 项目，构建 Docker 镜像并将 Docker 镜像存储在 Amazon Elastic Container Registry (Amazon ECR) 仓库中。打开 ECR 仓库的基本扫描。创建一个 Amazon EventBridge 规则，监控 Amazon GuardDuty 事件。配置 EventBridge 规则在 finding-severity-counts 参数在 CRITICAL 或 HIGH 级别超过 0 时发送事件到一个 SNS 主题。",
      "D": "创建一个 AWS CodeBuild 项目，构建 Docker 镜像并将 Docker 镜像存储在 Amazon Elastic Container Registry (Amazon ECR) 仓库中。打开 ECR 仓库的增强扫描。创建一个 Amazon EventBridge 规则，监控 ECR 镜像扫描事件。配置 EventBridge 规则在 finding-severity-counts 参数在 CRITICAL 或 HIGH 级别超过 0 时发送事件到一个 SNS 主题。",
      "E": "创建一个 AWS CodeBuild 项目，扫描 Dockerfile。配置项目构建 Docker 镜像并在扫描成功时将 Docker 镜像存储在 Amazon Elastic Container Registry (Amazon ECR) 仓库中。配置一个 SNS 主题以在扫描返回任何漏洞时提供通知。"
    },
    "best": ["B", "D"],
    "analysis": {
      "A": "此选项使用 Amazon S3 事件来触发管道，这不是最佳实践，因为 Dockerfile 更新更适合使用 EventBridge 事件来触发。",
      "B": "此选项使用 EventBridge 事件来触发管道，这是最佳实践，因为它可以更精确地处理代码提交事件。",
      "C": "此选项监控的是 Amazon GuardDuty 事件，而不是 ECR 镜像扫描事件，因此不符合题目要求。",
      "D": "此选项正确地设置了 ECR 的增强扫描，并使用 EventBridge 规则来监控 ECR 镜像扫描事件，符合题目要求。",
      "E": "此选项虽然涉及到扫描 Dockerfile 和通知，但没有明确使用 EventBridge 来处理 ECR 镜像扫描事件，因此不是最佳选项。"
    },
    "service": [
      "AWS CodeCommit",
      "AWS CodePipeline",
      "Amazon S3",
      "AWS CodeBuild",
      "Amazon Elastic Container Registry",
      "Amazon EventBridge",
      "Amazon Simple Notification Service",
      "Amazon GuardDuty"
    ],
    "reason": "1.1"
  },
  {
    "no": 238,
    "question": "一家公司正在将其基于容器的工作负载迁移到 AWS Organizations 多账户环境。该环境由公司用于部署和运行容器化工作负载的应用程序工作负载账户组成。公司还为组织中的共享工作负载配置了一个共享服务账户。公司必须遵守严格的合规性规定。所有容器映像在部署到任何环境之前必须进行安全扫描。映像在通过无关键漏洞的扫描后，可以被下游部署机制使用。预扫描和扫描后的映像必须相互隔离，以便部署永远不会使用预扫描映像。一名 DevOps 工程师需要创建一个策略来集中处理这个过程。哪两个步骤的组合将以最小的管理开销满足这些要求？（选择两个。）",
    "choose": 2,
    "options": {
      "A": "在共享服务账户中创建 Amazon Elastic Container Registry（Amazon ECR）存储库：每个预扫描映像一个存储库，每个扫描后映像一个存储库。配置 Amazon ECR 映像扫描在新映像推送到预扫描存储库时运行。使用基于资源的策略授予组织对预扫描存储库的写入权限和对扫描后存储库的读取权限。",
      "B": "在发布容器映像的每个账户中创建预扫描 Amazon Elastic Container Registry（Amazon ECR）存储库。在共享服务账户中创建扫描后映像的存储库。配置 Amazon ECR 映像扫描在新映像推送到预扫描存储库时运行。使用基于资源的策略授予组织对扫描后存储库的读取权限。",
      "C": "为每个映像从预扫描存储库配置映像复制到扫描后存储库。",
      "D": "为每个预扫描存储库创建一个 AWS CodePipeline 管道。创建一个源阶段，当新映像被推送到预扫描存储库时运行。创建一个使用 AWS CodeBuild 作为操作提供者的阶段。编写一个 buildspec.yaml 定义，确定映像扫描状态并将没有关键漏洞的映像推送到扫描后存储库。",
      "E": "创建一个 AWS Lambda 函数。创建一个 Amazon EventBridge 规则，该规则对映像扫描完成事件做出反应并调用 Lambda 函数。编写函数代码，确定映像扫描状态并将没有关键漏洞的映像推送到扫描后存储库。"
    },
    "best": ["A", "D"],
    "analysis": {
      "A": "这是最优选项之一，因为它通过在共享服务账户中集中管理预扫描和扫描后的存储库，简化了权限和资源管理。此外，通过自动化的 ECR 映像扫描和基于资源的策略，确保了安全和合规性。",
      "B": "此选项不是最优的，因为它在每个账户中创建预扫描存储库，这增加了管理开销和复杂性。",
      "C": "此选项不是最优的，因为它只涉及映像复制，没有提到如何确保映像在部署前进行扫描和验证。",
      "D": "这是最优选项之一，因为它使用 AWS CodePipeline 和 CodeBuild 自动化映像扫描和部署过程，确保只有通过安全扫描的映像才能被部署。",
      "E": "此选项不是最优的，因为虽然它提供了自动化处理，但与 CodePipeline 和 CodeBuild 相比，Lambda 函数和 EventBridge 规则的设置可能需要更多的细节配置和管理。"
    },
    "service": [
      "AWS Organizations",
      "Amazon Elastic Container Registry",
      "AWS CodePipeline",
      "AWS CodeBuild",
      "AWS Lambda",
      "Amazon EventBridge"
    ],
    "reason": "1.1"
  },
  {
    "no": 244,
    "question": "一位 DevOps 工程师正在为一个应用程序构建基础设施。该应用程序需要在一个包括 Amazon EC2 实例的 Amazon Elastic Kubernetes Service (Amazon EKS) 集群上运行。EC2 实例需要使用 Amazon Elastic File System (Amazon EFS) 文件系统作为存储后端。Amazon EFS Container Storage Interface (CSI) 驱动程序已安装在 EKS 集群上。当 DevOps 工程师启动应用程序时，EC2 实例未能挂载 EFS 文件系统。哪些解决方案可以解决这个问题？（选择三个。）",
    "choose": 3,
    "options": {
      "A": "将 EKS 节点从 Amazon EC2 切换到 AWS Fargate。",
      "B": "为 EFS 文件系统的安全组添加一个入站规则，允许来自 EKS 集群的 NFS 流量。",
      "C": "创建一个 IAM 角色，允许 Amazon EFS CSI 驱动程序与文件系统交互",
      "D": "设置 AWS DataSync 来配置 EFS 文件系统和 EKS 节点之间的文件传输。",
      "E": "在 EKS 节点的子网中为 EFS 文件系统创建一个挂载目标。",
      "F": "禁用 EFS 文件系统的加密。"
    },
    "best": ["B", "C", "E"],
    "analysis": {
      "A": "切换到 AWS Fargate 不会解决 EFS 文件系统的挂载问题，因为这与实例类型无关。",
      "B": "允许 NFS 流量是确保 EKS 节点可以访问 EFS 文件系统的关键配置，因此这是一个正确的解决方案。",
      "C": "创建允许 EFS CSI 驱动程序与文件系统交互的 IAM 角色是必要的，以确保正确的权限和访问控制。",
      "D": "AWS DataSync 主要用于数据迁移和在线数据传输，与解决挂载问题无直接关系。",
      "E": "在 EKS 节点所在子网中创建挂载目标是实现 EFS 文件系统访问的基本步骤之一。",
      "F": "禁用加密不会解决挂载问题，且可能会降低数据安全性。"
    },
    "service": ["Amazon EKS", "Amazon EC2", "Amazon EFS", "Amazon EFS CSI"],
    "reason": "1.4"
  },
  {
    "no": 246,
    "question": "一位 DevOps 工程师正在使用 AWS CodeDeploy 和 AWS CloudFormation 为应用程序设置 Amazon Elastic Container Service (Amazon ECS) 蓝/绿部署。在部署窗口期间，应用程序必须高度可用，并且 CodeDeploy 必须每分钟将 10% 的流量转移到应用程序的新版本，直到所有流量都转移过去。DevOps 工程师应该在 CloudFormation 模板中添加哪种配置以满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在 AppSpec 文件中添加 CodeDeployDefault.ECSLinear10PercentEvery1Minutes 部署配置。",
      "B": "添加 AWS::CodeDeployBlueGreen 转换和 AWS::CodeDeploy::BlueGreen 钩子参数，使用 CodeDeployDefault.ECSLinear10PercentEvery1Minutes 部署配置。",
      "C": "在 AppSpec 文件中添加 ECSCanary10Percent5Minutes 部署配置。",
      "D": "添加 AWS::CodeDeployBlueGreen 转换和 AWS::CodeDeploy::BlueGreen 钩子参数，使用 ECSCanary10Percent5Minutes 部署配置。"
    },
    "best": ["B"],
    "analysis": {
      "A": "虽然这个选项提到了正确的部署配置，但它没有提到必要的 AWS::CodeDeployBlueGreen 转换和 AWS::CodeDeploy::BlueGreen 钩子，这是实现蓝/绿部署的关键组件。",
      "B": "这个选项正确地结合了 AWS::CodeDeployBlueGreen 转换和 AWS::CodeDeploy::BlueGreen 钩子参数，并使用了正确的 CodeDeployDefault.ECSLinear10PercentEvery1Minutes 部署配置，完全符合题目要求。",
      "C": "这个选项虽然提到了 AppSpec 文件，但使用了 ECSCanary10Percent5Minutes 部署配置，这与题目要求的每分钟转移 10% 流量不符。",
      "D": "这个选项虽然使用了 AWS::CodeDeployBlueGreen 转换和 AWS::CodeDeploy::BlueGreen 钩子参数，但部署配置 ECSCanary10Percent5Minutes 并不符合题目要求的每分钟转移 10% 流量。"
    },
    "service": ["AWS CodeDeploy", "AWS CloudFormation", "Amazon ECS"],
    "reason": "1.4"
  },
  {
    "no": 242,
    "question": "一家公司使用 Amazon Elastic Kubernetes Service (Amazon EKS) 集群来托管其机器学习 (ML) 应用程序。随着 ML 模型和容器映像大小的增长，新 Pod 启动所需的时间已增加到几分钟。DevOps 工程师需要将启动时间减少到几秒钟。该解决方案还必须在 Pod 运行在最近添加到集群中的节点上时将启动时间减少到几秒钟。DevOps 工程师创建了一个 Amazon EventBridge 规则，该规则调用 AWS Systems Manager 中的自动化操作，以在向 Amazon Elastic Container Registry (Amazon ECR) 仓库推送新映像时预取容器映像。DevOps 工程师还配置了要应用于集群和节点组的标签。DevOps 工程师接下来应该做什么以满足要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 IAM 角色，该角色具有允许 EventBridge 使用 Systems Manager 在 EKS 集群的控制平面节点上运行命令的策略。创建一个 Systems Manager State Manager 关联，使用控制平面节点的标签预取相应的容器映像。",
      "B": "创建一个 IAM 角色，该角色具有允许 EventBridge 使用 Systems Manager 在 EKS 集群的节点上运行命令的策略。创建一个 Systems Manager State Manager 关联，使用节点的机器大小预取相应的容器映像。",
      "C": "创建一个 IAM 角色，该角色具有允许 EventBridge 使用 Systems Manager 在 EKS 集群的节点上运行命令的策略。创建一个 Systems Manager State Manager 关联，使用节点的标签预取相应的容器映像。",
      "D": "创建一个 IAM 角色，该角色具有允许 EventBridge 使用 Systems Manager 在 EKS 集群的控制平面节点上运行命令的策略。创建一个 Systems Manager State Manager 关联，使用节点的标签预取相应的容器映像。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它提到了控制平面节点，而实际上我们需要在工作节点上预取容器映像。",
      "B": "此选项不是最佳选择，因为它使用节点的机器大小来预取映像，这与预取特定映像无关。",
      "C": "此选项是最佳选择，因为它允许 EventBridge 使用 Systems Manager 在 EKS 集群的节点上运行命令，并使用节点的标签来预取相应的容器映像，这符合需求。",
      "D": "此选项不是最佳选择，因为它提到了控制平面节点，而实际上我们需要在工作节点上预取容器映像。"
    },
    "service": [
      "Amazon EKS",
      "AWS Systems Manager",
      "Amazon EventBridge",
      "Amazon ECR"
    ],
    "reason": "2.3"
  },
  {
    "no": 240,
    "question": "一家公司正在将其产品开发团队从本地数据中心迁移到混合环境。新环境将增加四个 AWS 区域，并将使开发人员能够使用地理位置最接近他们的区域。所有开发团队使用一组共享的 Linux 应用程序。本地数据中心的 NetApp ONTAP 存储设备上存储应用程序。存储卷在本地开发 VM 上以只读方式挂载。公司每周更新共享卷上的应用程序一次。DevOps 工程师需要将数据复制到所有新区域。DevOps 工程师必须确保数据始终是最新的，并进行去重。数据还必须不依赖于本地存储设备的可用性。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在本地数据中心创建一个 Amazon S3 文件网关。在每个区域创建 S3 存储桶。设置一个 cron 作业，将数据从存储设备复制到 S3 文件网关。在每个区域的 S3 存储桶中设置 S3 跨区域复制（CRR）。",
      "B": "在一个区域中创建一个 Amazon FSx 文件网关。在每个区域创建 Amazon FSx for Windows 文件服务器。设置一个 cron 作业，将数据从存储设备复制到 FSx 文件网关。",
      "C": "在每个区域创建多可用区的 Amazon FSx for NetApp ONTAP 实例和卷。配置从本地存储设备到 FSx for ONTAP 实例的定时 SnapMirror 关系。",
      "D": "在每个区域创建一个 Amazon Elastic File System (Amazon EFS) 文件系统。在本地数据中心部署一个 AWS DataSync 代理。配置 DataSync 每天将数据复制到 Amazon EFS。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然这个选项提供了跨区域复制，但它使用的是 S3 文件网关，这主要适用于集成存储系统与 S3 的场景，并不支持 NetApp ONTAP 的特定功能。",
      "B": "这个选项没有提供跨区域复制的功能，只是在每个区域设置了文件服务器，不满足题目要求的数据一致性和去重需求。",
      "C": "这个选项直接使用了 Amazon FSx for NetApp ONTAP，可以很好地与现有的 NetApp ONTAP 系统集成，支持数据去重和跨区域复制，满足题目的所有要求。",
      "D": "虽然这个选项提供了跨区域的数据复制，但它使用的是 Amazon EFS，这并不支持 NetApp ONTAP 的特定功能，如数据去重。"
    },
    "service": [
      "Amazon S3",
      "Amazon FSx",
      "Amazon EFS",
      "AWS DataSync",
      "NetApp ONTAP"
    ],
    "reason": "3.1"
  },
  {
    "no": 243,
    "question": "一家公司的应用程序有一个API，用于检索工作负载指标。该公司需要对这些来自应用程序的指标进行审计、分析和可视化，以便在大规模上检测问题。哪种步骤组合能满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "配置Amazon EventBridge计划以调用AWS Lambda函数，该函数调用API以检索工作负载指标。将工作负载指标数据存储在Amazon S3存储桶中。",
      "B": "配置Amazon EventBridge计划以调用AWS Lambda函数，该函数调用API以检索工作负载指标。将工作负载指标数据存储在启用了DynamoDB流的Amazon DynamoDB表中。",
      "C": "创建AWS Glue爬虫以在Amazon S3存储桶中编目工作负载指标数据。为编目的数据创建Amazon Athena视图。",
      "D": "连接AWS Glue爬虫到Amazon DynamoDB流以编目工作负载指标数据。为编目的数据创建Amazon Athena视图。",
      "E": "从Amazon Athena视图创建Amazon QuickSight数据集。创建QuickSight分析以将工作负载指标数据可视化为仪表板。",
      "F": "创建一个Amazon CloudWatch仪表板，其中包含自定义小部件，这些小部件调用AWS Lambda函数。配置Lambda函数以从Amazon Athena视图查询工作负载指标数据。"
    },
    "best": ["A", "C", "E"],
    "analysis": {
      "A": "这是最优选项之一，因为它涉及使用EventBridge和Lambda来定期检索和存储指标数据，这是数据收集的基础。",
      "B": "这不是最优选项，因为虽然使用了DynamoDB和Lambda，但DynamoDB主要用于事务性数据，而不是大规模分析和可视化。",
      "C": "这是最优选项之一，因为它涉及使用AWS Glue和Athena来编目和查询数据，这对于分析非常有用。",
      "D": "这不是最优选项，因为它涉及DynamoDB流，这对于实时处理有用，但不是最适合长期存储和分析的选择。",
      "E": "这是最优选项之一，因为它涉及使用QuickSight来可视化分析结果，这是满足需求的关键部分。",
      "F": "这不是最优选项，因为它涉及CloudWatch仪表板，这虽然可以用于监控，但不如QuickSight在数据分析和可视化方面强大。"
    },
    "service": [
      "Amazon EventBridge",
      "AWS Lambda",
      "Amazon S3",
      "Amazon DynamoDB",
      "AWS Glue",
      "Amazon Athena",
      "Amazon QuickSight",
      "Amazon CloudWatch"
    ],
    "reason": "4.2"
  },
  {
    "no": 245,
    "question": "一家公司在公司的本地数据中心的本地设备上部署了一个应用程序。该公司使用 AWS Direct Connect 连接在数据中心和公司的 AWS 账户之间。在本地设备的初始设置和应用程序更新期间，应用程序需要从 Amazon Elastic File System (Amazon EFS) 文件系统检索配置文件。所有来自本地设备到 Amazon EFS 的流量必须保持私密和加密。本地设备必须遵循 AWS 访问的最小权限原则。公司的 DevOps 团队需要能够撤销单个设备的访问权限，而不影响其他设备的访问权限。哪两个步骤的组合将满足这些要求？",
    "choose": 2,
    "options": {
      "A": "为每个设备创建一个具有访问密钥和密钥的 IAM 用户。将 AmazonElasticFileSystemFullAccess 策略附加到所有 IAM 用户。在本地设备上配置 AWS CLI 以使用 IAM 用户的访问密钥和密钥。",
      "B": "为每个本地设备在 AWS 私有证书颁发机构生成证书。在 IAM Roles Anywhere 中创建一个引用 AWS 私有 CA 的信任锚。创建一个信任 IAM Roles Anywhere 的 IAM 角色。将 AmazonElasticFileSystemClientReadWriteAccess 附加到该角色。为 IAM 角色创建一个 IAM Roles Anywhere 配置文件。在本地设备上配置 AWS CLI 以使用 aws_signing_helper 命令获取凭证。",
      "C": "为所有设备创建一个具有访问密钥和密钥的 IAM 用户。将 AmazonElasticFileSystemClientReadWriteAccess 策略附加到 IAM 用户。在本地设备上配置 AWS CLI 以使用 IAM 用户的访问密钥和密钥。",
      "D": "使用 amazon-efs-utils 包来挂载 EFS 文件系统。",
      "E": "使用原生 Linux NFS 客户端来挂载 EFS 文件系统。"
    },
    "best": ["B", "D"],
    "analysis": {
      "A": "这个选项不是最佳选择，因为它为每个设备创建单独的 IAM 用户，这可能导致管理复杂性，并且不符合最小权限原则。",
      "B": "这是最佳选择之一，因为它使用 IAM Roles Anywhere 和 AWS 私有 CA 来管理设备的访问权限，这样可以更灵活地控制每个设备的权限，并且可以轻松撤销单个设备的访问权限。",
      "C": "这个选项不是最佳选择，因为它使用单个 IAM 用户为所有设备提供访问权限，这不符合最小权限原则，并且难以撤销单个设备的访问权限。",
      "D": "这是最佳选择之一，因为使用 amazon-efs-utils 可以安全地挂载 EFS 文件系统，并且支持加密，符合题目要求。",
      "E": "这个选项不是最佳选择，因为虽然使用 Linux NFS 客户端可以挂载 EFS 文件系统，但它不提供与 amazon-efs-utils 相同的安全性和加密功能。"
    },
    "service": [
      "AWS Direct Connect",
      "Amazon Elastic File System",
      "IAM",
      "AWS CLI",
      "AWS Private Certificate Authority",
      "IAM Roles Anywhere",
      "amazon-efs-utils"
    ],
    "reason": "4.1"
  },
  {
    "no": 241,
    "question": "一家公司有一个应用程序，该应用程序将包含个人身份信息（PII）的数据存储在Amazon S3存储桶中。所有数据都使用AWS密钥管理服务（AWS KMS）客户管理的密钥进行加密。所有AWS资源都是从AWS CloudFormation模板部署的。一位DevOps工程师需要在不同的AWS账户中为该应用程序设置一个开发环境。开发环境的S3存储桶中的数据需要每周从生产环境的S3存储桶更新一次。公司必须在未匿名化PII的情况下不得将PII从生产环境移动。每个环境中的数据必须使用不同的KMS客户管理密钥进行加密。DevOps工程师应采取哪些步骤组合来满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "在生产账户的S3存储桶上激活Amazon Macie。创建一个AWS Step Functions状态机来启动一个发现作业并在将文件复制到开发账户的S3存储桶之前删除所有PII。给状态机任务解密生产账户中的KMS密钥的权限。给状态机任务加密开发账户中的KMS密钥的权限。",
      "B": "在生产S3存储桶和开发S3存储桶之间设置S3复制。在开发S3存储桶上激活Amazon Macie。创建一个AWS Step Functions状态机来启动一个发现作业并在文件被复制到开发S3存储桶时删除所有PII。给状态机任务在开发账户中的KMS密钥上的加密和解密权限。",
      "C": "设置一个S3批处理操作作业，将文件从生产S3存储桶复制到开发S3存储桶。在开发账户中，配置一个AWS Lambda函数来删除所有PII。配置S3对象Lambda以使用Lambda函数进行S3 GET请求。给Lambda函数的IAM角色在开发账户中的KMS密钥上的加密和解密权限。",
      "D": "在开发账户中从CloudFormation模板创建一个开发环境。安排一个Amazon EventBridge规则每周启动一次AWS Step Functions状态机。",
      "E": "在开发账户中从CloudFormation模板创建一个开发环境。安排一个Amazon EC2实例上的cron作业每周运行一次以启动S3批处理操作作业。"
    },
    "best": ["A", "C"],
    "analysis": {
      "A": "这是最佳选项之一，因为它涉及使用Amazon Macie来发现和红色处理PII，然后使用AWS Step Functions来自动化数据的复制和加密/解密过程，确保在不同的环境中使用不同的KMS密钥。",
      "B": "这个选项不是最佳的，因为它在数据复制到开发环境之后才进行PII的处理，这可能导致PII暴露。",
      "C": "这也是一个最佳选项，因为它使用Lambda和S3对象Lambda来处理PII，确保数据在离开生产环境之前就已经被处理，同时也确保了使用不同的KMS密钥。",
      "D": "这个选项不涉及PII的处理，只是简单地设置了环境和定时任务，没有满足题目的要求。",
      "E": "这个选项同样没有涉及PII的处理，只是设置了环境和定时任务，没有满足题目的要求。"
    },
    "service": [
      "Amazon S3",
      "AWS Key Management Service",
      "AWS CloudFormation",
      "Amazon Macie",
      "AWS Step Functions",
      "AWS Lambda",
      "S3 Object Lambda",
      "Amazon EventBridge",
      "Amazon EC2"
    ],
    "reason": "2.3"
  },
  {
    "no": 247,
    "question": "一家公司使用 AWS Organizations 管理其 AWS 账户。公司的 DevOps 团队开发了一个 AWS Lambda 函数，该函数调用 Organizations API 创建新的 AWS 账户。Lambda 函数在组织的管理账户中运行。DevOps 团队需要将 Lambda 函数从管理账户移动到一个专用的 AWS 账户。DevOps 团队必须确保 Lambda 函数在部署到新账户之前只能在 Organizations 中创建新的 AWS 账户。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在管理账户中，创建一个具有在 Organizations 中创建新账户所需权限的新 IAM 角色。允许新 AWS 账户中的 Lambda 执行角色扮演该角色。更新 Lambda 函数代码以在创建新 AWS 账户时扮演该角色。更新 Lambda 执行角色以确保它有权限扮演新角色。",
      "B": "在管理账户中，开启 Organizations 的委派管理。创建一个新的委派策略，授予新 AWS 账户在 Organizations 中创建新 AWS 账户的权限。确保 Lambda 执行角色具有 organizations:CreateAccount 权限。",
      "C": "在管理账户中，创建一个具有在 Organizations 中创建新账户所需权限的新 IAM 角色。允许 Lambda 服务主体扮演该角色。更新 Lambda 函数代码以在创建新 AWS 账户时扮演该角色。更新 Lambda 执行角色以确保它有权限扮演新角色。",
      "D": "在管理账户中，启用 AWS Control Tower。开启 AWS Control Tower 的委派管理。创建一个资源策略，允许新 AWS 账户在 AWS Control Tower 中创建新的 AWS 账户。更新 Lambda 函数代码以在新 AWS 账户中使用 AWS Control Tower API。确保 Lambda 执行角色具有 controltower:CreateManagedAccount 权限。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它通过创建一个新的 IAM 角色并允许新账户的 Lambda 执行角色扮演该角色，确保了权限的正确委派和限制。这样可以确保 Lambda 函数只能在 Organizations 中创建新账户。",
      "B": "这个选项不是最佳选项，因为它提到了开启 Organizations 的委派管理，但没有详细说明如何限制 Lambda 函数只能创建账户，可能导致权限过于宽泛。",
      "C": "这个选项不是最佳选项，因为它提到允许 Lambda 服务主体扮演角色，这可能导致权限不仅限于一个特定的 Lambda 函数，而是所有使用该服务主体的 Lambda 函数都能扮演该角色，增加了安全风险。",
      "D": "这个选项不是最佳选项，因为它涉及到使用 AWS Control Tower，这是一个更广泛的服务管理工具，不专门针对在 Organizations 中创建账户的需求，可能导致不必要的复杂性和成本。"
    },
    "service": ["AWS Organizations", "AWS Lambda", "IAM", "AWS Control Tower"],
    "reason": "2.2"
  },
  {
    "no": 249,
    "question": "一家公司为其 RDS DB 实例配置了 Amazon RDS 存储自动扩展。DevOps 团队需要在 Amazon CloudWatch 仪表板上可视化自动扩展事件。哪种解决方案能满足这一需求？",
    "choose": 1,
    "options": {
      "A": "创建一个 Amazon EventBridge 规则，该规则对 RDS 存储自动扩展事件作出反应。创建一个 AWS Lambda 函数，发布一个 CloudWatch 自定义指标。配置 EventBridge 规则以调用 Lambda 函数。使用 CloudWatch 仪表板可视化自定义指标。",
      "B": "使用 AWS CloudTrail 创建一个跟踪，配置管理事件。配置跟踪以将管理事件发送到 Amazon CloudWatch 日志。在 CloudWatch 日志中创建一个指标过滤器以匹配 RDS 存储自动扩展事件。使用 CloudWatch 仪表板可视化指标过滤器。",
      "C": "创建一个 Amazon EventBridge 规则，该规则对 RDS 存储自动扩展事件作出反应。创建一个 CloudWatch 警报。配置 EventBridge 规则以更改 CloudWatch 警报的状态。使用 CloudWatch 仪表板可视化警报状态。",
      "D": "使用 AWS CloudTrail 创建一个跟踪，配置数据事件。配置跟踪以将数据事件发送到 Amazon CloudWatch 日志。在 CloudWatch 日志中创建一个指标过滤器以匹配 RDS 存储自动扩展事件。使用 CloudWatch 仪表板可视化指标过滤器。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用 EventBridge 规则直接响应 RDS 存储自动扩展事件，并通过 Lambda 函数创建自定义指标，然后在 CloudWatch 仪表板上进行可视化，这种方式直接且高效。",
      "B": "此选项不是最佳选项，因为它涉及到 CloudTrail 和 CloudWatch 日志，这增加了复杂性，并且管理事件通常不包括 RDS 存储自动扩展事件。",
      "C": "此选项不是最佳选项，因为它使用 CloudWatch 警报来反映事件状态，这不如直接在仪表板上显示自定义指标直观。",
      "D": "此选项不是最佳选项，因为虽然它使用了 CloudTrail 来捕获数据事件，但数据事件通常用于捕获对象级别的操作，如 S3 桶操作，而不是 RDS 存储自动扩展事件。"
    },
    "service": [
      "Amazon RDS",
      "Amazon CloudWatch",
      "AWS Lambda",
      "Amazon EventBridge",
      "AWS CloudTrail"
    ],
    "reason": "4.1"
  },
  {
    "no": 248,
    "question": "一家公司在单一 AWS 区域部署了一个应用程序。应用程序后端使用 Amazon DynamoDB 表和 Amazon S3 存储桶。公司希望在第二个区域部署应用程序。公司必须确保 DynamoDB 表和 S3 存储桶中的数据在两个区域中持久存在。数据还必须立即在区域间传播。哪种解决方案在最大操作效率下满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在主区域的 S3 存储桶和次区域的 S3 存储桶之间实施双向 S3 存储桶复制。将 DynamoDB 表转换为全局表。将次区域设置为附加区域。",
      "B": "在主区域和次区域的所有 S3 存储桶之间实施 S3 批量操作复制作业。将 DynamoDB 表转换为全局表。将次区域设置为附加区域。",
      "C": "在主区域的 S3 存储桶和次区域的 S3 存储桶之间实施双向 S3 存储桶复制。在两个区域的 DynamoDB 表上启用 DynamoDB 流。在每个区域中创建一个订阅 DynamoDB 流的 AWS Lambda 函数。配置 Lambda 函数将新记录复制到另一个区域的 DynamoDB 表中。",
      "D": "在主区域和次区域的所有 S3 存储桶之间实施 S3 批量操作复制作业。在两个区域的 DynamoDB 表上启用 DynamoDB 流。在每个区域中创建一个订阅 DynamoDB 流的 AWS Lambda 函数。配置 Lambda 函数将新记录复制到另一个区域的 DynamoDB 表中。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用了 DynamoDB 全局表和 S3 存储桶的双向复制，这两种方法都是 AWS 推荐的用于数据复制和立即传播的解决方案，且操作效率高。",
      "B": "此选项不是最佳选择，因为 S3 批量操作复制作业可能不会立即传播更新，且操作效率较低。",
      "C": "此选项不是最佳选择，因为虽然使用了双向 S3 存储桶复制，但是通过 Lambda 函数手动处理 DynamoDB 数据的复制增加了复杂性和潜在的延迟。",
      "D": "此选项不是最佳选择，因为它使用了 S3 批量操作复制作业和 Lambda 函数处理 DynamoDB 数据，这增加了操作复杂性和潜在的延迟。"
    },
    "service": ["Amazon DynamoDB", "Amazon S3", "AWS Lambda"],
    "reason": "3.1"
  },
  {
    "no": 254,
    "question": "一家公司给其员工提供了有限的 AWS 权限。DevOps 工程师有能力承担管理员角色。为了跟踪目的，安全团队希望在管理员角色被承担时接收到近实时的通知。应如何实现这一目标？",
    "choose": 1,
    "options": {
      "A": "配置 AWS Config 以将日志发布到 Amazon S3 存储桶。使用 Amazon Athena 查询日志，并在管理员角色被承担时向安全团队发送通知。",
      "B": "配置 Amazon GuardDuty 以监控管理员角色被承担的情况，并向安全团队发送通知。",
      "C": "创建一个 Amazon EventBridge 事件规则，使用 AWS 管理控制台登录事件的事件模式，如果管理员角色被承担，则向 Amazon SNS 主题发布消息。",
      "D": "创建一个 Amazon EventBridge 事件规则，使用 AWS API 调用的 AWS CloudTrail 事件模式来调用一个 AWS Lambda 函数，该函数如果管理员角色被承担，则向 Amazon SNS 主题发布消息。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它涉及到使用 Athena 查询日志，这可能不会提供足够快的响应时间来满足近实时的通知需求。",
      "B": "此选项不是最佳选择，因为 GuardDuty 主要用于威胁检测和持续监控，而不是用于监控特定的 IAM 角色承担事件。",
      "C": "此选项不是最佳选择，因为它没有使用 AWS CloudTrail 来捕获具体的 API 调用事件，这是跟踪角色承担的关键。",
      "D": "这是最佳选项，因为它使用了 AWS CloudTrail 来监控特定的 API 调用事件，并通过 Lambda 函数和 SNS 主题实现了快速响应和通知。"
    },
    "service": [
      "AWS Config",
      "Amazon S3",
      "Amazon Athena",
      "Amazon GuardDuty",
      "Amazon EventBridge",
      "Amazon SNS",
      "AWS CloudTrail",
      "AWS Lambda"
    ],
    "reason": "4.3"
  },
  {
    "no": 251,
    "question": "一位 DevOps 工程师需要实施一种解决方案，在一个 AWS 账户中的所有 Amazon EC2 实例上安装防病毒软件。EC2 实例运行最新版本的 Amazon Linux。该解决方案必须检测所有实例，并且如果软件不存在，则使用 AWS Systems Manager 文档来安装软件。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "在 Systems Manager State Manager 中创建一个关联。目标是所有管理的节点。在关联中包括软件。配置关联以使用 Systems Manager 文档。",
      "B": "设置 AWS Config 以记录账户中的所有资源。创建一个 AWS Config 自定义规则以确定所有 EC2 实例上是否安装了软件。为不合规的 EC2 实例配置使用 Systems Manager 文档的自动修正操作。",
      "C": "激活 Amazon Inspector 上的 Amazon EC2 扫描，以确定所有 EC2 实例上是否安装了软件。将发现结果与 Systems Manager 文档关联。",
      "D": "创建一个 Amazon EventBridge 规则，使用 AWS CloudTrail 检测 RunInstances API 调用。在 Systems Manager Inventory 中配置库存收集，以确定 EC2 实例上是否安装了软件。将 Systems Manager 库存与 Systems Manager 文档关联。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它直接使用 Systems Manager State Manager 创建关联，自动检测并管理 EC2 实例上的软件安装。这种方法简单有效，符合题目要求。",
      "B": "此选项不是最佳选择，因为它依赖于 AWS Config 和自定义规则来检测软件安装，这增加了复杂性，并且自动修正操作可能不如直接使用 Systems Manager State Manager 那样直接有效。",
      "C": "此选项不是最佳选择，因为它依赖于 Amazon Inspector 来检测软件安装，这不是最直接或高效的方法来管理 EC2 实例上的软件安装。",
      "D": "此选项不是最佳选择，因为它使用了 EventBridge 和 CloudTrail 来检测 API 调用，并依赖于 Systems Manager Inventory 来管理软件安装，这比直接使用 Systems Manager State Manager 更复杂。"
    },
    "service": [
      "AWS Systems Manager",
      "AWS Config",
      "Amazon Inspector",
      "Amazon EventBridge",
      "AWS CloudTrail"
    ],
    "reason": "2.3"
  },
  {
    "no": 252,
    "question": "一家公司需要提高其生产环境中运行的容器映像的安全性。该公司希望将操作系统扫描和编程语言包漏洞扫描集成到其 CI/CD 管道中的容器中。CI/CD 管道是一个 AWS CodePipeline 管道，包括一个 AWS CodeBuild 构建项目、AWS CodeDeploy 操作和一个 Amazon Elastic Container Registry (Amazon ECR) 仓库。一位 DevOps 工程师需要将映像扫描添加到 CI/CD 管道中。CI/CD 管道必须只部署没有 CRITICAL 和 HIGH 发现的映像到生产环境中。哪两个步骤的组合将满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "使用 Amazon ECR 基本扫描。",
      "B": "使用 Amazon ECR 增强扫描。",
      "C": "配置 Amazon ECR 在映像扫描返回 CRITICAL 或 HIGH 发现时向 CI/CD 管道提交拒绝状态。",
      "D": "配置一个 Amazon EventBridge 规则在映像扫描完成时调用一个 AWS Lambda 函数。配置 Lambda 函数以消费 Amazon Inspector 扫描状态，并向 CI/CD 管道提交批准或拒绝状态。",
      "E": "配置一个 Amazon EventBridge 规则在映像扫描完成时调用一个 AWS Lambda 函数。配置 Lambda 函数以消费 Clair 扫描状态，并向 CI/CD 管道提交批准或拒绝状态。"
    },
    "best": ["B", "C"],
    "analysis": {
      "A": "基本扫描可能不足以检测所有关键和高级别的漏洞。",
      "B": "增强扫描提供了更深入的安全检查，能够识别 CRITICAL 和 HIGH 级别的漏洞。",
      "C": "配置 Amazon ECR 提交拒绝状态确保只有通过安全检查的映像才能部署到生产环境。",
      "D": "虽然这个选项提供了一个自动化的响应机制，但它依赖于 Amazon Inspector，而不是直接与 Amazon ECR 集成。",
      "E": "Clair 是一个开源项目，而不是 AWS 服务，这可能导致集成复杂和支持问题。"
    },
    "service": [
      "AWS CodePipeline",
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "Amazon ECR",
      "Amazon EventBridge",
      "AWS Lambda",
      "Amazon Inspector"
    ],
    "reason": "1.2"
  },
  {
    "no": 250,
    "question": "一家公司使用容器来部署其应用程序。公司发现一些容器映像缺少所需的安全配置。一位 DevOps 工程师需要实施一个解决方案来创建一个标准的基础映像，并且该解决方案必须每周将基础映像发布到美国西部2区域、美国东部2区域和欧洲中部1区域。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 EC2 Image Builder 管道，使用容器配方来构建映像。配置管道将映像分发到美国西部2区域的 Amazon Elastic Container Registry (Amazon ECR) 仓库。配置从美国西部2区域到美国东部2区域的 ECR 复制，以及从美国东部2区域到欧洲中部1区域的 ECR 复制。配置管道每周运行。",
      "B": "创建一个 AWS CodePipeline 管道，使用 AWS CodeBuild 项目来构建映像。使用 AWS CodeDeploy 将映像发布到美国西部2区域的 Amazon Elastic Container Registry (Amazon ECR) 仓库。配置从美国西部2区域到美国东部2区域的 ECR 复制，以及从美国东部2区域到欧洲中部1区域的 ECR 复制。配置管道每周运行。",
      "C": "创建一个 EC2 Image Builder 管道，使用容器配方来构建映像。配置管道将映像分发到所有三个区域的 Amazon Elastic Container Registry (Amazon ECR) 仓库。配置管道每周运行。",
      "D": "创建一个 AWS CodePipeline 管道，使用 AWS CodeBuild 项目来构建映像。使用 AWS CodeDeploy 将映像发布到所有三个区域的 Amazon Elastic Container Registry (Amazon ECR) 仓库。配置管道每周运行。"
    },
    "best": ["C"],
    "analysis": {
      "A": "虽然这个选项使用了 EC2 Image Builder，它只在一个区域创建了 ECR 仓库并配置了复制。这可能会导致延迟和复制错误，不是最优解。",
      "B": "这个选项使用了 AWS CodePipeline 和 CodeBuild，但同样只在一个区域创建了 ECR 仓库并配置了复制，存在同样的问题。",
      "C": "这个选项直接在所有目标区域创建 ECR 仓库，避免了复制的需要，确保了映像的及时更新和一致性，是最优解。",
      "D": "虽然这个选项在所有区域创建了 ECR 仓库，但使用了 CodePipeline 和 CodeDeploy，这在处理容器映像时不如 EC2 Image Builder 高效和专用。"
    },
    "service": [
      "EC2 Image Builder",
      "AWS CodePipeline",
      "AWS CodeBuild",
      "AWS CodeDeploy",
      "Amazon Elastic Container Registry"
    ],
    "reason": "1.4"
  },
  {
    "no": 253,
    "question": "一家公司的 DevOps 团队管理着一组在 AWS Organizations 中的 AWS 账户。公司需要一个解决方案，确保所有 Amazon EC2 实例使用 DevOps 团队管理的批准的 AMI。该解决方案还必须纠正未经批准的 AMI 的使用。各个账户管理员不能移除使用批准 AMI 的限制。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 AWS CloudFormation StackSets 向每个账户部署一个 Amazon EventBridge 规则。配置规则以响应 Amazon EC2 的 AWS CloudTrail 事件，并发送通知到一个 Amazon Simple Notification Service (Amazon SNS) 主题。订阅 DevOps 团队到 SNS 主题。",
      "B": "使用 AWS CloudFormation StackSets 向每个账户部署 approved-amis-by-id AWS Config 管理规则。配置规则使用批准的 AMI 列表。配置规则运行 AWS-StopEC2Instance AWS Systems Manager Automation 运行簿以处理不合规的 EC2 实例。",
      "C": "创建一个 AWS Lambda 函数来处理 Amazon EC2 的 AWS CloudTrail 事件。配置 Lambda 函数发送通知到一个 Amazon Simple Notification Service (Amazon SNS) 主题。订阅 DevOps 团队到 SNS 主题。在组织中的每个账户部署 Lambda 函数。在每个账户中创建一个 Amazon EventBridge 规则。配置 EventBridge 规则以响应 Amazon EC2 的 AWS CloudTrail 事件并调用 Lambda 函数。",
      "D": "在组织中启用 AWS Config。创建一个使用 approved-amis-by-id AWS Config 管理规则的合规性包，该规则包含批准的 AMI 列表。在组织中部署合规性包。配置规则运行 AWS-StopEC2Instance AWS Systems Manager Automation 运行簿以处理不合规的 EC2 实例。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项仅提供通知功能，不包括自动纠正未批准的 AMI 使用。",
      "B": "此选项提供了自动纠正功能，但没有在组织级别统一管理。",
      "C": "此选项虽然涉及 Lambda 和 EventBridge，但其复杂性较高，且没有提到在组织级别的统一管理。",
      "D": "此选项在组织级别启用 AWS Config，并使用合规性包来统一管理和自动纠正不合规的 EC2 实例，满足题目要求。"
    },
    "service": [
      "AWS Organizations",
      "Amazon EC2",
      "AWS CloudFormation",
      "Amazon EventBridge",
      "AWS CloudTrail",
      "Amazon SNS",
      "AWS Config",
      "AWS Systems Manager"
    ],
    "reason": "2.1"
  },
  {
    "no": 258,
    "question": "一家公司希望使用 AWS Systems Manager 文档来引导开发人员的物理笔记本电脑。引导代码存储在 GitHub 上。一位 DevOps 工程师已经创建了一个 Systems Manager 激活，安装了 Systems Manager 代理并在所有笔记本电脑上安装了激活 ID。接下来应该采取哪些步骤？",
    "choose": 1,
    "options": {
      "A": "配置 Systems Manager 文档以使用 AWS-RunShellScript 命令将文件从 GitHub 复制到 Amazon S3，然后使用 aws-downloadContent 插件，sourceType 为 S3。",
      "B": "配置 Systems Manager 文档以使用 aws-configurePackage 插件，执行安装操作并指向 Git 仓库。",
      "C": "配置 Systems Manager 文档以使用 aws-downloadContent 插件，sourceType 为 GitHub 并且 sourceInfo 包含仓库详细信息。",
      "D": "配置 Systems Manager 文档以使用 aws:softwareInventory 插件并从 Git 仓库运行脚本。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项不是最佳选择，因为它涉及将文件从 GitHub 复制到 S3，这增加了不必要的复杂性和步骤。",
      "B": "此选项不是最佳选择，因为 aws-configurePackage 插件主要用于安装和配置软件包，而不是直接从 Git 仓库下载内容。",
      "C": "这是最佳选择，因为 aws-downloadContent 插件可以直接从 GitHub 下载内容，这简化了流程并直接满足需求。",
      "D": "此选项不是最佳选择，因为 aws:softwareInventory 插件用于收集软件库存信息，而不是执行脚本或管理内容下载。"
    },
    "service": ["AWS Systems Manager", "GitHub", "Amazon S3"],
    "reason": "2.3"
  },
  {
    "no": 256,
    "question": "一名开发者正在使用 AWS 无服务器应用模型 (AWS SAM) 创建一个 AWS Lambda 函数的原型。AWS SAM 模板包含一个 AWS::Serverless::Function 资源，该资源的 CodeUri 属性指向一个 Amazon S3 位置。开发者希望在创建 CI/CD 管道之前确定正确的部署命令。开发者创建了一个名为 package.zip 的 Lambda 函数代码的存档，并将 .zip 文件存档上传到 CodeUri 属性指定的 S3 位置。开发者运行 sam deploy 命令并部署了 Lambda 函数。开发者更新了 Lambda 函数代码，并使用相同的步骤部署了新版本的 Lambda 函数。sam deploy 命令失败并返回了一个错误，没有变化可部署。哪些解决方案将部署新版本？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "使用 aws cloudformation update-stack 命令而不是 sam deploy 命令。",
      "B": "使用 aws cloudformation update-stack-instances 命令而不是 sam deploy 命令。",
      "C": "更新 CodeUri 属性以引用本地应用程序代码文件夹。使用 sam deploy 命令。",
      "D": "更新 CodeUri 属性以引用本地应用程序代码文件夹。使用 aws cloudformation create-change-set 命令和 aws cloudformation execute-change-set 命令。",
      "E": "更新 CodeUri 属性以引用本地应用程序代码文件夹。使用 aws cloudformation package 命令和 aws cloudformation deploy 命令。"
    },
    "best": ["C", "E"],
    "analysis": {
      "A": "虽然 aws cloudformation update-stack 命令可以用于更新 CloudFormation 栈，但它不适用于 AWS SAM 模型的部署，因为它不处理 SAM 模板的转换。",
      "B": "aws cloudformation update-stack-instances 命令用于更新 CloudFormation StackSet 实例，与部署单个 Lambda 函数无关。",
      "C": "更新 CodeUri 属性以引用本地代码文件夹，并使用 sam deploy 命令，可以确保 AWS SAM 能够检测到代码的变化并重新部署，这是一个有效的解决方案。",
      "D": "虽然使用 aws cloudformation create-change-set 和 execute-change-set 命令可以部署更改，但这种方法比直接使用 SAM 或 CloudFormation 的部署命令更复杂，不是最优选择。",
      "E": "更新 CodeUri 属性以引用本地代码文件夹，并使用 aws cloudformation package 和 deploy 命令，可以确保代码的变化被打包并部署，这是一个有效的解决方案。"
    },
    "service": ["AWS SAM", "AWS Lambda", "Amazon S3", "AWS CloudFormation"],
    "reason": "2.1"
  },
  {
    "no": 255,
    "question": "一家公司需要为其数据和应用程序的故障转移和灾难恢复制定策略。该应用程序使用 MySQL 数据库和 Amazon EC2 实例。公司要求其数据和应用程序在任何时候的最大 RPO 为 2 小时，最大 RTO 为 10 分钟。哪种部署策略组合能满足这些要求？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "在多个 AWS 区域创建一个 Amazon Aurora 单 AZ 集群作为数据存储。在灾难发生时使用 Aurora 的自动恢复功能。",
      "B": "在两个 AWS 区域创建一个 Amazon Aurora 全球数据库作为数据存储。在发生故障时，将次要区域提升为主要区域以供应用程序使用。更新应用程序以使用次要区域中的 Aurora 集群端点。",
      "C": "在多个 AWS 区域创建一个 Amazon Aurora 集群作为数据存储。使用网络负载均衡器来平衡不同区域的数据库流量。",
      "D": "在两个 AWS 区域设置应用程序。使用 Amazon Route 53 故障转移路由，指向两个区域中的应用程序负载均衡器。在每个区域使用健康检查和自动扩展组。",
      "E": "在两个 AWS 区域设置应用程序。配置 AWS Global Accelerator 指向两个区域中的应用程序负载均衡器（ALB）。将两个 ALB 添加到单个端点组。在每个区域使用健康检查和自动扩展组。"
    },
    "best": ["B", "D"],
    "analysis": {
      "A": "虽然 Amazon Aurora 的自动恢复功能提供了一定的故障恢复能力，但单 AZ 部署限制了其跨区域故障转移的能力，不符合最大 RTO 为 10 分钟的要求。",
      "B": "Amazon Aurora 全球数据库支持跨区域数据复制和快速故障转移，可以在故障时快速将次要区域提升为主要区域，满足 RPO 和 RTO 的要求。",
      "C": "虽然使用网络负载均衡器可以平衡流量，但它不提供数据复制或快速故障转移功能，因此不符合 RPO 和 RTO 的要求。",
      "D": "使用 Amazon Route 53 故障转移路由和应用程序负载均衡器可以实现快速的故障检测和故障转移，配合健康检查和自动扩展组，可以满足 RPO 和 RTO 的要求。",
      "E": "虽然 AWS Global Accelerator 提供了全球网络优化，但其主要优势在于性能提升而非故障恢复，因此不是最佳选项。"
    },
    "service": [
      "Amazon Aurora",
      "Amazon EC2",
      "Amazon Route 53",
      "AWS Global Accelerator",
      "Application Load Balancer",
      "Network Load Balancer"
    ],
    "reason": "3.3"
  },
  {
    "no": 263,
    "question": "一家公司将应用程序部署到 Amazon EC2 实例上。该应用程序运行 Amazon Linux 2 并使用 AWS CodeDeploy。应用程序的代码库具有以下文件结构：appspec.yml 文件在 files 部分的内容如下：对于 config.txt 文件的部署，结果将是什么？",
    "choose": 1,
    "options": {
      "A": "config.txt 文件将仅部署到 /var/www/html/config/config.txt。",
      "B": "config.txt 文件将部署到 /usr/local/src/config.txt 和 /var/www/html/config/config.txt。",
      "C": "config.txt 文件将仅部署到 /usr/local/src/config.txt。",
      "D": "config.txt 文件将部署到 /usr/local/src/config.txt 和 /var/www/html/application/web/config.txt。"
    },
    "best": ["B"],
    "analysis": {
      "A": "这个选项不正确，因为它只提到了一个目标路径，而根据 appspec.yml 文件的配置，config.txt 文件应该部署到两个路径。",
      "B": "这是正确的选项，因为根据 appspec.yml 文件的配置，config.txt 文件应该部署到 /usr/local/src/config.txt 和 /var/www/html/config/config.txt 两个路径。",
      "C": "这个选项不正确，因为它只提到了一个目标路径，而根据 appspec.yml 文件的配置，config.txt 文件应该部署到两个路径。",
      "D": "这个选项不正确，因为它提到了一个错误的目标路径 /var/www/html/application/web/config.txt，这个路径并不符合 appspec.yml 文件的配置。"
    },
    "service": ["AWS CodeDeploy", "Amazon EC2"],
    "reason": "1.4"
  },
  {
    "no": 260,
    "question": "一家公司正在使用 AWS CloudFormation 开发 Web 应用程序的基础设施。数据库工程团队在一个 CloudFormation 模板中维护数据库资源，而软件开发团队在另一个独立的 CloudFormation 模板中维护 Web 应用程序资源。随着应用程序范围的扩大，软件开发团队需要使用数据库工程团队维护的资源。然而，两个团队都有自己的审查和生命周期管理流程，他们希望保持这些流程。两个团队还需要资源级别的变更集审查。软件开发团队希望使用他们的 CI/CD 管道部署对这个模板的更改。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "从数据库 CloudFormation 模板创建一个堆栈导出，并将这些引用导入到 Web 应用程序 CloudFormation 模板中。",
      "B": "创建一个 CloudFormation 嵌套堆栈，使跨堆栈资源引用和参数在两个堆栈中可用。",
      "C": "创建一个 CloudFormation 堆栈集，使跨堆栈资源引用和参数在两个堆栈中可用。",
      "D": "在 Web 应用程序 CloudFormation 模板中创建输入参数，并从数据库堆栈传递资源名称和 ID。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它允许数据库工程团队和软件开发团队维护他们的独立模板，同时通过导出和导入机制共享必要的资源，这符合两个团队希望保持独立审查和生命周期管理流程的要求。",
      "B": "虽然嵌套堆栈允许资源共享，但它需要将一个堆栈作为另一个堆栈的一部分，这可能不符合两个团队希望保持独立管理的需求。",
      "C": "堆栈集主要用于在多个账户或区域中部署相同的资源，不适用于这种需要保持模板独立的场景。",
      "D": "这种方法需要软件开发团队知道具体的资源名称和 ID，这增加了管理复杂性，并可能与数据库团队的资源更新导致的资源名称和 ID 变化不同步。"
    },
    "service": ["AWS CloudFormation", "CI/CD"],
    "reason": "2.1"
  },
  {
    "no": 261,
    "question": "一家公司在 AWS Organizations 中有一个组织。一名 DevOps 工程师需要维护属于组织中不同 OU 的多个 AWS 账户。账户中的所有资源，包括 IAM 策略和 Amazon S3 策略，都是通过 AWS CloudFormation 部署的。所有模板和代码都维护在 AWS CodeCommit 仓库中。最近，一些开发人员无法从组织中的某些账户访问 S3 存储桶。以下策略附加到 S3 存储桶上：DevOps 工程师应该做什么来解决这个访问问题？",
    "choose": 1,
    "options": {
      "A": "修改 S3 存储桶策略。关闭 S3 存储桶上的 S3 Block Public Access 设置。在 S3 策略中添加 aws:SourceAccount 条件。添加所有遇到问题的开发人员的 AWS 账户 ID。",
      "B": "验证没有 IAM 权限边界拒绝开发人员访问 S3 存储桶。对 IAM 权限边界进行必要的更改。在遇到问题的各个开发人员账户中使用 AWS Config 记录器撤销阻止访问的任何更改。将修复提交回 CodeCommit 仓库。通过 CloudFormation 调用部署以应用更改。",
      "C": "配置一个 SCP 阻止任何人修改开发者 OU 中的 IAM 资源。在 S3 策略中添加 aws:SourceAccount 条件。添加所有遇到问题的开发人员的 AWS 账户 ID。将修复提交回 CodeCommit 仓库。通过 CloudFormation 调用部署以应用更改。",
      "D": "确保没有 SCP 阻止开发人员访问 S3 存储桶。确保没有 IAM 策略权限边界拒绝开发人员 IAM 用户的访问。在 CodeCommit 仓库中对 SCP 和 IAM 策略权限边界进行必要的更改。通过 CloudFormation 调用部署以应用更改。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项不是最佳选择，因为仅添加 aws:SourceAccount 条件和关闭 S3 Block Public Access 设置可能不足以解决问题，如果存在更广泛的权限或策略问题。",
      "B": "此选项不是最佳选择，因为它侧重于使用 AWS Config 撤销更改，这可能不是解决策略问题的最直接或有效方法。",
      "C": "此选项不是最佳选择，因为它提到了配置 SCP 阻止修改 IAM 资源，这并不直接解决访问 S3 存储桶的问题。",
      "D": "这是最佳选项，因为它直接解决了可能阻止访问 S3 存储桶的 SCP 和 IAM 策略权限边界问题，并通过 CloudFormation 实现更改，确保了一致性和可追溯性。"
    },
    "service": [
      "AWS Organizations",
      "IAM",
      "Amazon S3",
      "AWS CloudFormation",
      "AWS CodeCommit",
      "AWS Config",
      "SCP"
    ],
    "reason": "2.2"
  },
  {
    "no": 257,
    "question": "一家公司在 AWS App Runner 中运行其容器工作负载。一名 DevOps 工程师管理公司的容器存储库，该存储库位于 Amazon Elastic Container Registry (Amazon ECR) 中。DevOps 工程师必须实施一个解决方案，以持续监控容器存储库。当解决方案检测到操作系统漏洞或语言包漏洞时，该解决方案必须创建一个新的容器映像。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "使用 EC2 Image Builder 创建容器映像管道。使用 Amazon ECR 作为目标存储库。在 ECR 存储库上开启增强扫描。创建一个 Amazon EventBridge 规则来捕获 Inspector? 发现事件。使用该事件来调用映像管道。重新上传容器到存储库。",
      "B": "使用 EC2 Image Builder 创建容器映像管道。使用 Amazon ECR 作为目标存储库。启用 Amazon GuardDuty Malware Protection 在容器工作负载上。创建一个 Amazon EventBridge 规则来捕获 GuardDuty 发现事件。使用该事件来调用映像管道。",
      "C": "创建一个 AWS CodeBuild 项目来创建容器映像。使用 Amazon ECR 作为目标存储库。在存储库上开启基本扫描。创建一个 Amazon EventBridge 规则来捕获 ECR 图像操作事件。使用该事件来调用 CodeBuild 项目。重新上传容器到存储库。",
      "D": "创建一个 AWS CodeBuild 项目来创建容器映像。使用 Amazon ECR 作为目标存储库。配置 AWS Systems Manager Compliance 来扫描所有管理节点。创建一个 Amazon EventBridge 规则来捕获配置合规状态变更事件。使用该事件来调用 CodeBuild 项目。"
    },
    "best": ["A"],
    "analysis": {
      "A": "这是最佳选项，因为它使用了 EC2 Image Builder 来创建容器映像管道，并且使用了 Amazon ECR 作为目标存储库。通过开启增强扫描和使用 Amazon EventBridge 规则来捕获 Inspector 发现事件，可以确保在检测到漏洞时自动创建新的容器映像。",
      "B": "此选项不是最佳选择，因为它使用了 GuardDuty Malware Protection，这主要用于恶意软件保护，而不是针对操作系统或语言包漏洞。",
      "C": "此选项不是最佳选择，因为它只开启了基本扫描，这可能不足以全面检测所有类型的漏洞。",
      "D": "此选项不是最佳选择，因为它侧重于使用 AWS Systems Manager Compliance 来扫描管理节点，而不是直接监控容器映像的漏洞。"
    },
    "service": [
      "AWS App Runner",
      "Amazon Elastic Container Registry",
      "EC2 Image Builder",
      "Amazon EventBridge",
      "AWS CodeBuild",
      "AWS Systems Manager"
    ],
    "reason": "1.1"
  },
  {
    "no": 259,
    "question": "一家公司的开发团队使用 AWS CloudFormation 部署其应用程序资源。团队必须使用 CloudFormation 对环境进行所有更改。团队不能使用 AWS 管理控制台或 AWS CLI 直接进行手动更改。团队使用开发者 IAM 角色访问环境。该角色配置了 AdministratorAccess 管理 IAM 策略。公司创建了一个新的 CloudFormationDeployment IAM 角色，并附加了以下策略：公司希望确保只有 CloudFormation 可以使用新角色。开发团队不能对部署的资源进行任何手动更改。哪种步骤组合将满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "移除 AdministratorAccess 策略。将 ReadOnlyAccess 管理 IAM 策略分配给开发者角色。指导开发者在部署新堆栈时使用 CloudFormationDeployment 角色作为 CloudFormation 服务角色。",
      "B": "更新 CloudFormationDeployment 角色的信任策略，允许开发者 IAM 角色扮演 CloudFormationDeployment 角色。",
      "C": "配置开发者 IAM 角色能够获取并传递 CloudFormationDeployment 角色，如果 iam:PassedToService 等于。配置 CloudFormationDeployment 角色允许所有 cloudformation 操作对所有资源。",
      "D": "更新 CloudFormationDeployment 角色的信任策略，允许 cloudformation.amazonaws.com AWS 主体执行 iam:AssumeRole 操作。",
      "E": "移除 AdministratorAccess 策略。将 ReadOnlyAccess 管理 IAM 策略分配给开发者角色。指导开发者在部署新堆栈时扮演 CloudFormationDeployment 角色。",
      "F": "为 CloudFormationDeployment 角色添加一个 IAM 策略，允许对所有资源执行 cloudformation:* 操作。添加一个策略，允许对 CloudFormationDeployment 角色的 ARN 执行 iam:PassRole 操作，如果 iam:PassedToService 等于 cloudformation.amazonaws.com。"
    },
    "best": ["A", "D", "F"],
    "analysis": {
      "A": "这是最优选项，因为它确保开发者只能通过 CloudFormation 以服务角色的方式部署资源，而不能直接修改。",
      "B": "这不是最优选项，因为它允许开发者直接扮演 CloudFormationDeployment 角色，可能绕过 CloudFormation 进行更改。",
      "C": "这不是最优选项，因为它的表述不完整且含糊，没有明确限制只有 CloudFormation 可以使用该角色。",
      "D": "这是最优选项，因为它确保只有 CloudFormation 服务可以扮演 CloudFormationDeployment 角色，符合题目要求。",
      "E": "这不是最优选项，因为它允许开发者直接扮演 CloudFormationDeployment 角色，可能绕过 CloudFormation 进行更改。",
      "F": "这是最优选项，因为它确保只有 CloudFormation 可以执行对所有资源的操作，并且只有在通过 CloudFormation 服务时才允许传递角色。"
    },
    "service": ["AWS CloudFormation", "IAM"],
    "reason": "2.1"
  },
  {
    "no": 264,
    "question": "一家公司已经建立了带有公共上游仓库的 AWS CodeArtifact 仓库。公司的开发团队从公司内部网络中的仓库消费开源依赖项。公司的安全团队最近在开发团队消费的包的最新版本中发现了一个关键漏洞。安全团队已经制作了一个修补版本来修复这个漏洞。公司需要阻止下载易受攻击的版本。公司还需要允许安全团队发布修补版本。哪两个步骤的组合将满足这些要求？（选择两个。）",
    "choose": 2,
    "options": {
      "A": "将受影响的 CodeArtifact 包版本的状态更新为未列出。",
      "B": "将受影响的 CodeArtifact 包版本的状态更新为已删除。",
      "C": "将受影响的 CodeArtifact 包版本的状态更新为已存档。",
      "D": "更新 CodeArtifact 包的原始控制设置以允许直接发布并阻止上游操作。",
      "E": "更新 CodeArtifact 包的原始控制设置以阻止直接发布并允许上游操作。"
    },
    "best": ["A", "D"],
    "analysis": {
      "A": "将包版本状态设置为未列出可以阻止新的客户端下载，但不影响已经下载的客户端，这是一个有效的步骤来阻止进一步的下载。",
      "B": "删除包版本会从仓库中完全移除该版本，这可能不是最佳选择，因为它可能影响到需要回滚到旧版本的情况。",
      "C": "存档包版本会使其不可用，这可能过于严格，因为它会阻止所有访问，包括可能需要的特定情况。",
      "D": "允许直接发布并阻止上游操作确保安全团队可以发布修补版本，同时阻止从上游仓库自动下载易受攻击的版本，这是一个必要的步骤。",
      "E": "阻止直接发布并允许上游操作与需求相反，因为需要允许安全团队发布修补版本。"
    },
    "service": ["AWS CodeArtifact"],
    "reason": "1.3"
  },
  {
    "no": 262,
    "question": "一家公司在 AWS Organizations 中拥有一个多账户环境的组织。一位 DevOps 工程师正在开发一个基于 AWS CodeArtifact 的策略，用于跨组织管理应用程序包。公司的每个应用程序团队都有自己在组织中的账户。每个应用程序团队还可以访问一个集中的共享服务账户，但权限有限。每个应用程序团队需要完全访问权限来下载、发布和授权其自己的包。一些常用的库包也需要与整个组织共享。哪种步骤组合可以在最小的管理开销下满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "在每个应用程序团队的账户中创建一个域。授予每个应用程序团队的账户对该团队域的完全读取和写入访问权限。",
      "B": "在共享服务账户中创建一个域。授予组织读取访问权限和创建存储库的权限。",
      "C": "在每个应用程序团队的账户中创建一个存储库。授予每个应用程序团队的账户对其自己的存储库的完全读取和写入访问权限。",
      "D": "在共享服务账户中创建一个存储库。授予组织对共享服务账户中的存储库的读取访问权限，并将该存储库设置为每个应用程序团队存储库的上游存储库。",
      "E": "对于需要共享包的团队，创建基于资源的策略，允许从其他应用程序团队的账户读取访问存储库。",
      "F": "将其他应用程序团队的存储库设置为上游存储库。"
    },
    "best": ["B", "D", "E"],
    "analysis": {
      "A": "创建多个域会增加管理复杂性，不符合最小管理开销的要求。",
      "B": "在共享服务账户中创建一个域，并授予整个组织读取和创建存储库的权限，可以简化管理并满足需求。",
      "C": "创建多个存储库会增加管理复杂性，不符合最小管理开销的要求。",
      "D": "在共享服务账户中创建一个存储库，并设置为上游存储库，可以有效地共享常用库包，同时简化管理。",
      "E": "创建基于资源的策略允许特定团队访问共享包，这是一种有效的共享方法，同时保持管理简单。",
      "F": "设置其他团队的存储库为上游存储库可能会导致权限和访问控制问题，增加管理复杂性。"
    },
    "service": ["AWS Organizations", "AWS CodeArtifact"],
    "reason": "1.3"
  },
  {
    "no": 265,
    "question": "一家公司正在运行一个自定义构建的应用程序，该应用程序处理记录。所有组件都在运行在自动扩展组中的Amazon EC2实例上。每个记录的处理是一个多步骤的顺序动作，计算密集型。每个步骤总是在5分钟或更少时间内完成。当前系统的一个限制是，如果任何步骤失败，应用程序必须从头开始重新处理记录。公司希望更新架构，使应用程序只需重新处理失败的步骤。哪种解决方案在操作上最有效，且能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个Web应用程序将记录写入Amazon S3。使用S3事件通知发布到Amazon Simple Notification Service（Amazon SNS）主题。使用EC2实例轮询Amazon SNS并开始处理。将中间结果保存到Amazon S3以传递到下一步。",
      "B": "通过在应用程序中使用逻辑执行处理步骤。将应用程序代码转换为在容器中运行。使用AWS Fargate管理容器实例。配置容器以调用自身以传递从一个步骤到下一个步骤的状态。",
      "C": "创建一个Web应用程序将记录传递到Amazon Kinesis数据流。通过使用Kinesis数据流和AWS Lambda函数解耦处理。",
      "D": "创建一个Web应用程序将记录传递到AWS Step Functions。将处理解耦为Step Functions任务和AWS Lambda函数。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此方案通过使用S3和SNS实现了一定程度的解耦，但它不支持只重新处理失败的步骤，因为它没有提供一个明确的方式来管理每个步骤的状态。",
      "B": "虽然此方案使用了容器和AWS Fargate，但它依赖于容器自我调用来传递状态，这可能导致状态管理复杂和容错能力不足。",
      "C": "此方案使用了Kinesis和Lambda来解耦处理，但它更适合于流式处理，而不是需要明确步骤和状态管理的场景。",
      "D": "此方案使用AWS Step Functions和Lambda函数，可以精确地控制每个步骤的执行和状态，允许在任何步骤失败时只重新执行该步骤，满足题目要求的操作效率和功能需求。"
    },
    "service": [
      "Amazon EC2",
      "Auto Scaling",
      "Amazon S3",
      "Amazon SNS",
      "AWS Fargate",
      "Amazon Kinesis",
      "AWS Lambda",
      "AWS Step Functions"
    ],
    "reason": "3.2"
  },
  {
    "no": 268,
    "question": "一家公司最近将其应用程序迁移到使用 Amazon EC2 实例的 Amazon Elastic Kubernetes Service (Amazon EKS) 集群。公司配置了应用程序以根据 CPU 利用率自动扩展。当应用程序遇到重负载时会产生内存错误。应用程序也没有足够扩展以处理增加的负载。公司需要收集并分析一段时间内应用程序的内存指标。哪种步骤组合可以满足这些要求？（选择三个。）",
    "choose": 3,
    "options": {
      "A": "将 CloudWatchAgentServerPolicy 托管的 IAM 策略附加到集群使用的 IAM 实例配置文件。",
      "B": "将 CloudWatchAgentServerPolicy 托管的 IAM 策略附加到集群的服务账户角色。",
      "C": "通过在集群中的现有 EC2 实例上部署统一的 Amazon CloudWatch 代理来收集性能指标。将代理添加到添加到集群的任何新 EC2 实例的 AMI 中。",
      "D": "通过将 AWS Distro for OpenTelemetry 收集器部署为 DaemonSet 来收集性能日志。",
      "E": "通过使用 Service 维度分析 ContainerInsights 命名空间中的 pod_memory_utilization Amazon CloudWatch 指标。",
      "F": "通过使用 ClusterName 维度分析 ContainerInsights 命名空间中的 node_memory_utilization Amazon CloudWatch 指标。"
    },
    "best": ["C", "E", "F"],
    "analysis": {
      "A": "虽然这个选项确实涉及到 IAM 策略，但它不直接涉及到收集或分析内存指标的能力。",
      "B": "这个选项也是关于 IAM 策略，但它不是直接收集或分析内存指标的最佳方式。",
      "C": "部署 CloudWatch 代理可以直接收集 EC2 实例的性能指标，包括内存使用情况，是满足需求的关键步骤。",
      "D": "虽然 OpenTelemetry 收集器可以收集性能日志，但它不专注于 CloudWatch 和 AWS 的内存指标收集。",
      "E": "分析 pod_memory_utilization 指标可以直接帮助理解 Kubernetes pod 的内存使用情况，是解决问题的关键步骤。",
      "F": "分析 node_memory_utilization 指标可以帮助理解整个节点的内存使用情况，对于调整和优化集群性能至关重要。"
    },
    "service": ["Amazon EKS", "Amazon EC2", "Amazon CloudWatch"],
    "reason": "4.1"
  },
  {
    "no": 266,
    "question": "一家公司正在将其本地 Windows 应用程序和 Linux 应用程序迁移到 AWS。公司将使用自动化启动 Amazon EC2 实例以镜像本地配置。迁移的应用程序需要访问使用 SMB 的 Windows 和 NFS 的 Linux 的共享存储。公司还在另一个 AWS 区域创建了一个灾难恢复（DR）环境的引导灯。公司将使用自动化启动和配置 DR 区域中的 EC2 实例。公司需要将存储复制到 DR 区域。哪种存储解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "对于应用程序存储，使用 Amazon S3。在主要区域和 DR 区域创建一个 S3 存储桶。配置从主要区域到 DR 区域的 S3 跨区域复制（CRR）。",
      "B": "对于应用程序存储，使用 Amazon 弹性块存储（Amazon EBS）。在 AWS 备份中创建一个备份计划，该计划创建主要区域中的 EBS 卷的快照并将快照复制到 DR 区域。",
      "C": "对于应用程序存储，使用 AWS 存储网关中的卷网关。配置从主要区域到 DR 区域的卷网关的跨区域复制（CRR）。",
      "D": "对于应用程序存储，使用 Amazon FSx for NetApp ONTAP。在 DR 区域创建一个 FSx for ONTAP 实例。配置从主要区域到 DR 区域的 NetApp SnapMirror 复制。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然 Amazon S3 支持跨区域复制，但它不支持 SMB 或 NFS 协议，因此不适合 Windows 和 Linux 应用程序的共享存储需求。",
      "B": "Amazon EBS 支持快照和跨区域复制，但 EBS 本身不支持作为共享存储或直接通过 SMB 或 NFS 协议访问。",
      "C": "虽然 AWS 存储网关的卷网关支持 iSCSI，它并不直接支持 SMB 或 NFS 协议，也不是最佳选择。",
      "D": "Amazon FSx for NetApp ONTAP 支持 SMB 和 NFS 协议，适用于 Windows 和 Linux 系统的共享存储，并且支持 NetApp SnapMirror 进行数据复制，完全符合题目要求。"
    },
    "service": [
      "Amazon EC2",
      "Amazon S3",
      "Amazon EBS",
      "AWS Storage Gateway",
      "Amazon FSx for NetApp ONTAP"
    ],
    "reason": "3.3"
  },
  {
    "no": 273,
    "question": "一家公司使用 AWS Cloud Development Kit (AWS CDK) 来定义其应用程序。该公司使用由 AWS CodePipeline 和 AWS CodeBuild 组成的管道来部署 CDK 应用程序。公司希望在管道中引入单元测试来测试各种基础设施组件。公司希望确保如果没有单元测试导致失败，则部署可以继续进行。在管道中强制执行测试要求的步骤组合是什么？（选择两个。）",
    "choose": 2,
    "options": {
      "A": "更新 CodeBuild 构建阶段命令以运行测试然后部署应用程序。将 OnFailure 阶段属性设置为 ABORT。",
      "B": "更新 CodeBuild 构建阶段命令以运行测试然后部署应用程序。向 cdk deploy 命令添加 --rollback true 标志。",
      "C": "更新 CodeBuild 构建阶段命令以运行测试然后部署应用程序。向 cdk deploy 命令添加 --require-approval any-change 标志。",
      "D": "创建一个使用 AWS CDK assertions 模块的测试。使用 template.hasResourceProperties 断言来测试资源是否具有预期的属性。",
      "E": "创建一个使用 cdk diff 命令的测试。配置测试以在任何资源发生变化时失败。"
    },
    "best": ["A", "D"],
    "analysis": {
      "A": "这是最佳选项之一，因为它确保在测试失败时中止部署，从而满足公司希望在没有测试失败的情况下继续部署的要求。",
      "B": "虽然这个选项确保了在部署失败时回滚，但它并不直接关联到单元测试的失败导致部署中止。",
      "C": "这个选项要求任何变更都需要审批，这可能会导致部署延迟，而不是基于单元测试的结果自动决定是否继续部署。",
      "D": "这是最佳选项之一，因为它通过确保基础设施组件具有预期的属性来有效地实施单元测试。",
      "E": "这个选项虽然可以检测到资源变化，但它更多地关注于变化本身而不是单元测试的成功或失败。"
    },
    "service": ["AWS CDK", "AWS CodePipeline", "AWS CodeBuild"],
    "reason": "1.2"
  },
  {
    "no": 271,
    "question": "一家公司使用启用了所有功能的 AWS Organizations 中的组织。该公司在主账户中使用 AWS Backup，并使用 AWS Key Management Service (AWS KMS) 密钥加密备份。公司需要自动化跨账户备份主账户中 AWS Backup 备份的资源。公司在组织管理账户中配置了跨账户备份。公司在组织中创建了一个新的 AWS 账户，并在新账户中配置了一个 AWS Backup 备份库。公司在新账户中创建了一个 KMS 密钥来加密备份。最后，公司在主账户中配置了一个新的备份计划。新备份计划的目的地是新账户中的备份库。当在主账户中调用 AWS Backup 作业时，该作业在主账户中创建备份。然而，备份没有被复制到新账户的备份库中。公司必须采取哪些步骤组合，以便可以将备份复制到新账户的备份库中？（选择两项。）",
    "choose": 2,
    "options": {
      "A": "在新账户中编辑备份库访问策略，允许主账户访问。",
      "B": "在主账户中编辑备份库访问策略，允许新账户访问。",
      "C": "在主账户中编辑备份库访问策略，允许访问新账户中的 KMS 密钥。",
      "D": "编辑主账户中的 KMS 密钥策略，与新账户共享密钥。",
      "E": "编辑新账户中的 KMS 密钥策略，与主账户共享密钥。"
    },
    "best": ["A", "E"],
    "analysis": {
      "A": "这是最优选项之一，因为允许主账户访问新账户的备份库是实现跨账户备份的关键步骤。",
      "B": "这个选项不是最优的，因为主账户的备份库访问策略不需要允许新账户访问，反之才是。",
      "C": "这个选项不是最优的，因为主账户的备份库访问策略不需要涉及新账户中的 KMS 密钥。",
      "D": "这个选项不是最优的，因为主账户的 KMS 密钥不需要与新账户共享，反之才是。",
      "E": "这是最优选项之一，因为允许主账户使用新账户中的 KMS 密钥来加密备份是实现跨账户备份的关键步骤。"
    },
    "service": [
      "AWS Organizations",
      "AWS Backup",
      "AWS Key Management Service (AWS KMS)"
    ],
    "reason": "2.2"
  },
  {
    "no": 269,
    "question": "一家公司的视频流媒体平台使用量从每天10,000用户增加到每天50,000用户，并且在多个国家都有用户。该公司在Amazon Elastic Kubernetes Service（Amazon EKS）上部署了流媒体平台。在高峰观看时间，EKS工作负载会扩展到数千个节点。公司的用户报告出现未经授权的登录事件。用户还报告了平台突然中断和登出的情况。公司希望为整个平台增加额外的安全措施。公司还需要一个总结视图，显示公司整个AWS环境中的资源行为和交互，该视图必须显示登录尝试、API调用和网络流量。解决方案必须允许网络流量分析，同时最小化管理日志的开销。该解决方案还必须能够快速调查与EKS工作负载相关的任何潜在恶意行为。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "启用Amazon GuardDuty用于EKS审计日志监控。启用AWS CloudTrail日志。将EKS审计日志和CloudTrail日志文件存储在Amazon S3桶中。使用Amazon Athena创建外部表。使用Amazon QuickSight创建仪表板。",
      "B": "启用Amazon GuardDuty用于EKS审计日志监控。在公司的AWS账户中启用Amazon Detective。启用EKS审计日志来自可选源包在Detective中。",
      "C": "启用Amazon CloudWatch Container Insights。启用AWS CloudTrail日志。将EKS审计日志和CloudTrail日志文件存储在Amazon S3桶中。使用Amazon Athena创建外部表。使用Amazon QuickSight创建仪表板。",
      "D": "启用Amazon GuardDuty用于EKS审计日志监控。启用Amazon CloudWatch Container Insights和VPC流量日志。启用AWS CloudTrail日志。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然这个选项提供了日志存储和分析的功能，但它没有提供对网络流量的分析，这是题目要求的一个关键部分。",
      "B": "这个选项启用了Amazon Detective，可以帮助调查安全事件，但它缺乏对网络流量的直接监控和分析。",
      "C": "这个选项提供了对容器的监控，但同样缺乏对网络流量的直接监控，这是题目中特别强调的需求。",
      "D": "这个选项不仅启用了EKS的审计日志监控和AWS CloudTrail日志，还额外启用了CloudWatch Container Insights和VPC流量日志，提供了对容器和网络流量的全面监控，满足题目的所有要求。"
    },
    "service": [
      "Amazon GuardDuty",
      "Amazon EKS",
      "AWS CloudTrail",
      "Amazon S3",
      "Amazon Athena",
      "Amazon QuickSight",
      "Amazon Detective",
      "Amazon CloudWatch",
      "VPC Flow Logs"
    ],
    "reason": "4.2"
  },
  {
    "no": 267,
    "question": "一家公司的应用程序使用一组Amazon EC2按需实例来分析和处理数据。EC2实例位于一个自动扩展组中。自动扩展组是应用程序负载均衡器（ALB）的目标组。该应用程序分析关键数据，不能容忍中断。该应用程序还分析可以承受中断的非关键数据。关键数据分析需要快速扩展以响应实时应用程序需求。非关键数据分析涉及内存消耗。DevOps工程师必须实施一个解决方案，减少关键数据的扩展延迟。该解决方案还必须处理非关键数据。哪两个步骤的组合将满足这些要求？（选择两个。）",
    "choose": 2,
    "options": {
      "A": "对于关键数据，修改现有的自动扩展组。在停止状态下创建一个预热池实例。定义预热池大小。创建一个具有详细监控功能的新版本启动模板。使用Spot实例。",
      "B": "对于关键数据，修改现有的自动扩展组。在停止状态下创建一个预热池实例。定义预热池大小。创建一个具有详细监控功能的新版本启动模板。使用按需实例。",
      "C": "对于关键数据，修改现有的自动扩展组。创建一个生命周期钩子以确保引导脚本成功完成。确保实例上的应用程序在注册前已准备好接受流量。创建一个具有详细监控功能的新版本启动模板。",
      "D": "对于非关键数据，创建第二个自动扩展组，使用启动模板。配置启动模板以安装统一的Amazon CloudWatch代理，并使用自定义内存利用率指标配置CloudWatch代理。使用Spot实例。将新的自动扩展组添加为ALB的目标组。修改应用程序以使用两个目标组处理关键数据和非关键数据。",
      "E": "对于非关键数据，创建第二个自动扩展组。选择预定义的内存利用率指标类型作为目标跟踪扩展策略。使用Spot实例。将新的自动扩展组添加为ALB的目标组。修改应用程序以使用两个目标组处理关键数据和非关键数据。"
    },
    "best": ["B", "E"],
    "analysis": {
      "A": "使用Spot实例可能会导致关键数据处理中断，因为Spot实例可能会被回收，不适合关键任务。",
      "B": "使用按需实例确保关键数据处理的连续性，预热池可以减少扩展延迟，是最优选择。",
      "C": "虽然生命周期钩子可以确保应用程序准备就绪，但没有提到如何快速扩展以应对需求变化。",
      "D": "虽然这个选项适用于非关键数据，但使用Spot实例可能导致处理中断，不如选项E中使用预定义指标更为稳定。",
      "E": "使用预定义的内存利用率指标可以有效地自动扩展处理非关键数据，使用Spot实例可以节省成本，是非关键数据处理的最优选择。"
    },
    "service": [
      "Amazon EC2",
      "Auto Scaling",
      "Application Load Balancer",
      "Amazon CloudWatch"
    ],
    "reason": "3.2"
  },
  {
    "no": 270,
    "question": "一家公司使用 AWS Organizations 管理数百个 AWS 账户。该公司有一个负责 AWS 身份和访问管理（IAM）的团队。IAM 团队希望建立 AWS IAM 身份中心（AWS 单一登录）。IAM 团队必须只拥有管理 IAM 身份中心所需的最小权限。IAM 团队不能获得对组织管理账户不必要的访问权限。IAM 团队必须能够为现有和新成员账户配置新的 IAM 身份中心权限集和分配。哪种步骤组合能满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "为 IAM 团队创建一个新的 AWS 账户。在新账户中启用 IAM 身份中心。在组织管理账户中，将新账户注册为 IAM 身份中心的委派管理员。",
      "B": "为 IAM 团队创建一个新的 AWS 账户。在组织管理账户中启用 IAM 身份中心。在组织管理账户中，将新账户注册为 IAM 身份中心的委派管理员。",
      "C": "在 IAM 身份中心中，为 IAM 团队创建用户和一个组。将用户添加到该组。创建一个新的权限集。将 AWSSSODirectoryAdministrator 管理的 IAM 策略附加到该组。",
      "D": "在 IAM 身份中心中，为 IAM 团队创建用户和一个组。将用户添加到该组。创建一个新的权限集。将 AWSSSOMemberAccountAdministrator 管理的 IAM 策略附加到该组。",
      "E": "将权限集分配给组织管理账户。允许 IAM 团队组使用权限集。",
      "F": "将权限集分配给新的 AWS 账户。允许 IAM 团队组使用权限集。"
    },
    "best": ["A", "D", "F"],
    "analysis": {
      "A": "这是最优选项之一，因为它允许 IAM 团队在一个新的账户中管理 IAM 身份中心，而不会影响组织管理账户的安全。",
      "B": "这不是最优选项，因为它在组织管理账户中启用 IAM 身份中心，可能会给管理账户带来不必要的风险。",
      "C": "这不是最优选项，因为 AWSSSODirectoryAdministrator 策略可能不适合管理成员账户的权限集和分配。",
      "D": "这是最优选项之一，因为 AWSSOMemberAccountAdministrator 策略允许管理成员账户的权限集和分配，适合 IAM 团队的需求。",
      "E": "这不是最优选项，因为将权限集分配给组织管理账户可能会给管理账户带来不必要的风险。",
      "F": "这是最优选项之一，因为它允许 IAM 团队在新账户中使用权限集，而不会影响组织管理账户的安全。"
    },
    "service": ["AWS Organizations", "AWS IAM", "IAM Identity Center"],
    "reason": "6.1"
  },
  {
    "no": 272,
    "question": "一家公司运行一个应用程序，该应用程序使用 Amazon S3 存储桶存储图像。DevOps 工程师需要为存储在 S3 存储桶中的对象实施多区域策略。公司需要能够故障转移到另一个 AWS 区域的 S3 存储桶。当向任一 S3 存储桶添加图像时，必须在 15 分钟内将图像复制到另一个 S3 存储桶。DevOps 工程师启用了 S3 存储桶之间的双向复制。DevOps 工程师接下来应采取哪些步骤组合以满足要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "在每个复制规则上启用 S3 复制时间控制（S3 RTC）。",
      "B": "创建一个处于主动-被动配置的 S3 多区域访问点。",
      "C": "当公司需要故障转移到另一个区域的 S3 存储桶时，调用 AWS API 中的 SubmitMultiRegionAccessPointRoutes 操作。",
      "D": "在两个 S3 存储桶上启用 S3 传输加速。",
      "E": "配置 Amazon Route 53 恢复控制器中的路由控制。以主动-被动配置添加 S3 存储桶。",
      "F": "当公司需要故障转移到另一个区域的 S3 存储桶时，调用 AWS API 中的 UpdateRoutingControlStates 操作。"
    },
    "best": ["A", "B", "E"],
    "analysis": {
      "A": "启用 S3 RTC 确保在指定时间内完成复制，符合题目中的 15 分钟内复制要求。",
      "B": "创建多区域访问点以支持主动-被动配置，有助于实现高可用性和故障转移。",
      "C": "调用 SubmitMultiRegionAccessPointRoutes 操作不是必要的，因为故障转移应通过配置和自动化策略处理。",
      "D": "S3 传输加速主要用于加速 Internet 上的大规模数据传输，并不直接关联到区域间的复制或故障转移。",
      "E": "配置 Route 53 恢复控制器中的路由控制，以支持 S3 存储桶的主动-被动配置，是实现故障转移的有效方法。",
      "F": "调用 UpdateRoutingControlStates 操作通常用于更复杂的路由控制场景，而不是直接用于 S3 存储桶的故障转移。"
    },
    "service": [
      "Amazon S3",
      "S3 Replication Time Control",
      "S3 Multi-Region Access Point",
      "Amazon Route 53 Recovery Controller",
      "S3 Transfer Acceleration"
    ],
    "reason": "3.1"
  },
  {
    "no": 274,
    "question": "一家公司有一个应用程序运行在多个可用区的 Amazon EC2 实例上，这些实例位于一个应用程序负载均衡器（ALB）后面。应用程序在单个可用区中配置错误，导致应用程序部分中断。一位 DevOps 工程师进行了更改，以确保一个可用区中不健康的 EC2 实例不会影响其他可用区中健康的 EC2 实例。DevOps 工程师需要测试应用程序的故障转移，并改变 ALB 发送流量的位置。在故障转移期间，ALB 必须避免将流量发送到发生故障的可用区。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "关闭 ALB 上的跨区域负载均衡。使用 Amazon Route 53 应用程序恢复控制器开始从可用区迁移。",
      "B": "关闭 ALB 目标组的跨区域负载均衡。使用 Amazon Route 53 应用程序恢复控制器开始从可用区迁移。",
      "C": "创建一个使用 ALB 的 DNS 主机名的 Amazon Route 53 应用程序恢复控制器资源集。为资源集开始从可用区迁移。",
      "D": "创建一个使用 ALB 目标组的 ARN 的 Amazon Route 53 应用程序恢复控制器资源集。创建一个使用 ElbV2TargetGroupsCanServeTraffic 规则的就绪性检查。"
    },
    "best": ["C"],
    "analysis": {
      "A": "关闭 ALB 的跨区域负载均衡并不是必要的，因为这可能会影响 ALB 在多个可用区之间的负载均衡能力。",
      "B": "关闭目标组的跨区域负载均衡也不是必要的，因为目标组本身不具备跨区域负载均衡的设置。",
      "C": "这是最佳选项，因为它通过创建一个资源集并使用 ALB 的 DNS 主机名，可以有效地管理故障转移，确保流量不会被发送到故障的可用区。",
      "D": "虽然创建资源集和就绪性检查是一个好方法，但使用 ALB 目标组的 ARN 并不直接影响流量的路由，因此不是最佳选项。"
    },
    "service": [
      "Amazon EC2",
      "Application Load Balancer",
      "Amazon Route 53",
      "Amazon Route 53 Application Recovery Controller"
    ],
    "reason": "3.3"
  },
  {
    "no": 275,
    "question": "一家公司将其 AWS 网络防火墙流日志发送到 Amazon S3 存储桶。然后，该公司使用 Amazon Athena 分析流日志。公司需要在将流日志传送到现有 S3 存储桶之前转换流日志并添加额外数据。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 AWS Lambda 函数来转换数据并向现有 S3 存储桶写入新对象。为现有 S3 存储桶配置 Lambda 函数的 S3 触发器。为事件类型指定所有对象创建事件。确认递归调用。",
      "B": "在现有 S3 存储桶上启用 Amazon EventBridge 通知。创建一个自定义 EventBridge 事件总线。创建一个与自定义事件总线关联的 EventBridge 规则。配置规则以响应现有 S3 存储桶的所有对象创建事件，并调用 AWS Step Functions 工作流。配置 Step Functions 任务以转换数据并将数据写入新的 S3 存储桶。",
      "C": "创建一个与默认 EventBridge 事件总线关联的 Amazon EventBridge 规则。配置规则以响应现有 S3 存储桶的所有对象创建事件。为规则定义一个新的 S3 存储桶作为目标。创建 EventBridge 输入转换以在将事件传递到规则目标之前自定义事件。",
      "D": "创建一个配置有 AWS Lambda 转换器的 Amazon Kinesis Data Firehose 传送流。指定现有 S3 存储桶作为目的地。将网络防火墙日志记录目的地从 Amazon S3 更改为 Kinesis Data Firehose。"
    },
    "best": ["D"],
    "analysis": {
      "A": "虽然 Lambda 函数可以处理数据转换，但使用 S3 触发器可能导致递归调用问题，因为 Lambda 函数写入同一个 S3 存储桶可能再次触发该函数。",
      "B": "此方案涉及创建额外的 S3 存储桶和复杂的 EventBridge 和 Step Functions 配置，这不是最直接的解决方案。",
      "C": "此方案也提到了创建新的 S3 存储桶，这不符合题目要求将数据写入现有的 S3 存储桶。",
      "D": "这是最佳选项，因为它直接使用 Kinesis Data Firehose 进行数据转换，并将数据直接写入现有的 S3 存储桶，同时避免了更改现有的日志处理流程。"
    },
    "service": [
      "AWS Lambda",
      "Amazon S3",
      "Amazon EventBridge",
      "AWS Step Functions",
      "Amazon Kinesis Data Firehose"
    ],
    "reason": "4.1"
  },
  {
    "no": 277,
    "question": "一家公司在多个可用区的 AWS 区域中运行 Windows 和 Linux Amazon EC2 实例上的应用程序。该公司为每个应用程序使用自动扩展组。该公司需要为实例提供一个耐用的存储解决方案。该解决方案必须对 Windows 使用 SMB，对 Linux 使用 NFS。解决方案还必须具有亚毫秒级的延迟。所有实例都将读写数据。哪种步骤组合能满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "创建一个具有多个可用区目标的 Amazon Elastic File System (Amazon EFS) 文件系统。",
      "B": "创建一个 Amazon FSx for NetApp ONTAP 多可用区文件系统。",
      "C": "创建一个用于共享存储的通用 SSD (gp3) Amazon Elastic Block Store (Amazon EBS) 卷。",
      "D": "更新每个应用程序的启动模板的用户数据以挂载文件系统。",
      "E": "对每个自动扩展组执行实例刷新。",
      "F": "更新每个应用程序的 EC2 实例以在启动新实例时挂载文件系统。"
    },
    "best": ["B", "D", "F"],
    "analysis": {
      "A": "虽然 Amazon EFS 支持多可用区部署和 NFS，但它不支持 Windows 使用的 SMB 协议。",
      "B": "Amazon FSx for NetApp ONTAP 支持多可用区部署，同时支持 NFS 和 SMB 协议，满足亚毫秒级的延迟要求，是最佳选择。",
      "C": "Amazon EBS 卷只能被一个 EC2 实例在同一时间挂载，不适合作为多实例共享的解决方案。",
      "D": "更新启动模板以挂载文件系统是必要的步骤，确保所有自动扩展的新实例都能访问所需的文件系统。",
      "E": "实例刷新与存储解决方案的选择无直接关联，不是必要步骤。",
      "F": "确保所有现有的 EC2 实例在启动时挂载文件系统是必要的，以保证应用程序的连续性和数据的可用性。"
    },
    "service": ["Amazon FSx", "Amazon EFS", "Amazon EBS", "EC2 Auto Scaling"],
    "reason": "3.1"
  },
  {
    "no": 276,
    "question": "一名 DevOps 工程师需要将集成测试实施到现有的 AWS CodePipeline CI/CD 工作流中，用于 Amazon Elastic Container Service (Amazon ECS) 服务。CI/CD 工作流从 AWS CodeCommit 仓库检索新的应用程序代码并构建容器映像。然后，CI/CD 工作流将容器映像上传到 Amazon Elastic Container Registry (Amazon ECR) 并附加新的映像标签版本。集成测试必须确保服务端点的新版本是可达的，并且各种 API 方法返回成功的响应数据。DevOps 工程师已经创建了一个 ECS 集群来测试服务。哪种步骤组合可以在最小管理开销下满足这些要求？（选择三项。）",
    "choose": 3,
    "options": {
      "A": "向管道添加部署阶段。配置 Amazon ECS 作为操作提供者。",
      "B": "向管道添加部署阶段。配置 AWS CodeDeploy 作为操作提供者。",
      "C": "在 CodeCommit 仓库中添加 appspec.yml 文件。",
      "D": "更新映像构建管道阶段以输出引用新映像标签的 imagedefinitions.json 文件。",
      "E": "创建一个 AWS Lambda 函数，运行针对服务的连接检查和 API 调用。通过使用 Lambda 操作阶段将 Lambda 函数与 CodePipeline 集成。",
      "F": "编写一个运行针对服务的集成测试的脚本。将脚本上传到 Amazon S3 存储桶。通过使用 S3 操作阶段将 S3 存储桶中的脚本与 CodePipeline 集成。"
    },
    "best": ["A", "D", "E"],
    "analysis": {
      "A": "最优选项。通过将 ECS 配置为操作提供者，可以直接在 ECS 上部署和测试新的容器映像，这简化了部署和测试流程。",
      "B": "非最优选项。虽然 CodeDeploy 是一个强大的部署服务，但在这种情况下，使用 ECS 作为操作提供者更直接且与 ECS 集成更紧密。",
      "C": "非最优选项。appspec.yml 文件通常与 AWS CodeDeploy 一起使用，而不是直接与 ECS 集成。",
      "D": "最优选项。输出 imagedefinitions.json 文件是在 ECS 中部署新映像的标准方法，确保 CI/CD 流程可以正确引用并部署新的容器映像。",
      "E": "最优选项。通过创建 Lambda 函数来执行 API 测试和连接性检查，可以自动化测试过程，并且可以直接从 CodePipeline 触发。",
      "F": "非最优选项。虽然这种方法可以工作，但它增加了管理复杂性，因为需要维护 S3 存储桶和脚本，而不是直接在 CodePipeline 中集成测试。"
    },
    "service": [
      "AWS CodePipeline",
      "Amazon ECS",
      "AWS CodeCommit",
      "Amazon ECR",
      "AWS Lambda",
      "Amazon S3"
    ],
    "reason": "1.2"
  },
  {
    "no": 279,
    "question": "一个 Amazon EC2 Auto Scaling 组管理从 AMI 创建的 EC2 实例。AMI 中安装了 AWS Systems Manager Agent。当 EC2 实例启动到 Auto Scaling 组中时，会对 EC2 实例应用标签。由 Auto Scaling 组启动的 EC2 实例必须具有正确的操作系统配置。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "创建一个 Systems Manager Run Command 文档，用于配置所需的实例配置。设置 Systems Manager Compliance 以在 EC2 实例不符合最新补丁的情况下调用 Run Command 文档。",
      "B": "创建一个 Systems Manager State Manager 关联，链接到 Systems Manager 命令文档。创建一个立即运行的标签查询。",
      "C": "创建一个 Systems Manager Run Command 任务，指定所需的实例配置。在 Systems Manager Maintenance Windows 中创建一个每日运行的维护窗口。注册 Run Command 任务到维护窗口。指定目标。",
      "D": "创建一个 Systems Manager Patch Manager 补丁基线和一个使用 Auto Scaling 组应用的相同标签的补丁组。将补丁组注册到补丁基线。定义一个 Systems Manager 命令文档来补丁实例。使用 Systems Manager Run Command 调用文档。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项使用 Run Command 文档和 Compliance，但主要关注补丁合规性，而不是操作系统配置。",
      "B": "此选项创建了 State Manager 关联和标签查询，但没有明确说明如何确保操作系统配置的正确性。",
      "C": "此选项通过创建 Run Command 任务和维护窗口确保实例配置正确，并且可以定期执行，确保所有实例都符合要求。",
      "D": "此选项侧重于补丁管理而不是操作系统配置，虽然使用了补丁基线和补丁组，但不完全符合题目要求。"
    },
    "service": ["AWS Systems Manager", "Amazon EC2", "EC2 Auto Scaling"],
    "reason": "2.3"
  },
  {
    "no": 278,
    "question": "一家公司使用 AWS Organizations 中的组织，由安全团队和 DevOps 团队管理。两个团队都通过使用 AWS IAM Identity Center 访问账户。为每个团队创建了一个专用组。DevOps 团队的组被分配了一个名为 DevOps 的权限集。权限集附加了 AdministratorAccess 管理的 IAM 策略。权限集已应用于组织中的所有账户。安全团队希望确保 DevOps 团队无法访问组织管理账户中的 IAM Identity Center。安全团队已将以下 SCP 附加到组织根：在实施策略后，安全团队发现 DevOps 团队仍然可以访问 IAM Identity Center。哪种解决方案将解决这个问题？",
    "choose": 1,
    "options": {
      "A": "在组织的管理账户中，创建一个新的 OU。将组织的管理账户移动到新的 OU。从组织根部分离 SCP。将 SCP 附加到新的 OU。",
      "B": "在组织的管理账户中，更新 SCP 条件引用 DevOps 团队组角色的 ARN，以包括组织管理账户的 AWS 账户 ID。",
      "C": "在 IAM Identity Center 中，创建一个新的权限集。确保分配的策略具有完全访问权限，但明确拒绝 sso:* 操作和 sso-directory:* 操作的权限。更新组织管理账户中 DevOps 团队组角色的分配权限集。删除 SCP。",
      "D": "在 IAM Identity Center 中，更新 DevOps 权限集。确保分配的策略具有完全访问权限，但明确拒绝 sso:* 操作和 sso-directory:* 操作的权限。在拒绝语句中，添加一个 StringEquals 条件，比较 aws:SourceAccount 全局条件上下文键与组织的管理账户。删除 SCP。"
    },
    "best": ["C"],
    "analysis": {
      "A": "此选项不适用，因为仅移动账户和重新附加 SCP 不会限制 DevOps 团队对 IAM Identity Center 的访问。",
      "B": "此选项不适用，因为仅更新 SCP 条件不足以限制 DevOps 团队对 IAM Identity Center 的访问。",
      "C": "这是最佳选项，因为它通过创建一个新的权限集并明确拒绝对 sso:* 和 sso-directory:* 操作的访问，直接在 IAM Identity Center 中限制 DevOps 团队的访问权限。",
      "D": "此选项不适用，因为尽管它试图通过更新权限集来限制访问，但添加的 StringEquals 条件可能不足以确保 DevOps 团队无法访问 IAM Identity Center。"
    },
    "service": ["AWS Organizations", "AWS IAM Identity Center", "IAM"],
    "reason": "6.1"
  },
  {
    "no": 280,
    "question": "一家公司使用 AWS Organizations 管理其 AWS 账户。组织根部有一个名为 Department 的子 OU。Department OU 有一个名为 Engineering 的子 OU。默认的 FullAWSAccess 策略附加到根部、Department OU 和 Engineering OU。公司在 Engineering OU 中有许多 AWS 账户。每个账户都有一个附加了 AdministratorAccess IAM 策略的管理 IAM 角色。默认的 FullAWSAccessPolicy 也附加到每个账户。一位 DevOps 工程师计划从 Department OU 中移除 FullAWSAccess 策略。DevOps 工程师将用一个包含所有 Amazon EC2 API 操作的 Allow 语句的策略替换该策略。这种变化将对管理 IAM 角色的权限产生什么影响？",
    "choose": 1,
    "options": {
      "A": "所有资源上的所有 API 操作都将被允许。",
      "B": "EC2 资源上的所有 API 操作将被允许。所有其他 API 操作将被拒绝。",
      "C": "所有资源上的所有 API 操作都将被拒绝。",
      "D": "EC2 资源上的所有 API 操作将被拒绝。所有其他 API 操作将被允许。"
    },
    "best": ["B"],
    "analysis": {
      "A": "这个选项不正确，因为移除 FullAWSAccess 并替换为只允许 EC2 API 操作的策略意味着其他服务的 API 操作将不被允许。",
      "B": "这是正确的选项。因为新策略只允许 EC2 API 操作，其他服务的 API 操作将被拒绝。",
      "C": "这个选项不正确，因为新策略允许所有 EC2 API 操作，不是所有操作都被拒绝。",
      "D": "这个选项不正确，因为新策略允许 EC2 API 操作，而不是拒绝它们。"
    },
    "service": ["AWS Organizations", "IAM", "Amazon EC2"],
    "reason": "2.2"
  },
  {
    "no": 281,
    "question": "一家公司在 AWS Organizations 中管理 AWS 账户。该公司需要一种解决方案将 Amazon CloudWatch Logs 数据发送到一个专用 AWS 账户中的 Amazon S3 存储桶。该解决方案必须支持所有现有和未来的 CloudWatch Logs 日志组。哪种解决方案能满足这些要求？",
    "choose": 1,
    "options": {
      "A": "启用组织备份策略，将所有日志组备份到专用的 S3 存储桶。添加一个 S3 存储桶策略，允许属于该公司的所有账户访问。",
      "B": "在 AWS Backup 中创建一个备份计划。指定一个专用的 S3 存储桶作为备份库。将所有 CloudWatch Logs 日志组资源分配给备份计划。为属于该公司的所有账户创建备份计划中的资源分配。",
      "C": "在 AWS Backup 中创建一个备份计划。指定一个专用的 S3 存储桶作为备份库。将所有现有的日志组分配给备份计划。为属于该公司的所有账户创建备份计划中的资源分配。创建一个 AWS Systems Manager 自动化运行手册以将日志组分配给备份计划。创建一个 AWS Config 规则，该规则具有针对所有不合规日志组的自动修正操作。指定运行手册作为规则的目标。",
      "D": "在专用 AWS 账户中创建一个 CloudWatch Logs 目的地和一个 Amazon Kinesis Data Firehose 传输流。指定 S3 存储桶作为传输流的目的地。为所有账户中的所有现有日志组创建订阅过滤器。创建一个 AWS Lambda 函数来调用 CloudWatch Logs PutSubscriptionFilter API 操作。创建一个 Amazon EventBridge 规则以在发生 CreateLogGroup 事件时调用 Lambda 函数。"
    },
    "best": ["D"],
    "analysis": {
      "A": "此选项不适用，因为 AWS Organizations 的备份策略不支持直接备份 CloudWatch Logs 到 S3。",
      "B": "此选项不适用，因为 AWS Backup 不支持 CloudWatch Logs 的直接备份。",
      "C": "此选项不适用，因为虽然提到了自动化和 AWS Config，但 AWS Backup 本身不支持 CloudWatch Logs 的备份。",
      "D": "此选项是最佳选择，因为它使用 CloudWatch Logs 目的地和 Kinesis Data Firehose 传输流来集中管理和转发日志数据到 S3，同时通过 Lambda 和 EventBridge 自动处理新的日志组创建。"
    },
    "service": [
      "AWS Organizations",
      "Amazon CloudWatch Logs",
      "Amazon S3",
      "Amazon Kinesis Data Firehose",
      "AWS Lambda",
      "Amazon EventBridge"
    ],
    "reason": "4.1"
  }
]
