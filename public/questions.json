[
  {
    "number": "1",
    "best": ["C"],
    "question": "一家公司正在 Amazon EC2 实例上实现一个应用程序。该应用程序需要处理传入的交易。当应用程序检测到无效交易时，必须向公司的支持团队发送聊天消息。为了发送消息，应用程序需要检索访问令牌以通过聊天 API 进行身份验证。开发人员需要实施一个解决方案来存储访问令牌。访问令牌必须在静态和传输中加密。访问令牌还必须能够从其他 AWS 帐户访问。哪种解决方案以最少的管理开销满足这些要求？",
    "options": {
      "A": {
        "option": "使用 AWS Systems Manager Parameter Store 的 SecureString 参数，该参数使用 AWS Key Management Service (AWS KMS) AWS 管理的密钥来存储访问令牌。向参数添加基于资源的策略以允许其他账户访问。更新 EC2 实例的 IAM 角色以获得访问 Parameter Store 的权限。启用解密标志从 Parameter Store 检索令牌。使用解密后的访问令牌发送聊天消息。",
        "reason": "虽然 AWS Systems Manager Parameter Store 可以安全存储加密数据，但其主要用途是配置管理和参数存储。虽然它可以允许跨账户访问，但管理基于资源的策略和权限可能会增加一些管理开销。"
      },
      "B": {
        "option": "使用 AWS Key Management Service (AWS KMS) 客户管理密钥加密访问令牌。将访问令牌存储在 Amazon DynamoDB 表中。更新 EC2 实例的 IAM 角色以允许访问 DynamoDB 和 AWS KMS。从 DynamoDB 检索令牌。在 EC2 实例上使用 AWS KMS 解密令牌。使用解密后的访问令牌发送聊天消息。",
        "reason": "DynamoDB 虽然能够存储加密数据，但主要用于高性能的数据库解决方案。而将加密和解密过程与数据库读取操作结合起来可能会增加复杂性和管理开销。"
      },
      "C": {
        "option": "使用 AWS Secrets Manager 和 AWS Key Management Service (AWS KMS) 客户管理密钥来存储访问令牌。向秘密添加基于资源的策略以允许其他账户访问。更新 EC2 实例的 IAM 角色以获得访问 Secrets Manager 的权限。从 Secrets Manager 检索令牌。使用解密后的访问令牌发送聊天消息。",
        "reason": "AWS Secrets Manager 专为存储和管理敏感信息（如访问令牌）而设计，提供内置的加密和跨账户访问功能。它还提供了自动轮换和版本控制，减少了管理开销。因此，这是最优的解决方案。"
      },
      "D": {
        "option": "使用 AWS Key Management Service (AWS KMS) AWS 管理的密钥加密访问令牌。将访问令牌存储在 Amazon S3 存储桶中。向 S3 存储桶添加存储桶策略以允许其他账户访问。更新 EC2 实例的 IAM 角色以允许访问 Amazon S3 和 AWS KMS。从 S3 存储桶检索令牌。在 EC2 实例上使用 AWS KMS 解密令牌。使用解密后的访问令牌发送聊天消息。",
        "reason": "虽然 S3 可以安全存储加密数据，并且支持跨账户访问，但其主要用途是对象存储。将其用于存储和检索小的访问令牌并不是最佳实践，而且可能会增加一些管理复杂性。"
      }
    }
  },
  {
    "number": "2",
    "best": ["D"],
    "question": "公司在多个 AWS 账户中运行 Amazon EC2 实例。开发人员需要实现一个应用程序，以收集所有 EC2 实例的生命周期事件。应用程序需要将这些生命周期事件存储在公司主 AWS 账户中的一个 Amazon Simple Queue Service (Amazon SQS) 队列中，以便进一步处理。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "将所有账户的 Amazon EC2 配置为将 EC2 实例生命周期事件传送到主账户的 Amazon EventBridge 事件总线。向主账户的事件总线添加一个匹配所有 EC2 实例生命周期事件的 EventBridge 规则。将 SQS 队列作为规则的目标。",
        "reason": "此选项虽然看起来合理，但它没有提到如何跨账户设置权限。跨账户事件传递需要明确的权限设置，而这在选项中没有提及。因此，它并不是最优解。"
      },
      "B": {
        "option": "使用主账户中 SQS 队列的资源策略，给予每个账户写入该 SQS 队列的权限。在每个账户的 Amazon EventBridge 事件总线上添加一个匹配所有 EC2 实例生命周期事件的 EventBridge 规则。将主账户中的 SQS 队列作为规则的目标。",
        "reason": "此选项涉及对每个账户的 SQS 队列进行权限配置，并在每个账户中设置 EventBridge 规则。这虽然可行，但管理起来比较复杂，尤其是当账户数量很多时。因此，这不是最佳解决方案。"
      },
      "C": {
        "option": "编写一个 AWS Lambda 函数，扫描公司账户中的所有 EC2 实例以检测 EC2 实例生命周期变化。如果函数检测到 EC2 实例生命周期变化，则将通知消息写入主账户中的 SQS 队列。添加一个 Amazon EventBridge 定时规则，每分钟调用一次 Lambda 函数。",
        "reason": "此选项通过 Lambda 函数扫描所有 EC2 实例的生命周期变化并发送通知。这种方法效率较低，特别是在实例数量较多时性能会受影响。因此，这不是最佳解决方案。"
      },
      "D": {
        "option": "配置主账户事件总线的权限，以接收来自所有账户的事件。在每个账户中创建一个 Amazon EventBridge 规则，将所有 EC2 实例生命周期事件发送到主账户事件总线。向主账户事件总线添加一个匹配所有 EC2 实例生命周期事件的 EventBridge 规则。将 SQS 队列设置为规则的目标。",
        "reason": "此选项明确了跨账户事件传递的权限设置，并且使用了集中化的 EventBridge 规则和 SQS 队列管理方案。它简化了管理和监控过程，是最优解决方案。"
      }
    }
  },
  {
    "number": "3",
    "best": ["D"],
    "question": "一个应用程序使用 Amazon Cognito 用户池和身份池进行安全访问。开发人员希望在应用程序中集成用户特定的文件上传和下载功能，并使用 Amazon S3。开发人员必须确保文件以安全的方式保存和检索，并且用户只能访问自己的文件。文件大小范围从 3 KB 到 300 MB。哪种选项以最高的安全级别满足这些要求？",
    "options": {
      "A": {
        "option": "使用 S3 事件通知来验证文件上传和下载请求，并更新用户界面 (UI)。",
        "reason": "S3 事件通知主要用于触发其他服务（如 Lambda）在 S3 中发生特定事件时执行操作。它不能直接验证用户请求，也无法确保用户只能访问自己的文件。"
      },
      "B": {
        "option": "将上传文件的详细信息保存在一个单独的 Amazon DynamoDB 表中。通过将当前用户 ID 与表中与文件关联的用户 ID 进行比较来筛选用户界面 (UI) 中的文件列表。",
        "reason": "虽然这种方法可以在某种程度上实现文件访问控制，但它需要额外的复杂性和维护。并且它依赖于从 DynamoDB 表中进行验证和筛选，这可能会增加延迟和复杂性。"
      },
      "C": {
        "option": "使用 Amazon API Gateway 和 AWS Lambda 函数来上传和下载文件。在执行请求操作之前，在 Lambda 函数中验证每个请求。",
        "reason": "这种方法虽然提供了较高的安全性，但它增加了复杂性和潜在的延迟。Lambda 函数可以进行细粒度的权限控制，但不是最直接和高效的解决方案。"
      },
      "D": {
        "option": "在 Amazon Cognito 身份前缀内使用 IAM 策略来限制用户只能使用他们自己的文件夹。",
        "reason": "这是最直接和高效的解决方案。通过使用 Cognito 身份池和 IAM 策略，可以确保用户只能访问他们自己的 S3 文件夹。这种方法利用了 AWS 的内置安全机制，提供了高效和安全的访问控制。"
      }
    }
  },
  {
    "number": "4",
    "best": ["B"],
    "question": "某公司正在利用 AWS 服务构建一个可扩展的数据管理解决方案，以提高开发的速度和灵活性。该解决方案将从各种来源摄取大量数据，并通过多个业务规则和转换来处理这些数据。解决方案要求业务规则按顺序运行，并在业务规则运行时发生错误时处理数据的重新处理。公司需要该解决方案可扩展并且需要尽可能少的维护。公司应使用哪种 AWS 服务来管理和自动化数据流的编排以满足这些要求？",
    "options": {
      "A": {
        "option": "AWS Batch",
        "reason": "AWS Batch 适用于批处理作业的执行，但它不适合处理复杂的业务规则运行顺序和错误处理需求。"
      },
      "B": {
        "option": "AWS Step Functions",
        "reason": "AWS Step Functions 允许构建和管理复杂的工作流，支持按顺序运行任务，并提供错误处理和重试机制，非常适合管理和自动化数据流的编排。"
      },
      "C": {
        "option": "AWS Glue",
        "reason": "AWS Glue 主要用于数据的提取、转换和加载（ETL）任务，虽然可以处理数据转换，但不适合复杂的工作流编排和错误处理。"
      },
      "D": {
        "option": "AWS Lambda",
        "reason": "AWS Lambda 适用于无服务器计算和单个事件驱动的任务，但不适合处理复杂的工作流和业务规则的顺序执行和错误处理。"
      }
    }
  },
  {
    "number": "5",
    "best": ["C"],
    "question": "一位开发人员创建了一个用Python编写的AWS Lambda函数。该Lambda函数从Amazon S3中的对象读取数据，并将数据写入Amazon DynamoDB表。当对象被创建时，该函数成功地从S3事件通知中被调用。然而，当函数尝试向DynamoDB表写入数据时失败了。最有可能的原因是什么？",
    "options": {
      "A": {
        "option": "Lambda函数的并发限制已被超出。",
        "reason": "Lambda函数的并发限制超出通常会导致函数无法被调用，而不是在函数执行过程中失败。题目中提到函数成功被调用，因此并发限制不是最可能的原因。"
      },
      "B": {
        "option": "DynamoDB表需要一个全局二级索引（GSI）来支持写入操作。",
        "reason": "DynamoDB表默认支持写入操作，除非特定场景要求使用全局二级索引（GSI）。本题没有提到需要特定的索引来支持写入，因此这不是最可能的原因。"
      },
      "C": {
        "option": "Lambda函数没有向DynamoDB写入的IAM权限。",
        "reason": "如果Lambda函数没有适当的IAM权限来写入DynamoDB表，那么在尝试写入时会失败。这是最可能的原因，因为权限问题是常见的配置错误。"
      },
      "D": {
        "option": "DynamoDB表没有运行在与Lambda函数相同的可用区中。",
        "reason": "DynamoDB是一个全局分布的服务，可以跨多个可用区工作。Lambda函数和DynamoDB表不需要在相同的可用区中运行，因此这不是最可能的原因。"
      }
    }
  },
  {
    "number": "6",
    "best": ["D"],
    "question": "一名开发人员正在创建一个 AWS CloudFormation 模板，以跨多个 AWS 账户部署 Amazon EC2 实例。开发人员必须从批准的实例类型列表中选择 EC2 实例。开发人员如何在 CloudFormation 模板中合并批准的实例类型列表？",
    "options": {
      "A": {
        "option": "为列表中的每种 EC2 实例类型创建一个单独的 CloudFormation 模板。",
        "reason": "这种方法会导致创建和维护多个模板，增加了管理的复杂性和出错的风险，不是最佳实践。"
      },
      "B": {
        "option": "在 CloudFormation 模板的 Resources 部分，为列表中的每种 EC2 实例类型创建资源。",
        "reason": "这种方法虽然可以实现要求，但会导致模板冗长，并且不灵活，难以维护和管理。"
      },
      "C": {
        "option": "在 CloudFormation 模板中，为列表中的每种 EC2 实例类型创建一个单独的参数。",
        "reason": "这种方法增加了复杂性，因为用户需要为每个实例类型分别指定参数，不是最佳实践。"
      },
      "D": {
        "option": "在 CloudFormation 模板中，创建一个参数，并将 EC2 实例类型列表作为 AllowedValues。",
        "reason": "这是最佳方法，可以在参数中指定允许的 EC2 实例类型列表，使模板更加灵活和易于管理。用户可以通过选择这些允许的值来轻松指定实例类型。"
      }
    }
  },
  {
    "number": "7",
    "best": ["B", "D"],
    "question": "开发人员有一个应用程序，它通过使用 BatchGetItem 低级 API 操作直接向 Amazon DynamoDB 进行批量请求。响应中经常在 UnprocessedKeys 元素中返回值。当批量响应中包含 UnprocessedKeys 的值时，开发人员应采取哪些措施来提高应用程序的弹性？（选择两个）",
    "options": {
      "A": {
        "option": "立即重试批量操作。",
        "reason": "立即重试批量操作可能会导致过度的请求和更多的未处理密钥。这样做不会解决根本问题，可能会导致更高的延迟和更多的错误。"
      },
      "B": {
        "option": "使用指数退避和随机延迟重试批量操作。",
        "reason": "使用指数退避和随机延迟重试是 AWS 推荐的最佳实践。这有助于减少并发请求的冲突并提高批量操作的成功率。"
      },
      "C": {
        "option": "更新应用程序以使用 AWS 软件开发工具包 (AWS SDK) 进行请求。",
        "reason": "虽然使用 AWS SDK 可以简化代码并处理一些复杂的操作，但这并不会直接解决 UnprocessedKeys 的问题。"
      },
      "D": {
        "option": "增加操作访问的 DynamoDB 表的预置读取容量。",
        "reason": "增加读取容量可以减少未处理的读取请求，从而提高应用程序的弹性和响应能力。"
      },
      "E": {
        "option": "增加操作访问的 DynamoDB 表的预置写入容量。",
        "reason": "问题描述中提到的是读取操作，而不是写入操作。增加写入容量不会对该问题有直接帮助。"
      }
    }
  },
  {
    "number": "8",
    "best": ["B"],
    "question": "一家公司在一组本地的 Linux 服务器上运行自定义应用程序，这些应用程序通过 Amazon API Gateway 访问。AWS X-Ray 跟踪已在 API 测试阶段启用。开发人员如何以最少的配置在本地服务器上启用 X-Ray 跟踪？",
    "options": {
      "A": {
        "option": "在本地服务器上安装并运行 X-Ray SDK 以捕获并将数据传递到 X-Ray 服务。",
        "reason": "虽然 X-Ray SDK 可以捕获并传输数据，但它需要在应用程序代码中进行更多的集成和配置。相比之下，X-Ray daemon 的配置更少，因此不是最优选择。"
      },
      "B": {
        "option": "在本地服务器上安装并运行 X-Ray daemon 以捕获并将数据传递到 X-Ray 服务。",
        "reason": "X-Ray daemon 是独立的进程，能够捕获并传输跟踪数据，而无需对应用程序代码进行大量修改。这使其成为配置最少的解决方案。"
      },
      "C": {
        "option": "捕获本地请求并配置 AWS Lambda 函数以使用 PutTraceSegments API 调用拉取、处理和传递相关数据到 X-Ray。",
        "reason": "此选项需要创建和管理额外的 Lambda 函数，并且涉及更多的配置步骤和复杂性。因此，这不是最优选择。"
      },
      "D": {
        "option": "捕获本地请求并配置 AWS Lambda 函数以使用 PutTelemetryRecords API 调用拉取、处理和传递相关数据到 X-Ray。",
        "reason": "此选项同样需要创建和管理额外的 Lambda 函数，并且涉及更多的配置步骤和复杂性。因此，这不是最优选择。"
      }
    }
  },
  {
    "number": "9",
    "best": ["A"],
    "question": "一家公司希望与第三方共享信息。第三方有一个HTTP API端点，公司可以使用该端点来共享信息。公司拥有访问HTTP API所需的API密钥。公司需要一种使用代码管理API密钥的方法。API密钥与应用程序代码的集成不能影响应用程序性能。哪种解决方案最安全地满足这些要求？",
    "options": {
      "A": {
        "option": "将API凭证存储在AWS Secrets Manager中。在运行时使用AWS SDK检索API凭证。使用凭证进行API调用。",
        "reason": "AWS Secrets Manager专为存储和管理敏感信息（如API密钥、数据库凭证等）而设计。它提供了安全的存储、自动轮换和访问控制，确保凭证的安全性和可用性。在运行时使用AWS SDK检索凭证不会影响应用程序性能，这是最佳实践。"
      },
      "B": {
        "option": "将API凭证存储在本地代码变量中。将代码推送到安全的Git存储库。在运行时使用本地代码变量进行API调用。",
        "reason": "将敏感信息硬编码在代码中是不安全的做法，即使将代码存储在安全的Git存储库中，仍然存在泄露风险。此外，这种方法缺乏集中管理和自动轮换机制，不推荐。"
      },
      "C": {
        "option": "将API凭证作为对象存储在私有的Amazon S3桶中。使用IAM策略限制对S3对象的访问。在运行时使用AWS SDK检索API凭证。使用凭证进行API调用。",
        "reason": "虽然S3可以存储API凭证，并且可以通过IAM策略控制访问，但S3并不是专为存储和管理敏感信息而设计的。它缺乏Secrets Manager提供的自动轮换和其他安全功能。"
      },
      "D": {
        "option": "将API凭证存储在Amazon DynamoDB表中。使用基于资源的策略限制对表的访问。在运行时使用AWS SDK检索API凭证。使用凭证进行API调用。",
        "reason": "DynamoDB主要用于存储和检索数据，而不是专门设计用于管理敏感信息。尽管可以通过策略限制访问，但缺乏Secrets Manager提供的自动轮换和额外的安全特性。"
      }
    }
  },
  {
    "number": "10",
    "best": ["A"],
    "question": "开发人员正在将一个新应用程序部署到 Amazon Elastic Container Service (Amazon ECS)。开发人员需要安全地存储和检索不同类型的变量。这些变量包括远程 API 的身份验证信息、API 的 URL 和凭证。身份验证信息和 API URL 必须在开发、测试和生产环境中所有当前和未来部署的版本中可用。开发人员应如何在最少的应用程序更改下检索变量？",
    "options": {
      "A": {
        "option": "更新应用程序以从 AWS Systems Manager Parameter Store 检索变量。在 Parameter Store 中为每个环境的每个变量使用唯一路径。在每个环境中将凭证存储在 AWS Secrets Manager 中。",
        "reason": "AWS Systems Manager Parameter Store 是一个集中存储配置数据和管理配置参数的服务。它允许您以加密方式存储数据，并且支持版本控制。凭证存储在 AWS Secrets Manager 中，可以增强安全性，因为它专门用于管理秘密信息。这个选项可以确保变量在所有环境中可用，且只需最少的应用程序更改。"
      },
      "B": {
        "option": "更新应用程序以从 AWS Key Management Service (AWS KMS) 检索变量。将 API URL 和凭证存储为每个环境的唯一密钥。",
        "reason": "AWS Key Management Service (KMS) 主要用于管理加密密钥，而不是直接存储和检索配置数据。虽然可以使用 KMS 来加密和解密数据，但它并不是一种直接的、方便的配置管理解决方案。因此，这个选项不太适合这个场景。"
      },
      "C": {
        "option": "更新应用程序以从与应用程序一起存储的加密文件中检索变量。将 API URL 和凭证存储在每个环境的唯一文件中。",
        "reason": "使用加密文件来存储变量虽然可以解决存储和加密的问题，但在管理和维护多个环境中的变量时会带来复杂性和额外的开销。这需要更多的应用程序更改和管理工作，因此不如其他选项高效。"
      },
      "D": {
        "option": "更新应用程序以从每个部署的环境中检索变量。在部署过程中在 ECS 任务定义中以唯一名称定义身份验证信息和 API URL。",
        "reason": "在每次部署过程中手动定义变量增加了管理复杂性和出错的风险。每次部署都需要手动更新任务定义，这不利于自动化和持续集成/持续部署（CI/CD）流程。因此，这个选项不是最优选择。"
      }
    }
  },
  {
    "number": "11",
    "best": ["B"],
    "question": "一家公司正在将传统的内部应用程序迁移到 AWS。领导层希望重写内部员工目录以使用原生 AWS 服务。开发人员需要创建一个解决方案来存储员工联系信息和高分辨率照片，以用于新应用程序。哪种解决方案将使使用 AWS API 搜索和检索每个员工的个人详细信息和高分辨率照片成为可能？",
    "options": {
      "A": {
        "option": "使用 Base64 编码每个员工的联系信息和照片。使用排序键将信息存储在 Amazon DynamoDB 表中。",
        "reason": "虽然可以使用 Base64 编码将数据存储在 DynamoDB 中，但这不是高效的存储方式，尤其是对于高分辨率照片。Base64 编码会增加数据的大小，从而导致存储和检索成本增加。"
      },
      "B": {
        "option": "将每个员工的联系信息存储在 Amazon DynamoDB 表中，并将照片存储在 Amazon S3 中的对象键一起存储。",
        "reason": "这是最佳选项。DynamoDB 非常适合存储结构化数据（如员工联系信息），而 S3 非常适合存储大文件（如高分辨率照片）。通过将照片的对象键存储在 DynamoDB 中，可以轻松地检索和组合数据。"
      },
      "C": {
        "option": "使用 Amazon Cognito 用户池以完全托管的软件即服务 (SaaS) 方法实现员工目录。",
        "reason": "Amazon Cognito 主要用于身份验证和授权，而不是用于存储和检索联系信息和照片。因此，这不是一个合适的解决方案。"
      },
      "D": {
        "option": "将员工联系信息存储在 Amazon RDS DB 实例中，并将照片存储在 Amazon Elastic File System (Amazon EFS) 中。",
        "reason": "虽然这种方法是可行的，但它增加了复杂性和成本。RDS 适合关系型数据存储，而 EFS 适合文件存储。但对于高分辨率照片，使用 S3 更加高效和经济。"
      }
    }
  },
  {
    "number": "12",
    "best": ["B"],
    "question": "开发人员正在创建一个应用程序，该应用程序将使用户能够将手机上的照片存储在云中。该应用程序需要支持成千上万的用户。应用程序使用集成了 AWS Lambda 函数的 Amazon API Gateway REST API 来处理照片。应用程序将照片的详细信息存储在 Amazon DynamoDB 中。用户需要创建一个账户才能访问应用程序。在应用程序中，用户必须能够上传照片并检索以前上传的照片。照片的大小将从 300 KB 到 5 MB 不等。哪种解决方案可以在最少的操作开销下满足这些要求？",
    "options": {
      "A": {
        "option": "使用 Amazon Cognito 用户池管理用户账户。在 API Gateway 中创建一个 Amazon Cognito 用户池授权器来控制对 API 的访问。使用 Lambda 函数将照片和详细信息存储在 DynamoDB 表中。直接从 DynamoDB 表中检索以前上传的照片。",
        "reason": "此选项的主要问题是将照片存储在 DynamoDB 中并不是最佳选择，尤其是考虑到照片的大小范围（300 KB 到 5 MB）。DynamoDB 主要适用于存储结构化数据，不适合存储大文件。因此，这将增加不必要的存储成本和操作复杂性。"
      },
      "B": {
        "option": "使用 Amazon Cognito 用户池管理用户账户。在 API Gateway 中创建一个 Amazon Cognito 用户池授权器来控制对 API 的访问。使用 Lambda 函数将照片存储在 Amazon S3 中。将对象的 S3 键作为照片详细信息的一部分存储在 DynamoDB 表中。通过查询 DynamoDB 获取 S3 键来检索以前上传的照片。",
        "reason": "此选项提供了一个高效且可扩展的解决方案。Amazon S3 非常适合存储和检索大文件（如照片），并且具有高持久性和可扩展性。使用 Amazon Cognito 管理用户账户可以减少操作开销，而将 S3 键存储在 DynamoDB 中也有助于快速检索。"
      },
      "C": {
        "option": "在注册过程中为每个应用程序用户创建一个 IAM 用户。使用 IAM 认证访问 API Gateway API。使用 Lambda 函数将照片存储在 Amazon S3 中。将对象的 S3 键作为照片详细信息的一部分存储在 DynamoDB 表中。通过查询 DynamoDB 获取 S3 键来检索以前上传的照片。",
        "reason": "为每个用户创建 IAM 用户会导致极高的管理开销，特别是当用户数量达到成千上万时。这不是一个可扩展的解决方案。"
      },
      "D": {
        "option": "在 DynamoDB 中创建一个用户表。使用该表管理用户账户。创建一个 Lambda 授权器来验证用户表中的用户凭证。将 Lambda 授权器与 API Gateway 集成以控制对 API 的访问。使用 Lambda 函数将照片存储在 Amazon S3 中。将对象的 S3 键作为照片详细信息的一部分存储在 DynamoDB 表中。通过查询 DynamoDB 获取 S3 键来检索以前上传的照片。",
        "reason": "虽然这个方案是可行的，但在 DynamoDB 中管理用户账户和创建自定义 Lambda 授权器需要更多的开发和管理工作。相比之下，Amazon Cognito 提供了更简单和自动化的用户管理解决方案，因此选项 B 是更优的选择。"
      }
    }
  },
  {
    "number": "13",
    "best": ["C"],
    "question": "一家公司从多个合作伙伴处接收食品订单。公司有一个使用 Amazon API Gateway API 和 AWS Lambda 集成的微服务应用程序。每个合作伙伴通过调用 API Gateway 暴露的定制 API 来发送订单。API 调用会调用一个共享的 Lambda 函数来处理订单。Lambda 函数处理订单后需要通知合作伙伴。每个合作伙伴只需接收其自己的订单更新。公司希望在未来添加新合作伙伴时代码更改最少。哪种解决方案以最具可扩展性的方式满足这些要求？",
    "options": {
      "A": {
        "option": "为每个合作伙伴创建一个不同的 Amazon Simple Notification Service (Amazon SNS) 主题。配置 Lambda 函数将每个合作伙伴的消息发布到该合作伙伴的 SNS 主题。",
        "reason": "虽然这种方法可以实现目标，但为每个合作伙伴创建单独的 SNS 主题会导致管理上的复杂性，尤其是在增加新合作伙伴时，需要进行更多的配置和维护。"
      },
      "B": {
        "option": "为每个合作伙伴创建一个不同的 Lambda 函数。配置 Lambda 函数直接通知每个合作伙伴的服务端点。",
        "reason": "这种方法需要为每个合作伙伴创建单独的 Lambda 函数，增加了开发和维护的复杂性，并且不易扩展。"
      },
      "C": {
        "option": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题。配置 Lambda 函数将具有特定属性的消息发布到 SNS 主题。将每个合作伙伴订阅到 SNS 主题，并应用适当的过滤策略。",
        "reason": "这种方法是最具可扩展性的。通过使用 SNS 主题和过滤策略，可以确保每个合作伙伴只接收到他们自己的订单更新。添加新合作伙伴时，只需更新过滤策略，而不需要更改代码。"
      },
      "D": {
        "option": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题。将所有合作伙伴订阅到 SNS 主题。",
        "reason": "这种方法会导致所有合作伙伴收到所有订单的更新，而不仅仅是他们自己的订单更新，不符合题目要求。"
      }
    }
  },
  {
    "number": "14",
    "best": ["C"],
    "question": "一家金融公司出于法律原因必须储存原始客户记录10年。完整记录包含个人身份信息（PII）。根据当地法规，PII只能被公司内的特定人员访问，不能与第三方共享。公司需要让第三方机构进行统计分析，但不能共享PII。开发人员想把原始不可变记录存储在Amazon S3中。根据访问S3文档的人员不同，文档应该原样返回或删除所有PII。开发人员已写好一个名为removePii的AWS Lambda函数来删除文档中的PII。开发人员应该怎么做才能在只维护一份文档的情况下满足PII要求？",
    "options": {
      "A": {
        "option": "设置一个S3事件通知，在进行S3 GET请求时调用removePii函数。使用GET请求访问不包含PII的对象。",
        "reason": "该选项建议在每次GET请求时触发Lambda函数。此方法会对每次GET请求产生额外的延迟，且事件通知通常用于处理PUT、POST、COPY和DELETE操作，而不是GET操作。因此，这不是一个最佳选择。"
      },
      "B": {
        "option": "设置一个S3事件通知，在进行S3 PUT请求时调用removePii函数。使用PUT请求访问不包含PII的对象。",
        "reason": "该选项建议在每次PUT请求时触发Lambda函数，这意味着每次存储对象时都会删除PII，导致无法保留原始记录。因此，这不是一个最佳选择。"
      },
      "C": {
        "option": "从S3控制台创建一个S3 Object Lambda访问点。选择removePii函数。使用S3访问点访问不包含PII的对象。",
        "reason": "S3 Object Lambda允许在访问对象时动态处理数据。通过创建一个S3 Object Lambda访问点并选择removePii函数，可以确保在访问对象时删除PII，而无需维护多个副本。这是一个符合要求的最佳选择。"
      },
      "D": {
        "option": "从S3控制台创建一个S3访问点。使用访问点名称调用GetObjectLegalHold S3 API函数。传递removePii函数名称以访问不包含PII的对象。",
        "reason": "GetObjectLegalHold API用于管理对象的法律保留标记，与删除PII无关。因此，这不是一个可行的解决方案。"
      }
    }
  },
  {
    "number": "15",
    "best": ["B"],
    "question": "一名开发人员正在部署一个 AWS Lambda 函数。开发人员希望能够快速且无缝地返回到旧版本的函数。开发人员如何以最少的运营开销实现这一目标？",
    "options": {
      "A": {
        "option": "使用 AWS OpsWorks 执行蓝/绿部署。",
        "reason": "AWS OpsWorks 主要用于配置管理，不是专门为 Lambda 函数的版本管理设计的。而且，它的复杂性和运营开销较高，不是最佳选择。"
      },
      "B": {
        "option": "使用具有不同版本的函数别名。",
        "reason": "使用 Lambda 函数别名可以轻松管理不同版本的函数，并且可以快速切换到旧版本，运营开销最小。这是最优选项。"
      },
      "C": {
        "option": "在 Amazon S3 中维护旧版本的部署包。",
        "reason": "虽然可以在 S3 中存储旧版本的部署包，但这需要手动操作来管理版本，运营开销较大，不是最佳选择。"
      },
      "D": {
        "option": "使用 AWS CodePipeline 进行部署和回滚。",
        "reason": "AWS CodePipeline 可以自动化部署和回滚，但其设置和管理需要一定的复杂度，运营开销较高，不是最佳选择。"
      }
    }
  },
  {
    "number": "16",
    "best": ["B"],
    "question": "一位开发人员编写了一个 AWS Lambda 函数。该函数的性能受 CPU 限制。开发人员希望确保函数快速返回响应。开发人员可以如何提高函数的性能？",
    "options": {
      "A": {
        "option": "增加函数的 CPU 核心数量。",
        "reason": "AWS Lambda 的 CPU 配置是与内存配额相关联的。无法单独增加 CPU 核心数量，只能通过增加内存来间接增加 CPU 资源。"
      },
      "B": {
        "option": "增加函数的内存。",
        "reason": "在 AWS Lambda 中，内存的增加会相应增加 CPU 的资源配额。这是提高 CPU 受限函数性能的有效方法。"
      },
      "C": {
        "option": "增加函数的保留并发量。",
        "reason": "保留并发量控制的是某个特定 Lambda 函数能够并发执行的最大数量，对于单个执行的性能没有直接影响，因此无法解决 CPU 受限的问题。"
      },
      "D": {
        "option": "增加函数的超时时间。",
        "reason": "增加超时时间只是允许函数运行更长时间，但这并不能提高函数的性能。对于 CPU 受限的问题，增加内存是更有效的解决方案。"
      }
    }
  },
  {
    "number": "17",
    "best": ["B"],
    "question": "对于使用 AWS CodeDeploy 的部署，就地部署的钩子的运行顺序是什么？",
    "options": {
      "A": {
        "option": "BeforeInstall -> ApplicationStop -> ApplicationStart -> AfterInstall",
        "reason": "这个选项的顺序不正确。BeforeInstall 应该在 ApplicationStop 之后，而不是之前。"
      },
      "B": {
        "option": "ApplicationStop -> BeforeInstall -> AfterInstall -> ApplicationStart",
        "reason": "这是正确的运行顺序。在就地部署中，首先停止当前应用程序 (ApplicationStop)，然后进行安装前的操作 (BeforeInstall)，接着进行安装后的操作 (AfterInstall)，最后启动应用程序 (ApplicationStart)。"
      },
      "C": {
        "option": "BeforeInstall -> ApplicationStop -> ValidateService -> ApplicationStart",
        "reason": "这个选项的顺序不正确。ApplicationStop 应该在 BeforeInstall 之前，而不是之后。另外，ValidateService 不是常见的钩子步骤。"
      },
      "D": {
        "option": "ApplicationStop -> BeforeInstall -> ValidateService -> ApplicationStart",
        "reason": "这个选项的顺序不正确。虽然 ApplicationStop 和 BeforeInstall 的顺序正确，但 ValidateService 不是常见的钩子步骤。"
      }
    }
  },
  {
    "number": "18",
    "best": ["B"],
    "question": "一家公司正在 AWS 上构建一个无服务器应用程序。该应用程序使用 AWS Lambda 函数全天候处理客户订单。Lambda 函数调用外部供应商的 HTTP API 来处理支付。在负载测试期间，一名开发人员发现外部供应商支付处理 API 偶尔会超时并返回错误。公司预计某些支付处理 API 调用会返回错误。公司希望支持团队在支付处理外部 API 错误率超过每小时总交易数的 5% 时，能近乎实时地收到通知。开发人员需要使用现有的 Amazon Simple Notification Service (Amazon SNS) 主题，该主题已配置为通知支持团队。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "将支付处理 API 调用的结果写入 Amazon CloudWatch。使用 Amazon CloudWatch Logs Insights 查询 CloudWatch 日志。调度 Lambda 函数检查 CloudWatch 日志并通知现有的 SNS 主题。",
        "reason": "这个方案需要定期调度 Lambda 函数来检查日志文件，这会增加复杂性和延迟。虽然可以实现，但不是最佳选择。"
      },
      "B": {
        "option": "将外部支付处理 API 调用的失败情况发布为自定义指标到 CloudWatch。配置一个 CloudWatch 告警，当错误率超过指定的百分比时通知现有的 SNS 主题。",
        "reason": "这个选项是最佳选择，因为它利用了 CloudWatch 自定义指标和告警功能，可以实时监控错误率，并在错误率超过阈值时立即通知 SNS 主题，满足了实时通知的要求。"
      },
      "C": {
        "option": "将外部支付处理 API 调用的结果发布到一个新的 Amazon SNS 主题。将支持团队成员订阅到新的 SNS 主题。",
        "reason": "这个选项无法直接计算错误率并触发通知，需要额外的逻辑来分析和计算错误率，不是最佳选择。"
      },
      "D": {
        "option": "将外部支付处理 API 调用的结果写入 Amazon S3。定期调度 Amazon Athena 查询。配置 Athena 在错误率超过指定百分比时通知现有的 SNS 主题。",
        "reason": "虽然这个方案可以实现目标，但需要定期调度查询，会引入延迟。此外，将数据存储到 S3 并使用 Athena 查询增加了复杂性，不如选项 B 直接高效。"
      }
    }
  },
  {
    "number": "19",
    "best": ["A"],
    "question": "一家公司正在通过互联网提供API服务，提供对每日更新的统计信息的未认证读取访问。公司使用Amazon API Gateway和AWS Lambda开发API。由于服务变得流行，公司希望增强API的响应能力。哪种操作可以帮助公司实现这一目标？",
    "options": {
      "A": {
        "option": "在API Gateway中启用API缓存。",
        "reason": "启用API缓存可以显著提高API的响应速度，因为缓存可以减少对后端Lambda函数的调用次数，从而减少延迟。缓存通常用于处理经常请求的静态数据或不频繁更新的数据，这与题目中描述的每日更新的统计信息相符。"
      },
      "B": {
        "option": "配置API Gateway使用接口VPC端点。",
        "reason": "接口VPC端点用于在Amazon VPC内私密地访问AWS服务，而不是通过互联网访问。题目中提到的是互联网服务，因此这个选项不适用。"
      },
      "C": {
        "option": "为API启用跨域资源共享（CORS）。",
        "reason": "CORS是一个Web浏览器的安全功能，用于允许或限制不同域名之间的资源共享。虽然启用CORS对跨域请求有帮助，但它并不会直接提高API的响应速度。"
      },
      "D": {
        "option": "在API Gateway中配置使用计划和API密钥。",
        "reason": "使用计划和API密钥用于控制API的访问和使用限制，例如速率限制和配额。虽然这对管理API的使用非常有用，但它并不会直接提高API的响应速度。"
      }
    }
  },
  {
    "number": "20",
    "best": ["A"],
    "question": "一名开发人员希望存储有关电影的信息。每部电影都有一个标题、发行年份和类型。电影信息还可以包括关于演员和制作人员的额外属性。这些额外信息在不同的电影中是不一致的。例如，一部电影可能有一个助理导演，另一部电影可能有一个动物训练师。开发人员需要实现一个解决方案来支持以下用例：对于给定的标题和发行年份，获取具有该标题和发行年份的电影的所有详细信息。对于给定的标题，获取所有具有该标题的电影的所有详细信息。对于给定的类型，获取所有该类型的电影的所有详细信息。哪种数据存储配置可以满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个Amazon DynamoDB表。将表配置为使用标题作为分区键，发行年份作为排序键。创建一个使用类型作为分区键，标题作为排序键的全局二级索引。",
        "reason": "选项A最符合题目要求。使用DynamoDB表，主键由标题（分区键）和发行年份（排序键）组成，可以有效地查询特定标题和年份的电影。全局二级索引（GSI）使用类型作为分区键，标题作为排序键，可以有效地查询特定类型的所有电影，这样可以满足所有查询需求。DynamoDB还支持存储不一致的额外属性。"
      },
      "B": {
        "option": "创建一个Amazon DynamoDB表。将表配置为使用类型作为分区键，发行年份作为排序键。创建一个使用标题作为分区键的全局二级索引。",
        "reason": "选项B不太适合。虽然它可以通过类型和发行年份进行查询，但无法有效地查询特定标题和年份的电影。使用标题作为GSI的分区键也不适合查询所有同类型电影的信息。"
      },
      "C": {
        "option": "在Amazon RDS数据库实例上，创建一个包含标题、发行年份和类型列的表。将标题配置为主键。",
        "reason": "选项C不太适合。使用关系型数据库（RDS）无法灵活地处理不一致的额外属性，并且标题作为主键无法唯一标识同一标题的不同年份的电影。此外，查询同类型的所有电影也不够高效。"
      },
      "D": {
        "option": "在Amazon RDS数据库实例上创建一个表，主键是标题，所有其他数据都编码为一个额外的JSON格式列。",
        "reason": "选项D不太适合。虽然JSON格式可以存储不一致的额外属性，但使用RDS处理JSON数据查询效率较低。标题作为主键无法唯一标识同一标题的不同年份的电影，且查询特定类型的所有电影也不够高效。"
      }
    }
  },
  {
    "number": "21",
    "best": ["A"],
    "question": "一个开发人员维护一个 Amazon API Gateway REST API。客户通过前端 UI 和 Amazon Cognito 认证来使用该 API。开发人员有一个包含新端点和向后不兼容接口更改的新版本 API。开发人员需要为团队中的其他开发人员提供 beta 访问权限，而不影响客户。哪种解决方案将在最低运营开销下满足这些要求？",
    "options": {
      "A": {
        "option": "在 API Gateway API 上定义一个开发阶段。指示其他开发人员将端点指向开发阶段。",
        "reason": "这个选项允许开发人员在不影响当前客户的情况下测试新版本的 API。通过定义一个新的开发阶段，开发人员可以在不同的环境中进行测试，从而减少对生产环境的影响。这种方法的运营开销较低，因为它利用了现有的 API Gateway 配置，而不需要创建新的 API 或进行代码更改。"
      },
      "B": {
        "option": "定义一个指向新 API 应用程序代码的新 API Gateway API。指示其他开发人员将端点指向新的 API。",
        "reason": "虽然这个选项也能提供测试环境，但它需要创建一个全新的 API Gateway API，这会增加运营开销和复杂性。相比之下，使用现有 API 的开发阶段更为简单和高效。"
      },
      "C": {
        "option": "在 API 应用程序代码中实现一个查询参数，以确定调用哪个代码版本。",
        "reason": "这种方法需要修改应用程序代码，增加了开发和维护的复杂性，同时可能会影响现有客户的使用体验。因此，这不是一个理想的选择。"
      },
      "D": {
        "option": "为开发人员想要添加的 API 端点指定新的 API Gateway 端点。",
        "reason": "这种方法会增加 API 端点的数量，增加管理的复杂性，并且可能导致客户混淆。相比之下，使用开发阶段的方法更为高效且运营开销较低。"
      }
    }
  },
  {
    "number": "22",
    "best": ["A"],
    "question": "开发人员正在创建一个将存储个人健康信息（PHI）的应用程序。PHI 需要始终加密。一台加密的 Amazon RDS for MySQL 数据库实例正在存储数据。开发人员希望通过缓存经常访问的数据来提高应用程序的性能，同时添加对缓存数据集进行排序或排名的能力。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个 Amazon ElastiCache for Redis 实例。启用数据在传输和静止时的加密。将经常访问的数据存储在缓存中。",
        "reason": "Amazon ElastiCache for Redis 提供了丰富的数据结构，可以轻松实现数据排序和排名。同时，Redis 支持对数据进行传输和静止时的加密，满足了 PHI 的安全性要求。"
      },
      "B": {
        "option": "创建一个 Amazon ElastiCache for Memcached 实例。启用数据在传输和静止时的加密。将经常访问的数据存储在缓存中。",
        "reason": "虽然 Memcached 也可以用于缓存，但它不支持像 Redis 那样丰富的数据结构，因此在处理排序和排名时可能会不太方便。而且，Memcached 的加密支持也不如 Redis 完善。"
      },
      "C": {
        "option": "创建一个 Amazon RDS for MySQL 只读副本。通过 SSL 连接到只读副本。配置只读副本以存储经常访问的数据。",
        "reason": "虽然只读副本可以提高读取性能，但它并不是一个缓存解决方案。它仍然需要访问数据库，而且无法像缓存一样快速地响应频繁请求。"
      },
      "D": {
        "option": "创建一个 Amazon DynamoDB 表和一个针对该表的 DynamoDB Accelerator (DAX) 集群。将经常访问的数据存储在 DynamoDB 表中。",
        "reason": "虽然 DynamoDB 和 DAX 提供了快速的读取性能，但它们主要用于 NoSQL 数据存储，不适合需要复杂数据结构和排序操作的场景。此外，DynamoDB 的加密功能也不如 Redis 那么全面。"
      }
    }
  },
  {
    "number": "23",
    "best": ["C"],
    "question": "一家公司有一个多节点的 Windows 旧版应用程序在本地运行。该应用程序使用网络共享文件夹作为集中配置库来存储 .xml 格式的配置文件。公司正在将应用程序迁移到 Amazon EC2 实例。作为迁移到 AWS 的一部分，开发人员必须确定一个提供高可用性存储库的解决方案。哪种解决方案将以最具成本效益的方式满足此要求？",
    "options": {
      "A": {
        "option": "将一个 Amazon Elastic Block Store (Amazon EBS) 卷挂载到其中一个 EC2 实例上。在 EBS 卷上部署文件系统。使用主机操作系统共享一个文件夹。更新应用程序代码以从共享文件夹读取和写入配置文件。",
        "reason": "此选项使用 EBS 卷，但 EBS 卷是单个实例的存储，虽然可以实现高性能，但并不适合高可用性需求。而且，需要依赖操作系统进行文件共享，管理复杂度较高。适用于单实例存储需求，但不适用于多实例高可用性。"
      },
      "B": {
        "option": "部署一个带有实例存储卷的微型 EC2 实例。使用主机操作系统共享一个文件夹。更新应用程序代码以从共享文件夹读取和写入配置文件。",
        "reason": "实例存储卷是临时存储，实例停止或崩溃时数据会丢失。这不符合高可用性的要求。适用于临时数据的高性能访问，但不适用于持久存储和高可用性。"
      },
      "C": {
        "option": "创建一个 Amazon S3 存储桶来托管存储库。将现有的 .xml 文件迁移到 S3 存储桶。更新应用程序代码以使用 AWS SDK 从 Amazon S3 读取和写入配置文件。",
        "reason": "Amazon S3 提供了高度的持久性和可用性，同时成本低廉。使用 AWS SDK 可以轻松地从 S3 读取和写入文件，适合高可用性和持久存储需求。非常适合需要跨多个实例访问的数据存储。"
      },
      "D": {
        "option": "创建一个 Amazon S3 存储桶来托管存储库。将现有的 .xml 文件迁移到 S3 存储桶。将 S3 存储桶作为本地卷挂载到 EC2 实例。更新应用程序代码以从磁盘读取和写入配置文件。",
        "reason": "虽然可以将 S3 挂载为本地卷，但这种方法可能会增加复杂性和潜在的性能问题。直接使用 AWS SDK 访问 S3 更为简便和高效。适用于需要将 S3 作为文件系统使用的场景，但不如直接使用 AWS SDK 读取和写入高效。"
      }
    }
  },
  {
    "number": "24",
    "best": ["A"],
    "question": "一家公司希望在 AWS 上部署和维护静态网站。每个网站的源代码托管在多个版本控制系统中，包括 AWS CodeCommit、Bitbucket 和 GitHub。公司希望通过在 AWS 云中使用开发、暂存、用户验收测试和生产环境来实现分阶段发布。对每个环境的部署必须通过相关 Git 分支上的代码合并来启动。公司希望所有数据交换都使用 HTTPS。公司需要一个不要求服务器持续运行的解决方案。哪种解决方案能以最少的运营开销满足这些要求？",
    "options": {
      "A": {
        "option": "使用 AWS Amplify 和无服务器后端托管每个网站。连接对应于每个所需环境的存储库分支。通过将代码更改合并到所需分支来启动部署。",
        "reason": "AWS Amplify 是一个适用于前端和移动开发人员的全面工具链，支持静态网站和无服务器后端。Amplify 与多个版本控制系统集成，支持基于分支的部署。它支持 HTTPS 并且不需要持续运行的服务器，因此运营开销低。"
      },
      "B": {
        "option": "使用具有多个环境的 AWS Elastic Beanstalk 托管每个网站。使用 EB CLI 链接每个存储库分支。集成 AWS CodePipeline 以自动化从版本控制代码合并的部署。",
        "reason": "Elastic Beanstalk 适用于托管和管理应用程序，但对于静态网站来说可能过于复杂，并且需要更多的管理工作。此外，它通常用于处理动态内容的应用，而不是纯静态网站。"
      },
      "C": {
        "option": "在每个环境中将每个网站托管在不同的 Amazon S3 存储桶中。配置 AWS CodePipeline 从版本控制中拉取源代码。添加 AWS CodeBuild 阶段以将源代码复制到 Amazon S3。",
        "reason": "这个选项是可行的，但涉及配置和管理多个 S3 存储桶、CodePipeline 和 CodeBuild 阶段，增加了运营开销。相比之下，AWS Amplify 提供了更简便的解决方案。"
      },
      "D": {
        "option": "在各自的 Amazon EC2 实例上托管每个网站。编写自定义部署脚本来打包每个网站的静态资产。将资产复制到 Amazon EC2。当代码合并时设置一个工作流来运行脚本。",
        "reason": "这个选项需要持续运行的 EC2 实例和自定义脚本，运营开销高，并不符合静态网站的最佳实践。"
      }
    }
  },
  {
    "number": "25",
    "best": ["C"],
    "question": "一家公司正在将本地数据库迁移到 Amazon RDS for MySQL。该公司的工作负载读取量较大。公司希望重构代码以实现查询的最佳读取性能。哪种解决方案在目前和未来都能以最少的工作量满足这一要求？",
    "options": {
      "A": {
        "option": "使用多可用区的 Amazon RDS 部署。如果在使用连接池，则增加代码对数据库的连接数或增加连接池的大小。",
        "reason": "虽然增加连接数或连接池大小可能会提升性能，但这并不是针对读取量大的最佳解决方案。同时，Multi-AZ 主要用于高可用性和故障恢复，而不是读取性能优化。"
      },
      "B": {
        "option": "使用多可用区的 Amazon RDS 部署。修改代码以便查询访问次要 RDS 实例。",
        "reason": "在 Multi-AZ 部署中，次要实例是用于故障转移的，不用于处理读取请求。这样做不符合最佳实践，也不会提升读取性能。"
      },
      "C": {
        "option": "部署具有一个或多个只读副本的 Amazon RDS。修改应用程序代码以便查询使用只读副本的 URL。",
        "reason": "只读副本是专门为处理读取密集型工作负载而设计的。通过将读取操作分布到多个副本上，这种方法可以显著提升读取性能，并且具有较低的当前和未来维护工作量。"
      },
      "D": {
        "option": "使用开源复制软件在 Amazon EC2 实例上创建 MySQL 数据库的副本。修改应用程序代码以便查询使用 EC2 实例的 IP 地址。",
        "reason": "在 EC2 实例上自行管理数据库复制需要更多的维护工作和复杂性。相比 RDS 只读副本，这不是一个高效且易于维护的解决方案。"
      }
    }
  },
  {
    "number": "26",
    "best": ["B"],
    "question": "一名开发人员正在创建一个将在物联网设备上部署的应用程序。该应用程序将向作为AWS Lambda函数部署的RESTful API发送数据。应用程序将为每个API请求分配一个唯一标识符。应用程序的API请求量可能在一天中的任何时间随机增加。在请求节流期间，应用程序可能需要重试请求。API必须能够处理重复请求而不产生不一致或数据丢失。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个Amazon RDS for MySQL数据库实例。在数据库表中存储每个请求的唯一标识符。在处理请求之前，修改Lambda函数以检查表中的标识符。",
        "reason": "虽然Amazon RDS for MySQL可以存储唯一标识符，但关系型数据库的写入性能可能不如NoSQL数据库，尤其是在处理大量写入请求时。由于请求量可能随机增加，RDS可能无法有效处理高峰负载，导致延迟或性能问题。"
      },
      "B": {
        "option": "创建一个Amazon DynamoDB表。在表中存储每个请求的唯一标识符。在处理请求之前，修改Lambda函数以检查表中的标识符。",
        "reason": "Amazon DynamoDB是一种高度可扩展的NoSQL数据库，适用于处理高频次写入请求。它提供了高吞吐量和低延迟，非常适合处理物联网设备的高并发请求。因此，这个选项是最优解，可以满足唯一标识符检查、处理高并发请求以及避免数据丢失的需求。"
      },
      "C": {
        "option": "创建一个Amazon DynamoDB表。在表中存储每个请求的唯一标识符。当Lambda函数收到重复请求时，修改函数以返回客户端错误响应。",
        "reason": "虽然这个选项也使用了DynamoDB，但它建议在重复请求时返回客户端错误响应，这可能不符合应用程序的业务需求。重试机制可能需要能够处理重复请求而不是简单地返回错误。"
      },
      "D": {
        "option": "创建一个Amazon ElastiCache for Memcached实例。在缓存中存储每个请求的唯一标识符。在处理请求之前，修改Lambda函数以检查缓存中的标识符。",
        "reason": "ElastiCache for Memcached是一个内存缓存服务，适用于需要快速访问的临时数据。然而，缓存数据的持久性和一致性不如DynamoDB，可能在高负载情况下导致数据丢失或不一致。因此，尽管它可以快速存取数据，但并不是处理持久性数据存储和高并发请求的最佳选择。"
      }
    }
  },
  {
    "number": "27",
    "best": ["A"],
    "question": "一名开发人员希望扩展应用程序以在多个 AWS 区域运行。开发人员希望复制具有最新更改的 Amazon 机器映像（AMIs），并在目标区域创建新的应用程序栈。根据公司要求，所有 AMIs 必须在所有区域进行加密。但是，公司使用的并非所有 AMIs 都是加密的。开发人员如何在满足加密要求的同时将应用程序扩展到目标区域运行？",
    "options": {
      "A": {
        "option": "创建新的 AMIs，并指定加密参数。将加密的 AMIs 复制到目标区域。删除未加密的 AMIs。",
        "reason": "这个选项是最优解，因为它确保了所有 AMIs 在复制之前都是加密的，并且符合公司要求。这也是常见的做法，通过指定加密参数来创建新的 AMIs，从而确保数据安全。"
      },
      "B": {
        "option": "使用 AWS Key Management Service (AWS KMS) 对未加密的 AMIs 启用加密。将加密的 AMIs 复制到目标区域。",
        "reason": "这个选项看似可行，但 AWS KMS 并不能直接对已有的未加密 AMIs 进行加密。KMS 主要用于管理和创建加密密钥，而不是直接加密已有的 AMIs。"
      },
      "C": {
        "option": "使用 AWS Certificate Manager (ACM) 对未加密的 AMIs 启用加密。将加密的 AMIs 复制到目标区域。",
        "reason": "这个选项是不正确的，因为 AWS Certificate Manager (ACM) 的主要功能是管理 SSL/TLS 证书，而不是加密 AMIs。"
      },
      "D": {
        "option": "将未加密的 AMIs 复制到目标区域。在目标区域启用默认加密。",
        "reason": "这个选项不符合要求，因为在将 AMIs 复制到目标区域之前，它们仍然是未加密的，这不满足公司所有 AMIs 必须加密的要求。"
      }
    }
  },
  {
    "number": "28",
    "best": ["C"],
    "question": "一家公司为其子公司之一在 Amazon S3 上托管了一个客户端 Web 应用程序。该 Web 应用程序可以通过 Amazon CloudFront 从 https://www.example.com 访问。成功上线后，公司希望为其剩余的子公司再托管三个客户端 Web 应用程序在三个单独的 S3 存储桶中。为了实现这个目标，开发人员将所有常用的 JavaScript 文件和 Web 字体移动到一个中央 S3 存储桶中，该存储桶为 Web 应用程序提供服务。但是，在测试期间，开发人员注意到浏览器阻止了 JavaScript 文件和 Web 字体。开发人员应该怎么做以防止浏览器阻止 JavaScript 文件和 Web 字体？",
    "options": {
      "A": {
        "option": "创建四个允许访问中央 S3 存储桶的访问点。为每个 Web 应用程序存储桶分配一个访问点。",
        "reason": "此选项涉及到 S3 访问点，它们能简化对特定 S3 对象的访问管理。然而，它并不能解决浏览器阻止资源的问题，因为阻止的原因是跨来源资源共享 (CORS) 而非访问权限。"
      },
      "B": {
        "option": "创建一个允许访问中央 S3 存储桶的存储桶策略。将存储桶策略附加到中央 S3 存储桶。",
        "reason": "虽然存储桶策略可以控制对 S3 存储桶的访问，但这并不能解决跨来源资源共享 (CORS) 的问题。浏览器会继续阻止请求，因为它们来自不同的来源。"
      },
      "C": {
        "option": "创建一个允许访问中央 S3 存储桶的跨来源资源共享 (CORS) 配置。将 CORS 配置添加到中央 S3 存储桶。",
        "reason": "这是最佳选项。CORS 配置允许浏览器从一个来源访问托管在另一个来源的资源。通过在中央 S3 存储桶中配置 CORS，开发人员可以允许 Web 应用程序访问共享的 JavaScript 文件和 Web 字体。"
      },
      "D": {
        "option": "创建一个提供消息完整性检查的 Content-MD5 头。为每个 Web 应用程序请求插入 Content-MD5 头。",
        "reason": "Content-MD5 头用于确保数据传输的完整性，但它并不能解决跨来源资源共享 (CORS) 的问题，因而无法防止浏览器阻止资源。"
      }
    }
  },
  {
    "number": "29",
    "best": ["A", "C"],
    "question": "一个应用程序正在使用 Amazon Kinesis 处理点击流数据。点击流数据输入 Kinesis 时会出现周期性峰值。PutRecords API 调用偶尔会失败，日志显示失败调用返回如下响应：哪种技术将有助于缓解此异常？（选择两项）",
    "options": {
      "A": {
        "option": "实现带有指数退避的重试机制。",
        "reason": "实现带有指数退避的重试机制可以帮助处理瞬时的服务端限制错误，Kinesis 在高流量或突发流量情况下可能会遇到这种错误。通过指数退避，应用程序可以在失败后等待一段时间再尝试，从而减少重试的频率并增加成功的机会。"
      },
      "B": {
        "option": "使用 PutRecord API 而不是 PutRecords。",
        "reason": "PutRecord API 每次只能发送一条记录，而 PutRecords API 可以批量发送多条记录。使用 PutRecord 会增加 API 调用的次数，从而可能增加失败的概率，并且没有利用批量处理的优势。"
      },
      "C": {
        "option": "减少请求的频率和/或大小。",
        "reason": "减少请求的频率和/或大小可以减轻 Kinesis 的负载，防止达到服务的限制。通过控制请求的大小和频率，可以更好地管理流量峰值，减少 API 调用失败的可能性。"
      },
      "D": {
        "option": "使用 Amazon SNS 而不是 Kinesis。",
        "reason": "Amazon SNS 是一种消息传递服务，与 Kinesis 的流数据处理用途不同。SNS 更适用于发布/订阅消息模式，不适合用于实时处理高吞吐量的点击流数据。"
      },
      "E": {
        "option": "减少 KCL 消费者的数量。",
        "reason": "减少 KCL（Kinesis Client Library）消费者数量不会直接解决 PutRecords API 调用失败的问题。消费者的数量通常与数据处理能力有关，而不是数据输入的能力。因此，这不是一个有效的解决方案。"
      }
    }
  },
  {
    "number": "30",
    "best": ["B"],
    "question": "公司有一个应用程序使用 Amazon Cognito 用户池作为身份提供者。公司必须确保对用户记录的访问安全。公司已经设置了多因素认证（MFA）。公司还希望每次用户登录时通过电子邮件发送登录活动通知。哪种解决方案在操作上最有效，以满足这一要求？",
    "options": {
      "A": {
        "option": "创建一个使用 Amazon Simple Email Service (Amazon SES) 发送电子邮件通知的 AWS Lambda 函数。添加一个 Amazon API Gateway API 来调用该函数。当收到登录确认时从客户端调用该 API。",
        "reason": "此选项需要在客户端进行额外的开发工作，并且需要维护 API 网关，增加了复杂性和维护成本，操作效率较低。"
      },
      "B": {
        "option": "创建一个使用 Amazon Simple Email Service (Amazon SES) 发送电子邮件通知的 AWS Lambda 函数。为该函数添加一个 Amazon Cognito 认证后 Lambda 触发器。",
        "reason": "此选项利用了 Amazon Cognito 本身的功能，在用户成功登录后自动触发 Lambda 函数，直接发送电子邮件通知。这是最简洁、最有效的解决方案，因为它完全在 AWS 服务内部进行管理，减少了操作和维护的复杂性。"
      },
      "C": {
        "option": "创建一个使用 Amazon Simple Email Service (Amazon SES) 发送电子邮件通知的 AWS Lambda 函数。创建一个 Amazon CloudWatch Logs 日志订阅过滤器，根据登录状态调用该函数。",
        "reason": "此选项需要设置和管理 CloudWatch Logs 和日志订阅过滤器，这增加了系统的复杂性和维护工作，不如选项 B 操作效率高。"
      },
      "D": {
        "option": "配置 Amazon Cognito 将所有日志流传输到 Amazon Kinesis Data Firehose。创建一个 AWS Lambda 函数来处理这些流日志并根据每个用户的登录状态发送电子邮件通知。",
        "reason": "此选项需要配置和管理 Kinesis Data Firehose 流和 Lambda 函数来处理流数据，增加了系统的复杂性和运营成本，不如选项 B 操作效率高。"
      }
    }
  },
  {
    "number": "31",
    "best": ["B"],
    "question": "某开发人员有一个应用程序，该应用程序将数据存储在 Amazon S3 存储桶中。该应用程序使用 HTTP API 存储和检索对象。当 PutObject API 操作将对象添加到 S3 存储桶时，开发人员必须使用 Amazon S3 管理密钥 (SSE-S3) 对这些对象进行静态加密。哪种解决方案可以满足此要求？",
    "options": {
      "A": {
        "option": "创建一个 AWS Key Management Service (AWS KMS) 密钥。将 KMS 密钥分配给 S3 存储桶。",
        "reason": "此选项不符合要求，因为题目中要求使用 Amazon S3 管理密钥 (SSE-S3) 进行加密，而不是使用 AWS KMS 密钥 (SSE-KMS)。"
      },
      "B": {
        "option": "在调用 PutObject API 操作时设置 x-amz-server-side-encryption 标头。",
        "reason": "此选项符合要求。通过设置 x-amz-server-side-encryption 标头并将其值设为 'AES256'，可以启用 SSE-S3 加密。"
      },
      "C": {
        "option": "在每个请求的 HTTP 标头中提供加密密钥。",
        "reason": "此选项不合适。SSE-S3 不需要开发人员提供加密密钥；Amazon S3 管理密钥自动处理加密和解密。"
      },
      "D": {
        "option": "应用 TLS 以加密到 S3 存储桶的流量。",
        "reason": "虽然 TLS 可以保护传输中的数据，但它与静态加密无关。题目要求的是在静态时使用 SSE-S3 进行加密。"
      }
    }
  },
  {
    "number": "32",
    "best": ["B"],
    "question": "开发人员需要对一个 API 进行地理负载测试。开发人员必须在多个 AWS 区域部署资源以支持 API 的负载测试。开发人员如何在不添加额外应用程序代码的情况下满足这些要求？",
    "options": {
      "A": {
        "option": "在每个所需的区域创建和部署一个 AWS Lambda 函数。配置 Lambda 函数以便在调用函数时从 AWS CloudFormation 模板创建一个堆栈。",
        "reason": "这种方法涉及到多个步骤和手动配置，增加了复杂性和出错的可能性。而且，使用 Lambda 函数来创建堆栈并不是最直接的方法。"
      },
      "B": {
        "option": "创建一个定义负载测试资源的 AWS CloudFormation 模板。使用 AWS CLI create-stack-set 命令在所需的区域创建一个堆栈集。",
        "reason": "这是最合适的解决方案。使用 CloudFormation StackSets 可以在多个 AWS 区域部署同一套资源，从而实现一致性和简化管理。StackSets 支持跨区域操作，并且不需要额外的应用程序代码。"
      },
      "C": {
        "option": "创建一个定义资源的 AWS Systems Manager 文档。使用该文档在所需的区域创建资源。",
        "reason": "虽然 AWS Systems Manager 可以管理跨区域的资源，但它主要用于系统管理任务（例如补丁管理、配置合规性检查），而不是部署和管理基础设施资源。"
      },
      "D": {
        "option": "创建一个定义负载测试资源的 AWS CloudFormation 模板。使用 AWS CLI deploy 命令在每个区域从模板创建一个堆栈。",
        "reason": "虽然这种方法也能实现目标，但需要分别在每个区域手动执行 deploy 命令，不如使用 StackSets 的方案高效和简洁。"
      }
    }
  },
  {
    "number": "33",
    "best": ["D"],
    "question": "开发人员正在创建一个包括位于us-east-2区域的Amazon API Gateway REST API的应用程序。开发人员希望为API使用Amazon CloudFront和自定义域名。开发人员已从第三方提供商处获取了该域名的SSL/TLS证书。开发人员应如何配置应用程序的自定义域名？",
    "options": {
      "A": {
        "option": "将SSL/TLS证书导入到与API同一区域的AWS证书管理器（ACM）中。为自定义域名创建一个DNS A记录。",
        "reason": "虽然将证书导入到与API同一区域的ACM中是正确的，但使用DNS A记录并不是最佳实践。对于API Gateway和CloudFront的自定义域名，通常使用CNAME记录。"
      },
      "B": {
        "option": "将SSL/TLS证书导入CloudFront。为自定义域名创建一个DNS CNAME记录。",
        "reason": "虽然使用CloudFront和CNAME记录是正确的，但CloudFront不直接支持导入第三方证书。证书需要导入到ACM中，尤其是在us-east-1区域，以便CloudFront使用。"
      },
      "C": {
        "option": "将SSL/TLS证书导入到与API同一区域的AWS证书管理器（ACM）中。为自定义域名创建一个DNS CNAME记录。",
        "reason": "尽管在API所在区域导入证书是正确的，但CloudFront要求证书位于us-east-1区域。"
      },
      "D": {
        "option": "将SSL/TLS证书导入到us-east-1区域的AWS证书管理器（ACM）中。为自定义域名创建一个DNS CNAME记录。",
        "reason": "这是最佳答案。CloudFront要求证书存储在us-east-1区域的ACM中，即使API Gateway在其他区域。使用DNS CNAME记录也是正确的做法。"
      }
    }
  },
  {
    "number": "34",
    "best": ["C"],
    "question": "开发人员正在创建一个使用 AWS CloudFormation 部署应用程序的模板。该应用程序是无服务器的并使用 Amazon API Gateway、Amazon DynamoDB 和 AWS Lambda。开发人员应该使用哪个 AWS 服务或工具在 YAML 中定义无服务器资源？",
    "options": {
      "A": {
        "option": "CloudFormation 无服务器内置函数",
        "reason": "虽然 CloudFormation 提供了一些内置函数用于定义和管理资源，但它并没有专门的无服务器内置函数来简化无服务器架构的定义。"
      },
      "B": {
        "option": "AWS Elastic Beanstalk",
        "reason": "AWS Elastic Beanstalk 是一个用于快速部署和管理应用程序的服务，但它主要用于基于 EC2 的应用程序，而不是无服务器应用程序。"
      },
      "C": {
        "option": "AWS 无服务器应用程序模型 (AWS SAM)",
        "reason": "AWS SAM 是一种用于定义和部署无服务器应用程序的框架。它扩展了 AWS CloudFormation 的功能，提供了一些简化的语法来定义无服务器资源，如 Lambda 函数、API Gateway 和 DynamoDB 表，因此是最适合此场景的工具。"
      },
      "D": {
        "option": "AWS 云开发工具包 (AWS CDK)",
        "reason": "AWS CDK 是一种用编程语言来定义云基础设施的工具，虽然它也可以用于定义无服务器架构，但题目中特别提到需要使用 YAML，而 AWS SAM 更加适合这种场景。"
      }
    }
  },
  {
    "number": "35",
    "best": ["B"],
    "question": "开发人员希望在将新文件添加到 Amazon S3 存储桶时立即将记录插入到 Amazon DynamoDB 表中。实现此目标需要哪些步骤？",
    "options": {
      "A": {
        "option": "创建一个事件与 Amazon EventBridge 监控 S3 存储桶，然后将记录插入到 DynamoDB。",
        "reason": "虽然 Amazon EventBridge 可以用于监控事件，但直接使用 S3 事件通知更为合适。EventBridge 通常用于跨服务的复杂事件处理，而这里的需求相对简单。"
      },
      "B": {
        "option": "配置一个 S3 事件以调用一个插入记录到 DynamoDB 的 AWS Lambda 函数。",
        "reason": "这是最佳选项。S3 事件通知可以直接触发 AWS Lambda 函数，而不需要额外的轮询或时间调度。Lambda 函数可以处理事件并将记录插入到 DynamoDB 里，这种方式高效且延迟低。"
      },
      "C": {
        "option": "创建一个 AWS Lambda 函数，轮询 S3 存储桶，然后将记录插入到 DynamoDB。",
        "reason": "不推荐。轮询 S3 存储桶会导致不必要的性能开销和延迟。S3 事件通知能够自动触发 Lambda 函数，无需轮询。"
      },
      "D": {
        "option": "创建一个定时任务，在预定时间运行并将记录插入到 DynamoDB。",
        "reason": "不合适。定时任务无法实时响应 S3 中的新文件添加事件，无法满足立即插入记录的需求。"
      }
    }
  },
  {
    "number": "36",
    "best": ["A", "B"],
    "question": "一个开发团队使用单个 AWS CloudFormation 模板维护一个 Web 应用程序。模板定义了 Web 服务器和一个 Amazon RDS 数据库。团队使用 CloudFormation 模板在不同环境中部署 CloudFormation 堆栈。在最近的应用程序部署中，一名开发人员导致主开发数据库被删除并重新创建。此次事件的结果是数据丢失。团队需要避免将来意外删除数据库。哪些解决方案可以满足这些要求？（选择两个）",
    "options": {
      "A": {
        "option": "为数据库资源添加一个具有 Retain 值的 CloudFormation 删除策略属性。",
        "reason": "使用 CloudFormation 的 DeletionPolicy 属性并设置为 Retain，可以防止在删除 CloudFormation 堆栈时删除数据库资源。这样可以确保数据库不会被意外删除，从而避免数据丢失。"
      },
      "B": {
        "option": "更新 CloudFormation 堆栈策略以防止对数据库的更新。",
        "reason": "通过更新 CloudFormation 堆栈策略，可以将对数据库资源的更新操作限制为只读，从而防止意外的删除或修改操作。这可以作为一种保护机制，确保数据库的安全。"
      },
      "C": {
        "option": "将数据库修改为使用 Multi-AZ 部署。",
        "reason": "Multi-AZ 部署可以提供高可用性和数据冗余，但它无法防止意外删除数据库。因此，虽然它对提高数据库的可用性有帮助，但不满足防止删除的需求。"
      },
      "D": {
        "option": "为 Web 应用程序和数据库部署创建一个 CloudFormation 堆栈集。",
        "reason": "CloudFormation 堆栈集用于跨多个账户和区域管理堆栈，这与防止数据库删除无关。因此，这不是一个合适的解决方案。"
      },
      "E": {
        "option": "为堆栈添加一个具有 Retain 值的 CloudFormation 删除策略属性。",
        "reason": "删除策略属性应该添加到具体的资源上而不是堆栈上。因此，这个选项不合适。"
      }
    }
  },
  {
    "number": "37",
    "best": ["A"],
    "question": "一家公司有一个包含敏感数据的 Amazon S3 存储桶。数据必须在传输和静态时加密。公司使用 AWS Key Management Service (AWS KMS) 密钥对 S3 存储桶中的数据进行加密。一名开发人员需要授予其他几个 AWS 帐户使用 S3 GetObject 操作从 S3 存储桶中检索数据的权限。开发人员如何强制要求所有请求在传输中提供加密？",
    "options": {
      "A": {
        "option": "在 S3 存储桶上定义基于资源的策略，以在请求满足条件“aws:SecureTransport”为“false”时拒绝访问。",
        "reason": "选项 A 是正确的。通过在 S3 存储桶上定义基于资源的策略，并在请求未通过安全传输（即不使用 HTTPS）时拒绝访问，可以确保所有请求在传输中加密。这符合要求，即强制所有请求在传输中提供加密。"
      },
      "B": {
        "option": "在 S3 存储桶上定义基于资源的策略，以在请求满足条件“aws:SecureTransport”为“false”时允许访问。",
        "reason": "选项 B 是不正确的。允许不安全传输的请求访问会违反传输加密的要求。因此，这不是正确选项。"
      },
      "C": {
        "option": "在其他账户的角色上定义基于角色的策略，以在请求满足条件“aws:SecureTransport”为“false”时拒绝访问。",
        "reason": "选项 C 是不正确的。虽然这可以限制访问，但这需要对每个账户的角色进行配置，管理复杂且不易维护。使用基于资源的策略会更加简便和有效。"
      },
      "D": {
        "option": "在 KMS 密钥上定义基于资源的策略，以在请求满足条件“aws:SecureTransport”为“false”时拒绝访问。",
        "reason": "选项 D 是不正确的。KMS 密钥的策略主要用于控制对密钥的访问，而不是直接控制 S3 对象的传输加密。要确保传输加密，应该在 S3 存储桶上设置策略。"
      }
    }
  },
  {
    "number": "38",
    "best": ["B"],
    "question": "一个托管在 Amazon EC2 实例上的应用程序需要访问存储在 Amazon S3 存储桶中的文件。该应用程序列出存储在 S3 存储桶中的对象，并向用户显示一个表格。在测试期间，开发人员发现应用程序在列表中没有显示任何对象。解决此问题的最安全方法是什么？",
    "options": {
      "A": {
        "option": "更新附加到 EC2 实例的 IAM 实例配置文件，以包含 S3:* 权限。",
        "reason": "虽然这种方法可以解决问题，但授予 S3:* 权限会给予 EC2 实例对 S3 服务的所有操作权限，这是过度授权，不符合最小权限原则。"
      },
      "B": {
        "option": "更新附加到 EC2 实例的 IAM 实例配置文件，以包含 S3:ListBucket 权限。",
        "reason": "这种方法授予 EC2 实例列出 S3 存储桶内容的最小权限，符合最小权限原则，是最安全的解决方案。"
      },
      "C": {
        "option": "更新开发人员的用户权限以包含 S3:ListBucket 权限。",
        "reason": "这种方法不会解决问题，因为问题是 EC2 实例需要访问 S3 存储桶，而不是开发人员本身。"
      },
      "D": {
        "option": "通过包括 S3:ListBucket 权限并设置 Principal 元素以指定 EC2 实例的帐户号来更新 S3 存储桶策略。",
        "reason": "这种方法虽然可以解决问题，但一般情况下，最好通过 IAM 实例角色来管理 EC2 实例的权限，而不是直接修改 S3 存储桶策略。"
      }
    }
  },
  {
    "number": "39",
    "best": ["C"],
    "question": "一家公司计划在 AWS 中安全地管理一次性固定许可密钥。该公司的开发团队需要在 Amazon EC2 实例和 AWS CloudFormation 堆栈中运行的自动化脚本中访问许可密钥。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options": {
      "A": {
        "option": "使用带有前缀 'config' 的加密文件的 Amazon S3",
        "reason": "虽然 Amazon S3 可以用于存储加密文件，但它并不是管理敏感数据（如许可密钥）的最佳选择，特别是当需要在多个 AWS 服务之间进行访问和集成时。S3 的主要使用场景是大规模存储和分发数据，而不是密钥管理。"
      },
      "B": {
        "option": "带有名为 SecretString 标签的 AWS Secrets Manager 密钥",
        "reason": "AWS Secrets Manager 是一种专为管理敏感信息（如密码、API 密钥和数据库凭证）而设计的服务。然而，它的成本较高，特别是对于一次性固定许可密钥的管理而言。Secrets Manager 更适合于需要频繁轮换和高安全需求的数据。"
      },
      "C": {
        "option": "AWS Systems Manager 参数存储 SecureString 参数",
        "reason": "AWS Systems Manager Parameter Store 提供了一个安全和成本效益高的方式来管理敏感数据。SecureString 参数可以加密存储，并且可以在 EC2 实例和 CloudFormation 堆栈中轻松访问。它的成本效益更高，特别是对于一次性密钥的存储和访问。"
      },
      "D": {
        "option": "CloudFormation NoEcho 参数",
        "reason": "CloudFormation NoEcho 参数用于在 CloudFormation 模板中隐藏敏感信息，但它并不是一个专门的密钥管理解决方案。它仅在 CloudFormation 堆栈中有用，无法在 EC2 实例和其他 AWS 服务中轻松访问。"
      }
    }
  },
  {
    "number": "40",
    "best": ["A"],
    "question": "一家公司在AWS上部署了基础设施。开发团队希望创建一个AWS Lambda函数，从Amazon Aurora数据库中检索数据。Amazon Aurora数据库位于公司的VPC的私有子网中。该VPC名为VPC1。这些数据是关系型数据。Lambda函数需要安全地访问数据。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "创建Lambda函数。配置该函数的VPC1访问权限。将名为SG1的安全组附加到Lambda函数和数据库。配置安全组的入站和出站规则以允许3306端口上的TCP流量。",
        "reason": "这是最佳选择。将Lambda函数配置为访问VPC1，并确保Lambda函数和数据库使用相同的安全组，这样安全组规则可以控制流量。通过SG1安全组配置端口3306的入站和出站规则，可以实现Lambda函数与Aurora数据库的安全通信。"
      },
      "B": {
        "option": "在新的VPC2中的新公共子网中创建并启动一个Lambda函数。在VPC1和VPC2之间创建对等连接。",
        "reason": "这个选项是不必要的复杂。Lambda函数可以直接在VPC1中创建，而不需要新的VPC和对等连接。对等连接会增加管理复杂性和成本，没有必要。"
      },
      "C": {
        "option": "创建Lambda函数。配置该函数的VPC1访问权限。将名为SG1的安全组分配给Lambda函数。将名为SG2的第二个安全组分配给数据库。向SG1添加入站规则以允许来自3306端口的TCP流量。",
        "reason": "这个选项不正确。虽然创建两个不同的安全组是一个有效的安全实践，但入站规则应该配置在SG2（数据库的安全组）上，而不是SG1（Lambda函数的安全组）。SG1需要允许出站到SG2, SG2需要允许入站来自SG1。"
      },
      "D": {
        "option": "将Aurora数据库中的数据导出到Amazon S3。创建并在VPC1中启动一个Lambda函数。配置Lambda函数从Amazon S3查询数据。",
        "reason": "这个选项不符合要求。题目明确要求Lambda函数直接从Aurora数据库中检索数据，而不是从S3查询数据。导出数据到S3并不是题目要求的解决方案。"
      }
    }
  },
  {
    "number": "41",
    "best": ["B", "D"],
    "question": "一名开发人员正在构建一个网络应用程序，该应用程序使用 Amazon API Gateway 来暴露一个 AWS Lambda 函数，以处理来自客户端的请求。在测试期间，开发人员注意到 API Gateway 超时，即使 Lambda 函数在设定的时间限制内完成。以下哪个 Amazon CloudWatch 中的 API Gateway 指标可以帮助开发人员排除故障？（选择两个。）",
    "options": {
      "A": {
        "option": "Cache 命中计数",
        "reason": "CacheHitCount 指标用于跟踪 API Gateway 缓存命中次数，它与 API Gateway 超时问题无关，因此不适合用于排除超时故障。"
      },
      "B": {
        "option": "集成延迟",
        "reason": "IntegrationLatency 指标显示了从 API Gateway 调用集成后，直到收到响应所用的时间。这对于分析 API Gateway 和 Lambda 函数之间的延迟非常有帮助，可以用来排查超时问题。"
      },
      "C": {
        "option": "Cache 未命中计数",
        "reason": "CacheMissCount 指标用于跟踪 API Gateway 缓存未命中次数，这与 API Gateway 超时问题无关，因此不适合用于排除超时故障。"
      },
      "D": {
        "option": "延迟",
        "reason": "Latency 指标表示从 API Gateway 接收到客户端请求开始，到 API Gateway 返回响应结束所用的总时间。通过分析此指标，可以确定 API Gateway 中哪个环节导致了超时。"
      },
      "E": {
        "option": "请求计数",
        "reason": "Count 指标表示 API Gateway 接收到的请求总数，它不能直接提供与超时相关的信息，因此不适合用于排除超时故障。"
      }
    }
  },
  {
    "number": "42",
    "best": ["C"],
    "question": "开发团队希望构建一个持续集成/持续交付（CI/CD）管道。团队使用 AWS CodePipeline 来自动化代码构建和部署。团队希望存储程序代码以为 CI/CD 管道做准备。团队应该使用哪个 AWS 服务来存储程序代码？",
    "options": {
      "A": {
        "option": "AWS CodeDeploy",
        "reason": "AWS CodeDeploy 是一个自动化部署服务，用于将应用程序代码部署到各种计算服务（如 EC2、Lambda 等）。它并不适合用于存储源代码。"
      },
      "B": {
        "option": "AWS CodeArtifact",
        "reason": "AWS CodeArtifact 是一个完全托管的软件包管理服务，主要用于存储和管理软件包和依赖项，而不是源代码。"
      },
      "C": {
        "option": "AWS CodeCommit",
        "reason": "AWS CodeCommit 是一个托管的源代码控制服务，类似于 Git，用于存储和管理源代码。它是为 CI/CD 管道中的程序代码存储而设计的最佳选择。"
      },
      "D": {
        "option": "Amazon CodeGuru",
        "reason": "Amazon CodeGuru 是一个用于自动代码审查和性能建议的工具，它并不用于存储源代码。"
      }
    }
  },
  {
    "number": "43",
    "best": ["A"],
    "question": "一名开发人员正在设计一个 AWS Lambda 函数，该函数在调用期间会创建大小小于 10 MB 的临时文件。临时文件在调用期间会被多次访问和修改。开发人员不需要在将来保存或检索这些文件。临时文件应存储在哪里？",
    "options": {
      "A": {
        "option": "/tmp 目录",
        "reason": "/tmp 目录是 AWS Lambda 函数的本地存储，适合存储调用期间需要的临时文件。它支持多次读写操作，并且在调用结束后会自动清理，非常适合这种临时文件的使用场景。"
      },
      "B": {
        "option": "Amazon Elastic File System (Amazon EFS)",
        "reason": "Amazon EFS 是一个可扩展的文件存储服务，适用于需要持久存储和跨多个 Lambda 函数共享数据的场景。由于题目中明确表示不需要将来保存这些文件，因此 EFS 并不是最佳选择。"
      },
      "C": {
        "option": "Amazon Elastic Block Store (Amazon EBS)",
        "reason": "Amazon EBS 提供持久性块存储，适用于需要长期存储和高性能 I/O 操作的场景。由于题目中明确表示文件是临时的且不需要在将来保存，因此 EBS 不是最佳选择。"
      },
      "D": {
        "option": "Amazon S3",
        "reason": "Amazon S3 是对象存储服务，适用于需要持久存储和大规模数据存储的场景。由于题目中明确表示文件是临时的且不需要在将来保存，因此 S3 不是最佳选择。"
      }
    }
  },
  {
    "number": "44",
    "best": ["B"],
    "question": "开发人员正在设计一个无服务器应用程序，其中包含两个 AWS Lambda 函数来处理照片。一个 Lambda 函数将对象存储在 Amazon S3 存储桶中，并将相关的元数据存储在 Amazon DynamoDB 表中。另一个 Lambda 函数使用来自 DynamoDB 表的元数据从 S3 存储桶中获取对象。两个 Lambda 函数都使用相同的 Python 库来执行复杂计算，并且正在接近最大压缩部署包大小的配额。开发人员应该怎么做才能以最少的操作开销减少 Lambda 部署包的大小？",
    "options": {
      "A": {
        "option": "将每个 Python 库打包在自己的 .zip 文件归档中。为每个 Lambda 函数部署自己的库副本。",
        "reason": "这种方法会导致每个 Lambda 函数都有自己独立的库副本，从而增加了总体的存储需求和管理开销，不是最佳选择。"
      },
      "B": {
        "option": "创建一个包含所需 Python 库的 Lambda 层。在两个 Lambda 函数中使用该 Lambda 层。",
        "reason": "使用 Lambda 层可以将公共库与函数代码分离，减少每个 Lambda 部署包的大小，并且可以在多个 Lambda 函数中重用这个层，从而减少了操作开销，是最佳选择。"
      },
      "C": {
        "option": "将两个 Lambda 函数合并为一个 Lambda 函数。将 Lambda 函数部署为一个 .zip 文件归档。",
        "reason": "虽然合并函数可以减少总的部署包大小，但会导致函数职责不清晰，增加代码的复杂性和维护难度，不是最佳实践。"
      },
      "D": {
        "option": "将 Python 库下载到 S3 存储桶。编程 Lambda 函数以引用对象 URL。",
        "reason": "这种方法会导致每次函数调用都需要从 S3 下载库，增加了网络延迟和成本，不是最佳选择。"
      }
    }
  },
  {
    "number": "45",
    "best": ["A"],
    "question": "开发人员正在编写一个 AWS Lambda 函数。开发人员希望记录 Lambda 函数运行时发生的关键事件。开发人员希望包括一个唯一标识符，以将事件与特定的函数调用相关联。开发人员在 Lambda 函数中添加了以下代码： 哪种解决方案可以满足此要求？",
    "options": {
      "A": {
        "option": "从上下文对象中的 AWS 请求 ID 字段获取请求标识符。配置应用程序将日志写入标准输出。",
        "reason": "从上下文对象获取 AWS 请求 ID 是正确的，因为这是 Lambda 提供的每个调用的唯一标识符。将日志写入标准输出是符合 Lambda 最佳实践的，因为这些日志会自动流向 Amazon CloudWatch Logs，便于查看和监控。"
      },
      "B": {
        "option": "从事件对象中的 AWS 请求 ID 字段获取请求标识符。配置应用程序将日志写入文件。",
        "reason": "从事件对象中获取请求 ID 并不是最佳选择，因为 AWS 请求 ID 通常在上下文对象中。将日志写入文件不是最佳实践，因为 Lambda 的执行环境是短暂的，文件可能无法持久存储且难以管理。"
      },
      "C": {
        "option": "从事件对象中的 AWS 请求 ID 字段获取请求标识符。配置应用程序将日志写入标准输出。",
        "reason": "虽然将日志写入标准输出是正确的，但从事件对象中获取请求 ID 不是最佳选择。AWS 请求 ID 通常在上下文对象中。"
      },
      "D": {
        "option": "从上下文对象中的 AWS 请求 ID 字段获取请求标识符。配置应用程序将日志写入文件。",
        "reason": "从上下文对象获取请求 ID 是正确的，但将日志写入文件不是最佳实践，因为 Lambda 的执行环境是短暂的，文件可能无法持久存储且难以管理。"
      }
    }
  },
  {
    "number": "46",
    "best": ["C"],
    "question": "开发人员正在开发一个无服务器应用程序，需要使用AWS Lambda函数处理对Amazon DynamoDB表的任何更改。开发人员应如何配置Lambda函数以检测DynamoDB表的更改？",
    "options": {
      "A": {
        "option": "创建一个Amazon Kinesis数据流，并将其附加到DynamoDB表。创建一个触发器以将数据流连接到Lambda函数。",
        "reason": "虽然Kinesis数据流可以用于实时数据处理，但在这种情况下并不是最佳选择。DynamoDB Streams是专门为此类任务设计的，且与DynamoDB无缝集成。"
      },
      "B": {
        "option": "创建一个Amazon EventBridge规则以定期调用Lambda函数。从Lambda函数连接到DynamoDB表以检测更改。",
        "reason": "这种方法会增加延迟，因为它依赖于定期调用来检测更改，而不是实时检测。这也会增加不必要的复杂性和成本。"
      },
      "C": {
        "option": "在表上启用DynamoDB Streams。创建一个触发器以将DynamoDB流连接到Lambda函数。",
        "reason": "这是最佳选择。DynamoDB Streams可以捕获对表的更改，并且可以直接触发Lambda函数来处理这些更改。这种方法是实时的，并且是AWS官方推荐的解决方案。"
      },
      "D": {
        "option": "创建一个Amazon Kinesis Data Firehose传输流，并将其附加到DynamoDB表。将传输流目标配置为Lambda函数。",
        "reason": "Kinesis Data Firehose主要用于将数据传输到S3、Redshift、Elasticsearch等数据存储，而不是用于实时处理DynamoDB表的更改。"
      }
    }
  },
  {
    "number": "47",
    "best": ["B", "C"],
    "question": "一个应用程序使用 Amazon EC2 Auto Scaling 组。开发人员注意到，在扩展事件期间，EC2 实例需要很长时间才能可用。UserData 脚本运行时间很长。开发人员必须实施一个解决方案，以减少 EC2 实例可用之前的时间。该解决方案必须始终提供应用程序的最新版本，并且必须应用所有可用的安全更新。解决方案还必须尽量减少创建的图像数量。图像必须经过验证。开发人员应该采取哪些步骤来满足这些要求？（选择两个。）",
    "options": {
      "A": {
        "option": "使用 EC2 Image Builder 创建一个 Amazon Machine Image (AMI)。安装所有管理和运行应用程序所需的补丁和代理。更新 Auto Scaling 组启动配置以使用 AMI。",
        "reason": "虽然这个选项会减少实例启动时间，但它没有考虑到始终提供应用程序最新版本的要求。"
      },
      "B": {
        "option": "使用 EC2 Image Builder 创建一个 Amazon Machine Image (AMI)。安装最新版本的应用程序和所有管理和运行应用程序所需的补丁和代理。更新 Auto Scaling 组启动配置以使用 AMI。",
        "reason": "这个选项既满足了减少实例启动时间的需求，又确保了应用程序的最新版本和所需的安全更新。"
      },
      "C": {
        "option": "设置 AWS CodeDeploy 在运行时部署最新版本的应用程序。",
        "reason": "使用 AWS CodeDeploy 可以确保在实例启动时始终部署最新版本的应用程序，符合题目要求的持续更新需求。"
      },
      "D": {
        "option": "设置 AWS CodePipeline 在运行时部署最新版本的应用程序。",
        "reason": "虽然 AWS CodePipeline 可以用于部署，但它更多用于构建、测试和部署整个 CI/CD 流水线，不是最佳选择来直接减少实例启动时间。"
      },
      "E": {
        "option": "从 UserData 脚本中删除执行操作系统修补的任何命令。",
        "reason": "虽然这会减少启动时间，但无法确保应用程序和操作系统的最新更新，违背了题目要求。"
      }
    }
  },
  {
    "number": "48",
    "best": ["C"],
    "question": "开发人员正在创建一个 AWS Lambda 函数，该函数需要凭证来连接到 Amazon RDS for MySQL 数据库。目前，凭证存储在一个 Amazon S3 存储桶中。开发人员需要通过实现凭证轮换和安全存储来改进现有解决方案。开发人员还需要提供与 Lambda 函数的集成。开发人员应该使用哪种解决方案以最少的管理开销来存储和检索凭证？",
    "options": {
      "A": {
        "option": "将凭证存储在 AWS Systems Manager Parameter Store 中。选择参数将访问的数据库。使用默认的 AWS Key Management Service (AWS KMS) 密钥加密参数。启用参数的自动轮换。在 Lambda 函数中使用 Parameter Store 中的参数连接到数据库。",
        "reason": "虽然 Systems Manager Parameter Store 支持参数加密和自动轮换，但它主要用于简单的配置数据管理。相比于 Secrets Manager，Parameter Store 的管理功能较少，尤其在复杂的凭证管理和轮换方面。"
      },
      "B": {
        "option": "使用默认的 AWS Key Management Service (AWS KMS) 密钥加密凭证。将凭证存储为 Lambda 函数的环境变量。创建第二个 Lambda 函数以生成新凭证，并通过更新第一个 Lambda 函数的环境变量来轮换凭证。使用 Amazon EventBridge 规则按计划调用第二个 Lambda 函数。更新数据库以使用新凭证。在第一个 Lambda 函数中，从环境变量中检索凭证。使用 AWS KMS 解密凭证，连接到数据库。",
        "reason": "这个方案涉及多个步骤和组件，包括环境变量管理、多个 Lambda 函数、EventBridge 规则等，增加了管理和维护的复杂性。相比之下，Secrets Manager 提供了更集成和简化的解决方案。"
      },
      "C": {
        "option": "将凭证存储在 AWS Secrets Manager 中。将密钥类型设置为 Amazon RDS 数据库凭证。选择密钥将访问的数据库。使用默认的 AWS Key Management Service (AWS KMS) 密钥加密密钥。启用密钥的自动轮换。在 Lambda 函数中使用 Secrets Manager 中的密钥连接到数据库。",
        "reason": "Secrets Manager 专为管理敏感信息（如数据库凭证）设计，提供内置的凭证轮换功能，且与 Lambda 和 RDS 的集成非常紧密。它能最小化管理开销并确保凭证的安全和自动轮换。"
      },
      "D": {
        "option": "使用 AWS Key Management Service (AWS KMS) 加密凭证。将凭证存储在 Amazon DynamoDB 表中。创建第二个 Lambda 函数以轮换凭证。使用 Amazon EventBridge 规则按计划调用第二个 Lambda 函数。更新 DynamoDB 表。更新数据库以使用生成的凭证。从 DynamoDB 表中检索凭证的第一个 Lambda 函数连接到数据库。",
        "reason": "将凭证存储在 DynamoDB 中并不常见，且涉及到多个组件和步骤，包括 DynamoDB 表管理、多个 Lambda 函数、EventBridge 规则等，增加了管理复杂性。相比之下，Secrets Manager 提供了更简化和集成的解决方案。"
      }
    }
  },
  {
    "number": "49",
    "best": ["D"],
    "question": "开发人员编写了以下 IAM 策略，以提供对 Amazon S3 存储桶的访问权限：该策略允许关于 s3:GetObject 和 s3:PutObject 操作的哪些访问？",
    "options": {
      "A": {
        "option": "访问所有存储桶，除了名为 “DOC-EXAMPLE-BUCKET” 的存储桶",
        "reason": "如果策略中没有明确指定资源，那么默认情况下，策略不会应用于所有存储桶。题目提到的是特定的存储桶 “DOC-EXAMPLE-BUCKET”，因此这个选项不正确。"
      },
      "B": {
        "option": "访问所有以 “DOC-EXAMPLE-BUCKET” 开头的存储桶，除了 “DOC-EXAMPLE-BUCKET/secrets” 存储桶",
        "reason": "策略中没有提到以 “DOC-EXAMPLE-BUCKET” 开头的存储桶，因此这个选项不正确。"
      },
      "C": {
        "option": "访问 “DOC-EXAMPLE-BUCKET” 存储桶中的所有对象，并且对该存储桶中以 “secrets” 开头的对象有所有 S3 操作的访问权限",
        "reason": "策略没有提到允许对以 ‘secrets’ 开头的对象进行所有 S3 操作的访问权限，因此这个选项不正确。"
      },
      "D": {
        "option": "访问 “DOC-EXAMPLE-BUCKET” 存储桶中的所有对象，除了以 “secrets” 开头的对象",
        "reason": "这是正确的答案。策略中可能包含了对该特定存储桶中除了以 ‘secrets’ 开头的对象外的所有对象的访问权限。这符合题目描述的约束条件。"
      }
    }
  },
  {
    "number": "50",
    "best": ["D"],
    "question": "开发人员正在创建一个移动应用程序，该应用程序通过 Amazon API Gateway REST API 调用后端服务。在开发阶段的集成测试中，开发人员希望在不调用后端服务的情况下模拟不同的后端响应。哪种解决方案在最少的操作开销下满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个 AWS Lambda 函数。使用 API Gateway 代理集成返回恒定的 HTTP 响应。",
        "reason": "虽然使用 Lambda 函数可以实现模拟响应，但这增加了额外的组件和维护开销。"
      },
      "B": {
        "option": "使用 AWS CloudFormation 模板创建一个 Amazon EC2 实例，该实例提供后端 REST API 服务。",
        "reason": "创建和维护 EC2 实例会带来较高的操作开销，不符合最少操作开销的要求。"
      },
      "C": {
        "option": "定制 API Gateway 阶段以根据请求选择响应类型。",
        "reason": "API Gateway 阶段设置主要用于部署和版本管理，不直接支持模拟不同的响应类型。"
      },
      "D": {
        "option": "使用请求映射模板选择模拟集成响应。",
        "reason": "使用请求映射模板选择模拟集成响应是直接且有效的方法，它允许在不调用实际后端服务的情况下定制响应，操作开销最少，完全符合题目要求。"
      }
    }
  },
  {
    "number": "51",
    "best": ["B"],
    "question": "开发人员有一个托管在本地的遗留应用程序。托管在 AWS 上的其他应用程序依赖于本地应用程序的正常运行。为了能够在出现任何应用程序错误时使用 Amazon CloudWatch 从一个地方监控和排除所有应用程序的故障，开发人员应该怎么做？",
    "options": {
      "A": {
        "option": "在本地服务器上安装 AWS SDK 以自动将日志发送到 CloudWatch。",
        "reason": "AWS SDK 主要用于与 AWS 服务进行编程交互，并不适用于直接发送日志到 CloudWatch。它适合的场景是应用程序需要调用 AWS API 来进行操作，而不是日志管理。"
      },
      "B": {
        "option": "下载 CloudWatch 代理到本地服务器。配置代理以使用具有 CloudWatch 权限的 IAM 用户凭证。",
        "reason": "这是最优解。CloudWatch 代理能够将本地服务器上的日志数据发送到 CloudWatch。通过配置适当的 IAM 用户权限，可以确保日志数据安全地传输和监控。这种方式允许跨越本地和 AWS 环境进行集中化的监控和排错。"
      },
      "C": {
        "option": "将日志文件从本地服务器上传到 Amazon S3 并让 CloudWatch 读取这些文件。",
        "reason": "这种方法需要额外的步骤和配置，而且 CloudWatch 并不直接从 S3 读取日志文件。它增加了复杂性，不如直接使用 CloudWatch 代理高效。"
      },
      "D": {
        "option": "将日志文件从本地服务器上传到 Amazon EC2 实例，并让该实例将日志转发到 CloudWatch。",
        "reason": "这种方法同样增加了额外的步骤和维护成本。需要管理 EC2 实例的生命周期和安全性，不如直接使用 CloudWatch 代理来得高效和简便。"
      }
    }
  },
  {
    "number": "52",
    "best": ["A"],
    "question": "一个 Amazon Kinesis Data Firehose 传输流正在接收包含个人身份信息的客户数据。开发人员需要从数据中删除基于模式的客户标识符，并将修改后的数据存储在 Amazon S3 桶中。开发人员应该怎么做才能满足这些要求？",
    "options": {
      "A": {
        "option": "实现 Kinesis Data Firehose 数据转换为 AWS Lambda 函数。配置该函数以删除客户标识符。将 Amazon S3 桶设置为传输流的目标。",
        "reason": "这是最佳选项，因为 AWS Lambda 可以轻松地与 Kinesis Data Firehose 集成以进行数据转换。通过使用 Lambda 函数，开发人员可以编写代码来删除敏感信息，然后将修改后的数据直接发送到 S3 桶中。这种方法是无服务器的，不需要管理 EC2 实例或复杂的工作流。"
      },
      "B": {
        "option": "启动一个 Amazon EC2 实例。将 EC2 实例设置为传输流的目标。在 EC2 实例上运行一个应用程序以删除客户标识符。将转换后的数据存储在 Amazon S3 桶中。",
        "reason": "这是一个可行的选项，但不是最佳选择。使用 EC2 实例需要更多的管理和维护，包括实例的启动、监控和扩展。而且，这种方法比使用无服务器的 Lambda 函数更复杂。"
      },
      "C": {
        "option": "创建一个 Amazon OpenSearch Service 实例。将 OpenSearch Service 实例设置为传输流的目标。使用搜索和替换来删除客户标识符。将数据导出到 Amazon S3 桶中。",
        "reason": "这是一个不太合适的选项。OpenSearch Service 主要用于搜索和分析数据，而不是用于数据转换。使用 OpenSearch Service 进行这种操作会增加不必要的复杂性和成本。"
      },
      "D": {
        "option": "创建一个 AWS Step Functions 工作流来删除客户标识符。作为工作流的最后一步，将转换后的数据存储在 Amazon S3 桶中。将工作流设置为传输流的目标。",
        "reason": "这是一个不太合适的选项。虽然 AWS Step Functions 可以编排复杂的任务，但使用它来处理 Kinesis Data Firehose 数据转换并不是一个常见的用例。相比之下，使用 Lambda 函数更加简洁和高效。"
      }
    }
  },
  {
    "number": "53",
    "best": ["A"],
    "question": "开发人员正在使用 AWS Lambda 函数为上传到 Amazon S3 存储桶的个人资料图片生成头像。对于保存到 /original/ S3 前缀下的个人资料图片，Lambda 函数会自动触发。开发人员注意到有些图片会导致 Lambda 函数超时。开发人员想要通过使用另一个 Lambda 函数调整个人资料图片大小来实现回退机制。哪种解决方案可以以最少的开发工作量满足这些需求？",
    "options": {
      "A": {
        "option": "将图像调整大小的 Lambda 函数设置为头像生成器 Lambda 函数处理失败事件的目标。",
        "reason": "选项A提供了最直接且最少开发工作量的解决方案。AWS Lambda 允许配置处理失败事件的目标，可以自动触发另一个 Lambda 函数来处理失败的情况，简化了开发和配置流程。"
      },
      "B": {
        "option": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。将 SQS 队列设置为头像生成器 Lambda 函数的失败条件目标。配置图像调整大小的 Lambda 函数从 SQS 队列轮询。",
        "reason": "尽管此选项也是一种有效的解决方案，但它涉及到额外的 SQS 队列配置和轮询逻辑，增加了开发和管理的复杂性。"
      },
      "C": {
        "option": "创建一个 AWS Step Functions 状态机，调用头像生成器 Lambda 函数，并将图像调整大小的 Lambda 函数作为回退。创建一个匹配 S3 存储桶事件的 Amazon EventBridge 规则来调用状态机。",
        "reason": "此选项提供了强大的控制和扩展性，但涉及到配置和管理 Step Functions 状态机和 EventBridge 规则，增加了开发工作量和复杂性。"
      },
      "D": {
        "option": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题。将 SNS 主题设置为头像生成器 Lambda 函数的失败条件目标。订阅图像调整大小的 Lambda 函数到 SNS 主题。",
        "reason": "虽然此选项也可以实现回退机制，但它涉及到额外的 SNS 主题和订阅配置，增加了开发工作量和管理的复杂性。"
      }
    }
  },
  {
    "number": "54",
    "best": ["B"],
    "question": "一名开发人员需要将一个在线零售应用程序迁移到 AWS，以处理预期的流量增加。该应用程序目前运行在两台服务器上：一台用于 Web 应用程序，另一台用于数据库。Web 服务器呈现网页并在内存中管理会话状态。数据库服务器托管一个包含订单详情的 MySQL 数据库。当应用程序的流量很大时，Web 服务器的内存使用率接近 100%，应用程序显著变慢。开发人员发现，大多数内存增加和性能下降与管理额外用户会话的负载有关。对于 Web 服务器迁移，开发人员将使用带有应用程序负载均衡器的 Auto Scaling 组的 Amazon EC2 实例。开发人员还应该对应用程序进行哪些其他更改来提高应用程序的性能？",
    "options": {
      "A": {
        "option": "使用 EC2 实例托管 MySQL 数据库。将会话数据和应用程序数据存储在 MySQL 数据库中。",
        "reason": "将会话数据和应用程序数据存储在同一个 MySQL 数据库中会导致数据库成为性能瓶颈，并且会话数据频繁读写会增加数据库负担，不适合高性能需求。"
      },
      "B": {
        "option": "使用 Amazon ElastiCache for Memcached 存储和管理会话数据。使用 Amazon RDS for MySQL 数据库实例存储应用程序数据。",
        "reason": "使用 ElastiCache for Memcached 存储会话数据可以减轻 Web 服务器的内存负担，提高性能。而使用 Amazon RDS for MySQL 数据库实例存储应用程序数据可以提供高可用性和持久性，是最佳实践。"
      },
      "C": {
        "option": "使用 Amazon ElastiCache for Memcached 存储和管理会话数据和应用程序数据。",
        "reason": "Memcached 适合缓存会话数据，但不是持久存储应用程序数据的理想选择，因为它不提供数据持久性和复杂查询能力。"
      },
      "D": {
        "option": "使用 EC2 实例存储管理会话数据。使用 Amazon RDS for MySQL 数据库实例存储应用程序数据。",
        "reason": "EC2 实例存储不适合存储会话数据，因为它在实例终止时不会持久化数据，可能导致会话数据丢失。"
      }
    }
  },
  {
    "number": "55",
    "best": ["C"],
    "question": "一个应用程序使用Lambda函数从上传到S3桶的文件中提取元数据；元数据存储在Amazon DynamoDB中。应用程序开始表现异常，开发人员想检查Lambda函数代码的日志以查找错误。基于这个系统配置，开发人员应该在哪里找到日志？",
    "options": {
      "A": {
        "option": "Amazon S3",
        "reason": "Amazon S3主要用于存储文件和对象数据，而不是用来存储Lambda函数的运行日志。因此日志不会存储在S3中。"
      },
      "B": {
        "option": "AWS CloudTrail",
        "reason": "AWS CloudTrail主要记录对AWS账户的API调用和相关活动的历史记录，用于安全审计和合规性监控，而不是专门用于存储和查看Lambda函数的运行日志。"
      },
      "C": {
        "option": "Amazon CloudWatch",
        "reason": "Amazon CloudWatch是用于监控AWS资源和应用程序的服务，包括Lambda函数的运行日志。开发人员可以在CloudWatch中查看Lambda函数的执行日志和错误信息。"
      },
      "D": {
        "option": "Amazon DynamoDB",
        "reason": "Amazon DynamoDB是一个NoSQL数据库，用于存储和查询数据，与监控或日志记录无关。因此Lambda函数的日志不会存储在DynamoDB中。"
      }
    }
  },
  {
    "number": "56",
    "best": ["A", "C"],
    "question": "一家公司正在使用 AWS Lambda 函数处理来自 Amazon Kinesis 数据流的记录。公司最近观察到记录处理速度变慢。一位开发人员注意到函数的迭代器年龄指标在增加，并且 Lambda 运行时间持续高于正常水平。开发人员应该采取哪些措施来提高处理速度？（选择两项）",
    "options": {
      "A": {
        "option": "增加 Kinesis 数据流的分片数量。",
        "reason": "增加分片数量可以提高数据流的并行处理能力，使更多的记录能够同时被处理，从而提高整体处理速度。"
      },
      "B": {
        "option": "减少 Lambda 函数的超时时间。",
        "reason": "减少超时时间不会提高处理速度，反而可能导致函数在处理没有完成时被强制终止，从而丢失数据或未完成处理。"
      },
      "C": {
        "option": "增加分配给 Lambda 函数的内存。",
        "reason": "增加内存分配不仅会增加可用内存，还会增加可用 CPU 资源，从而提高 Lambda 函数的处理速度。"
      },
      "D": {
        "option": "减少 Kinesis 数据流的分片数量。",
        "reason": "减少分片数量会降低并行处理能力，从而进一步减慢处理速度。"
      },
      "E": {
        "option": "增加 Lambda 函数的超时时间。",
        "reason": "增加超时时间只是防止函数因超时而被终止，不会直接提高处理速度。"
      }
    }
  },
  {
    "number": "57",
    "best": ["B"],
    "question": "公司需要在容器镜像进入运行状态之前对其进行加固。公司的应用程序使用 Amazon Elastic Container Registry (Amazon ECR) 作为镜像注册表，Amazon Elastic Kubernetes Service (Amazon EKS) 进行计算，并使用 AWS CodePipeline 管道来编排持续集成和持续交付 (CI/CD) 工作流。动态应用程序安全测试在管道的最后阶段进行，在新的镜像部署到 EKS 集群中的开发命名空间后进行。开发人员需要在此部署之前添加一个分析阶段，以便在 CI/CD 管道中更早地分析容器镜像。哪种解决方案能够以最高的操作效率满足这些要求？",
    "options": {
      "A": {
        "option": "构建容器镜像并在本地运行 docker scan 命令。在将更改推送到源代码库之前，缓解任何发现。编写一个预提交钩子，强制在提交之前使用此工作流。",
        "reason": "选项 A 要求在本地进行扫描和缓解，这需要开发人员手动操作，可能会降低操作效率。另外，预提交钩子的使用虽然有助于确保扫描，但这并不是最佳的自动化解决方案。"
      },
      "B": {
        "option": "创建一个新的 CodePipeline 阶段，该阶段在容器镜像构建之后发生。配置 ECR 基本镜像扫描在镜像推送时进行扫描。使用 AWS Lambda 函数作为操作提供者。配置 Lambda 函数检查扫描结果，如果有发现则使管道失败。",
        "reason": "选项 B 提供了一个自动化的解决方案，利用了现有的 AWS 服务（ECR 和 Lambda）在镜像推送后立即进行扫描，确保在部署之前进行安全分析。这种方案具有高操作效率，因为它是完全自动化的。"
      },
      "C": {
        "option": "创建一个新的 CodePipeline 阶段，该阶段在从其存储库中检索源代码之后发生。在最新版本的源代码上运行安全扫描器。如果有发现则使管道失败。",
        "reason": "选项 C 只对源代码进行扫描，而不是对构建后的容器镜像进行扫描。因此，它不能满足对容器镜像进行安全分析的需求。"
      },
      "D": {
        "option": "在管道的部署阶段添加一个操作，使该操作在部署到 EKS 集群之前发生。配置 ECR 基本镜像扫描在镜像推送时进行扫描。使用 AWS Lambda 函数作为操作提供者。配置 Lambda 函数检查扫描结果，如果有发现则使管道失败。",
        "reason": "选项 D 尽管也利用了 ECR 和 Lambda 进行扫描，但它在部署阶段进行操作，这与题目要求在部署之前进行安全分析的需求不完全一致。"
      }
    }
  },
  {
    "number": "58",
    "best": ["A"],
    "question": "开发人员正在测试一个新的文件存储应用程序，该应用程序使用Amazon CloudFront分配从Amazon S3桶提供内容。分配使用原点访问标识（OAI）访问S3桶。S3桶的权限明确拒绝所有其他用户的访问。应用程序提示用户在登录页面上进行身份验证，然后使用签名的cookie允许用户访问其个人存储目录。开发人员已将分配配置为使用其默认缓存行为，限制查看者访问，并将原点设置为指向S3桶。但是，当开发人员尝试导航到登录页面时，收到403 Forbidden错误。开发人员需要实施一个解决方案以允许未认证的访问登录页面，该解决方案还必须保持所有私人内容的安全。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "为分配添加第二个缓存行为，其原点与默认缓存行为相同。将第二个缓存行为的路径模式设置为登录页面的路径，并使查看者访问不受限制。保持默认缓存行为的设置不变。",
        "reason": "选项A提供了一种解决方案，即在不更改默认缓存行为的情况下，允许未认证的用户访问登录页面。通过为登录页面添加一个单独的缓存行为并使其访问不受限制，可以确保用户能够访问登录页面，而不会影响私人内容的安全性。"
      },
      "B": {
        "option": "为分配添加第二个缓存行为，其原点与默认缓存行为相同。将第二个缓存行为的路径模式设置为*，并使查看者访问受限制。将默认缓存行为的路径模式更改为登录页面的路径，并使查看者访问不受限制。",
        "reason": "选项B将默认缓存行为的路径模式更改为登录页面路径，这可能会导致除登录页面之外的所有内容都变得不安全，因为未认证用户可能会访问其他内容。因此，这不是最佳解决方案。"
      },
      "C": {
        "option": "将第二个原点作为默认缓存行为的故障转移原点。将故障转移原点指向S3桶。将主原点的路径模式设置为*，并使查看者访问受限制。将故障转移原点的路径模式设置为登录页面的路径，并使查看者访问不受限制。",
        "reason": "选项C使用故障转移原点的方式不符合需求，因为它通常用于高可用性和灾难恢复，而不是用于管理访问控制。此外，这种方法可能会导致复杂的配置和潜在的性能问题。"
      },
      "D": {
        "option": "向S3桶添加一个桶策略以允许读取访问。将策略中的资源设置为S3桶中登录页面对象的Amazon资源名称（ARN）。向默认缓存行为添加一个CloudFront函数，以将未授权的请求重定向到登录页面的S3 URL。",
        "reason": "选项D允许对登录页面对象的公开访问，这可能会导致安全风险。此外，使用CloudFront函数进行重定向虽然可以工作，但比直接配置缓存行为要复杂得多。因此，这不是最佳解决方案。"
      }
    }
  },
  {
    "number": "59",
    "best": ["C"],
    "question": "一名开发人员正在使用 AWS Amplify Hosting 构建和部署应用程序。开发人员收到的用户错误报告日益增多。开发人员希望为应用程序添加端到端测试，以便在这些错误进入生产环境之前尽可能消除它们。开发人员应该实施哪种解决方案来满足这些要求？",
    "options": {
      "A": {
        "option": "在 Amplify CLI 中运行 amplify add test 命令。",
        "reason": "AWS Amplify CLI 并没有提供 `amplify add test` 命令来直接添加测试阶段。这不是一个有效的解决方案。"
      },
      "B": {
        "option": "在应用程序中创建单元测试。使用 Amplify CLI 中的 amplify push 命令部署单元测试。",
        "reason": "单元测试虽然有助于捕获代码中的一些错误，但它们通常只测试单个函数或模块，并不能实现端到端的测试。"
      },
      "C": {
        "option": "在应用程序的 amplify.yml 构建设置中添加测试阶段。",
        "reason": "在 amplify.yml 文件中添加测试阶段可以在构建过程中运行端到端测试，从而确保在代码部署到生产环境之前捕获尽可能多的错误。这是一个符合要求的解决方案。"
      },
      "D": {
        "option": "在应用程序的 aws-exports.js 文件中添加测试阶段。",
        "reason": "aws-exports.js 文件主要用于配置 Amplify 项目的 AWS 资源，并不适合用于添加测试阶段。这不是一个有效的解决方案。"
      }
    }
  },
  {
    "number": "60",
    "best": ["B"],
    "question": "一家电子商务公司使用 Amazon API Gateway 背后的 AWS Lambda 函数作为其应用程序层。在结账时处理订单，应用程序从前端调用一个 POST API。POST API 异步调用 Lambda 函数。在极少数情况下，应用程序未处理订单。Lambda 应用程序日志显示没有错误或失败。开发人员应该怎么做来解决这个问题？",
    "options": {
      "A": {
        "option": "检查前端日志中的 API 失败。使用日志文件中的请求手动调用 POST API。",
        "reason": "检查前端日志可能会提供一些有用的信息，但这并不能解决 Lambda 函数没有处理订单的问题。手动调用 POST API 也不是一个可行的解决方案，因为它无法解决根本问题。"
      },
      "B": {
        "option": "创建并检查 Lambda 死信队列。排查失败的函数。重新处理事件。",
        "reason": "使用 Lambda 死信队列（DLQ）可以捕捉异步调用失败的事件。通过检查 DLQ，可以发现并排除导致订单未处理的潜在问题。重新处理失败的事件可以确保订单被正确处理。"
      },
      "C": {
        "option": "检查 Amazon CloudWatch 中的 Lambda 日志以查找可能的错误。修复错误。",
        "reason": "虽然检查 Lambda 日志以查找错误是一个好习惯，但题目中已经说明 Lambda 日志没有显示错误或失败。因此，这不是解决问题的最佳方法。"
      },
      "D": {
        "option": "确保在 API Gateway 中禁用了 POST API 的缓存。",
        "reason": "API Gateway 的缓存与 Lambda 函数的执行无关。缓存的作用是减少对后端的请求频率，并不能解决 Lambda 函数未处理订单的问题。"
      }
    }
  },
  {
    "number": "61",
    "best": ["C"],
    "question": "一家公司正在 AWS 上构建一个 Web 应用程序。当客户发送请求时，应用程序将生成报告，然后在一小时内将报告提供给客户。报告应在 8 小时内对客户可访问。有些报告大于 1 MB。每个报告对于客户都是唯一的。应用程序应删除超过 2 天的所有报告。哪种解决方案在操作开销最小的情况下满足这些要求？",
    "options": {
      "A": {
        "option": "生成报告，然后将报告作为具有指定 TTL（生存时间）的 Amazon DynamoDB 项目存储。生成一个从 DynamoDB 检索报告的 URL。通过 Web 应用程序向客户提供 URL。",
        "reason": "DynamoDB 更适合存储结构化数据，而不是大文件。对于大于 1 MB 的报告，DynamoDB 并不是最佳选择。此外，生成和管理 DynamoDB 项目并生成 URL 可能会增加操作复杂性。"
      },
      "B": {
        "option": "生成报告，然后将报告存储在使用服务器端加密的 Amazon S3 存储桶中。将报告附加到 Amazon Simple Notification Service（Amazon SNS）消息中。订阅客户接收来自 Amazon SNS 的电子邮件通知。",
        "reason": "将报告附加到 SNS 消息并通过电子邮件发送并不是一种常见的做法，尤其是当报告较大时。SNS 主要用于通知，而不是传输大文件。这会增加操作复杂性且不符合最佳实践。"
      },
      "C": {
        "option": "生成报告，然后将报告存储在使用服务器端加密的 Amazon S3 存储桶中。生成一个包含到期日期的预签名 URL。通过 Web 应用程序向客户提供 URL。向 S3 存储桶添加生命周期配置规则以删除旧报告。",
        "reason": "此选项利用了 S3 的强大功能，包括存储大文件、生成预签名 URL 以控制访问权限以及使用生命周期规则自动删除过期的报告。这大大减少了操作开销并符合最佳实践。"
      },
      "D": {
        "option": "生成报告，然后将报告存储在带有日期戳的 Amazon RDS 数据库中。生成一个从 RDS 数据库检索报告的 URL。通过 Web 应用程序向客户提供 URL。安排一个每小时运行的 AWS Lambda 函数以删除过期的数据库记录。",
        "reason": "RDS 更适合结构化数据的存储，而不是大文件。对于大于 1 MB 的报告，RDS 并不是最佳选择。此外，定期运行 Lambda 函数删除过期记录增加了操作复杂性。"
      }
    }
  },
  {
    "number": "62",
    "best": ["C"],
    "question": "公司在 AWS Elastic Beanstalk 上部署了一个应用程序，并将与 Elastic Beanstalk 环境关联的 Auto Scaling 组配置为具有五个 Amazon EC2 实例。如果在部署期间容量少于四个 EC2 实例，应用程序性能会下降。公司正在使用一次性部署策略。解决部署问题的最具成本效益的方法是什么？",
    "options": {
      "A": {
        "option": "将 Auto Scaling 组更改为六个期望实例。",
        "reason": "增加实例数量可以确保在部署期间始终有足够的实例，但这会增加成本，并不是最具成本效益的方法。"
      },
      "B": {
        "option": "将部署策略更改为流量拆分。指定评估时间为 1 小时。",
        "reason": "流量拆分策略可以更平滑地进行部署，但由于缺乏明确的实例管理，它可能无法保证部署过程中始终有足够的实例。"
      },
      "C": {
        "option": "将部署策略更改为滚动部署并添加额外批次。指定批次大小为 1。",
        "reason": "滚动部署策略允许逐步替换实例，并且“滚动部署并添加额外批次”策略会在原有实例之外添加新实例，确保在任何时候都有足够的实例，避免了性能下降。指定批次大小为 1 可以确保最小的实例替换影响，从而是最具成本效益的解决方案。"
      },
      "D": {
        "option": "将部署策略更改为滚动部署。指定批次大小为 2。",
        "reason": "虽然滚动部署可以逐步替换实例，但指定批次大小为 2 可能仍会导致在某些时间点上实例数量不足，影响性能。因此，这不是最优解。"
      }
    }
  },
  {
    "number": "63",
    "best": ["A"],
    "question": "开发人员正在将 AWS X-Ray 集成到处理个人身份信息 (PII) 的应用程序中。该应用程序托管在 Amazon EC2 实例上。应用程序跟踪消息包含加密的 PII 并发送到 Amazon CloudWatch。开发人员需要确保没有 PII 离开 EC2 实例。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "手动在应用程序代码中使用 X-Ray SDK 进行仪表化。",
        "reason": "手动在应用程序代码中使用 X-Ray SDK 可以让开发人员完全控制哪些数据被收集和发送到 X-Ray。通过这种方式，开发人员可以确保任何 PII 数据都不会被发送到 X-Ray 或其他外部服务。这种方法提供了最大的灵活性和控制，因此是最佳选择。"
      },
      "B": {
        "option": "使用 X-Ray 自动仪表化代理。",
        "reason": "X-Ray 的自动仪表化代理虽然能简化仪表化过程，但它可能无法完全控制和过滤哪些数据被发送到 X-Ray。这可能会导致 PII 数据意外泄露到外部服务。因此，这不是最佳选择。"
      },
      "C": {
        "option": "使用 Amazon Macie 检测和隐藏 PII。调用 AWS Lambda 中的 X-Ray API。",
        "reason": "Amazon Macie 是用于检测和保护 PII 的服务，但本题目中要求确保没有 PII 离开 EC2 实例。将数据发送到 Lambda 和 Macie 都会导致数据离开 EC2 实例，因此这种方案不符合要求。"
      },
      "D": {
        "option": "使用 AWS Distro for Open Telemetry。",
        "reason": "AWS Distro for Open Telemetry 是一种开源的分布式跟踪和监控工具。虽然它提供了类似 X-Ray 的功能，但它本身并没有特别的机制来确保 PII 数据不会离开 EC2 实例。因此，这不是最佳选择。"
      }
    }
  },
  {
    "number": "64",
    "best": ["D"],
    "question": "开发人员正在将某些功能从传统的单体应用程序迁移到使用 AWS Lambda 函数。该应用程序目前将数据存储在运行在 VPC 私有子网中的 Amazon Aurora DB 集群中。AWS 帐户只有一个 VPC 部署。Lambda 函数和 DB 集群部署在同一个 AWS 区域和同一个 AWS 帐户中。开发人员需要确保 Lambda 函数可以在不通过公共互联网的情况下安全地访问 DB 集群。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "将 DB 集群的公共访问设置配置为是。",
        "reason": "这不是一个安全的做法，因为它会允许公共互联网访问数据库，从而增加了暴露在外部攻击的风险。"
      },
      "B": {
        "option": "为 Lambda 函数配置 Amazon RDS 数据库代理。",
        "reason": "虽然 Amazon RDS 数据库代理可以帮助管理数据库连接，但它并不能解决 Lambda 函数在不通过公共互联网的情况下访问数据库的问题。"
      },
      "C": {
        "option": "为 Lambda 函数配置 NAT 网关和安全组。",
        "reason": "NAT 网关的主要用途是允许私有子网中的资源访问互联网，而不是提供对私有资源的访问。此外，这会增加不必要的成本。"
      },
      "D": {
        "option": "为 Lambda 函数配置 VPC、子网和安全组。",
        "reason": "这是最佳解决方案。通过将 Lambda 函数配置在相同的 VPC 和子网中，并使用适当的安全组配置，可以确保 Lambda 函数可以通过私有网络路径安全地访问 Aurora DB 集群。"
      }
    }
  },
  {
    "number": "65",
    "best": ["A"],
    "question": "一名开发人员在 AWS 上构建一个新应用程序。该应用程序使用一个 AWS Lambda 函数从 Amazon DynamoDB 表中检索信息。开发人员在 Lambda 函数代码中硬编码了 DynamoDB 表名。表名可能会随时间变化。开发人员不希望在表名更改时修改 Lambda 代码。哪种解决方案最有效地满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个 Lambda 环境变量来存储表名。使用编程语言的标准方法来检索该变量。",
        "reason": "通过使用 Lambda 环境变量，表名可以轻松地在 AWS 管理控制台或命令行界面中进行更新，而无需修改和重新部署代码。这种方法易于管理且高效。"
      },
      "B": {
        "option": "将表名存储在文件中。将文件存储在 /tmp 文件夹中。使用编程语言的 SDK 来检索表名。",
        "reason": "这不是一个理想的解决方案，因为 /tmp 文件夹是临时存储，每次 Lambda 函数执行时可能会被清除。而且这种方法的管理和更新都比较复杂。"
      },
      "C": {
        "option": "创建一个文件来存储表名。将文件压缩并上传到 Lambda 层。使用编程语言的 SDK 来检索表名。",
        "reason": "虽然 Lambda 层可以用于共享代码和资源，但这种方法对于一个简单的表名存储来说过于复杂，并且每次表名更改时都需要重新创建和部署 Lambda 层。"
      },
      "D": {
        "option": "在 Lambda 函数的处理程序外部创建一个全局变量来存储表名。",
        "reason": "全局变量无法在代码外部进行动态更新，这意味着每次表名更改都需要修改和重新部署代码。这与题目要求不符。"
      }
    }
  },
  {
    "number": "66",
    "best": ["B"],
    "question": "一家公司在 AWS 上有一个关键应用程序。该应用程序通过使用 Amazon API Gateway 暴露 HTTP API。API 集成了一个 AWS Lambda 函数。该应用程序将数据存储在具有 2 个虚拟 CPU（vCPUs）和 64 GB 内存的 Amazon RDS for MySQL 数据库实例中。客户报告称，一些 API 调用返回 HTTP 500 内部服务器错误响应。Amazon CloudWatch Logs 显示“too many connections”的错误。这些错误发生在不可预测的高峰使用时间。公司需要使应用程序具有弹性。除了计划的维护时间外，数据库不能宕机。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "减少数据库实例的 vCPU 数量。增加 max_connections 设置。",
        "reason": "减少 vCPU 数量可能会降低数据库性能，而增加 max_connections 设置可能会导致更多的连接问题。这种方法不能从根本上解决连接数过多的问题。"
      },
      "B": {
        "option": "使用 Amazon RDS Proxy 创建一个连接到数据库实例的代理。更新 Lambda 函数以连接到代理。",
        "reason": "使用 Amazon RDS Proxy 会为数据库连接提供池化和管理，从而减少数据库的直接连接数量，提高应用程序的弹性和可扩展性。这是解决“too many connections”问题的最佳方法。"
      },
      "C": {
        "option": "添加一个 CloudWatch 警报，当连接数增加到超过 1000 时更改数据库实例类别。",
        "reason": "虽然更改数据库实例类别可能会提高性能，但它不是一个实时解决方案，且可能会导致数据库的短暂不可用。这个方法不能保证在高峰时段立即解决连接问题。"
      },
      "D": {
        "option": "添加一个 Amazon EventBridge 规则，当 CPU 使用率超过 75% 时增加数据库实例的 max_connections 设置。",
        "reason": "增加 max_connections 设置可能会导致更多的连接问题，并且根据 CPU 使用率调整连接数并不能直接解决“too many connections”问题。"
      }
    }
  },
  {
    "number": "67",
    "best": ["B"],
    "question": "公司在所有客户地点安装了智能电表。这些智能电表每分钟测量一次电力使用情况，并将使用读数发送到远程端点进行收集。公司需要创建一个端点来接收智能电表读数并将读数存储在数据库中。公司希望存储位置ID和时间戳信息。公司希望向客户提供低延迟的当前使用情况和历史使用情况访问。公司预计需求将显著增加。解决方案在扩展时必须不影响性能或包括停机时间。哪种解决方案最具成本效益地满足这些要求？",
    "options": {
      "A": {
        "option": "将智能电表读数存储在Amazon RDS数据库中。在位置ID和时间戳列上创建索引。使用这些列过滤客户数据。",
        "reason": "Amazon RDS是一种关系型数据库服务，它适合结构化数据的存储和复杂查询。然而，RDS在处理高频率写入和大规模数据扩展时可能会遇到性能瓶颈。另外，RDS的维护成本较高，特别是在需要高可用性和自动扩展的情况下。因此，这不是最具成本效益的解决方案。"
      },
      "B": {
        "option": "将智能电表读数存储在Amazon DynamoDB表中。使用位置ID和时间戳列创建复合键。使用这些列过滤客户数据。",
        "reason": "Amazon DynamoDB是一种完全托管的NoSQL数据库，具有自动扩展、高性能和低延迟的特点。它非常适合处理高频率读写操作和大规模数据。通过使用复合键，可以高效地查询特定位置和时间范围内的数据。因此，这种解决方案最具成本效益并能满足需求。"
      },
      "C": {
        "option": "将智能电表读数存储在Amazon ElastiCache for Redis中。使用位置ID和时间戳列创建一个SortedSet键。使用这些列过滤客户数据。",
        "reason": "Amazon ElastiCache for Redis是一种内存中数据存储服务，非常适合需要低延迟访问的数据。然而，它主要用于缓存和临时存储，而不是持久存储。智能电表读数需要持久存储和长期查询，这超出了Redis的主要用途。此外，内存存储的成本较高，不适合大规模数据存储。因此，这不是最佳选择。"
      },
      "D": {
        "option": "将智能电表读数存储在Amazon S3中。使用位置ID和时间戳列分区数据。使用Amazon Athena过滤客户数据。",
        "reason": "Amazon S3是一种对象存储服务，具有高可扩展性和低成本特点。通过分区，可以高效地存储和查询大规模数据。Amazon Athena是一种基于SQL的查询服务，可以直接查询存储在S3中的数据。然而，Athena查询可能会引入延迟，不适合需要低延迟访问的场景。因此，这种解决方案尽管成本低，但在低延迟要求下不是最佳选择。"
      }
    }
  },
  {
    "number": "68",
    "best": ["A"],
    "question": "一家公司正在构建一个使用 AWS Lambda 函数的无服务器应用程序。公司需要创建一组测试事件来在开发环境中测试 Lambda 函数。这些测试事件将创建一次，然后由 IAM 开发者组中的所有开发人员使用。测试事件必须可以被 IAM 开发者组中的任何 IAM 用户编辑。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "将测试事件作为 JSON 对象存储在 Amazon S3 中。允许所有 IAM 用户访问 S3 存储桶。",
        "reason": "此选项是最佳选择，因为 Amazon S3 提供了一个简单且高度可访问的存储解决方案，允许开发人员轻松共享和编辑 JSON 格式的测试事件。通过适当的 IAM 权限配置，所有开发人员都可以访问和修改存储在 S3 中的测试事件。"
      },
      "B": {
        "option": "创建测试事件。配置事件共享设置以使测试事件可共享。",
        "reason": "此选项在问题描述中没有说明具体的存储位置或共享机制，因此难以评估其可行性。"
      },
      "C": {
        "option": "将测试事件存储在 Amazon DynamoDB 中。使用 IAM 角色允许对 DynamoDB 的访问。",
        "reason": "虽然 DynamoDB 是一个持久化存储解决方案，但它更适用于结构化数据存储和快速查询，而不是简单的 JSON 文件共享。使用 DynamoDB 可能会增加不必要的复杂性。"
      },
      "D": {
        "option": "创建测试事件。配置事件共享设置以使测试事件为私有。",
        "reason": "此选项不符合需求，因为测试事件需要由 IAM 开发者组中的所有用户共享和编辑，而不是私有的。"
      }
    }
  },
  {
    "number": "69",
    "best": ["B", "E"],
    "question": "开发人员正在 AWS CodePipeline 中配置应用程序的部署环境。应用程序代码存储在 GitHub 仓库中。开发人员希望确保在新的部署环境中运行仓库包的单元测试。开发人员已经将管道的源提供程序设置为 GitHub，并指定了用于部署的仓库和分支。接下来开发人员应该采取哪些步骤来以最少的开销满足这些要求？（选择两个。）",
    "options": {
      "A": {
        "option": "创建一个 AWS CodeCommit 项目。将仓库包的构建和测试命令添加到项目的 buildspec 中。",
        "reason": "AWS CodeCommit 是一个源代码控制服务，而不是用来构建和测试代码的服务。因此，它不适合用于运行单元测试。"
      },
      "B": {
        "option": "创建一个 AWS CodeBuild 项目。将仓库包的构建和测试命令添加到项目的 buildspec 中。",
        "reason": "AWS CodeBuild 是一个完全托管的构建服务，可以编译源代码、运行测试并生成软件包。创建 CodeBuild 项目并添加构建和测试命令是确保在部署环境中运行单元测试的正确步骤。"
      },
      "C": {
        "option": "创建一个 AWS CodeDeploy 项目。将仓库包的构建和测试命令添加到项目的 buildspec 中。",
        "reason": "AWS CodeDeploy 用于自动化代码部署，不适合用于运行构建和测试命令。因此，这不是一个合适的选择。"
      },
      "D": {
        "option": "向源阶段添加一个操作。指定新创建的项目作为操作提供程序。将构建工件指定为操作的输入工件。",
        "reason": "在源阶段添加操作并不合适，因为构建和测试通常在源阶段之后进行。"
      },
      "E": {
        "option": "在源阶段之后为管道添加一个新阶段。向新阶段添加一个操作。指定新创建的项目作为操作提供程序。将源工件指定为操作的输入工件。",
        "reason": "在源阶段之后添加一个新阶段，并在新阶段中添加一个操作以指定 CodeBuild 项目，这是正确的步骤。这将确保在拉取源代码后立即运行构建和测试命令。"
      }
    }
  },
  {
    "number": "70",
    "best": ["A"],
    "question": "一位工程师在一个 Amazon CloudWatch Evidently 项目中创建了一个新功能的 A/B 测试。工程师为测试配置了该功能的两个变体（变体 A 和变体 B）。工程师希望只使用变体 A，并且需要进行更新以使工程师在访问应用程序的端点时仅显示变体 A。哪种解决方案可以满足这一要求？",
    "options": {
      "A": {
        "option": "为该功能添加一个覆盖。将覆盖的标识符设置为工程师的用户 ID。将变体设置为变体 A。",
        "reason": "通过添加覆盖并将标识符设置为工程师的用户 ID，工程师可以确保在访问应用程序端点时只接收到变体 A。这种方法使得特定用户（在这种情况下是工程师）只看到指定的变体，这正是题目要求的内容。"
      },
      "B": {
        "option": "为该功能添加一个覆盖。将覆盖的标识符设置为变体 A。将变体设置为 100%。",
        "reason": "这种方法试图通过设置覆盖来仅显示变体 A，但覆盖的标识符应该是用户 ID，而不是变体本身。因此，这个选项是不正确的。"
      },
      "C": {
        "option": "为项目添加一个实验。将实验的标识符设置为变体 B。将变体设置为 0%。",
        "reason": "这种方法通过实验设置变体 B 为 0%来达到目标，但题目要求的是覆盖功能而不是实验。此外，这种方法不完全符合工程师专门使用变体 A 的需求。"
      },
      "D": {
        "option": "为项目添加一个实验。将实验的标识符设置为 AWS 账户的账户 ID。将变体设置为变体 A。",
        "reason": "这种方法试图通过实验来解决问题，但题目要求的是覆盖功能。此外，将实验的标识符设置为 AWS 账户的账户 ID 也不符合题意。"
      }
    }
  },
  {
    "number": "71",
    "best": ["A"],
    "question": "一位开发人员正在处理一个使用 Amazon DynamoDB 作为数据存储的现有应用程序。DynamoDB 表具有以下属性：partNumber（分区键）、vendor（排序键）、description、productFamily 和 productType。当开发人员分析使用模式时，注意到有些应用程序模块经常根据 productFamily 和 productType 属性查找产品列表。开发人员希望对应用程序进行更改以提高查询操作的性能。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个全局二级索引（GSI），使用 productFamily 作为分区键，productType 作为排序键。",
        "reason": "全局二级索引（GSI）可以在不影响现有主表结构的情况下，支持对不同属性的高效查询。使用 productFamily 作为分区键，productType 作为排序键，可以满足根据这两个属性查询的需求，并且大大提高查询性能。"
      },
      "B": {
        "option": "创建一个本地二级索引（LSI），使用 productFamily 作为分区键，productType 作为排序键。",
        "reason": "本地二级索引（LSI）只能在创建表时定义，且分区键必须与主表的分区键相同。由于现有表的分区键是 partNumber，这种索引不能满足查询需求。"
      },
      "C": {
        "option": "重新创建表。添加 partNumber 作为分区键，vendor 作为排序键。在创建表时，添加一个本地二级索引（LSI），使用 productFamily 作为分区键，productType 作为排序键。",
        "reason": "重新创建表是一个复杂和高成本的操作，可能会导致数据迁移和停机时间。而且，本地二级索引（LSI）也不能满足查询需求，因为其分区键必须与主表的分区键相同。"
      },
      "D": {
        "option": "更新查询以使用 Scan 操作，productFamily 作为分区键，productType 作为排序键。",
        "reason": "Scan 操作会扫描整个表，导致性能低下，特别是当表的数据量很大时。这不是一个高效的查询方法，并且会增加延迟和成本。因此，这不是一个合适的解决方案。"
      }
    }
  },
  {
    "number": "72",
    "best": ["C"],
    "question": "开发人员创建了一个名为 VPC-A 的 VPC，其中包含公有子网和私有子网。开发人员还在 VPC-A 的私有子网中创建了一个 Amazon RDS 数据库。为了执行一些查询，开发人员在默认 VPC 中创建了一个 AWS Lambda 函数。Lambda 函数包含访问 RDS 数据库的代码。当 Lambda 函数运行时，错误消息表明该函数无法连接到 RDS 数据库。开发人员应如何解决这个问题？",
    "options": {
      "A": {
        "option": "修改 RDS 安全组。添加一条规则，允许来自 VPC CIDR 块的所有端口的流量。",
        "reason": "这种方法过于宽泛，可能会带来安全风险。允许所有端口的流量并不是最佳实践。"
      },
      "B": {
        "option": "在与 RDS 实例相同的子网中重新部署 Lambda 函数。确保 RDS 安全组允许来自 Lambda 函数的流量。",
        "reason": "虽然这可能有效，但在实际操作中，Lambda 函数通常部署在默认 VPC 中，重新部署到特定子网可能会增加复杂性和管理负担。"
      },
      "C": {
        "option": "为 Lambda 函数创建一个安全组。在 RDS 安全组中添加一条新规则，允许来自新 Lambda 安全组的流量。",
        "reason": "这是最佳解决方案。通过创建一个新的安全组并在 RDS 安全组中添加规则，可以确保仅允许来自特定安全组的流量，从而提高安全性。"
      },
      "D": {
        "option": "创建一个 IAM 角色。附加一个允许访问 RDS 数据库的策略。将角色附加到 Lambda 函数。",
        "reason": "虽然 IAM 角色可以控制 Lambda 函数的权限，但无法解决网络层面的连接问题。Lambda 函数仍然需要通过安全组规则访问 RDS 数据库。"
      }
    }
  },
  {
    "number": "73",
    "best": ["C"],
    "question": "公司在 AWS 上运行一个应用程序。公司在 Amazon EC2 实例上部署了该应用程序。该应用程序将数据存储在 Amazon Aurora 上。最近，该应用程序将多个应用程序特定的自定义 DECRYP_ERROR 错误记录到 Amazon CloudWatch 日志中。公司直到每 30 分钟运行一次的自动化测试失败时才检测到问题。开发人员必须实施一个解决方案，以在生产环境中发生这些错误时实时监控并警告开发团队。哪种解决方案可以以最少的操作开销满足这些要求？",
    "options": {
      "A": {
        "option": "配置应用程序以创建一个自定义指标并将指标推送到 CloudWatch。创建一个 AWS CloudTrail 警报。配置 CloudTrail 警报以使用 Amazon Simple Notification Service (Amazon SNS) 主题发送通知。",
        "reason": "这个选项涉及应用程序级别的修改，并且需要创建自定义指标和 CloudTrail 警报，操作开销较大。"
      },
      "B": {
        "option": "创建一个 AWS Lambda 函数，每 5 分钟运行一次以扫描 CloudWatch 日志中的 DECRYP_ERROR 关键字。配置 Lambda 函数以使用 Amazon Simple Notification Service (Amazon SNS) 发送通知。",
        "reason": "这个选项需要编写和维护 Lambda 函数，并且每 5 分钟运行一次会增加操作开销。"
      },
      "C": {
        "option": "使用 Amazon CloudWatch Logs 创建一个具有 DECRYP_ERROR 过滤模式的指标过滤器。为此指标创建一个 CloudWatch 警报，阈值 >=1。配置警报以发送 Amazon Simple Notification Service (Amazon SNS) 通知。",
        "reason": "这个选项直接利用 CloudWatch Logs 的内置功能，设置简单，自动化程度高，操作开销最小。"
      },
      "D": {
        "option": "在 EC2 实例上安装 CloudWatch 统一代理。配置应用程序以生成 DECRYP_ERROR 错误的指标。配置代理以发送 Amazon Simple Notification Service (Amazon SNS) 通知。",
        "reason": "这个选项需要在 EC2 实例上安装和配置 CloudWatch 代理，增加了操作和维护工作。"
      }
    }
  },
  {
    "number": "74",
    "best": ["A"],
    "question": "开发人员创建了一个访问 VPC 资源的 AWS Lambda 函数。该 Lambda 函数通过 VPC 端点轮询 Amazon Simple Queue Service (Amazon SQS) 队列中的新消息。然后函数计算消息中包含的数值的滚动平均值。在 Lambda 函数的初步测试后，开发人员发现函数返回的滚动平均值不准确。开发人员如何确保函数计算准确的滚动平均值？",
    "options": {
      "A": {
        "option": "将函数的保留并发设置为 1。在函数中计算滚动平均值。将计算出的滚动平均值存储在 Amazon ElastiCache 中。",
        "reason": "将保留并发设置为 1 确保了 Lambda 函数在任何时间点只有一个实例在运行，这样就避免了并发执行导致的数据不一致问题。将计算结果存储在 Amazon ElastiCache 中可以持久化计算结果并在后续使用中读取，是一种有效的缓存解决方案。"
      },
      "B": {
        "option": "修改函数以将数值存储在 Amazon ElastiCache 中。当函数初始化时，使用缓存中的先前值来计算滚动平均值。",
        "reason": "虽然将数值存储在 ElastiCache 中是合理的，但这并没有解决并发执行导致的数据不一致问题。仅仅依赖初始化时的缓存数据可能仍然会受到并发执行的影响，因此不推荐。"
      },
      "C": {
        "option": "将函数的预置并发设置为 1。在函数中计算滚动平均值。将计算出的滚动平均值存储在 Amazon ElastiCache 中。",
        "reason": "预置并发用于确保 Lambda 函数的冷启动时间最小化，但并不保证只有一个实例在运行。这个设置没有解决并发执行的问题，因此不适合解决该问题。"
      },
      "D": {
        "option": "修改函数以将数值存储在函数的层中。当函数初始化时，使用先前存储的值来计算滚动平均值。",
        "reason": "Lambda 层用于共享代码和资源，不适合存储动态数据。并且，这种方法也无法解决并发执行导致的数据不一致问题。因此不推荐。"
      }
    }
  },
  {
    "number": "75",
    "best": ["A"],
    "question": "开发人员正在为一个即将在 AWS 上部署的新应用程序编写单元测试。开发人员希望使用单元测试验证所有的拉取请求，并且只有在所有测试通过后才能将代码合并到主分支中。开发人员将代码存储在 AWS CodeCommit 中，并设置 AWS CodeBuild 运行单元测试。开发人员创建了一个 AWS Lambda 函数来启动 CodeBuild 任务。开发人员需要识别 Amazon EventBridge 事件中的 CodeCommit 事件，以便在创建或更新拉取请求时调用 Lambda 函数。哪一个 CodeCommit 事件可以满足这些要求？",
    "options": {
      "A": {
        "option": "当拉取请求创建或更新时触发的 CodeCommit 事件。",
        "reason": "这是最符合题干要求的选项，因为题目明确要求在创建或更新拉取请求时调用 Lambda 函数。与其他选项相比，这是最符合要求的。"
      },
      "B": {
        "option": "当代码提交到主分支时触发的 CodeCommit 事件。",
        "reason": "这个事件在代码提交到主分支时触发，但题目要求是在拉取请求创建或更新时进行单元测试验证。"
      },
      "C": {
        "option": "当代码被推送到任何分支时触发的 CodeCommit 事件。",
        "reason": "这个事件在代码推送到任何分支时触发，但并没有特别针对拉取请求的创建或更新。"
      },
      "D": {
        "option": "当删除拉取请求时触发的 CodeCommit 事件。",
        "reason": "这个事件在拉取请求被删除时触发，并不符合题目中关于创建或更新拉取请求的要求。"
      }
    }
  },
  {
    "number": "76",
    "best": ["A"],
    "question": "开发人员将应用程序部署到 Amazon EC2 实例。该应用程序需要知道实例的公有 IPv4 地址。应用程序如何获取此信息？",
    "options": {
      "A": {
        "option": "从 http://169.254.169.254/latest/meta-data/ 查询实例元数据。",
        "reason": "实例元数据服务提供有关实例的各种信息，包括实例的公有 IPv4 地址。通过访问特定的元数据 URL，应用程序可以获取到实例的公有 IPv4 地址。"
      },
      "B": {
        "option": "从 http://169.254.169.254/latest/user-data/ 查询实例用户数据。",
        "reason": "实例用户数据用于在实例启动时传递启动脚本和配置数据。它不会包含实例的公有 IPv4 地址，因此不适合用来获取此信息。"
      },
      "C": {
        "option": "从 http://169.254.169.254/latest/meta-data/ami/ 查询 Amazon Machine Image (AMI) 信息。",
        "reason": "AMI 信息包含有关用于启动实例的 AMI 的详细信息，但不包含实例的公有 IPv4 地址。因此，这不是获取实例公有 IPv4 地址的正确方法。"
      },
      "D": {
        "option": "检查操作系统的 hosts 文件。",
        "reason": "操作系统的 hosts 文件用于静态 IP 地址和主机名之间的映射，通常不包含动态分配的公有 IPv4 地址。因此，这不是获取实例公有 IPv4 地址的正确方法。"
      }
    }
  },
  {
    "number": "77",
    "best": ["C"],
    "question": "一个正在开发的应用程序需要存储数百个视频文件。数据在存储之前必须在应用程序内进行加密，并且每个视频文件需要一个唯一的密钥。开发人员应该如何编写应用程序代码？",
    "options": {
      "A": {
        "option": "使用 KMS Encrypt API 来加密数据。存储加密的数据密钥和数据。",
        "reason": "KMS Encrypt API 主要用于加密小块数据（最多 4KB），不适合用于加密大量视频文件。"
      },
      "B": {
        "option": "使用加密库为应用程序生成一个加密密钥。使用加密密钥对数据进行加密。存储加密的数据。",
        "reason": "虽然这提供了加密，但没有满足每个视频文件使用唯一密钥的要求。此外，自行管理密钥的复杂性较高，不推荐。"
      },
      "C": {
        "option": "使用 KMS GenerateDataKey API 获取数据密钥。使用数据密钥加密数据。存储加密的数据密钥和数据。",
        "reason": "使用 KMS GenerateDataKey API 可以为每个视频文件生成一个唯一的加密密钥，这符合题目要求。数据密钥用来对视频文件进行加密，之后加密的数据密钥和加密的数据一起存储，符合最佳实践。"
      },
      "D": {
        "option": "使用带有 AWS KMS 密钥的服务器端加密将数据上传到 S3 存储桶。",
        "reason": "这种方法是由 S3 管理加密密钥和加密过程，不符合题目中要求的在应用程序内进行加密以及为每个视频文件使用唯一密钥的要求。"
      }
    }
  },
  {
    "number": "78",
    "best": ["A"],
    "question": "一家公司计划在 AWS 上部署一个应用程序，应用程序位于一个弹性负载均衡器（Elastic Load Balancer）后面。该应用程序使用 HTTP/HTTPS 监听器，并且必须访问客户端 IP 地址。哪种负载均衡解决方案满足这些要求？",
    "options": {
      "A": {
        "option": "使用应用程序负载均衡器（Application Load Balancer）和 X-Forwarded-For 头。",
        "reason": "应用程序负载均衡器（ALB）支持 HTTP/HTTPS 协议，并且可以通过 X-Forwarded-For 头传递客户端 IP 地址。这正是题目中的要求。"
      },
      "B": {
        "option": "使用网络负载均衡器（Network Load Balancer）。在 NLB 和目标应用程序上启用代理协议支持。",
        "reason": "尽管网络负载均衡器（NLB）能够处理 TCP/UDP 流量并且可以启用代理协议来传递客户端 IP 地址，但它不支持直接的 HTTP/HTTPS 监听器。题目中特别提到使用 HTTP/HTTPS 监听器，这使得 NLB 不是最佳选择。"
      },
      "C": {
        "option": "使用应用程序负载均衡器（Application Load Balancer）。通过实例 ID 注册目标。",
        "reason": "虽然应用程序负载均衡器支持 HTTP/HTTPS 协议，但是通过实例 ID 注册目标并不能确保客户端 IP 地址被传递。题目中明确要求访问客户端 IP 地址，因此这种方法不合适。"
      },
      "D": {
        "option": "使用网络负载均衡器和 X-Forwarded-For 头。",
        "reason": "网络负载均衡器（NLB）不支持 X-Forwarded-For 头。NLB 主要用于处理 TCP/UDP 流量，而不是 HTTP/HTTPS 流量。因此，这不是一个可行的解决方案。"
      }
    }
  },
  {
    "number": "79",
    "best": ["B"],
    "question": "一位开发人员希望通过搜索和筛选日志数据来调试应用程序。应用程序日志存储在 Amazon CloudWatch Logs 中。开发人员创建了一个新的指标过滤器来统计应用程序日志中的异常情况。然而，日志中没有返回任何结果。为什么没有返回筛选结果？",
    "options": {
      "A": {
        "option": "在 VPC 中筛选 CloudWatch Logs 需要设置 Amazon CloudWatch 接口 VPC 端点。",
        "reason": "这个选项不正确，因为 VPC 端点配置与日志过滤无关。VPC 端点主要用于在 VPC 内部访问 AWS 服务，而不需要通过互联网。"
      },
      "B": {
        "option": "CloudWatch Logs 仅为在过滤器创建后发生的事件发布指标数据。",
        "reason": "这个选项是正确的。CloudWatch Logs 中的指标过滤器仅对创建后发生的事件进行指标数据统计。之前的日志事件不会被重新处理，因此不会返回任何结果。"
      },
      "C": {
        "option": "在进行指标过滤之前，CloudWatch Logs 的日志组应首先流式传输到 Amazon OpenSearch Service。",
        "reason": "这个选项不正确。将日志流式传输到 Amazon OpenSearch Service 是为了进行更复杂的搜索和分析，但与 CloudWatch Logs 的指标过滤无关。"
      },
      "D": {
        "option": "日志组的指标数据点只能在导出到 Amazon S3 存储桶后进行过滤。",
        "reason": "这个选项不正确。日志组的指标数据点不需要导出到 S3 后才能进行过滤。CloudWatch Logs 直接支持日志过滤和指标创建。"
      }
    }
  },
  {
    "number": "80",
    "best": ["A"],
    "question": "公司计划使用 AWS CodeDeploy 将一个应用程序部署到 Amazon Elastic Container Service (Amazon ECS)。在部署新版本的应用程序时，公司最初必须只将10%的实时流量暴露给新版本的已部署应用程序。然后，在15分钟后，公司必须将所有剩余的实时流量路由到新版本的已部署应用程序。哪个 CodeDeploy 预定义配置将满足这些要求？",
    "options": {
      "A": {
        "option": "CodeDeployDefault.ECSCanary10Percent15Minutes",
        "reason": "此配置符合题目要求，最初将10%的流量暴露给新版本，在15分钟后将所有流量路由到新版本。适用于Amazon ECS的金丝雀部署策略。"
      },
      "B": {
        "option": "CodeDeployDefault.LambdaCanary10Percent5Minutes",
        "reason": "此配置只适用于AWS Lambda函数部署，并且时间间隔是5分钟，不符合题目中关于15分钟的要求。"
      },
      "C": {
        "option": "CodeDeployDefault.LambdaCanary10Percent15Minutes",
        "reason": "此配置也只适用于AWS Lambda函数部署，尽管时间间隔是15分钟，但不适用于Amazon ECS。"
      },
      "D": {
        "option": "CodeDeployDefault.ECSLinear10PercentEvery1Minutes",
        "reason": "此配置是线性部署策略，每分钟增加10%的流量，不符合题目中先10%流量然后在15分钟后全部切换的要求。"
      }
    }
  },
  {
    "number": "81",
    "best": ["C"],
    "question": "一家公司在 AWS Elastic Beanstalk 上托管一个批处理应用程序，实例运行最新版本的 Amazon Linux。该应用程序对大型数据集进行排序和处理。最近几周，在流量高峰期，应用程序的性能显著下降。开发人员怀疑应用程序的问题与内存使用有关。开发人员检查了 Elastic Beanstalk 控制台，注意到内存使用情况没有被跟踪。开发人员应如何收集有关应用程序性能问题的更多信息？",
    "options": {
      "A": {
        "option": "配置 Amazon CloudWatch 代理，通过端口 443 将日志推送到 Amazon CloudWatch Logs。",
        "reason": "虽然将日志推送到 CloudWatch Logs 可以帮助分析应用程序行为，但它不能直接跟踪内存使用情况。"
      },
      "B": {
        "option": "配置 Elastic Beanstalk .ebextensions 目录以跟踪实例的内存使用情况。",
        "reason": "Elastic Beanstalk 的 .ebextensions 目录用于配置和自定义环境，但它本身不直接提供内存使用跟踪功能。"
      },
      "C": {
        "option": "配置 Amazon CloudWatch 代理以跟踪实例的内存使用情况。",
        "reason": "这是最优选项。Amazon CloudWatch 代理可以配置为收集系统级指标，包括内存使用情况，并将这些指标发送到 CloudWatch 进行监控和分析。"
      },
      "D": {
        "option": "配置一个 Amazon CloudWatch 仪表板以跟踪实例的内存使用情况。",
        "reason": "虽然 CloudWatch 仪表板可以用于可视化内存使用情况，但它需要先配置代理来收集内存使用数据。因此，这不是最佳的第一个步骤。"
      }
    }
  },
  {
    "number": "82",
    "best": ["B"],
    "question": "一个开发人员正在使用无服务器组件构建一个高度安全的医疗应用程序。该应用程序需要将临时数据写入 AWS Lambda 函数的 /tmp 存储中。开发人员应该如何加密这些数据？",
    "options": {
      "A": {
        "option": "在 Lambda 函数配置中启用使用 AWS KMS 密钥的 Amazon EBS 卷加密，以便附加到 Lambda 函数的所有存储都被加密。",
        "reason": "Lambda 函数的 /tmp 存储是一个临时文件系统，而不是 EBS 卷。因此，EBS 卷加密无法应用于 Lambda 函数的临时存储。"
      },
      "B": {
        "option": "为 Lambda 函数设置一个角色和密钥策略，以访问 AWS KMS 密钥。使用该密钥生成一个数据密钥，用于在写入 /tmp 存储之前加密所有数据。",
        "reason": "这是最佳选项。使用 AWS KMS 生成的数据密钥可以确保数据在写入 /tmp 存储之前被加密。这是一种安全且符合 AWS 最佳实践的方法。"
      },
      "C": {
        "option": "使用 OpenSSL 在 Lambda 启动时生成对称加密密钥。使用该密钥在写入 /tmp 之前加密数据。",
        "reason": "虽然这也是一种加密数据的方法，但它缺乏使用 AWS KMS 提供的密钥管理和安全性。管理加密密钥的生命周期和保护密钥安全会更加复杂。"
      },
      "D": {
        "option": "使用本地硬件安全模块 (HSM) 生成密钥，Lambda 函数请求数据密钥并在所有请求中使用该数据密钥加密数据。",
        "reason": "此选项增加了不必要的复杂性，而且使用本地 HSM 可能会增加延迟和成本。AWS KMS 提供了内置的云原生密钥管理功能，更适合无服务器架构。"
      }
    }
  },
  {
    "number": "83",
    "best": ["B"],
    "question": "开发人员创建了一个 AWS Lambda 函数，用于在Amazon S3 中上传的文件大于 50 MB 时，通过 Amazon Simple Notification Service (Amazon SNS) 提供通知。开发人员已使用 CLI 部署并测试了 Lambda 函数。但是，当事件通知被添加到 S3 桶并上传了一个 3,000 MB 的文件时，Lambda 函数未启动。以下哪个可能是 Lambda 函数无法启动的原因？",
    "options": {
      "A": {
        "option": "对于大于 1,000 MB 的文件，S3 事件通知不会激活。",
        "reason": "这种说法不正确。S3 事件通知没有文件大小的限制，可以对任何大小的文件触发。"
      },
      "B": {
        "option": "Lambda 函数的基于资源的策略没有被 Amazon S3 调用所需的权限。",
        "reason": "这是最可能的原因。Lambda 函数需要在其资源策略中明确授予 Amazon S3 调用它的权限。如果缺失此权限，Lambda 将无法响应来自 S3 的事件通知。"
      },
      "C": {
        "option": "Lambda 函数不能直接由 S3 事件调用。",
        "reason": "这种说法不正确。S3 事件可以直接触发 Lambda 函数，这是一个常见的用例，例如用于处理文件上传事件。"
      },
      "D": {
        "option": "S3 桶需要被设为公开。",
        "reason": "这种说法不正确。S3 桶不需要公开即可触发 Lambda 函数。S3 事件通知和 Lambda 函数的调用权限是通过 IAM 策略和资源策略来管理的，而不是通过桶的公开访问权限。"
      }
    }
  },
  {
    "number": "84",
    "best": ["D"],
    "question": "开发人员正在创建一个 Ruby 应用程序，并需要在不需要了解底层基础设施的情况下自动化部署、扩展和管理环境。哪个服务最适合完成这个任务？",
    "options": {
      "A": {
        "option": "AWS CodeDeploy",
        "reason": "AWS CodeDeploy 是一种自动化部署服务，用于将代码部署到任何实例，包括 Amazon EC2 实例和本地服务器。然而，它不提供扩展和管理环境的功能，需要开发人员了解一些基础设施细节。"
      },
      "B": {
        "option": "AWS CloudFormation",
        "reason": "AWS CloudFormation 是一种基础设施即代码（IaC）服务，允许用户通过模板配置和管理 AWS 资源。虽然它可以自动化环境配置，但需要对底层基础设施有详细了解，因此不完全符合题目要求。"
      },
      "C": {
        "option": "AWS OpsWorks",
        "reason": "AWS OpsWorks 是一种配置管理服务，可以使用 Chef 和 Puppet 自动化服务器配置、部署和管理。然而，它仍然需要一定的基础设施知识，不完全符合题目要求。"
      },
      "D": {
        "option": "AWS Elastic Beanstalk",
        "reason": "AWS Elastic Beanstalk 是一种平台即服务（PaaS），允许开发人员在不需要了解底层基础设施的情况下部署和管理应用程序。它自动处理环境的部署、扩展和管理，是本题目中最优的选择。"
      }
    }
  },
  {
    "number": "85",
    "best": ["B", "D"],
    "question": "一家公司有一个部署在 AWS 上的 Web 应用程序。该应用程序使用 Amazon API Gateway API 和 AWS Lambda 函数作为其后端。最近，该应用程序表现出意外行为。开发人员检查 Lambda 函数代码，发现错误并修改代码以解决问题。在将更改部署到生产环境之前，开发人员需要运行测试以验证应用程序是否正常运行。该应用程序只有一个生产环境可用。开发人员必须创建一个新的开发环境来测试代码更改。开发人员还必须防止其他开发人员在测试周期期间覆盖这些更改。哪种步骤组合以最少的开发工作量满足这些要求？（选择两个）",
    "options": {
      "A": {
        "option": "在当前阶段创建一个新资源。使用 Lambda 代理集成创建一个新方法。选择 Lambda 函数。添加 hotfix 别名。重新部署当前阶段。测试后端。",
        "reason": "此选项需要在现有阶段上进行更改，可能会影响生产环境，不符合题意中提到的最少开发工作量和防止其他开发人员覆盖更改的要求。"
      },
      "B": {
        "option": "更新 API Gateway API 集成请求中的 Lambda 函数以使用 hotfix 别名。将 API Gateway API 部署到名为 hotfix 的新阶段。测试后端。",
        "reason": "此选项创建了一个新的阶段，并将 Lambda 函数指向 hotfix 别名，确保了开发环境与生产环境隔离，并且防止其他开发人员覆盖更改。"
      },
      "C": {
        "option": "通过修复代码修改 Lambda 函数。测试 Lambda 函数。创建 hotfix 别名。将别名指向 $LATEST 版本。",
        "reason": "此选项没有创建新的开发环境，仅仅创建了一个别名，并且指向最新版本，无法有效隔离测试环境和生产环境。"
      },
      "D": {
        "option": "通过修复代码修改 Lambda 函数。测试 Lambda 函数。当 Lambda 函数按预期工作时，将其发布为新版本。创建 hotfix 别名。将别名指向新版本。",
        "reason": "此选项确保代码修复后的 Lambda 函数被发布为一个新版本，并且通过 hotfix 别名指向该版本。结合选项 B，可以实现开发环境与生产环境的有效隔离。"
      },
      "E": {
        "option": "为开发环境创建一个新的 API Gateway API。添加一个具有 Lambda 集成的资源和方法。选择 Lambda 函数和 hotfix 别名。部署到新阶段。测试后端。",
        "reason": "此选项虽然创建了一个全新的 API Gateway API，但步骤相对繁琐，不符合最少开发工作量的要求。"
      }
    }
  },
  {
    "number": "86",
    "best": ["C"],
    "question": "一名开发人员正在实现一个 AWS Cloud Development Kit (AWS CDK) 无服务器应用程序。开发人员将在 AWS CloudFormation 堆栈创建过程中配置多个 AWS Lambda 函数和 Amazon API Gateway API。开发人员的工作站本地安装了 AWS Serverless Application Model (AWS SAM) 和 AWS CDK。开发人员如何在本地测试特定的 Lambda 函数？",
    "options": {
      "A": {
        "option": "运行 sam package 和 sam deploy 命令。从 AWS 管理控制台创建 Lambda 测试事件。测试 Lambda 函数。",
        "reason": "此选项涉及将更改部署到云环境，而不是在本地测试 Lambda 函数，因此不适合在本地测试。"
      },
      "B": {
        "option": "运行 cdk synth 和 cdk deploy 命令。从 AWS 管理控制台创建 Lambda 测试事件。测试 Lambda 函数。",
        "reason": "此选项也涉及将更改部署到云环境，而不是在本地测试 Lambda 函数，因此不适合在本地测试。"
      },
      "C": {
        "option": "运行 cdk synth 和 sam local invoke 命令，使用函数构造标识符和合成的 CloudFormation 模板路径。",
        "reason": "此选项是正确的，因为它使用 `cdk synth` 生成 CloudFormation 模板，并使用 `sam local invoke` 在本地测试特定的 Lambda 函数。这是最有效的本地测试方法。"
      },
      "D": {
        "option": "运行 cdk synth 和 sam local start-lambda 命令，使用函数构造标识符和合成的 CloudFormation 模板路径。",
        "reason": "此选项部分正确，`sam local start-lambda` 是用于启动本地 Lambda 服务的命令，但不是直接调用特定函数的方法。`sam local invoke` 更适合直接测试特定的 Lambda 函数。"
      }
    }
  },
  {
    "number": "87",
    "best": ["D"],
    "question": "公司的新移动应用程序使用 Amazon API Gateway。开发团队完成了其 API 的新版本，一个开发人员必须安全且透明地推出 API 更改。开发人员通过 API Gateway 向少量用户推出新 API 版本的最简单解决方案是什么？",
    "options": {
      "A": {
        "option": "在 API Gateway 中创建一个新的 API。使用 Amazon Route 53 加权路由策略将部分流量引导到新的 API。",
        "reason": "虽然使用加权路由可以实现流量的分配，但它需要配置和管理额外的资源（如创建新的 API 和配置 Route 53），这增加了复杂性。相比之下，API Gateway 的 canary release 部署选项更为简单和直接。"
      },
      "B": {
        "option": "验证新的 API 版本，并在预期最低使用时间窗口内将其提升到生产环境。",
        "reason": "在最低使用时间窗口内部署新版本虽然可以减少对用户的影响，但它不属于渐进式发布方式，无法保证只有一小部分用户会首先体验新版本，从而难以及时发现潜在问题。"
      },
      "C": {
        "option": "实施一个 Amazon CloudWatch 警报，如果观察到的 HTTP 500 状态码率超过预定阈值，则触发回滚。",
        "reason": "虽然 CloudWatch 警报可以帮助监控和触发回滚，但它不是一种流量分配策略，无法实现将新版本 API 透明地推出给少量用户并进行验证的目标。"
      },
      "D": {
        "option": "使用 API Gateway 中的 canary release 部署选项。使用 canarySettings 设置引导一部分 API 流量。",
        "reason": "canary release 是一种较为简单且有效的策略，可以将 API 流量的一小部分引导到新版本，从而在生产环境中进行验证。这种方式允许开发人员在新版本上线过程中逐步增加流量，确保新版本的稳定性和可靠性。"
      }
    }
  },
  {
    "number": "88",
    "best": ["B"],
    "question": "公司缓存一个web应用的会话信息在一张Amazon DynamoDB表中。公司希望有一种自动化的方法来删除表中的旧项目。最简单的方法是什么？",
    "options": {
      "A": {
        "option": "编写一个脚本来删除旧记录；将脚本作为cron作业调度在一台Amazon EC2实例上。",
        "reason": "这种方法需要手动编写和维护脚本，并且需要管理EC2实例的运行和安全，增加了复杂性和管理开销，不是最简单的方法。"
      },
      "B": {
        "option": "添加一个带有过期时间的属性；基于该属性启用Time To Live功能。",
        "reason": "DynamoDB的Time To Live (TTL) 功能非常适合自动删除过期的数据。只需添加一个包含过期时间的属性，并启用TTL功能，DynamoDB会自动删除过期的项目。这种方法简单且自动化，无需额外的管理工作。"
      },
      "C": {
        "option": "每天创建一个新的表来保存会话数据；删除前一天的表。",
        "reason": "这种方法会导致每天都需要创建和删除表，增加了管理的复杂性，并且可能引入数据一致性问题，不是最简单的方法。"
      },
      "D": {
        "option": "添加一个带有过期时间的属性；将该属性命名为ItemExpiration。",
        "reason": "虽然添加过期时间属性是正确的方向，但仅仅命名为ItemExpiration并不会启用自动删除功能。还需要手动管理这些过期项目，不如使用TTL功能自动化来得简单。"
      }
    }
  },
  {
    "number": "89",
    "best": ["C"],
    "question": "一家公司正在使用 Amazon API Gateway REST API 端点作为 Webhook，将事件从本地源代码管理 (SCM) 系统发布到 Amazon EventBridge。公司已经配置了一个 EventBridge 规则来监听这些事件，并在中央 AWS 账户中控制应用程序部署。公司需要在多个接收方 AWS 账户中接收相同的事件。开发人员在不改变 SCM 系统配置的情况下，如何满足这些要求？",
    "options": {
      "A": {
        "option": "将 API Gateway REST API 部署到所有需要的 AWS 账户。对所有网关端点使用相同的自定义域名，这样一个 SCM webhook 就可以用于所有账户的所有事件。",
        "reason": "虽然这种方法可以使所有账户使用相同的域名，但仍然需要在每个账户中分别部署 API Gateway REST API，这增加了复杂性和维护成本。"
      },
      "B": {
        "option": "将 API Gateway REST API 部署到所有接收方 AWS 账户。创建与 AWS 账户数量相同的 SCM webhooks。",
        "reason": "这种方法要求为每个接收方 AWS 账户创建单独的 SCM webhook，这将增加 SCM 系统的管理负担，并且不符合“不改变 SCM 系统配置”的要求。"
      },
      "C": {
        "option": "授予中央 AWS 账户访问接收方 AWS 账户的 EventBridge 的权限。将接收方 AWS 账户上的 EventBridge 事件总线添加为现有 EventBridge 规则的目标。",
        "reason": "这种方法可以在不改变 SCM 系统配置的情况下，通过中央 AWS 账户将事件分发到多个接收方 AWS 账户。这是最直接和最有效的方法。"
      },
      "D": {
        "option": "将 API Gateway 类型从 REST API 转换为 HTTP API。",
        "reason": "这种方法虽然可能简化一些配置，但并不能解决如何在多个接收方 AWS 账户中接收相同事件的问题。因此不适合作为本题的解答。"
      }
    }
  },
  {
    "number": "90",
    "best": ["B"],
    "question": "一家公司将一些安全文件移动到一个没有公共访问权限的私有 Amazon S3 存储桶中。公司希望开发一个无服务器应用程序，使其员工能够登录并安全地与其他用户共享文件。公司应该使用哪种 AWS 功能来安全地共享和访问文件？",
    "options": {
      "A": {
        "option": "Amazon Cognito 用户池",
        "reason": "Amazon Cognito 用户池主要用于管理用户身份验证和授权，但它并不直接提供文件共享功能。"
      },
      "B": {
        "option": "S3 预签名 URL",
        "reason": "S3 预签名 URL 允许临时访问存储在私有 S3 存储桶中的对象。你可以生成一个预签名的 URL，并将其共享给其他用户，他们可以通过该 URL 安全地访问文件。这是最符合题意的选项。"
      },
      "C": {
        "option": "S3 存储桶策略",
        "reason": "S3 存储桶策略用于定义谁可以访问 S3 存储桶及其内容，但它并不适用于临时和安全地共享单个文件。"
      },
      "D": {
        "option": "Amazon Cognito 身份池",
        "reason": "Amazon Cognito 身份池用于为应用程序用户提供临时的 AWS 凭证，以访问 AWS 服务，但它并不直接提供文件共享功能。"
      }
    }
  },
  {
    "number": "91",
    "best": ["B"],
    "question": "一家公司需要为一个网络服务应用程序开发概念验证。该应用程序将显示公司某个办公室位置的天气预报。应用程序将提供一个客户端可以调用的 REST 端点。在可能的情况下，应用程序应使用 AWS 提供的缓存功能来限制对后端服务的请求数量。应用程序后端在测试期间只会接收到少量流量。开发人员应采用哪种方法最具成本效益地提供 REST 端点？",
    "options": {
      "A": {
        "option": "创建一个容器镜像。使用 Amazon Elastic Kubernetes Service (Amazon EKS) 部署容器镜像。通过使用 Amazon API Gateway 来暴露功能。",
        "reason": "Amazon EKS 是一个强大的容器编排服务，适用于需要管理大量容器和复杂部署的应用。但对于一个只在测试期间接收少量流量的应用来说，这种方案可能过于复杂和昂贵。"
      },
      "B": {
        "option": "使用 AWS Serverless Application Model (AWS SAM) 创建一个 AWS Lambda 函数。使用 Amazon API Gateway 来暴露 Lambda 的功能。",
        "reason": "AWS Lambda 和 API Gateway 的组合非常适合小流量、零管理的应用场景。Lambda 是按调用次数计费，对于测试期间只会接收到少量流量的应用非常经济高效。同时，API Gateway 提供了内置的缓存功能，可以减少对后端的请求数量。"
      },
      "C": {
        "option": "创建一个容器镜像。使用 Amazon Elastic Container Service (Amazon ECS) 部署容器镜像。通过使用 Amazon API Gateway 来暴露功能。",
        "reason": "Amazon ECS 适用于需要容器化部署但不需要 EKS 那么复杂的场景。但对于此案例中的小流量测试应用来说，Lambda 和 API Gateway 的无服务器架构会更简便和成本效益更高。"
      },
      "D": {
        "option": "创建一个微服务应用。将应用部署到 AWS Elastic Beanstalk。通过使用应用负载均衡器 (Application Load Balancer) 来暴露 AWS Lambda 的功能。",
        "reason": "Elastic Beanstalk 提供了简化的应用部署和管理，但它比 Lambda 更适合已经进入生产阶段的应用。对于一个概念验证和小流量测试应用来说，使用 Lambda 和 API Gateway 更为适用和经济。"
      }
    }
  },
  {
    "number": "92",
    "best": ["A"],
    "question": "一个共享会话状态的电子商务 Web 应用程序正在从本地迁移到 AWS。该应用程序必须具有容错性、本地高度可扩展性，并且任何服务中断都不应影响用户体验。存储会话状态的最佳选项是什么？",
    "options": {
      "A": {
        "option": "将会话状态存储在 Amazon ElastiCache 中。",
        "reason": "Amazon ElastiCache 是一个托管的内存缓存服务，支持 Redis 和 Memcached，能够提供高性能、低延迟的数据访问，非常适合存储会话状态。它能够自动处理节点故障，提供高可用性和可扩展性，确保即使在服务中断时也不会影响用户体验。"
      },
      "B": {
        "option": "将会话状态存储在 Amazon CloudFront 中。",
        "reason": "Amazon CloudFront 是一个内容分发网络（CDN）服务，适用于快速分发静态和动态内容，但并不适合存储会话状态。它的设计目标是加速内容交付，而不是数据存储。"
      },
      "C": {
        "option": "将会话状态存储在 Amazon S3 中。",
        "reason": "Amazon S3 是一个对象存储服务，适用于存储大量非结构化数据，如文件和备份。然而，S3 不适合存储会话状态，因为它的访问延迟较高，不符合低延迟、高性能的需求。"
      },
      "D": {
        "option": "使用弹性负载均衡器启用会话粘性。",
        "reason": "启用会话粘性将会话固定到特定的 EC2 实例，但这不能实现真正的会话状态共享，也无法确保高可用性和故障转移。此外，这种方法在实例故障时可能导致会话丢失，不符合题目要求的容错性和高可用性。"
      }
    }
  },
  {
    "number": "93",
    "best": ["A"],
    "question": "开发人员正在构建一个使用 Amazon DynamoDB 的应用程序。开发人员希望通过一次 API 调用从数据库中检索多个特定项目。哪种 DynamoDB API 调用将以最小的数据库影响满足这些要求？",
    "options": {
      "A": {
        "option": "BatchGetItem",
        "reason": "BatchGetItem API 调用允许开发人员通过一次 API 请求从 DynamoDB 表中检索多个特定项目。这种方法有效地减少了数据库的操作次数，从而减少了数据库的负载和影响。"
      },
      "B": {
        "option": "GetItem",
        "reason": "GetItem API 调用用于检索单个项目。如果需要检索多个特定项目，使用 GetItem 需要多个 API 调用，这将增加数据库的负载和影响。"
      },
      "C": {
        "option": "Scan",
        "reason": "Scan API 调用将扫描整个表以查找项目，这会导致大量的读取操作，对数据库产生较大的影响和负载，尤其是在大型表上。因此，这不是最优的选择。"
      },
      "D": {
        "option": "Query",
        "reason": "Query API 调用用于按分区键和可选排序键检索多个项目。虽然它比 Scan 更高效，但它并不适合一次性检索多个特定项目。"
      }
    }
  },
  {
    "number": "94",
    "best": ["A"],
    "question": "开发人员编写了一个在 Amazon EC2 实例上运行的应用程序。开发人员正在为应用程序添加功能，使其能够将对象写入 Amazon S3 存储桶。开发人员必须修改哪个策略以允许实例写入这些对象？",
    "options": {
      "A": {
        "option": "附加到 EC2 实例配置文件角色的 IAM 策略",
        "reason": "在 AWS 中，EC2 实例通过关联的 IAM 角色来获得权限。如果开发人员希望 EC2 实例能够将对象写入 Amazon S3 存储桶，需要修改附加到该 EC2 实例配置文件角色的 IAM 策略，以便授予写入 S3 的权限。"
      },
      "B": {
        "option": "应用于 EC2 实例角色会话的会话策略",
        "reason": "会话策略是临时附加到角色会话中的权限策略，通常用于临时权限授予。虽然会话策略可以限制或扩展角色的权限，但这里的场景更适合使用 IAM 策略，因为它提供了更持久和明确的权限管理。"
      },
      "C": {
        "option": "附加到 EC2 实例配置文件角色的 AWS Key Management Service (AWS KMS) 密钥策略",
        "reason": "AWS KMS 密钥策略用于控制对加密密钥的访问，而不是直接管理 EC2 实例对 S3 的访问权限。因此，这里的密钥策略不适用于允许 EC2 实例写入 S3 对象的需求。"
      },
      "D": {
        "option": "Amazon VPC 终端节点策略",
        "reason": "VPC 终端节点策略用于控制通过 VPC 终端节点访问特定服务的权限，但它并不负责管理 EC2 实例对 S3 的写入权限。终端节点策略主要在网络层面进行控制，而不是应用层面的权限管理。"
      }
    }
  },
  {
    "number": "95",
    "best": ["C"],
    "question": "开发人员正在利用基于边界网关协议（BGP）的AWS VPN连接从本地连接到开发人员账户中的Amazon EC2实例。开发人员能够访问VPC中子网A中的EC2实例，但无法访问同一VPC中子网B中的EC2实例。开发人员可以使用哪些日志来验证流量是否到达子网B？",
    "options": {
      "A": {
        "option": "VPN日志",
        "reason": "VPN日志主要用于监控和排查VPN连接本身的问题，如连接建立和断开、隧道状态等，但不适用于检查特定子网的流量情况。"
      },
      "B": {
        "option": "BGP日志",
        "reason": "BGP日志主要记录BGP路由协议的信息，如路由表的更新和路由通告，但不适用于检查特定子网的流量情况。"
      },
      "C": {
        "option": "VPC流日志",
        "reason": "VPC流日志可以记录进入和离开VPC子网的网络流量，能够帮助开发人员查看流量是否到达子网B，并进行进一步的排查。因此，这是检查流量是否到达子网B的最佳选项。"
      },
      "D": {
        "option": "AWS CloudTrail日志",
        "reason": "AWS CloudTrail日志用于记录API调用和账户活动，适用于审计和监控API级别的操作，但不适用于检查特定子网的流量情况。"
      }
    }
  },
  {
    "number": "96",
    "best": ["A"],
    "question": "一名开发人员正在创建一个使用 Amazon S3 存储桶进行图像上传的服务。该服务将使用 AWS Lambda 函数为每个图像创建缩略图。每次上传图像时，服务需要发送电子邮件通知并创建缩略图。开发人员需要配置图像处理和电子邮件通知设置。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题。配置 S3 事件通知，目标为 SNS 主题。将 Lambda 函数订阅到 SNS 主题。创建一个电子邮件通知订阅到 SNS 主题。",
        "reason": "此选项可以满足所有要求。利用 S3 事件通知将图像上传事件发送到 SNS 主题，然后 Lambda 函数和电子邮件订阅都可以订阅该 SNS 主题，从而实现图像处理和通知的功能。"
      },
      "B": {
        "option": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题。配置 S3 事件通知，目标为 SNS 主题。将 Lambda 函数订阅到 SNS 主题。创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。将 SQS 队列订阅到 SNS 主题。创建一个电子邮件通知订阅到 SQS 队列。",
        "reason": "此选项增加了不必要的复杂性。虽然 SQS 队列可以用于解耦和缓冲消息，但在这种情况下使用 SNS 主题和 Lambda 函数已经足够，而且更加简洁和高效。"
      },
      "C": {
        "option": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。配置 S3 事件通知，目标为 SQS 队列。将 Lambda 函数订阅到 SQS 队列。创建一个电子邮件通知订阅到 SQS 队列。",
        "reason": "此选项仅使用 SQS 队列来处理事件通知和电子邮件，但没有利用 SNS 的优势。SNS 更适合在多个消费者之间分发消息，而不仅仅是一个队列。"
      },
      "D": {
        "option": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。将 S3 事件通知发送到 Amazon EventBridge。创建一个 EventBridge 规则，在图像上传到 S3 存储桶时运行 Lambda 函数。创建一个 EventBridge 规则，将通知发送到 SQS 队列。创建一个电子邮件通知订阅到 SQS 队列。",
        "reason": "此选项涉及更多服务和配置，增加了不必要的复杂性。使用 SNS 和 Lambda 结合，可以更简单地实现所需功能，而不需要引入 EventBridge。"
      }
    }
  },
  {
    "number": "97",
    "best": ["A"],
    "question": "开发人员设计了一个应用程序，将传入数据以JSON文件的形式存储在Amazon S3对象中。AWS Lambda函数中的自定义业务逻辑随后会转换这些对象，并将数据加载到Amazon DynamoDB表中。最近，工作负载经历了突发和显著的流量变化。向DynamoDB表的数据流变得受限。开发人员需要实施一个解决方案，以消除限制并更一致地将数据加载到DynamoDB表中。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "将Lambda函数重构为两个函数。配置一个函数来转换数据，另一个函数将数据加载到DynamoDB表中。在两个函数之间创建一个Amazon Simple Queue Service (Amazon SQS)队列，以将项目作为消息保存并调用第二个函数。",
        "reason": "选项A通过引入Amazon SQS队列，可以缓冲突发流量，确保数据流的平滑过渡。这种方式能够有效地分离数据转换和数据加载过程，减少DynamoDB表的节流问题。Amazon SQS适用于需要处理突发流量的场景，确保消息在流量高峰期不丢失并且能够被后续处理。"
      },
      "B": {
        "option": "为DynamoDB表开启自动扩展。使用Amazon CloudWatch监控表的读写容量指标并跟踪消耗的容量。",
        "reason": "虽然自动扩展可以帮助DynamoDB表应对负载变化，但它可能无法立即响应突发的流量变化，存在延迟问题。而且，题目中未提到DynamoDB表的容量问题，仅提到流量突发，表明问题在于流量的平稳流动而非容量本身。"
      },
      "C": {
        "option": "为Lambda函数创建一个别名。为应用程序配置预置并发。",
        "reason": "预置并发可以减少Lambda函数的冷启动时间，但这并不能解决DynamoDB表的节流问题。题目中提到的问题主要是在DynamoDB表的负载管理，而非Lambda函数的执行效率。"
      },
      "D": {
        "option": "将Lambda函数重构为两个函数。配置一个函数将数据存储在DynamoDB表中。配置第二个函数在数据存储到DynamoDB之后处理数据并更新项目。创建一个DynamoDB流在数据存储后调用第二个函数。",
        "reason": "选项D通过DynamoDB流来触发第二个Lambda函数，这可能会增加系统的复杂性，并且仍然无法有效缓冲突发流量。主要问题仍然是在突发流量情况下的数据处理和加载的平稳性，这个方案并未直接解决该问题。"
      }
    }
  },
  {
    "number": "98",
    "best": ["A"],
    "question": "开发人员正在 VPC 模式下创建一个 AWS Lambda 函数。当对象上传到 S3 存储桶时，Amazon S3 事件将调用 Lambda 函数。Lambda 函数将处理对象并生成分析结果，这些结果将记录到文件中。每个处理过的对象还将生成一个日志条目，该条目将记录到文件中。其他 Lambda 函数、AWS 服务和本地资源必须能够访问结果文件和日志文件。每个日志条目还必须附加到同一个共享日志文件中。开发人员需要一个可以共享文件并将结果附加到现有文件的解决方案。开发人员应该使用哪个解决方案来满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个 Amazon Elastic File System (Amazon EFS) 文件系统。在 Lambda 中挂载 EFS 文件系统。将结果文件和日志文件存储在挂载点中。将日志条目附加到日志文件中。",
        "reason": "Amazon EFS 是一个可扩展的文件存储服务，允许多个 EC2 实例、Lambda 函数和其他 AWS 服务并发访问文件系统。它支持并发访问和文件的附加操作，适合需要多个服务和资源访问同一文件系统的场景。"
      },
      "B": {
        "option": "创建一个 Amazon Elastic Block Store (Amazon EBS) Multi-Attach 启用的卷。将 EBS 卷附加到所有 Lambda 函数。更新 Lambda 函数代码以下载日志文件、附加日志条目，并将修改后的日志文件上传到 Amazon EBS。",
        "reason": "Amazon EBS 是块存储服务，更适合单实例访问和高性能需求。虽然 Multi-Attach 可以允许多个实例访问同一个卷，但它不支持并发写入和文件系统级别的共享，可能导致数据一致性问题。"
      },
      "C": {
        "option": "创建对 /tmp 本地目录的引用。使用目录引用存储结果文件和日志文件。将日志条目附加到日志文件中。",
        "reason": "/tmp 目录是 Lambda 函数的临时存储（最大 512 MB），仅在函数执行期间可用。它不适合存储需要持久化和共享的文件。"
      },
      "D": {
        "option": "创建对 /opt 存储目录的引用。使用目录引用存储结果文件和日志文件。将日志条目附加到日志文件中。",
        "reason": "/opt 目录在 Lambda 中不可用。此选项无效。"
      }
    }
  },
  {
    "number": "99",
    "best": ["B"],
    "question": "公司有一个 AWS Lambda 函数用于处理来自 Amazon API Gateway API 的请求。API 使用 Lambda 别名调用 Lambda 函数。开发人员更新了 Lambda 函数代码以处理更多与传入请求相关的详细信息。开发人员希望在不影响使用 API 的客户的情况下，将新的 Lambda 函数部署给其他开发人员进行更多测试。哪种解决方案能够以最少的运营开销满足这些要求？",
    "options": {
      "A": {
        "option": "创建 Lambda 函数的新版本。在 API Gateway 上创建一个新阶段并集成到新的 Lambda 版本。使用新的 API Gateway 阶段测试 Lambda 函数。",
        "reason": "这个选项需要在 API Gateway 上创建一个新阶段，这会增加一些运营开销。另外，如果有多个 API Gateway 阶段，管理和同步这些阶段可能会变得复杂。"
      },
      "B": {
        "option": "将 API Gateway 使用的现有 Lambda 别名更新为加权别名。将新的 Lambda 版本添加为具有 10% 权重的附加 Lambda 函数。使用现有的 API Gateway 阶段进行测试。",
        "reason": "这个选项通过使用加权别名，可以在不影响大多数客户的情况下，将一小部分流量引导到新的 Lambda 版本进行测试。这种方法最小化了运营开销，因为不需要创建新的 API Gateway 阶段或 API。"
      },
      "C": {
        "option": "创建 Lambda 函数的新版本。创建并部署第二个 Lambda 函数，以过滤来自 API Gateway 的传入请求。如果过滤 Lambda 函数检测到测试请求，则调用新 Lambda 版本代码。对于其他请求，调用旧的 Lambda 版本。更新 API Gateway API 以使用过滤 Lambda 函数。",
        "reason": "这个选项涉及额外的复杂性，因为需要创建和管理一个过滤 Lambda 函数，并且需要更新 API Gateway 的配置。这增加了运营开销和管理复杂度。"
      },
      "D": {
        "option": "创建 Lambda 函数的新版本。创建一个新的 API Gateway API 进行测试目的。更新新 API 的集成与新的 Lambda 版本。使用新的 API 进行测试。",
        "reason": "这个选项需要创建一个新的 API Gateway API，这会增加运营开销，并且需要管理多个 API Gateway API。这增加了管理复杂性。"
      }
    }
  },
  {
    "number": "100",
    "best": ["C"],
    "question": "一家公司使用 AWS Lambda 函数和 Amazon S3 触发器来处理存储在 S3 存储桶中的图像。开发团队在单个 AWS 账户中设置了多个环境。最近的一次生产部署后，开发团队观察到开发环境的 S3 存储桶触发了生产环境的 Lambda 函数。这些触发导致生产环境的 Lambda 函数不必要地执行了开发环境的 S3 文件。开发团队必须防止这些触发发生，并且必须遵循安全最佳实践。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "更新生产 Lambda 函数的执行角色，添加一个策略只允许该执行角色读取生产环境的 S3 存储桶。",
        "reason": "这选项只限制了 Lambda 函数的读取权限，但未解决 S3 存储桶触发 Lambda 函数的问题。"
      },
      "B": {
        "option": "将开发环境和生产环境移到不同的 AWS 账户中。向每个 Lambda 函数添加资源策略，只允许同一账户内的 S3 存储桶触发函数。",
        "reason": "尽管这一选项能够隔离开发和生产环境，但将环境分离到不同账户增加了管理复杂性。"
      },
      "C": {
        "option": "向生产 Lambda 函数添加资源策略，只允许生产环境的 S3 存储桶触发函数。",
        "reason": "这是最佳选项，因为它直接限制了生产 Lambda 函数的触发源，仅允许来自生产环境的 S3 存储桶触发。符合安全最佳实践。"
      },
      "D": {
        "option": "将开发环境和生产环境移到不同的 AWS 账户中。更新每个函数的 Lambda 执行角色，添加一个策略只允许执行角色读取同一账户内的 S3 存储桶。",
        "reason": "虽然这一选项也能解决问题，但与选项 B 类似，增加了管理复杂性，而不是直接解决触发问题。"
      }
    }
  },
  {
    "number": "101",
    "best": ["C"],
    "question": "一名开发人员正在创建一个应用程序。新用户必须能够使用他们自己的社交媒体帐户创建帐户并进行注册。开发人员应该使用哪个 AWS 服务或资源来满足这些要求？",
    "options": {
      "A": {
        "option": "IAM 角色",
        "reason": "IAM 角色主要用于授予 AWS 资源的访问权限，而不是用于用户注册或身份验证。"
      },
      "B": {
        "option": "Amazon Cognito 身份池",
        "reason": "身份池（Identity Pools）允许用户通过联合身份（如社交媒体帐户）获得临时 AWS 凭证，但它通常用于授权，而不是用于用户注册。"
      },
      "C": {
        "option": "Amazon Cognito 用户池",
        "reason": "用户池（User Pools）专门设计用于用户注册和登录，包括使用社交媒体帐户。这正是题目中所需的功能，因此是最优选项。"
      },
      "D": {
        "option": "AWS 目录服务",
        "reason": "AWS 目录服务主要用于与现有的本地 Active Directory 集成，不适用于通过社交媒体帐户注册新用户。"
      }
    }
  },
  {
    "number": "102",
    "best": ["A"],
    "question": "一个社交媒体应用程序使用 AWS SDK for JavaScript 在前端从 AWS 安全令牌服务 (AWS STS) 获取用户凭证。该应用程序将其资源存储在 Amazon S3 存储桶中。应用程序通过 Amazon CloudFront 分发其内容，原点设置为 S3 存储桶。应用程序所假设的角色的凭证以明文形式存储在应用程序代码中的 JSON 文件中。开发人员需要实现一个解决方案，使应用程序能够获取用户凭证，而无需在应用程序代码中硬编码任何凭证。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "向分发中添加一个 Lambda@Edge 函数。在查看器请求时调用该函数。为该函数的执行角色添加权限以允许该函数访问 AWS STS。将所有 SDK 调用从前端移到该函数中。",
        "reason": "选择此选项是因为 Lambda@Edge 函数可以在 CloudFront 边缘位置执行，从而减少延迟并提高响应速度。将所有 SDK 调用移至 Lambda@Edge 可以确保凭证不再硬编码在前端代码中，并且可以安全地从 AWS STS 获取。"
      },
      "B": {
        "option": "向分发中添加一个 CloudFront 函数。在查看器请求时调用该函数。为该函数的执行角色添加权限以允许该函数访问 AWS STS。将所有 SDK 调用从前端移到该函数中。",
        "reason": "不选择此选项是因为 CloudFront 函数目前不支持与 AWS 服务（如 AWS STS）的直接集成。CloudFront 函数主要用于轻量级的 HTTP 请求和响应操作，而不适合处理复杂的逻辑或与 AWS 服务的交互。"
      },
      "C": {
        "option": "向分发中添加一个 Lambda@Edge 函数。在查看器请求时调用该函数。将凭证从 JSON 文件移到该函数中。将所有 SDK 调用从前端移到该函数中。",
        "reason": "不选择此选项是因为虽然 Lambda@Edge 可以处理复杂逻辑并与 AWS 服务集成，但将凭证从一个不安全的地方（JSON 文件）移到另一个地方（Lambda@Edge 函数）并不能解决凭证安全管理的问题。更好的做法是动态获取凭证，而不是硬编码。"
      },
      "D": {
        "option": "向分发中添加一个 CloudFront 函数。在查看器请求时调用该函数。将凭证从 JSON 文件移到该函数中。将所有 SDK 调用从前端移到该函数中。",
        "reason": "不选择此选项是因为 CloudFront 函数不支持与 AWS 服务的直接集成，并且将凭证从前端代码移到 CloudFront 函数中并不能解决凭证安全管理的问题。"
      }
    }
  },
  {
    "number": "103",
    "best": ["B"],
    "question": "一个电子商务网站使用 AWS Lambda 函数和 Amazon RDS for MySQL 数据库提供订单履行服务。该服务需要立即返回订单确认。 在一次导致订单数量增加的营销活动中，网站的运营团队注意到 Amazon RDS 出现“连接过多”的错误。然而，RDS 数据库集群的指标是健康的。CPU 和内存容量仍然可用。开发人员应该怎么做来解决这些错误？",
    "options": {
      "A": {
        "option": "在处理程序函数外部初始化数据库连接。增加数据库集群参数组中的 max_user_connections 值。重启数据库集群。",
        "reason": "虽然在处理程序函数外部初始化数据库连接可以减少连接的开销，但增加 max_user_connections 值并重启数据库集群是一种临时解决方案，可能无法从根本上解决问题。此外，重启数据库集群会导致服务中断。"
      },
      "B": {
        "option": "在处理程序函数外部初始化数据库连接。使用 RDS Proxy 而不是直接连接到数据库集群。",
        "reason": "使用 RDS Proxy 是最优解，因为它可以池化数据库连接，有效地管理并发连接，减少“连接过多”的错误。RDS Proxy 提供了更高的可用性和性能，特别是在高并发场景下。"
      },
      "C": {
        "option": "使用 Amazon Simple Queue Service (Amazon SQS) FIFO 队列来排队订单。将订单导入数据库。将 Lambda 函数的并发性设置为等于可用数据库连接的数量。",
        "reason": "使用 SQS 队列来排队订单是一个不错的解法，可以缓解瞬时高负载，但将 Lambda 函数的并发性设置为等于可用数据库连接的数量可能会导致数据库连接再次饱和，并不是最佳选择。"
      },
      "D": {
        "option": "使用 Amazon Simple Queue Service (Amazon SQS) FIFO 队列来排队订单。将订单导入数据库。将 Lambda 函数的并发性设置为小于可用数据库连接的数量。",
        "reason": "虽然这种方法可以缓解部分连接问题，但它并不能充分利用数据库的可用连接资源，可能导致性能下降。"
      }
    }
  },
  {
    "number": "104",
    "best": ["B"],
    "question": "一家公司将其数据存储在一系列 Amazon S3 存储桶中的数据表中。公司收到警报，客户信用卡信息可能已在公司的某个公共应用程序中的数据表上暴露。开发人员需要识别应用程序环境中的所有潜在暴露情况。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "使用 Amazon Athena 在包含受影响数据的 S3 存储桶上运行作业。通过使用 SensitiveData:S3Object/Personal 查找类型来过滤结果。",
        "reason": "Amazon Athena 是一种交互式查询服务，用于分析存储在 Amazon S3 中的数据。它可以用于查询和分析数据，但它并不是专门设计用于识别敏感数据暴露的工具。SensitiveData:S3Object/Personal 查找类型并不适用于检测金融信息（如信用卡信息）的暴露。"
      },
      "B": {
        "option": "使用 Amazon Macie 在包含受影响数据的 S3 存储桶上运行作业。通过使用 SensitiveData:S3Object/Financial 查找类型来过滤结果。",
        "reason": "Amazon Macie 是一种安全服务，使用机器学习自动发现、分类和保护敏感数据。它专门设计用于识别和保护敏感数据，包括金融信息（如信用卡信息）。SensitiveData:S3Object/Financial 查找类型最适合用于检测信用卡信息的暴露。因此，这是最佳选择。"
      },
      "C": {
        "option": "使用 Amazon Macie 在包含受影响数据的 S3 存储桶上运行作业。通过使用 SensitiveData:S3Object/Personal 查找类型来过滤结果。",
        "reason": "虽然 Amazon Macie 是识别和保护敏感数据的适当工具，但 SensitiveData:S3Object/Personal 查找类型主要用于个人信息（如姓名、社会安全号码等），而不是金融信息。因此，这不是最佳选择。"
      },
      "D": {
        "option": "使用 Amazon Athena 在包含受影响数据的 S3 存储桶上运行作业。通过使用 SensitiveData:S3Object/Financial 查找类型来过滤结果。",
        "reason": "如前所述，Amazon Athena 主要用于数据查询和分析，而不是专门设计用于识别敏感数据暴露的工具。即使使用 SensitiveData:S3Object/Financial 查找类型，Athena 也不是最佳选择。"
      }
    }
  },
  {
    "number": "105",
    "best": ["B", "D"],
    "question": "一家软件公司正在推出一款多媒体应用程序。该应用程序将允许访客用户访问示例内容，然后再决定是否创建账户以获得完整访问权限。公司希望实施一个身份验证过程，以识别已经创建账户的用户。公司还需要跟踪最终创建账户的访客用户数量。以下哪种组合步骤可以满足这些要求？（选择两个。）",
    "options": {
      "A": {
        "option": "创建一个 Amazon Cognito 用户池。配置用户池以允许未经身份验证的用户。将用户令牌交换为允许身份验证用户假定角色的临时凭证。",
        "reason": "虽然 Amazon Cognito 用户池可以用来管理用户的身份验证，但它不直接支持未验证用户的访问权限。"
      },
      "B": {
        "option": "创建一个 Amazon Cognito 身份池。配置身份池以允许未经身份验证的用户。将唯一身份交换为允许所有用户假定角色的临时凭证。",
        "reason": "Amazon Cognito 身份池允许管理未验证和验证用户的身份，并可以分配不同的角色和权限以满足需求。"
      },
      "C": {
        "option": "创建一个 Amazon CloudFront 分配。配置分配以允许未经身份验证的用户。将用户令牌交换为允许所有用户假定角色的临时凭证。",
        "reason": "CloudFront 主要用于内容分发网络（CDN），不适用于用户身份验证和授权管理。"
      },
      "D": {
        "option": "为身份验证用户创建一个允许访问所有内容的角色。为未经身份验证的用户创建一个仅允许访问示例内容的角色。",
        "reason": "通过为身份验证和未验证用户创建不同的 IAM 角色，可以有效地控制不同用户的访问权限。"
      },
      "E": {
        "option": "默认允许所有用户访问示例内容。为身份验证用户创建一个允许访问其他内容的角色。",
        "reason": "此选项虽然部分满足要求，但并未明确提到如何跟踪最终创建账户的访客用户数量。"
      }
    }
  },
  {
    "number": "106",
    "best": ["B"],
    "question": "一家公司正在更新一个应用程序，将其后端从Amazon EC2实例迁移到无服务器模型。该应用程序使用Amazon RDS for MySQL数据库实例，并在AWS中的一个单一VPC中运行。应用程序和数据库实例部署在VPC的一个私有子网中。公司需要将AWS Lambda函数连接到数据库实例。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "在VPC内部创建Lambda函数，并将AWSLambdaBasicExecutionRole策略附加到Lambda执行角色。修改RDS安全组以允许从Lambda安全组的入站访问。",
        "reason": "AWSLambdaBasicExecutionRole策略不包含VPC访问的权限。Lambda函数需要有权限访问VPC资源，所以这个方案不完整。"
      },
      "B": {
        "option": "在VPC内部创建Lambda函数，并将AWSLambdaVPCAccessExecutionRole策略附加到Lambda执行角色。修改RDS安全组以允许从Lambda安全组的入站访问。",
        "reason": "AWSLambdaVPCAccessExecutionRole策略包含了Lambda函数访问VPC资源所需的权限。并且通过修改RDS安全组以允许从Lambda安全组的入站访问，可以确保Lambda函数能够连接到RDS实例。这是一个完整且符合题目要求的解决方案。"
      },
      "C": {
        "option": "创建具有AWSLambdaBasicExecutionRole策略的Lambda函数。为Lambda函数创建一个接口VPC端点。配置接口端点策略以允许lambda:InvokeFunction操作针对每个Lambda函数的Amazon Resource Name (ARN)。",
        "reason": "这个选项提到创建接口VPC端点和配置端点策略，但没有提到必要的VPC访问权限。AWSLambdaBasicExecutionRole策略不包含VPC访问的权限，因此这个方案不完整。"
      },
      "D": {
        "option": "创建具有AWSLambdaVPCAccessExecutionRole策略的Lambda函数。为Lambda函数创建一个接口VPC端点。配置接口端点策略以允许lambda:InvokeFunction操作针对每个Lambda函数的Amazon Resource Name (ARN)。",
        "reason": "虽然这个选项提到了必要的VPC访问权限，但创建接口VPC端点并配置接口端点策略是多余的步骤。直接修改RDS安全组以允许从Lambda安全组的入站访问是更直接的解决方案。"
      }
    }
  },
  {
    "number": "107",
    "best": ["B"],
    "question": "一家公司有一个在 Amazon EC2 实例上运行的 Web 应用程序，并使用自定义的 Amazon Machine Image (AMI)。该公司使用 AWS CloudFormation 来配置应用程序。该应用程序运行在 us-east-1 区域，公司需要将应用程序部署到 us-west-1 区域。尝试在 us-west-1 中创建 AWS CloudFormation 堆栈时失败。错误信息指出 AMI ID 不存在。开发人员必须以最少的操作开销解决此错误。哪种解决方案满足这些要求？",
    "options": {
      "A": {
        "option": "更改 us-east-1 和 us-west-1 的 AWS CloudFormation 模板以使用 AWS AMI。重新启动两个区域的堆栈。",
        "reason": "选项 A 需要修改两个区域的 AWS CloudFormation 模板，并重新启动堆栈，这会带来额外的操作开销，且不符合题目要求的最少操作开销。"
      },
      "B": {
        "option": "将自定义的 AMI 从 us-east-1 复制到 us-west-1。更新 us-west-1 的 AWS CloudFormation 模板以引用复制的 AMI ID。重新启动堆栈。",
        "reason": "选项 B 是最佳选项，因为它只涉及将现有的 AMI 复制到目标区域并更新 CloudFormation 模板，操作简单且开销最小。"
      },
      "C": {
        "option": "在 us-west-1 中构建自定义 AMI。创建一个新的 AWS CloudFormation 模板，以使用新的 AMI ID 在 us-west-1 中启动堆栈。",
        "reason": "选项 C 需要在目标区域重新构建 AMI 和创建新的 CloudFormation 模板，这增加了操作开销，不是最优解。"
      },
      "D": {
        "option": "手动在 us-west-1 中部署应用程序，不使用 AWS CloudFormation。",
        "reason": "选项 D 要求手动部署应用程序，完全绕过 CloudFormation，操作开销大且不符合自动化部署的最佳实践。"
      }
    }
  },
  {
    "number": "108",
    "best": ["C"],
    "question": "一名开发人员正在更新多个 AWS Lambda 函数，并注意到所有 Lambda 函数共享相同的自定义库。开发人员想要集中管理所有库，方便地更新库，并对库进行版本控制。哪种解决方案能以最少的开发工作量满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个包含所有自定义库的 AWS CodeArtifact 存储库。",
        "reason": "AWS CodeArtifact 是一个软件包管理服务，可用于存储、发布和共享软件包。但对于 Lambda 函数的场景，直接使用 Lambda 层会更加方便，因为它是专门为此设计的，且可以简化依赖管理。"
      },
      "B": {
        "option": "为 Lambda 函数创建一个自定义容器镜像以保存所有自定义库。",
        "reason": "使用自定义容器镜像也可以解决库共享和版本控制的问题，但这会增加复杂性并需要额外的开发工作。相比之下，Lambda 层提供了更简单和直接的解决方案。"
      },
      "C": {
        "option": "创建一个包含所有自定义库的 Lambda 层。",
        "reason": "Lambda 层专门用于共享库和代码片段，它可以方便地被多个 Lambda 函数引用，同时支持版本控制。这是以最少开发工作量实现集中管理和更新库的最佳解决方案。"
      },
      "D": {
        "option": "创建一个 Amazon Elastic File System (Amazon EFS) 文件系统来存储所有自定义库。",
        "reason": "虽然 EFS 可以实现文件共享，但它并不是管理和版本控制库的最佳选择。EFS 主要用于文件存储和共享，使用它会增加不必要的复杂性。"
      }
    }
  },
  {
    "number": "109",
    "best": ["D"],
    "question": "一名开发人员希望使用 AWS Elastic Beanstalk 在测试环境中测试一个新版本的应用程序。哪种部署方法提供最快的部署速度？",
    "options": {
      "A": {
        "option": "不可变部署",
        "reason": "不可变部署会创建一个全新的环境，然后将流量切换到新环境中。这种方法虽然能确保零停机时间，但创建新环境的时间较长，因此不是最快的部署方法。"
      },
      "B": {
        "option": "滚动部署",
        "reason": "滚动部署会逐步替换现有实例中的应用程序版本，以减少停机时间。虽然这种方法减少了风险和停机时间，但部署速度比“全部同时”要慢。"
      },
      "C": {
        "option": "带有额外批次的滚动部署",
        "reason": "带有额外批次的滚动部署在滚动更新的基础上增加了额外的实例批次，以进一步减少停机时间。然而，这种方法仍然比“全部同时”部署慢。"
      },
      "D": {
        "option": "全部同时",
        "reason": "全部同时部署方法会在所有实例上同时部署新版本。这种方法最快，但可能会导致短暂的服务中断。因此，它适合在测试环境中使用，因为速度是主要考虑因素。"
      }
    }
  },
  {
    "number": "110",
    "best": ["A"],
    "question": "一家公司正在为不同的客户提供对 Amazon S3 存储桶中的对象的只读访问权限。公司使用 IAM 权限来限制对 S3 存储桶的访问。客户只能访问自己的文件。由于法规要求，公司需要强制对与 Amazon S3 的交互进行传输中的加密。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "在 S3 存储桶中添加一个存储桶策略，当 aws:SecureTransport 条件等于 false 时拒绝 S3 操作。",
        "reason": "该选项通过存储桶策略强制传输中的加密（HTTPS），确保客户与 S3 交互时的数据在传输中是加密的，符合题目的要求。"
      },
      "B": {
        "option": "在 S3 存储桶中添加一个存储桶策略，当 s3:x-amz-acl 条件等于 public-read 时拒绝 S3 操作。",
        "reason": "该选项与传输中的加密无关，主要是控制对象的访问权限，不能满足题目中对传输加密的要求。"
      },
      "C": {
        "option": "为 IAM 用户添加一个 IAM 策略，强制使用 AWS SDK。",
        "reason": "虽然使用 AWS SDK 可以配置传输中的加密，但这不是强制加密传输的直接方法，也不能确保所有客户都使用加密传输。"
      },
      "D": {
        "option": "为 IAM 用户添加一个 IAM 策略，允许当 s3:x-amz-acl 条件等于 bucket-owner-read 时进行 S3 操作。",
        "reason": "该选项与传输中的加密无关，主要是控制对象的访问权限，不能满足题目中对传输加密的要求。"
      }
    }
  },
  {
    "number": "111",
    "best": ["A"],
    "question": "公司有一个图像存储的web应用程序在AWS上运行。公司在一个Auto Scaling组中的Amazon EC2实例上托管该应用程序。Auto Scaling组作为Application Load Balancer (ALB)的目标组，并使用Amazon S3存储用于销售的图像。公司希望开发一个功能来测试系统请求。该功能将请求引导到托管新测试版应用程序的单独目标组。哪种解决方案以最少的努力满足这一要求？",
    "options": {
      "A": {
        "option": "为测试版应用程序创建一个新的Auto Scaling组和目标组。使用一个条件更新ALB路由规则，该条件检查名为version的cookie，值为beta。更新测试系统代码以使用这个cookie来测试测试版应用程序。",
        "reason": "选项A是最优解，因为它利用现有的ALB，只需要增加一个新的Auto Scaling组和目标组，并通过cookie来实现路由，这样可以最低的努力实现需求。使用cookie进行路由可以确保测试版和正式版应用程序的分离，同时无需对现有基础设施做大规模的改动。"
      },
      "B": {
        "option": "为测试版应用程序创建一个新的ALB、Auto Scaling组和目标组。为新的ALB端点配置一个备用的Amazon Route 53记录。在测试系统请求中使用备用的Route 53端点来测试测试版应用程序。",
        "reason": "选项B增加了额外的复杂性，因为需要创建新的ALB并配置Route 53记录，这需要更多的时间和资源。虽然可以实现目标，但不是最简便的方法。"
      },
      "C": {
        "option": "为测试版应用程序创建一个新的ALB、Auto Scaling组和目标组。使用Amazon CloudFront和Lambda@Edge来决定哪些特定请求将转到新的ALB。使用CloudFront端点发送测试系统请求来测试测试版应用程序。",
        "reason": "选项C同样增加了额外的复杂性，包括CloudFront和Lambda@Edge，这不符合最低努力的要求。而且，CloudFront通常用于内容分发网络（CDN）场景，在这种情况下不是最合适的选择。"
      },
      "D": {
        "option": "为测试版应用程序创建一个新的Auto Scaling组和目标组。使用一个条件更新ALB路由规则，该条件检查名为version的cookie，值为beta。使用Amazon CloudFront和Lambda@Edge来更新测试系统请求，在请求发送到ALB时添加所需的cookie。",
        "reason": "选项D增加了不必要的复杂性。虽然它利用了现有的ALB和cookie，但引入了CloudFront和Lambda@Edge来处理cookie，这增加了系统的复杂性和维护成本，不符合最低努力的要求。"
      }
    }
  },
  {
    "number": "112",
    "best": ["A", "B"],
    "question": "一个团队正在开发一个部署在Amazon EC2实例上的应用程序。在测试期间，团队收到一个错误信息，EC2实例无法访问Amazon S3存储桶。团队应采取哪些步骤来排除这个问题？（选择两个。）",
    "options": {
      "A": {
        "option": "检查分配给附加到EC2实例的IAM角色的策略是否授予对Amazon S3的访问权限。",
        "reason": "这是一个常见的错误排查步骤，因为EC2实例通常通过附加的IAM角色来获取S3的访问权限。需要确保这个角色有适当的策略来允许访问S3。"
      },
      "B": {
        "option": "检查S3存储桶策略以验证S3存储桶的访问权限。",
        "reason": "S3存储桶策略也可能限制了访问权限。即使IAM角色有权限，如果S3存储桶策略中有相应的限制，访问仍然会被拒绝。因此，验证存储桶策略是排查问题的另一重要步骤。"
      },
      "C": {
        "option": "检查分配给附加到EC2实例的IAM用户的策略是否授予对Amazon S3的访问权限。",
        "reason": "EC2实例通常不会直接附加IAM用户，而是通过IAM角色来获取权限。因此，这不是一个常见的排查步骤。"
      },
      "D": {
        "option": "检查S3生命周期策略以验证分配给S3存储桶的权限。",
        "reason": "S3生命周期策略主要用于管理对象的存储类转换和到期删除，与访问权限无关。因此，这不是一个相关的排查步骤。"
      },
      "E": {
        "option": "检查分配给EC2实例的安全组。确保没有规则阻止对Amazon S3的访问。",
        "reason": "安全组主要用于控制进出EC2实例的流量，而S3是一个外部服务，其访问通过HTTPS进行。通常情况下，安全组不会影响到S3访问。因此，这不是一个主要的排查步骤。"
      }
    }
  },
  {
    "number": "113",
    "best": ["D"],
    "question": "一位开发人员正在开发一个电子商务网站。该开发人员希望在不逐个登录到每个应用程序服务器的情况下查看服务器日志。该网站运行在多个 Amazon EC2 实例上，用 Python 编写，并且需要高度可用。开发人员可以如何以最少的更改来更新应用程序以满足这些要求？",
    "options": {
      "A": {
        "option": "重写应用程序，使其成为云原生应用程序并在 AWS Lambda 上运行，这样日志可以在 Amazon CloudWatch 中查看。",
        "reason": "重写应用程序并迁移到 AWS Lambda 需要大量的代码改动和重新架构，不符合题目中“最少的更改”的要求。虽然 AWS Lambda 能自动将日志发送到 CloudWatch，但这种方法不适用于现有的 EC2 部署。"
      },
      "B": {
        "option": "使用 Amazon OpenSearch 服务、Logstash 和 OpenSearch Dashboards 设置集中日志记录。",
        "reason": "虽然设置集中日志记录是一个有效的解决方案，但它涉及多个新服务的集成和配置，复杂度较高，不符合题目中“最少的更改”的要求。"
      },
      "C": {
        "option": "将应用程序缩减到一个更大的 EC2 实例，其中只有一个实例记录日志。",
        "reason": "缩减应用程序到一个更大的 EC2 实例会影响网站的高可用性，不符合题目中“需要高度可用”的要求。"
      },
      "D": {
        "option": "在 EC2 实例上安装统一的 Amazon CloudWatch 代理。配置代理将应用程序日志推送到 CloudWatch。",
        "reason": "安装和配置 Amazon CloudWatch 代理是实现集中日志记录的最简单和直接的方法。它无需对现有应用程序进行重大更改，同时满足集中查看日志的需求。因此，这是最优解。"
      }
    }
  },
  {
    "number": "114",
    "best": ["A", "C"],
    "question": "公司正在创建一个处理来自 Amazon S3 的 .csv 文件的应用程序。开发人员创建了一个 S3 存储桶，并且还创建了一个 AWS Lambda 函数来处理 S3 存储桶中的 .csv 文件。当 .csv 文件上传到 Amazon S3 时，哪种步骤组合将调用 Lambda 函数？（选择两个。）",
    "options": {
      "A": {
        "option": "创建一个 Amazon EventBridge 规则。使用模式配置该规则以匹配创建的 S3 对象事件。",
        "reason": "Amazon EventBridge 可以用来监控特定事件并触发响应操作。在本例中，可以创建一个规则来监控 S3 对象创建事件，并在该事件发生时调用 Lambda 函数。"
      },
      "B": {
        "option": "计划一个 Amazon EventBridge 规则运行一个新的 Lambda 函数来扫描 S3 存储桶。",
        "reason": "这个选项不合适，因为通过计划规则扫描存储桶会增加不必要的复杂性和延迟。目标是立即响应 S3 对象创建事件，而不是定期扫描。"
      },
      "C": {
        "option": "给现有的 Lambda 函数添加一个触发器。将触发类型设置为 EventBridge，并选择 Amazon EventBridge 规则。",
        "reason": "为 Lambda 函数添加一个 EventBridge 触发器是一个直接的解决方案，可以确保在匹配的事件发生时立即调用 Lambda 函数。"
      },
      "D": {
        "option": "创建一个新的 Lambda 函数来扫描 S3 存储桶中最近添加的 S3 对象。",
        "reason": "这个选项不合适，因为创建一个新的 Lambda 函数来扫描存储桶并不是最有效的方式。目标是利用事件驱动的架构，而不是周期性扫描。"
      },
      "E": {
        "option": "添加 S3 生命周期规则来调用现有的 Lambda 函数。",
        "reason": "S3 生命周期规则用于管理对象的存储期限和过期，而不是用于在对象创建时触发 Lambda 函数。因此，这个选项不合适。"
      }
    }
  },
  {
    "number": "115",
    "best": ["A"],
    "question": "开发人员需要构建一个 AWS CloudFormation 模板，该模板可以自动填充部署该 CloudFormation 模板的 AWS 区域变量。最具操作效率的方法来确定模板正在部署的区域是什么？",
    "options": {
      "A": {
        "option": "使用 AWS::Region 伪参数。",
        "reason": "AWS::Region 伪参数是一个内置的 CloudFormation 伪参数，它会自动返回当前正在部署模板的区域。这是最简洁且操作效率最高的方式，无需额外的参数或复杂的操作。"
      },
      "B": {
        "option": "将区域作为 CloudFormation 参数要求。",
        "reason": "虽然使用参数可以解决问题，但这是不必要的复杂化。开发人员需要手动提供区域信息，增加了操作的复杂性和出错的可能性。"
      },
      "C": {
        "option": "使用 Fn::Split 内置函数从 AWS::StackId 伪参数中找到区域。",
        "reason": "虽然可以通过解析 AWS::StackId 伪参数获取区域，但这是一个复杂且不直观的方法。操作效率低，不如直接使用 AWS::Region 伪参数。"
      },
      "D": {
        "option": "通过引用 AWS Systems Manager 参数存储中的相关参数动态导入区域。",
        "reason": "这种方法需要预先在 AWS Systems Manager 参数存储中设置区域参数，并在模板中引用。这增加了额外的配置步骤和复杂性，不如使用 AWS::Region 伪参数直接明了。"
      }
    }
  },
  {
    "number": "116",
    "best": ["A"],
    "question": "公司有数百个 AWS Lambda 函数，公司 QA 团队需要使用 Lambda 函数 URL 进行测试。开发人员需要配置 Lambda 函数的身份验证，以允许 QA IAM 组通过公共 URL 调用 Lambda 函数。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个 CLI 脚本，循环处理 Lambda 函数，以 AWS_IAM 身份验证类型添加 Lambda 函数 URL。运行另一个脚本，创建一个允许 lambda:InvokeFunctionUrl 操作的 IAM 身份策略，适用于所有 Lambda 函数的 Amazon 资源名称（ARN）。将策略附加到 QA IAM 组。",
        "reason": "这个选项使用 AWS_IAM 身份验证类型，这样可以确保只有具有适当 IAM 权限的用户才能调用 Lambda 函数 URL。这符合安全性要求，并且通过将策略附加到 QA IAM 组，可以集中管理权限。"
      },
      "B": {
        "option": "创建一个 CLI 脚本，循环处理 Lambda 函数，以 NONE 身份验证类型添加 Lambda 函数 URL。运行另一个脚本，创建一个允许 lambda:InvokeFunctionUrl 操作的 IAM 资源策略，适用于所有 Lambda 函数的 Amazon 资源名称（ARN）。将策略附加到 QA IAM 组。",
        "reason": "这个选项使用 NONE 身份验证类型，这意味着 URL 是公开的，任何人都可以访问。这不符合安全性要求，因此不适合本场景。"
      },
      "C": {
        "option": "创建一个 CLI 脚本，循环处理 Lambda 函数，以 AWS_IAM 身份验证类型添加 Lambda 函数 URL。运行另一个脚本，循环处理 Lambda 函数，创建一个允许 lambda:InvokeFunctionUrl 操作的 IAM 身份策略，适用于 QA IAM 组的 Amazon 资源名称（ARN）。",
        "reason": "虽然这个选项也使用了 AWS_IAM 身份验证类型，但在创建策略时没有集中管理所有 Lambda 函数的权限，而是逐个函数创建。这种方法不如选项 A 高效和简洁。"
      },
      "D": {
        "option": "创建一个 CLI 脚本，循环处理 Lambda 函数，以 NONE 身份验证类型添加 Lambda 函数 URL。运行另一个脚本，循环处理 Lambda 函数，创建一个允许 lambda:InvokeFunctionUrl 操作的 IAM 资源策略，适用于 QA IAM 组的 Amazon 资源名称（ARN）。",
        "reason": "这个选项使用 NONE 身份验证类型，导致 URL 公开访问。这不符合安全性要求，因此不适合本场景。"
      }
    }
  },
  {
    "number": "117",
    "best": ["B"],
    "question": "一位开发人员维护一个使用 Amazon DynamoDB 作为主要数据存储的关键业务应用程序。DynamoDB 表包含数百万个文档，每分钟接收 30-60 个请求。开发人员需要在将文档添加或更新到 DynamoDB 表时进行近实时处理。开发人员如何在最少更改现有应用程序代码的情况下实现此功能？",
    "options": {
      "A": {
        "option": "在 Amazon EC2 实例上设置一个 cron 作业。每小时运行一次脚本以查询表的更改并处理文档。",
        "reason": "这种方法涉及设置和维护额外的 EC2 实例，并且查询整个表来查找更改效率低下。每小时运行一次脚本无法满足近实时处理的需求。"
      },
      "B": {
        "option": "在表上启用 DynamoDB 流。调用 AWS Lambda 函数来处理文档。",
        "reason": "DynamoDB Streams 能够捕获对表的更改，并且可以触发 AWS Lambda 函数来处理这些更改。这种方法实现了近实时处理，并且对现有应用代码的更改最少。"
      },
      "C": {
        "option": "更新应用程序以向 Amazon EventBridge 发送 PutEvents 请求。创建一个 EventBridge 规则来调用 AWS Lambda 函数处理文档。",
        "reason": "这种方法需要修改应用程序代码以发送事件到 EventBridge，而不是直接利用 DynamoDB 的功能，因此需要更多的代码更改。"
      },
      "D": {
        "option": "更新应用程序以在 DynamoDB 写入后同步处理文档。",
        "reason": "这种方法需要修改应用程序代码以在写入后立即处理文档，这可能会影响应用程序的性能，并且需要更多的代码更改。"
      }
    }
  },
  {
    "number": "118",
    "best": ["C"],
    "question": "一位开发人员正在为公司编写应用程序。该应用程序将部署在 Amazon EC2 上，并将使用 Amazon RDS for Microsoft SQL Server 数据库。公司的安全团队要求数据库凭证至少每周轮换一次。开发人员应如何配置此应用程序的数据库凭证？",
    "options": {
      "A": {
        "option": "创建数据库用户。将用户名和密码存储在 AWS Systems Manager Parameter Store 安全字符串参数中。启用用于加密参数的 AWS Key Management Service (AWS KMS) 密钥的轮换。",
        "reason": "虽然 AWS Systems Manager Parameter Store 可以安全存储敏感信息，但它并不提供自动凭证轮换功能。需要开发额外的逻辑来实现凭证轮换，因此不符合自动轮换的要求。"
      },
      "B": {
        "option": "为数据库启用 IAM 身份验证。创建用于 IAM 身份验证的数据库用户。启用密码轮换。",
        "reason": "虽然 IAM 身份验证是一种安全的访问方法，但它并不直接支持数据库凭证的自动轮换。需要额外的配置和管理来实现密码轮换。"
      },
      "C": {
        "option": "创建数据库用户。将用户名和密码存储在 AWS Secrets Manager 秘密中，并启用每日轮换。",
        "reason": "AWS Secrets Manager 提供自动凭证轮换功能，可以轻松配置并管理数据库凭证的轮换。这是最符合题目要求的解决方案。"
      },
      "D": {
        "option": "使用 EC2 用户数据创建数据库用户。在环境变量中向应用程序提供用户名和密码。",
        "reason": "这种方法不提供任何自动凭证轮换机制，并且在环境变量中存储敏感信息存在安全风险。因此不符合安全团队的要求。"
      }
    }
  },
  {
    "number": "119",
    "best": ["D", "E"],
    "question": "一个实时消息应用程序使用 Amazon API Gateway WebSocket API 和后端 HTTP 服务。开发人员需要在应用程序中构建一个功能，以识别不断连接和断开 WebSocket 连接的客户端。开发人员还需要能够移除该客户端。开发人员应该对应用程序进行哪些更改以满足这些要求？（选择两个。）",
    "options": {
      "A": {
        "option": "在后端服务中切换到 HTTP API。",
        "reason": "HTTP API 并不适合用于 WebSocket 的持续连接管理，因此不能满足识别和移除客户端的需求。"
      },
      "B": {
        "option": "在后端服务中切换到 REST API。",
        "reason": "REST API 也不适用于 WebSocket 的持续连接管理，不能满足题目中的需求。"
      },
      "C": {
        "option": "使用回调 URL 从后端服务断开客户端。",
        "reason": "回调 URL 可以用于通知后端服务，但它并不能直接管理 WebSocket 连接的状态。"
      },
      "D": {
        "option": "在后端服务中添加代码以在 Amazon ElastiCache 中跟踪客户端状态。",
        "reason": "使用 Amazon ElastiCache 跟踪客户端状态可以有效地记录客户端的连接和断开历史，从而识别那些不断连接和断开的客户端。"
      },
      "E": {
        "option": "在后端服务中实现 $connect 和 $disconnect 路由。",
        "reason": "$connect 和 $disconnect 路由用于处理 WebSocket 连接的建立和断开，开发人员可以通过这些路由实现客户端的识别和移除。"
      }
    }
  },
  {
    "number": "120",
    "best": ["C"],
    "question": "一名开发人员编写了一个应用程序的代码，并希望与团队中的其他开发人员分享，以便接收反馈。共享的应用程序代码需要长期存储，具有多个版本和批量变更跟踪。开发人员应该使用哪项 AWS 服务？",
    "options": {
      "A": {
        "option": "AWS CodeBuild",
        "reason": "AWS CodeBuild 是一种完全托管的构建服务，用于编译源代码、运行测试和生成软件包。它并不用于长期存储代码和版本控制。"
      },
      "B": {
        "option": "Amazon S3",
        "reason": "Amazon S3 是一种对象存储服务，适用于存储和检索任何数量的数据。虽然它可以存储代码，但不具备专业的版本控制和批量变更跟踪功能。"
      },
      "C": {
        "option": "AWS CodeCommit",
        "reason": "AWS CodeCommit 是一种托管的源代码控制服务，可以轻松托管 Git 仓库。它支持长期存储、版本控制和变更跟踪，非常适合团队协作开发和代码审查。"
      },
      "D": {
        "option": "AWS Cloud9",
        "reason": "AWS Cloud9 是一个基于云的集成开发环境（IDE），用于编写、运行和调试代码。尽管它可以协助开发工作，但并不用于长期存储和管理代码的版本控制。"
      }
    }
  },
  {
    "number": "121",
    "best": ["A"],
    "question": "一家公司的一名开发人员正在开发一个静态网站，该网站将在生产环境中部署到 Amazon S3。网站通过一个 AWS Lambda 函数与一个 Amazon Aurora PostgreSQL 数据库集成。部署到生产环境的网站将使用指向 Lambda 函数特定版本的 Lambda 别名。公司必须每两周轮换一次数据库凭证。公司之前部署的 Lambda 函数必须能够使用最新的凭证。 哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "将数据库凭证存储在 AWS Secrets Manager 中。开启轮换。在 Lambda 函数中编写代码以从 Secrets Manager 中检索凭证。",
        "reason": "AWS Secrets Manager 专为管理和轮换凭证而设计。它可以自动轮换凭证，并且可以通过 API 轻松集成到 Lambda 函数中，从而确保 Lambda 函数始终可以获取最新的数据库凭证。这种方法不仅简化了凭证管理，还提高了安全性和合规性。"
      },
      "B": {
        "option": "将数据库凭证包含在 Lambda 函数代码中。定期更新凭证并部署新的 Lambda 函数。",
        "reason": "将凭证硬编码到 Lambda 函数中并不是一个好的实践，因为每次凭证更改都需要重新部署 Lambda 函数，这会增加运维的复杂度和风险。同时，这种方法不利于凭证的安全管理，容易导致凭证泄露。"
      },
      "C": {
        "option": "使用 Lambda 环境变量。当新凭证可用时更新环境变量。",
        "reason": "虽然使用环境变量可以存储凭证，但更新这些环境变量仍然需要重新部署 Lambda 函数，这并不能满足自动轮换的需求。而且环境变量的安全性也不如专门的凭证管理服务高。"
      },
      "D": {
        "option": "将数据库凭证存储在 AWS Systems Manager Parameter Store 中。开启轮换。在 Lambda 函数中编写代码以从 Systems Manager Parameter Store 中检索凭证。",
        "reason": "虽然 AWS Systems Manager Parameter Store 可以存储和检索参数，并支持一些基本的凭证管理功能，但其自动轮换功能不如 AWS Secrets Manager 强大和灵活。Secrets Manager 专为此类用例设计，更加适合这类需求。"
      }
    }
  },
  {
    "number": "122",
    "best": ["A", "D"],
    "question": "开发人员正在开发一个使用签名请求（签名版本 4）来调用其他 AWS 服务的应用程序。开发人员已经创建了规范请求，创建了要签名的字符串，并计算了签名信息。开发人员可以使用哪些方法来完成签名请求？（选择两个。）",
    "options": {
      "A": {
        "option": "将签名添加到名为 Authorization 的 HTTP 头中。",
        "reason": "在使用 AWS Signature Version 4 时，签名通常会被添加到一个名为 Authorization 的 HTTP 头中。这样可以确保请求的完整性和身份验证。"
      },
      "B": {
        "option": "将签名添加到会话 cookie 中。",
        "reason": "将签名添加到会话 cookie 中并不是 AWS Signature Version 4 的标准做法，因此不合适。"
      },
      "C": {
        "option": "将签名添加到名为 Authentication 的 HTTP 头中。",
        "reason": "签名应添加到名为 Authorization 的 HTTP 头中，而不是 Authentication 头中。因此此选项不正确。"
      },
      "D": {
        "option": "将签名添加到名为 X-Amz-Signature 的查询字符串参数中。",
        "reason": "在某些情况下，可以将签名添加到查询字符串参数中，这通常用于预签名 URL。因此这是一个正确的选项。"
      },
      "E": {
        "option": "将签名添加到名为 WWW-Authenticate 的 HTTP 头中。",
        "reason": "WWW-Authenticate 头主要用于 HTTP 的基本和摘要认证，并不适用于 AWS Signature Version 4。因此此选项不正确。"
      }
    }
  },
  {
    "number": "123",
    "best": ["D"],
    "question": "一家公司必须使用 AWS CloudFormation 模板来部署所有的 Amazon RDS 数据库实例，作为 AWS CodePipeline 持续集成和持续交付（CI/CD）自动化的一部分。数据库实例的主要密码必须在部署过程中自动生成。哪种解决方案可以以最少的开发工作量满足这些需求？",
    "options": {
      "A": {
        "option": "创建一个由 AWS Lambda 支持的 CloudFormation 自定义资源。编写生成安全字符串的 Lambda 代码。将安全字符串的值作为自定义资源响应对象的数据字段返回。使用 CloudFormation Fn::GetAtt 内置函数获取安全字符串的值。使用该值创建数据库实例。",
        "reason": "虽然这个解决方案可行，但它需要编写和维护自定义的 Lambda 函数，这增加了开发工作量和复杂性。"
      },
      "B": {
        "option": "使用 CodePipeline 的 AWS CodeBuild 操作，通过以下 AWS CLI 命令生成一个安全字符串：aws secretsmanager get-random-password。将生成的安全字符串作为 CloudFormation 参数传递，并将 NoEcho 属性设置为 true。使用该参数引用来创建数据库实例。",
        "reason": "这个方案涉及在 CodeBuild 中生成密码，然后将其传递给 CloudFormation，流程相对复杂，而且参数传递过程存在潜在的安全风险。"
      },
      "C": {
        "option": "创建一个由 AWS Lambda 支持的 CloudFormation 自定义资源。编写生成安全字符串的 Lambda 代码。将安全字符串的值作为自定义资源响应对象的数据字段返回。使用 CloudFormation Fn::GetAtt 内置函数获取安全字符串的值。在 AWS Secrets Manager 中创建秘密。使用 secretsmanager 动态引用来使用存储在秘密中的值来创建数据库实例。",
        "reason": "这个方案结合了 Lambda 和 Secrets Manager，尽管可行，但增加了开发和管理的复杂性。"
      },
      "D": {
        "option": "使用 AWS::SecretsManager::Secret 资源生成一个安全字符串。将安全字符串存储为 AWS Secrets Manager 中的秘密。使用 secretsmanager 动态引用来使用存储在秘密中的值来创建数据库实例。",
        "reason": "这是最优的解决方案，因为它利用了 AWS Secrets Manager 的内置功能，无需编写额外的代码，简化了部署过程，并最小化了开发工作量。"
      }
    }
  },
  {
    "number": "124",
    "best": ["A"],
    "question": "一个组织正在 Amazon S3 中存储大文件，并编写一个 web 应用程序以向最终用户显示文件的元数据。根据元数据，用户选择一个对象进行下载。该组织需要一种机制来索引文件并为元数据提供单位数字毫秒的延迟检索。应该使用哪种 AWS 服务来实现这一目标？",
    "options": {
      "A": {
        "option": "Amazon DynamoDB",
        "reason": "Amazon DynamoDB 是一种完全托管的 NoSQL 数据库服务，能够提供单位数字毫秒的响应时间，非常适合需要快速访问和检索元数据的场景。它能够轻松扩展以处理大量数据，并且与 Amazon S3 集成良好。"
      },
      "B": {
        "option": "Amazon EC2",
        "reason": "Amazon EC2 是一种可扩展的计算服务，虽然可以用来托管应用程序和数据库，但它不适合直接提供单位数字毫秒的延迟检索。使用 EC2 需要额外的配置和维护工作，因此并不是最佳选择。"
      },
      "C": {
        "option": "AWS Lambda",
        "reason": "AWS Lambda 是一种无服务器计算服务，可以用于处理事件驱动的任务。虽然它可以用来处理和检索数据，但它不是专门设计来提供单位数字毫秒的延迟检索元数据。Lambda 更适合处理不需要低延迟的后台任务。"
      },
      "D": {
        "option": "Amazon RDS",
        "reason": "Amazon RDS 是一种关系数据库服务，适用于需要事务处理和复杂查询的应用程序。虽然 RDS 可以用来存储和检索元数据，但它的响应时间通常比 DynamoDB 慢，特别是在需要单位数字毫秒延迟的情况下，不是最佳选择。"
      }
    }
  },
  {
    "number": "125",
    "best": ["B"],
    "question": "开发人员正在创建一个 AWS 无服务器应用程序模型 (AWS SAM) 模板。这个 AWS SAM 模板包含多个 AWS Lambda 函数、一个 Amazon S3 存储桶以及一个 Amazon CloudFront 分发的定义。其中一个 Lambda 函数在 CloudFront 分发中运行 Lambda@Edge。S3 存储桶被配置为 CloudFront 分发的源。当开发人员在 eu-west-1 区域部署 AWS SAM 模板时，堆栈创建失败。以下哪个可能是导致此问题的原因？",
    "options": {
      "A": {
        "option": "CloudFront 分发只能在 us-east-1 区域创建。",
        "reason": "CloudFront 分发可以在全球任何区域创建，而不仅仅是在 us-east-1 区域。因此，这不是问题的原因。"
      },
      "B": {
        "option": "Lambda@Edge 函数只能在 us-east-1 区域创建。",
        "reason": "Lambda@Edge 必须在 us-east-1 区域创建，然后才能在全球范围内分发和使用。因此，在其他区域创建 Lambda@Edge 函数会导致堆栈创建失败，这是问题的原因。"
      },
      "C": {
        "option": "单个 AWS SAM 模板不能包含多个 Lambda 函数。",
        "reason": "AWS SAM 模板可以包含多个 Lambda 函数，因此这不是问题的原因。"
      },
      "D": {
        "option": "CloudFront 分发和 S3 存储桶不能在同一区域创建。",
        "reason": "CloudFront 分发和 S3 存储桶可以在同一区域创建，因此这不是问题的原因。"
      }
    }
  },
  {
    "number": "126",
    "best": ["D"],
    "question": "开发人员正在将 Amazon ElastiCache 集成到应用程序中。缓存将存储数据库中的数据。缓存的数据必须填充实时仪表板。哪种缓存策略将满足这些要求？",
    "options": {
      "A": {
        "option": "读取缓存",
        "reason": "读取缓存策略在读取数据时首先检查缓存，如果缓存中没有数据，则从数据库中读取并存储在缓存中。这种策略不能确保缓存中的数据实时更新，不适合需要实时更新的仪表板。"
      },
      "B": {
        "option": "写后缓存",
        "reason": "写后缓存策略将数据首先写入缓存，然后异步地写入数据库。这种策略在写入时的性能较好，但并不能保证缓存中的数据是实时更新的，因此不适合实时仪表板的需求。"
      },
      "C": {
        "option": "延迟加载缓存",
        "reason": "延迟加载缓存策略在数据被请求时才从数据库中加载到缓存中。虽然这种策略可以减少不必要的缓存数据，但同样不能确保缓存数据的实时更新，不适合实时仪表板。"
      },
      "D": {
        "option": "写入缓存",
        "reason": "写入缓存策略在数据写入数据库的同时也写入缓存，确保缓存中的数据与数据库中的数据实时同步。对于需要实时更新的仪表板，这是最佳选择。"
      }
    }
  },
  {
    "number": "127",
    "best": ["A"],
    "question": "一名开发人员正在创建一个 AWS Lambda 函数。该 Lambda 函数需要一个外部库来连接第三方解决方案。外部库是一个文件集合，总大小为 100 MB。开发人员需要使外部库在 Lambda 执行环境中可用，并减少 Lambda 包的空间。哪种解决方案在尽可能少的操作开销下满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个 Lambda 图层来存储外部库。配置 Lambda 函数以使用该图层。",
        "reason": "Lambda 图层允许你将外部库与 Lambda 函数代码分离，这减少了 Lambda 函数包的大小。图层可以被多个函数重用，降低了管理和操作的复杂性，因此具有最小的操作开销。"
      },
      "B": {
        "option": "创建一个 Amazon S3 存储桶。将外部库上传到 S3 存储桶。在 Lambda 函数中挂载 S3 存储桶文件夹。通过使用挂载点中的正确文件夹导入库。",
        "reason": "虽然 S3 可以用来存储外部库，但 Lambda 函数不能直接挂载 S3 存储桶。因此，这个选项不可行。"
      },
      "C": {
        "option": "在部署 Lambda 包期间将外部库加载到 Lambda 函数的 /tmp 目录中。从 /tmp 目录导入库。",
        "reason": "这种方法将库文件直接放在 /tmp 目录中，但 /tmp 目录的大小限制为 512 MB，并且在每个函数调用之间不持久，这可能会增加操作复杂性和开销。"
      },
      "D": {
        "option": "创建一个 Amazon Elastic File System (Amazon EFS) 卷。将外部库上传到 EFS 卷。在 Lambda 函数中挂载 EFS 卷。通过使用挂载点中的正确文件夹导入库。",
        "reason": "EFS 可以提供持久存储，并且可以被多个 Lambda 函数挂载和使用。然而，配置和管理 EFS 需要更多的操作开销，因此不是最优选择。"
      }
    }
  },
  {
    "number": "128",
    "best": ["C"],
    "question": "一家公司有一个前端应用程序，该应用程序在四个 Amazon EC2 实例上运行，这些实例位于生产环境中的 Elastic Load Balancer (ELB) 后面，并由 AWS Elastic Beanstalk 提供。开发人员需要在将 Elastic Beanstalk 平台从当前版本更新到较新的 Node.js 版本时，部署和测试新的应用程序代码。该解决方案必须确保应用程序的零停机时间。哪种解决方案满足这些要求？",
    "options": {
      "A": {
        "option": "克隆生产环境到不同的平台版本。部署新的应用程序代码并进行测试。验证后交换环境 URL。",
        "reason": "克隆生产环境并切换 URL 可能会引起一些复杂性和额外的配置步骤。虽然这种方法可以确保零停机时间，但它并不是最优的选项，因为它需要更多的资源和时间来设置和管理两个环境。"
      },
      "B": {
        "option": "在现有 EC2 实例上一次性部署新的应用程序代码。测试代码。如果验证失败，重新部署以前的代码。",
        "reason": "一次性部署（all-at-once deployment）会导致整个应用程序在部署期间不可用，因此无法实现零停机时间。如果新代码有问题，将需要重新部署，这增加了风险。"
      },
      "C": {
        "option": "执行不可变更新，将新的应用程序代码部署到新的 EC2 实例。在新的实例通过健康检查后，开始为其提供流量。",
        "reason": "不可变更新（immutable update）是一种最佳实践，因为它创建了新的 EC2 实例来部署新代码，而不会影响现有的实例。这确保了零停机时间，因为旧的实例仍然运行，直到新的实例通过健康检查。这是最优解。"
      },
      "D": {
        "option": "使用滚动部署新应用程序代码。将代码应用于一部分 EC2 实例，直到测试通过。如果测试失败，重新部署以前的代码。",
        "reason": "滚动部署可以减少停机时间，但不能完全消除停机时间，因为在某些实例上更新代码时，这些实例可能会暂时不可用。因此，这不是最佳解决方案。"
      }
    }
  },
  {
    "number": "129",
    "best": ["C"],
    "question": "一位开发人员正在创建一个 AWS Lambda 函数。该 Lambda 函数将从 Amazon Simple Queue Service (Amazon SQS) 队列中消费消息。开发人员希望将单元测试集成到函数的持续集成和持续交付 (CI/CD) 过程中。开发人员该如何进行函数的单元测试？",
    "options": {
      "A": {
        "option": "创建一个 AWS CloudFormation 模板，该模板创建一个 SQS 队列并部署 Lambda 函数。在 CI/CD 过程中从模板创建一个堆栈。调用已部署的函数。验证输出。",
        "reason": "虽然这种方法在 CI/CD 过程中可以动态创建资源并验证输出，但它更适合集成测试而不是单元测试。单元测试应尽量避免依赖实际的 AWS 资源，更多地依赖于模拟和本地测试。"
      },
      "B": {
        "option": "为测试创建一个 SQS 事件。在函数的 CI/CD 过程中使用该测试事件消费 SQS 队列中的消息。",
        "reason": "这个选项没有明确说明如何创建和使用这个事件，且在单元测试中直接消费实际的 SQS 队列消息并不是最佳实践。单元测试通常需要更为精细化的控制和隔离。"
      },
      "C": {
        "option": "为测试创建一个 SQS 队列。在应用程序的单元测试中使用这个 SQS 队列。在 CI/CD 过程中运行单元测试。",
        "reason": "这个选项建议专门为测试创建一个 SQS 队列，并在单元测试中使用它，这样可以确保测试环境和生产环境分离，且能够在 CI/CD 过程中自动化运行单元测试。这符合单元测试的最佳实践。"
      },
      "D": {
        "option": "在 CI/CD 过程中使用 aws lambda invoke 命令与测试事件。",
        "reason": "使用 aws lambda invoke 命令可以在本地或 CI/CD 管道中触发 Lambda 函数，但这更适合集成测试而不是单元测试。单元测试通常不依赖于 AWS 资源，而是通过模拟来测试函数的逻辑。"
      }
    }
  },
  {
    "number": "130",
    "best": ["C"],
    "question": "一个开发人员正在开发一个使用 Amazon DynamoDB 作为数据存储的 web 应用程序。该应用程序有两个 DynamoDB 表：一个名为 artists 的表和一个名为 songs 的表。artists 表有 artistName 作为分区键。songs 表有 songName 作为分区键和 artistName 作为排序键。表的使用模式包括从网页中单次数据库操作中检索多个歌曲和艺术家信息。开发人员需要一种方式以最小的网络流量和最佳的应用程序性能来检索这些信息。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "执行一个 BatchGetItem 操作，从两个表中返回项目。使用 songs 表的 songName/artistName 键列表和 artists 表的 artistName 键列表。",
        "reason": "BatchGetItem 可以从多个表中检索数据，但需要分别为每个表单独指定键列表，这样做会增加复杂性和网络流量。"
      },
      "B": {
        "option": "在 songs 表上创建一个本地二级索引（LSI），使用 artistName 作为分区键。对 songs 表中的每个 artistName 执行一个查询操作，按 songName 列表进行过滤。对 artists 表中的每个 artistName 执行一个查询操作。",
        "reason": "虽然 LSI 可以提高查询性能，但在这种情况下创建并不必要。并且这需要多个查询操作，增加了复杂性和网络流量。"
      },
      "C": {
        "option": "对 songs 表使用 songName/artistName 键执行 BatchGetItem 操作。对 artists 表使用 artistName 作为键执行 BatchGetItem 操作。",
        "reason": "BatchGetItem 操作适用于从多个表中高效检索数据，同时减少网络流量和提高性能。这种方法可以一次性获取所需数据，是最佳选择。"
      },
      "D": {
        "option": "对每个表执行 Scan 操作，按 songs 表中的 songName/artistName 列表和 artists 表中的 artistName 列表进行过滤。",
        "reason": "Scan 操作会扫描整个表，导致高延迟和高成本，尤其是在表数据量大的情况下。这不是一种高效的解决方案。"
      }
    }
  },
  {
    "number": "131",
    "best": ["C"],
    "question": "一家公司正在开发一个使用 Amazon API Gateway API 的电子商务应用程序。该应用程序使用 AWS Lambda 作为后端。公司需要在代码发布到生产环境之前，在一个专用的、监控的测试环境中测试代码。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "在 API Gateway 中使用单个阶段。为每个环境创建一个 Lambda 函数。配置 API 客户端发送一个指示环境和特定 Lambda 函数的查询参数。",
        "reason": "这种方法增加了客户端的复杂性，因为客户端需要知道不同环境的查询参数。此外，不同环境的 Lambda 函数共用一个 API Gateway 阶段，可能影响测试的独立性和隔离性。"
      },
      "B": {
        "option": "在 API Gateway 中使用多个阶段。为所有环境创建一个 Lambda 函数。根据 Lambda 环境变量在 Lambda 函数中添加不同的代码块以适应不同环境。",
        "reason": "虽然这种方法在 Lambda 函数中使用环境变量来区分环境，但使用单个 Lambda 函数可能会增加代码复杂性和维护成本。此外，不同环境的代码在同一个函数中运行，可能会导致意外的交互和问题。"
      },
      "C": {
        "option": "在 API Gateway 中使用多个阶段。为每个环境创建一个 Lambda 函数。配置 API Gateway 阶段变量以将流量路由到不同环境中的 Lambda 函数。",
        "reason": "这种方法最符合需求。使用多个阶段可以确保不同环境之间的隔离性和独立性。通过配置 API Gateway 阶段变量，可以方便地将流量路由到不同的 Lambda 函数，确保测试环境与生产环境的独立性。"
      },
      "D": {
        "option": "在 API Gateway 中使用单个阶段。配置 API 客户端发送一个指示环境的查询参数。根据查询参数的值在 Lambda 函数中添加不同的代码块以适应不同环境。",
        "reason": "这种方法与选项 A 类似，增加了客户端的复杂性。此外，单个阶段无法实现环境的隔离性，测试环境与生产环境的代码共用一个 Lambda 函数，可能会导致问题。"
      }
    }
  },
  {
    "number": "132",
    "best": ["C"],
    "question": "一名开发人员创建了一个 AWS Lambda 函数，用于从多个公共 API 端点检索和分组数据。该 Lambda 函数已更新并配置为连接到 VPC 的私有子网。一个互联网网关已附加到 VPC。VPC 使用默认的网络 ACL 和安全组配置。开发人员发现 Lambda 函数无法再访问公共 API。开发人员已经确保公共 API 是可访问的，但 Lambda 函数无法连接到 API。开发人员应该如何修复连接问题？",
    "options": {
      "A": {
        "option": "确保网络 ACL 允许出站流量到公共互联网。",
        "reason": "默认的网络 ACL 允许所有出站和入站流量，所以问题不在这里。"
      },
      "B": {
        "option": "确保安全组允许出站流量到公共互联网。",
        "reason": "默认的安全组允许所有出站流量，所以问题不在这里。"
      },
      "C": {
        "option": "确保来自私有子网的出站流量路由到公共 NAT 网关。",
        "reason": "私有子网中的资源无法直接访问互联网，需要通过 NAT 网关进行出站访问。"
      },
      "D": {
        "option": "确保来自私有子网的出站流量路由到新的互联网网关。",
        "reason": "互联网网关只能直接连接公共子网，不能直接用于私有子网。"
      }
    }
  },
  {
    "number": "133",
    "best": ["C"],
    "question": "开发人员需要为应用程序存储配置变量。开发人员需要设置配置的过期日期和时间，并希望在配置过期之前收到通知。哪种解决方案可以以最少的操作开销满足这些要求？",
    "options": {
      "A": {
        "option": "在 AWS Systems Manager Parameter Store 中创建一个标准参数。设置 Expiration 和 ExpirationNotification 策略类型。",
        "reason": "标准参数不支持 Expiration 和 ExpirationNotification 策略类型。此选项无法实现开发人员的需求。"
      },
      "B": {
        "option": "在 AWS Systems Manager Parameter Store 中创建一个标准参数。创建一个 AWS Lambda 函数来使配置过期并发送 Amazon Simple Notification Service (Amazon SNS) 通知。",
        "reason": "虽然这种方法可以实现需求，但它涉及编写和管理 Lambda 函数，增加了操作开销，不是最优解。"
      },
      "C": {
        "option": "在 AWS Systems Manager Parameter Store 中创建一个高级参数。设置 Expiration 和 ExpirationNotification 策略类型。",
        "reason": "高级参数支持 Expiration 和 ExpirationNotification 策略类型，能够自动处理配置过期和通知，是最优解。"
      },
      "D": {
        "option": "在 AWS Systems Manager Parameter Store 中创建一个高级参数。创建一个带有 cron 作业的 Amazon EC2 实例来使配置过期并发送通知。",
        "reason": "虽然这种方法可以实现需求，但它涉及管理 EC2 实例和编写 cron 作业，增加了操作开销，不是最优解。"
      }
    }
  },
  {
    "number": "134",
    "best": ["D"],
    "question": "某公司正在开发一个无服务器应用程序，该应用程序由 Amazon API Gateway API 后的各种 AWS Lambda 函数组成。开发人员需要自动化部署 Lambda 函数代码。开发人员将使用 AWS CodeDeploy 部署更新的 Lambda 函数。部署必须尽量减少对最终用户的潜在错误暴露。在应用程序投产时，应用程序不能在指定的维护窗口之外出现停机时间。哪种部署配置将在最短的部署时间内满足这些要求？",
    "options": {
      "A": {
        "option": "使用 AWS CodeDeploy 的就地部署配置进行 Lambda 函数的部署。部署后立即转移所有流量。",
        "reason": "就地部署（in-place deployment）会替换正在运行的实例上的应用程序版本，并且在部署过程中会有停机时间，因此不符合题目要求的“应用程序不能在指定的维护窗口之外出现停机时间”的要求。"
      },
      "B": {
        "option": "使用 AWS CodeDeploy 线性部署配置，每分钟转移 10% 的流量。",
        "reason": "线性部署（linear deployment）虽然可以逐步转移流量，从而减少错误暴露，但相对来说部署时间较长，不符合题目中“最短的部署时间”的要求。"
      },
      "C": {
        "option": "使用 AWS CodeDeploy 一次性部署配置，立即将所有流量转移到更新的版本。",
        "reason": "一次性部署（all-at-once deployment）会立即将所有流量转移到新的版本，这样可能会在新版本有潜在错误的情况下暴露给所有用户，不符合题目中“尽量减少对最终用户的潜在错误暴露”的要求。"
      },
      "D": {
        "option": "使用 AWS CodeDeploy 预定义的金丝雀部署配置，立即转移 10% 的流量，然后在 5 分钟后转移剩余的流量。",
        "reason": "金丝雀部署（canary deployment）通过先转移一小部分流量到新版本以检测潜在问题，在 5 分钟后再转移剩余流量，这样可以尽量减少错误暴露，同时部署时间相对较短，符合题目要求。"
      }
    }
  },
  {
    "number": "135",
    "best": ["B"],
    "question": "一家公司创建了四个 AWS Lambda 函数，这些函数连接到运行在 Amazon RDS 实例上的关系数据库服务器。安全团队要求公司每 30 天自动更改一次数据库密码。哪种解决方案最安全地满足这些要求？",
    "options": {
      "A": {
        "option": "将数据库凭证存储在 Lambda 函数的环境变量中。每 30 天部署一次具有新凭证的 Lambda 函数。",
        "reason": "将数据库凭证存储在 Lambda 环境变量中并不安全，因为环境变量在运行时可以被轻松读取。此外，每 30 天重新部署 Lambda 函数也不是一个自动化的解决方案，需要手动干预。"
      },
      "B": {
        "option": "将数据库凭证存储在 AWS Secrets Manager 中。为凭证配置一个 30 天的轮换计划。",
        "reason": "AWS Secrets Manager 提供了安全的凭证存储和自动轮换功能。它可以自动更新数据库密码并将新密码安全分发给使用这些凭证的 Lambda 函数。此选项最符合安全团队的要求，并提供了一个自动化的解决方案。"
      },
      "C": {
        "option": "将数据库凭证存储在 AWS Systems Manager Parameter Store 的安全字符串中。为安全字符串配置一个 30 天的计划。",
        "reason": "AWS Systems Manager Parameter Store 的安全字符串可以安全存储敏感数据，但它不提供自动轮换功能。手动管理轮换过程可能会导致操作复杂性和安全风险。"
      },
      "D": {
        "option": "将数据库凭证存储在使用客户提供的加密密钥 (SSE-C) 进行服务器端加密的 Amazon S3 存储桶中。为客户密钥配置一个 30 天的密钥轮换计划。",
        "reason": "虽然 Amazon S3 可以安全存储加密数据，但这不是存储和管理数据库凭证的最佳实践。使用 S3 和 SSE-C 进行凭证存储和轮换缺乏专门的管理和自动化功能。"
      }
    }
  },
  {
    "number": "136",
    "best": ["C"],
    "question": "开发人员正在设置一个部署管道。管道包括一个需要访问数据库来运行集成测试的 AWS CodeBuild 构建阶段。开发人员正在使用 buildspec.yml 文件配置数据库连接。公司政策要求自动轮换所有数据库凭证。哪种解决方案将最安全地处理数据库凭证？",
    "options": {
      "A": {
        "option": "从硬编码在 buildspec.yml 文件中的变量中检索凭证。配置一个 AWS Lambda 函数来轮换凭证。",
        "reason": "这种方法不符合公司的安全政策，因为凭证是硬编码在代码文件中的，容易被泄露。虽然 AWS Lambda 可以用来轮换凭证，但这种方法不够安全。"
      },
      "B": {
        "option": "从链接到 AWS Systems Manager Parameter Store 中的 SecureString 参数的环境变量中检索凭证。配置 Parameter Store 进行自动轮换。",
        "reason": "虽然 AWS Systems Manager Parameter Store 支持存储 SecureString，但它本身并不提供自动轮换功能。需要额外的步骤来实现自动轮换，这增加了复杂性和潜在的安全风险。"
      },
      "C": {
        "option": "从链接到 AWS Secrets Manager 密钥的环境变量中检索凭证。配置 Secrets Manager 进行自动轮换。",
        "reason": "AWS Secrets Manager 是专门设计用于管理和自动轮换凭证的服务。它可以安全地存储数据库凭证，并提供内置的自动轮换功能，是最符合公司安全政策的解决方案。"
      },
      "D": {
        "option": "从包含明文连接字符串的环境变量中检索凭证。配置一个 Amazon EventBridge 事件来轮换凭证。",
        "reason": "这种方法不安全，因为凭证以明文形式存储在环境变量中，容易被泄露。虽然 Amazon EventBridge 可以用于触发轮换事件，但明文存储仍然是不安全的。"
      }
    }
  },
  {
    "number": "137",
    "best": ["A"],
    "question": "一家公司正在 AWS 上开发一个无服务器的多层应用程序。公司将使用 Amazon API Gateway 和 AWS Lambda 构建无服务器逻辑层。在公司构建逻辑层的同时，负责应用程序前端的开发人员必须开发集成测试。这些测试必须涵盖根据成功和错误的 HTTP 状态码的正面和负面情景。哪种解决方案可以以最少的努力满足这些要求？",
    "options": {
      "A": {
        "option": "在 API Gateway 中为 API 方法设置模拟集成。在方法执行的集成请求中，添加简单的逻辑以根据 HTTP 状态码返回成功或错误。在集成响应中，添加与 HTTP 状态码相对应的消息。",
        "reason": "此选项可以直接在 API Gateway 中设置模拟集成，而不需要额外的 Lambda 函数或其他资源。这种方法最简单且不需要额外的开发工作，符合题目中'最少的努力'的要求。"
      },
      "B": {
        "option": "为 API Gateway 中的 API 方法创建两个模拟集成资源。在集成请求中，一个资源返回成功的 HTTP 状态码，另一个资源返回错误的 HTTP 状态码。在集成响应中，添加与 HTTP 状态码相对应的消息。",
        "reason": "尽管这个选项也使用了模拟集成，但它需要创建两个不同的资源，这增加了配置的复杂性，不如选项 A 简单。"
      },
      "C": {
        "option": "创建 Lambda 函数来执行测试。添加简单的逻辑以根据 HTTP 状态码返回成功或错误。构建 API Gateway Lambda 集成。选择与 HTTP 状态码相对应的 Lambda 函数。",
        "reason": "这个选项需要编写和维护 Lambda 函数，并进行 Lambda 集成，增加了开发和维护工作量，不符合'最少的努力'要求。"
      },
      "D": {
        "option": "创建一个 Lambda 函数来执行测试。添加简单的逻辑以根据 HTTP 状态码返回成功或错误。创建 API Gateway 中的模拟集成。选择与 HTTP 状态码相对应的 Lambda 函数。",
        "reason": "这个选项也需要编写和维护 Lambda 函数，并且还需要配置模拟集成，同样增加了开发和维护的工作量，不如选项 A 简单。"
      }
    }
  },
  {
    "number": "138",
    "best": ["A", "D"],
    "question": "用户在报告应用程序中的错误。该应用程序由几个微服务组成，这些微服务部署在使用 AWS Fargate 的 Amazon Elastic Container Service (Amazon ECS) 上。 开发人员应采取哪些步骤来修复这些错误？（选择两个。）",
    "options": {
      "A": {
        "option": "将 AWS X-Ray 作为 sidecar 容器部署到微服务中。更新任务角色策略以允许访问 X-Ray API。",
        "reason": "将 AWS X-Ray 作为 sidecar 容器部署，可以捕获分布式应用程序中的请求和响应数据。这种方法在微服务架构中非常常见。更新任务角色策略以允许访问 X-Ray API 是必需的，以便应用程序能够与 X-Ray 服务通信。"
      },
      "B": {
        "option": "将 AWS X-Ray 作为 daemonset 部署到 Fargate 集群。更新服务角色策略以允许访问 X-Ray API。",
        "reason": "AWS X-Ray 不能作为 daemonset 部署到 Fargate 集群，因为 Fargate 不支持 daemonset。这种选项适用于 Amazon EKS（Kubernetes 服务），但不适用于 Fargate。"
      },
      "C": {
        "option": "使用 AWS X-Ray SDK 对应用程序进行检测。更新应用程序以使用 PutXrayTrace API 调用与 X-Ray API 通信。",
        "reason": "虽然这个选项提到使用 AWS X-Ray SDK 进行检测是正确的，但直接使用 PutXrayTrace API 调用并不是最佳实践。通常应将应用程序更新为与 X-Ray daemon 通信。"
      },
      "D": {
        "option": "使用 AWS X-Ray SDK 对应用程序进行检测。更新应用程序与 X-Ray daemon 通信。",
        "reason": "这是最佳实践，应该使用 AWS X-Ray SDK 对应用程序进行检测，并确保应用程序与 X-Ray daemon 通信。这允许 X-Ray 收集和处理跟踪数据，然后将其发送到 X-Ray 服务。"
      },
      "E": {
        "option": "将 ECS 任务配置为将 stdout 和 stderr 输出发送到 Amazon CloudWatch Logs。更新任务角色策略以允许 cloudwatch:PullLogs 操作。",
        "reason": "虽然将日志发送到 Amazon CloudWatch Logs 有助于调试，但这不是解决分布式追踪问题的最佳方法。题目要求的是解决微服务间通信错误，而不是单纯的日志记录。"
      }
    }
  },
  {
    "number": "139",
    "best": ["A"],
    "question": "一名开发人员正在为公司创建一个应用程序。该应用程序需要读取位于名为DOC-EXAMPLE-BUCKET的Amazon S3存储桶根文件夹中的doc.txt文件。公司的安全团队要求将最小权限原则应用于应用程序的IAM策略。哪条IAM策略语句可以满足这些安全要求？",
    "options": {
      "A": {
        "option": "允许读取位于名为DOC-EXAMPLE-BUCKET的Amazon S3存储桶根文件夹中的doc.txt文件。",
        "reason": "选项A提供了对特定文件的最小权限访问，这是符合最小权限原则的最佳选择。该策略语句仅允许读取特定的doc.txt文件，并未授予对整个存储桶或其他文件的访问权限。"
      },
      "B": {
        "option": "允许读取和写入位于名为DOC-EXAMPLE-BUCKET的Amazon S3存储桶根文件夹中的所有文件。",
        "reason": "选项B不符合最小权限原则。虽然它允许读取doc.txt文件，但它还授予了写入权限，并且对根文件夹中的所有文件都生效，这是不必要的过度权限。"
      },
      "C": {
        "option": "允许读取和删除位于名为DOC-EXAMPLE-BUCKET的Amazon S3存储桶中的所有文件。",
        "reason": "选项C也不符合最小权限原则。它不仅允许读取，还允许删除存储桶中的所有文件，这是不必要的过度权限。"
      },
      "D": {
        "option": "允许读取位于名为DOC-EXAMPLE-BUCKET的Amazon S3存储桶中的所有文件。",
        "reason": "选项D授予了对整个存储桶中所有文件的读取权限，而不仅仅是doc.txt文件。这超出了最小权限原则的要求。"
      }
    }
  },
  {
    "number": "140",
    "best": ["D"],
    "question": "一家公司有一个应用程序，使用 AWS CodePipeline 自动化其持续集成和持续交付 (CI/CD) 工作流。该应用程序使用 AWS CodeCommit 进行版本控制。一名开发人员在处理某个任务时没有从主分支拉取最新的更改。一周后，开发人员注意到了合并冲突。开发人员如何以最少的开发工作量解决开发人员分支中的合并冲突？",
    "options": {
      "A": {
        "option": "克隆存储库。创建一个新分支。用更改更新该分支。",
        "reason": "此选项会增加额外的步骤和复杂性，需要手动将更改应用到新分支中。这不是解决合并冲突的最佳方法。"
      },
      "B": {
        "option": "创建一个新分支。从以前的分支应用更改。",
        "reason": "此选项同样会增加不必要的步骤和工作量，并不能直接解决合并冲突的问题。"
      },
      "C": {
        "option": "使用 Commit Visualizer 视图来比较添加功能时的提交。修复合并冲突。",
        "reason": "虽然 Commit Visualizer 可以帮助查看提交历史，但它并不能直接解决合并冲突，仍然需要手动解决冲突。"
      },
      "D": {
        "option": "停止从主分支到功能分支的拉取。将功能分支重新基于主分支。",
        "reason": "重新基于主分支（rebase）是解决这种合并冲突的最佳方法，因为它可以将功能分支上的更改应用到最新的主分支上，从而最小化手动解决冲突的工作量。"
      }
    }
  },
  {
    "number": "141",
    "best": ["D"],
    "question": "一名开发人员希望在生产环境的 Amazon API Gateway API 中添加请求验证。开发人员需要在 API 部署到生产环境之前测试这些更改。为了进行测试，开发人员将通过测试工具向 API 发送测试请求。哪种解决方案能够以最少的操作开销满足这些要求？",
    "options": {
      "A": {
        "option": "导出现有 API 到一个 OpenAPI 文件。创建一个新的 API。导入 OpenAPI 文件。修改新的 API 以添加请求验证。进行测试。修改现有 API 以添加请求验证。将现有 API 部署到生产环境。",
        "reason": "这种方法涉及导出和导入 OpenAPI 文件，然后再进行修改和测试，操作步骤较多，开销较大。"
      },
      "B": {
        "option": "修改现有 API 以添加请求验证。将更新的 API 部署到一个新的 API Gateway 阶段。进行测试。将更新的 API 部署到 API Gateway 生产阶段。",
        "reason": "这种方法直接修改现有 API，并在新的阶段进行测试，虽然步骤较少，但直接修改现有 API 可能会影响生产环境的稳定性。"
      },
      "C": {
        "option": "创建一个新的 API。添加必要的资源和方法，包括新的请求验证。进行测试。修改现有 API 以添加请求验证。将现有 API 部署到生产环境。",
        "reason": "这种方法从头创建一个新的 API 并进行验证测试，步骤较多，且开发人员需要重复添加资源和方法，操作开销大。"
      },
      "D": {
        "option": "克隆现有 API。修改新的 API 以添加请求验证。进行测试。修改现有 API 以添加请求验证。将现有 API 部署到生产环境。",
        "reason": "这种方法通过克隆现有 API 并在克隆的 API 上进行修改和测试，避免了直接修改生产环境中的 API，操作步骤少且安全性高，是最优选择。"
      }
    }
  },
  {
    "number": "142",
    "best": ["C"],
    "question": "一家在线食品公司提供了一个 Amazon API Gateway HTTP API 来接收合作伙伴的订单。该 API 集成了一个 AWS Lambda 函数。Lambda 函数将订单存储在 Amazon DynamoDB 表中。公司预计将引入更多合作伙伴，其中一些合作伙伴需要额外的 Lambda 函数来接收订单。公司已经创建了一个 Amazon S3 存储桶，需要将所有订单和更新存储在 S3 存储桶中以便将来分析。开发人员如何确保所有订单和更新都存储到 Amazon S3 中，且开发工作量最小？",
    "options": {
      "A": {
        "option": "创建一个新的 Lambda 函数和一个新的 API Gateway API 端点。配置新的 Lambda 函数写入 S3 存储桶。修改原始的 Lambda 函数以将更新发布到新的 API 端点。",
        "reason": "这种方法需要创建新的 API 端点和修改现有的 Lambda 函数，增加了额外的开发和维护工作，不符合最小开发工作量的要求。"
      },
      "B": {
        "option": "使用 Amazon Kinesis Data Streams 创建一个新的数据流。修改 Lambda 函数将订单发布到数据流。配置数据流写入 S3 存储桶。",
        "reason": "虽然 Kinesis Data Streams 可以实现这个功能，但需要额外配置数据流和修改 Lambda 函数发布到数据流，增加了复杂性和开发量。"
      },
      "C": {
        "option": "在 DynamoDB 表上启用 DynamoDB Streams。创建一个新的 Lambda 函数。将流的 Amazon 资源名称 (ARN) 与 Lambda 函数关联。配置 Lambda 函数在表的流中出现记录时写入 S3 存储桶。",
        "reason": "这种方法利用了 DynamoDB Streams 的内置功能，只需配置一个新的 Lambda 函数来处理流中的记录并写入 S3 存储桶，最小化了开发工作量，是最优解。"
      },
      "D": {
        "option": "在接收订单时修改 Lambda 函数发布到一个新的 Amazon Simple Notification Service (Amazon SNS) 主题。订阅一个新的 Lambda 函数到该主题。配置新的 Lambda 函数在更新通过主题时写入 S3 存储桶。",
        "reason": "这种方法需要额外配置 SNS 主题和修改现有的 Lambda 函数，增加了开发和维护工作，不符合最小开发工作量的要求。"
      }
    }
  },
  {
    "number": "143",
    "best": ["D", "E"],
    "question": "某公司的网站运行在 Amazon EC2 实例上，并使用 Auto Scaling 在高峰期扩展环境。即使在非高峰时段，全球的用户也在访问网站时遇到由于静态内容导致的高延迟。哪种组合步骤可以解决延迟问题？（选择两项。）",
    "options": {
      "A": {
        "option": "将 Auto Scaling 组的最大服务器数量加倍。",
        "reason": "增加 Auto Scaling 组的服务器数量只能在高峰期帮助处理更多的请求，但无法解决静态内容导致的高延迟问题。"
      },
      "B": {
        "option": "将应用代码托管在 AWS Lambda 上。",
        "reason": "将应用代码托管在 AWS Lambda 上可以提高某些动态内容的性能，但对于静态内容的高延迟问题没有直接帮助。"
      },
      "C": {
        "option": "通过调整 EC2 实例的大小进行垂直扩展。",
        "reason": "垂直扩展可以提高单个实例的性能，但无法解决由于静态内容导致的全球用户的高延迟问题。"
      },
      "D": {
        "option": "创建一个 Amazon CloudFront 分发，以缓存静态内容。",
        "reason": "使用 Amazon CloudFront 可以将静态内容缓存到全球的边缘位置，从而大大减少用户请求的延迟。这是解决静态内容高延迟问题的最佳方法之一。"
      },
      "E": {
        "option": "将应用的静态内容存储在 Amazon S3 中。",
        "reason": "将静态内容存储在 Amazon S3 中可以提高其可访问性和可扩展性，结合 Amazon CloudFront 使用效果更佳。这也是解决静态内容高延迟问题的有效方法。"
      }
    }
  },
  {
    "number": "144",
    "best": ["B"],
    "question": "一家公司有一个包含高级内容的 Amazon S3 存储桶，它打算只向其网站的付费订阅者提供这些内容。S3 存储桶当前的默认权限是所有对象均为私有，以防止高级内容无意中暴露给非付费网站访问者。公司如何限制只有付费订阅者才能下载 S3 存储桶中的高级内容文件？",
    "options": {
      "A": {
        "option": "应用一个允许匿名用户从 S3 存储桶下载内容的存储桶策略。",
        "reason": "这将使存储桶中的内容公开，任何人都可以下载。这与仅限付费订阅者访问的要求不符。"
      },
      "B": {
        "option": "当付费订阅者请求下载高级内容文件时，生成一个预签名的对象 URL。",
        "reason": "预签名的 URL 允许公司为特定用户生成临时访问权，这样只有付费订阅者才能下载内容。这符合限制下载权限的要求。"
      },
      "C": {
        "option": "添加一个存储桶策略，要求访问 S3 存储桶对象的请求进行多因素认证。",
        "reason": "虽然多因素认证可以增加安全性，但它不能单独识别付费订阅者。此方法不适用于明确区分付费和非付费用户。"
      },
      "D": {
        "option": "启用 S3 存储桶的服务器端加密，以防止非付费网站访问者获取数据。",
        "reason": "加密可以保护数据的传输和存储，但它不能控制谁可以访问和下载文件，无法实现只有付费订阅者才能下载的要求。"
      }
    }
  },
  {
    "number": "145",
    "best": ["A"],
    "question": "开发人员正在创建一个 AWS Lambda 函数，该函数从包含客户联系信息的 Amazon DynamoDB 表中搜索条目。该 DynamoDB 表项的分区键是客户的 email_address，另外还有 customer_type、name 和 job_title 等属性。每当用户在 customer_type 文本输入中输入新字符时，Lambda 函数就会运行。开发人员希望搜索返回特定 customer_type 的所有 email_address 属性的部分匹配项。开发人员不想重新创建 DynamoDB 表。开发人员应该怎么做以满足这些要求？",
    "options": {
      "A": {
        "option": "向 DynamoDB 表添加一个全局二级索引（GSI），以 customer_type 作为分区键，email_address 作为排序键。使用 begins_with 键条件表达式对 GSI 执行查询操作，使用 email_address 属性。",
        "reason": "选项 A 满足了题目中的需求。全局二级索引（GSI）允许我们在不同的属性上进行查询，在这种情况下，我们可以用 customer_type 作为分区键，email_address 作为排序键，来实现对 email_address 的部分匹配查询。begins_with 表达式可以用于实现部分匹配查询。"
      },
      "B": {
        "option": "向 DynamoDB 表添加一个全局二级索引（GSI），以 email_address 作为分区键，customer_type 作为排序键。使用 begins_with 键条件表达式对 GSI 执行查询操作，使用 email_address 属性。",
        "reason": "选项 B 不符合要求，因为我们需要根据 customer_type 分区键进行查询。以 email_address 作为分区键无法实现基于 customer_type 的查询。"
      },
      "C": {
        "option": "向 DynamoDB 表添加一个本地二级索引（LSI），以 customer_type 作为分区键，email_address 作为排序键。使用 begins_with 键条件表达式对 LSI 执行查询操作，使用 email_address 属性。",
        "reason": "选项 C 不符合要求，因为本地二级索引（LSI）只能在创建表时定义，而题目中明确指出不重新创建表。因此，LSI 不是合适的选择。"
      },
      "D": {
        "option": "向 DynamoDB 表添加一个本地二级索引（LSI），以 job_title 作为分区键，email_address 作为排序键。使用 begins_with 键条件表达式对 LSI 执行查询操作，使用 email_address 属性。",
        "reason": "选项 D 同样不符合要求，因为同样涉及 LSI，需要在创建表时定义。此外，job_title 作为分区键也不符合题目中基于 customer_type 进行查询的需求。"
      }
    }
  },
  {
    "number": "146",
    "best": ["D"],
    "question": "开发人员正在构建一个使用 AWS API Gateway API、AWS Lambda 函数和 AWS DynamoDB 表的应用程序。开发人员使用 AWS 无服务器应用程序模型 (AWS SAM) 在 AWS 上构建和运行无服务器应用程序。每次开发人员仅推送 Lambda 函数的更改时，应用程序中的所有工件都会被重新构建。开发人员希望通过运行一个命令来实现 AWS SAM Accelerate，只重新部署已更改的 Lambda 函数。哪个命令可以满足这些要求？",
    "options": {
      "A": {
        "option": "sam deploy --force-upload",
        "reason": "该命令会强制上传所有工件，而不仅仅是更改的 Lambda 函数。这与问题要求不符，因为问题要求是仅重新部署已更改的 Lambda 函数。"
      },
      "B": {
        "option": "sam deploy --no-execute-changeset",
        "reason": "该命令会生成更改集但不执行它，这并不能满足仅重新部署已更改的 Lambda 函数的需求。"
      },
      "C": {
        "option": "sam package",
        "reason": "该命令会打包应用程序的工件，但不会部署更改。因此，这并不能满足问题中所要求的重新部署已更改的 Lambda 函数的需求。"
      },
      "D": {
        "option": "sam sync --watch",
        "reason": "该命令会监视项目中的更改，并在检测到更改时同步这些更改。这个命令非常适合实现 AWS SAM Accelerate 下的快速迭代和部署，满足问题中仅重新部署已更改的 Lambda 函数的要求。"
      }
    }
  },
  {
    "number": "147",
    "best": ["A"],
    "question": "开发者正在构建一个应用程序，允许用户在一个仪表板中查看来自多个来源的银行账户。开发者已经自动化了检索这些来源的 API 凭证的过程。该过程调用了一个与 AWS CloudFormation 自定义资源关联的 AWS Lambda 函数。开发者希望找到一个解决方案，以最小的运维开销存储 API 凭证。哪种解决方案可以以最安全的方式满足这些需求？",
    "options": {
      "A": {
        "option": "在 CloudFormation 模板中添加一个 AWS Secrets Manager GenerateSecretString 资源。将值设置为引用 CloudFormation 资源的新凭证。",
        "reason": "AWS Secrets Manager 专门用于管理和自动轮换密钥和凭证，提供了高安全性和低运维开销的解决方案。使用 Secrets Manager 可以确保凭证的安全存储和管理，从而符合题目中“最安全方式”的要求。"
      },
      "B": {
        "option": "在现有自定义资源的 Lambda 函数中使用 AWS SDK 的 ssm:PutParameter 操作将凭证存储为参数。将参数值设置为引用新凭证。将参数类型设置为 SecureString。",
        "reason": "虽然 AWS Systems Manager Parameter Store 的 SecureString 类型可以加密存储数据，但它主要用于简单的参数存储和配置管理，而不是专门用于敏感信息的管理和轮换。因此在安全性和专门性上不如 Secrets Manager。"
      },
      "C": {
        "option": "在 CloudFormation 模板中添加一个 AWS Systems Manager Parameter Store 资源。将 CloudFormation 资源值设置为引用新凭证。将资源的 NoEcho 属性设置为 true。",
        "reason": "虽然设置 NoEcho 属性可以防止输出日志中显示敏感信息，但 Parameter Store 主要用于配置管理而不是专门管理敏感信息。相比之下，Secrets Manager 提供了更强的安全性和自动轮换功能。"
      },
      "D": {
        "option": "在现有自定义资源的 Lambda 函数中使用 AWS SDK 的 ssm:PutParameter 操作将凭证存储为参数。将参数值设置为引用新凭证。将参数的 NoEcho 属性设置为 true。",
        "reason": "与选项 C 类似，虽然 NoEcho 属性可以防止输出日志中显示敏感信息，但 Parameter Store 主要用于配置管理而不是专门管理敏感信息。相比之下，Secrets Manager 提供了更强的安全性和自动轮换功能。"
      }
    }
  },
  {
    "number": "148",
    "best": ["D"],
    "question": "开发人员尝试从一个名为 demoman-table 的 Amazon DynamoDB 表中获取数据。开发人员配置了 AWS CLI 以使用特定 IAM 用户的凭证，并运行以下命令：aws dynamodb get-item --table-name demoman-table --key '{\"id\": {\"N\":\"1993\"}}'。命令返回错误，没有返回任何行。最可能导致这些问题的原因是什么？",
    "options": {
      "A": {
        "option": "命令不正确；它应该重写为使用字符串参数的 put-item。",
        "reason": "该选项错误。put-item 用于插入数据，而不是获取数据。get-item 是获取数据的正确命令。"
      },
      "B": {
        "option": "开发人员需要提交 AWS 支持工单以启用对 demoman-table 的访问。",
        "reason": "不需要提交支持工单。通常，权限问题可以通过 IAM 策略来解决，而不是需要 AWS 支持的干预。"
      },
      "C": {
        "option": "Amazon DynamoDB 不能通过 AWS CLI 访问，需要通过 REST API 调用。",
        "reason": "该选项错误。Amazon DynamoDB 可以通过 AWS CLI 访问。"
      },
      "D": {
        "option": "IAM 用户需要一个与 demoman-table 具有读取访问权限的关联策略。",
        "reason": "这是最可能的原因。为了能够访问 DynamoDB 表，IAM 用户需要适当的权限。没有适当的权限，AWS CLI 命令将无法成功执行。"
      }
    }
  },
  {
    "number": "Question #149",
    "best": ["B", "D"],
    "question": "某组织正在使用 Amazon CloudFront 确保其用户能够低延迟地访问其 Web 应用程序。该组织已经确定需要加密用户与 CloudFront 之间的所有流量，以及 CloudFront 与 Web 应用程序之间的所有流量。如何满足这些要求？（选择两个。）",
    "options": {
      "A": {
        "option": "使用 AWS KMS 加密 CloudFront 与 Web 应用程序之间的流量。",
        "reason": "AWS KMS（Key Management Service）用于管理加密密钥，不直接用于加密流量。此选项不符合要求。"
      },
      "B": {
        "option": "将源协议策略设置为“仅 HTTPS”。",
        "reason": "将源协议策略设置为“仅 HTTPS”确保了 CloudFront 与 Web 应用程序之间的流量是加密的，这符合要求。"
      },
      "C": {
        "option": "将源的 HTTP 端口设置为 443。",
        "reason": "设置 HTTP 端口为 443 并不会自动加密流量，只是指定了一个常用于 HTTPS 的端口。此选项不完全符合要求。"
      },
      "D": {
        "option": "将查看器协议策略设置为“仅 HTTPS”或“重定向 HTTP 到 HTTPS”。",
        "reason": "将查看器协议策略设置为“仅 HTTPS”或“重定向 HTTP 到 HTTPS”确保了用户与 CloudFront 之间的流量是加密的，这符合要求。"
      },
      "E": {
        "option": "启用 CloudFront 选项限制查看器访问。",
        "reason": "限制查看器访问选项是用来控制谁可以访问内容，并不涉及流量加密问题。此选项与题目要求不符。"
      }
    }
  },
  {
    "number": "150",
    "best": ["B"],
    "question": "一名开发人员计划将公司内部数据迁移到 Amazon S3。数据必须加密，并且加密密钥必须支持自动年度轮换。公司必须使用 AWS Key Management Service (AWS KMS) 来加密数据。开发人员应该使用哪种类型的密钥来满足这些要求？",
    "options": {
      "A": {
        "option": "Amazon S3 管理的密钥",
        "reason": "Amazon S3 管理的密钥（SSE-S3）由 Amazon S3 管理，不支持使用 AWS KMS 进行密钥管理和自动年度轮换，因此不符合题目要求。"
      },
      "B": {
        "option": "由 AWS 生成密钥材料的对称客户管理密钥",
        "reason": "由 AWS 生成密钥材料的对称客户管理密钥（CMK）是使用 AWS KMS 创建的，支持自动年度轮换，并且可以用于加密 Amazon S3 中的数据，符合题目要求。"
      },
      "C": {
        "option": "由 AWS 生成密钥材料的非对称客户管理密钥",
        "reason": "非对称客户管理密钥不支持自动轮换，并且通常用于数字签名和验证，而不是数据加密，因此不符合题目要求。"
      },
      "D": {
        "option": "导入密钥材料的对称客户管理密钥",
        "reason": "导入密钥材料的对称客户管理密钥不支持自动轮换，因此不符合题目要求。"
      }
    }
  },
  {
    "number": "151",
    "best": ["C"],
    "question": "一个开发团队正在使用 AWS CodePipeline 管道作为 Web 应用程序的持续集成和持续交付 (CI/CD) 机制。一名开发人员编写了单元测试以编程方式测试应用程序代码的功能。单元测试生成一个测试报告，显示每个单独检查的结果。开发人员现在希望在 CI/CD 过程中自动运行这些测试。哪种解决方案将在最少的操作努力下满足此要求？",
    "options": {
      "A": {
        "option": "编写一个 Git pre-commit 钩子，在每次提交之前运行测试。确保所有参与项目的开发人员在本地安装了 pre-commit 钩子。在推送更改到 AWS CodeCommit 之前，检查测试报告并解决任何问题。",
        "reason": "虽然 pre-commit 钩子可以确保在提交之前进行测试，但它需要每个开发人员在本地环境中进行配置和维护，不符合最少操作努力的要求。"
      },
      "B": {
        "option": "向管道添加一个新阶段。使用 AWS CodeBuild 作为提供者。在将代码修订部署到测试环境的阶段之后添加新阶段。编写一个 buildspec，如果任何测试未通过，则使 CodeBuild 阶段失败。使用 CodeBuild 的测试报告功能将报告集成到 CodeBuild 控制台中。在 CodeBuild 中查看测试结果。解决任何问题。",
        "reason": "虽然这个选项使用了自动化工具，但它在测试环境部署之后才运行测试，这意味着如果测试失败，已经部署的代码可能会影响测试环境。这不符合最佳实践。"
      },
      "C": {
        "option": "向管道添加一个新阶段。使用 AWS CodeBuild 作为提供者。在将代码修订部署到测试环境的阶段之前添加新阶段。编写一个 buildspec，如果任何测试未通过，则使 CodeBuild 阶段失败。使用 CodeBuild 的测试报告功能将报告集成到 CodeBuild 控制台中。在 CodeBuild 中查看测试结果。解决任何问题。",
        "reason": "这个选项在代码部署到测试环境之前运行测试，确保只有通过所有测试的代码才会被部署。这是符合 CI/CD 最佳实践的，并且使用 AWS 的原生服务，符合最少操作努力的要求。"
      },
      "D": {
        "option": "向管道添加一个新阶段。使用 Jenkins 作为提供者。配置 CodePipeline 使用 Jenkins 运行单元测试。编写一个 Jenkinsfile，如果任何测试未通过，则使阶段失败。使用 Jenkins 的测试报告插件将报告集成到 Jenkins 控制台中。在 Jenkins 中查看测试结果。解决任何问题。",
        "reason": "虽然 Jenkins 是一个功能强大的 CI/CD 工具，但它需要额外的配置和维护，与 AWS CodeBuild 相比增加了操作复杂性。因此不是最少操作努力的最佳选择。"
      }
    }
  },
  {
    "number": "152",
    "best": ["A"],
    "question": "某公司在同一个VPC中有多个Amazon VPC端点。开发人员需要配置一个Amazon S3存储桶策略，以便用户只能通过这些VPC端点访问S3存储桶。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "使用每个VPC端点ID创建多个S3存储桶策略，在StringNotEquals条件中使用aws:SourceVpce值。",
        "reason": "选项A通过为每个VPC端点ID创建多个S3存储桶策略，确保只有通过这些特定的VPC端点才能访问存储桶。这符合题目的要求。"
      },
      "B": {
        "option": "创建一个单一的S3存储桶策略，在StringNotEquals条件中使用aws:SourceVpc值和VPC ID。",
        "reason": "选项B使用了aws:SourceVpc，但题目要求的是限制通过特定的VPC端点访问。因此，这个选项不符合要求。"
      },
      "C": {
        "option": "创建一个单一的S3存储桶策略，在StringNotEquals条件中使用aws:SourceVpce值和vpce*。",
        "reason": "选项C使用了通配符vpce*，这将允许所有VPC端点访问，而不是仅限于特定的VPC端点。这不符合题目的要求。"
      },
      "D": {
        "option": "创建一个单一的S3存储桶策略，在StringNotEquals条件中使用多个aws:sourceVpce值。为所有VPC端点ID重复此操作。",
        "reason": "选项D看似合理，但实际上会导致策略变得复杂且难以维护。选项A的解决方案更加简洁和直接。"
      }
    }
  },
  {
    "number": "153",
    "best": ["B", "E"],
    "question": "一家公司使用自定义的根证书颁发机构证书链（Root CA Cert），大小为10 KB，用于生成其本地 HTTPS 端点的 SSL 证书。公司的一个基于云的应用程序有数百个 AWS Lambda 函数从这些端点提取数据。一位开发人员在 Lambda 执行环境初始化时更新了信任存储，以使用 Root CA Cert。开发人员将 Root CA Cert 作为文本文件打包在 Lambda 部署包中。经过3个月的开发，Root CA Cert 不再有效，必须更新。开发人员需要一种更有效的解决方案来更新所有已部署的 Lambda 函数的 Root CA Cert。该解决方案不得包括重新构建或更新所有使用 Root CA Cert 的 Lambda 函数。该解决方案还必须适用于所有开发、测试和生产环境。每个环境都在一个单独的 AWS 账户中管理。开发人员应采取哪些步骤来最具成本效益地满足这些要求？（选择两项）",
    "options": {
      "A": {
        "option": "将 Root CA Cert 作为秘密存储在 AWS Secrets Manager 中。创建一个基于资源的策略。添加 IAM 用户以允许访问该秘密。",
        "reason": "AWS Secrets Manager 适用于存储和轮换敏感信息，但它的成本较高，而且不需要每个 Lambda 函数单独配置访问权限。"
      },
      "B": {
        "option": "将 Root CA Cert 作为 SecureString 参数存储在 AWS Systems Manager Parameter Store 中。创建一个基于资源的策略。添加 IAM 用户以允许访问该策略。",
        "reason": "AWS Systems Manager Parameter Store 是一个更具成本效益的解决方案，尤其适用于需要跨多个账户和环境共享配置的情况。"
      },
      "C": {
        "option": "将 Root CA Cert 存储在一个 Amazon S3 存储桶中。创建一个基于资源的策略以允许访问该存储桶。",
        "reason": "虽然 Amazon S3 可以存储证书，但它不是最佳实践，不适合用于管理和引导信任存储。此外，需要额外的安全配置来保护存储桶中的敏感数据。"
      },
      "D": {
        "option": "重构 Lambda 代码以从 Root CA Cert 的位置加载 Root CA Cert。在 Lambda 函数处理程序内修改运行时信任存储。",
        "reason": "在处理程序内部修改运行时信任存储可能会增加每个函数的初始化时间，不是最佳实践。"
      },
      "E": {
        "option": "重构 Lambda 代码以从 Root CA Cert 的位置加载 Root CA Cert。在 Lambda 函数处理程序外部修改运行时信任存储。",
        "reason": "在处理程序外部修改运行时信任存储可以减少初始化时间，提高性能。这种方法与 B 选项结合使用，可以动态获取和更新证书。"
      }
    }
  },
  {
    "number": "154",
    "best": ["A"],
    "question": "一位开发人员维护存储在 AWS Secrets Manager 中的多个秘密。应用程序使用的秘密已随时间变化。开发人员需要识别仍在使用的必要秘密。开发人员不希望导致任何应用程序停机。开发人员应该怎么做来满足这些要求？",
    "options": {
      "A": {
        "option": "配置一个 AWS CloudTrail 日志文件传输到 Amazon S3 存储桶。为 GetSecretValue Secrets Manager API 操作请求创建一个 Amazon CloudWatch 警报。",
        "reason": "通过配置 AWS CloudTrail 日志文件传输到 S3 并为 GetSecretValue API 操作请求创建 CloudWatch 警报，可以监控哪些秘密仍在被使用，而不会导致应用程序停机。CloudTrail 可以记录所有 API 调用，并将其发送到 S3，便于分析和监控。CloudWatch 警报可以在检测到特定操作时发送通知。"
      },
      "B": {
        "option": "创建一个 secretsmanager-secret-unused AWS Config 管理规则。创建一个 Amazon EventBridge 规则，在满足 AWS Config 管理规则时启动通知。",
        "reason": "这个选项虽然也可以帮助识别未使用的秘密，但它并不适合用于实时监控，并且可能导致一些延迟。此外，AWS Config 和 EventBridge 的规则设置复杂度较高，可能不适合不希望导致任何应用程序停机的情况。"
      },
      "C": {
        "option": "暂时停用应用程序的秘密并监控应用程序错误日志。",
        "reason": "这个选项会导致应用程序停机或产生错误，不符合开发人员不希望导致任何应用程序停机的要求。"
      },
      "D": {
        "option": "为应用程序配置 AWS X-Ray。创建一个采样规则以匹配 GetSecretValue Secrets Manager API 操作请求。",
        "reason": "AWS X-Ray 主要用于跟踪和分析应用程序的运行情况，并不专门针对 Secrets Manager 的使用情况进行监控。虽然可以通过采样规则匹配 API 请求，但这不是最直接和有效的方法来满足题目要求。"
      }
    }
  },
  {
    "number": "155",
    "best": ["C"],
    "question": "开发人员正在编写一个无服务器应用程序，该应用程序需要每10分钟调用一次 AWS Lambda 函数。哪种方法是自动化且无服务器的方式来调用该函数？",
    "options": {
      "A": {
        "option": "部署一个基于 Linux 的 Amazon EC2 实例，并通过编辑 /etc/crontab 文件添加一个命令来定期调用 Lambda 函数。",
        "reason": "此方法需要维护一个 EC2 实例，并且不符合无服务器的要求。尽管可以通过 cron 作业来调度任务，但这不是一种自动化且无服务器的方式。"
      },
      "B": {
        "option": "为 Lambda 函数配置一个名为 PERIOD 的环境变量。将其值设置为600。",
        "reason": "环境变量仅用于在函数运行时提供配置数据，而不能用于调度 Lambda 函数。"
      },
      "C": {
        "option": "创建一个 Amazon EventBridge 规则，以定期调度来调用 Lambda 函数。",
        "reason": "Amazon EventBridge（以前称为 CloudWatch Events）能够以无服务器的方式定期调度和调用 Lambda 函数。这是最符合要求的解决方案。"
      },
      "D": {
        "option": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题，并设置一个订阅到 Lambda 函数的600秒计时器。",
        "reason": "SNS 通常用于消息传递和通知，而不是定期调度任务。虽然可以设置一个计时器，但这不是一种标准的调度 Lambda 函数的方法。"
      }
    }
  },
  {
    "number": "156",
    "best": ["D"],
    "question": "公司正在使用 Amazon OpenSearch Service 实现审计监控系统。开发人员需要创建一个 AWS CloudFormation 自定义资源，并与一个 AWS Lambda 函数相关联，以配置 OpenSearch Service 域。Lambda 函数必须使用 OpenSearch Service 内部主用户凭证访问该域。将这些凭证传递给 Lambda 函数的最安全方式是什么？",
    "options": {
      "A": {
        "option": "使用 CloudFormation 参数在部署时将主用户凭证传递到 OpenSearch Service 域的 MasterUserOptions 和 Lambda 函数的环境变量中。将 NoEcho 属性设置为 true。",
        "reason": "虽然 NoEcho 属性可以防止参数值在 CloudFormation 输出中显示，但将凭证直接传递给环境变量存在安全隐患，因为环境变量是明文存储的，容易被泄露。"
      },
      "B": {
        "option": "使用 CloudFormation 参数在部署时将主用户凭证传递到 OpenSearch Service 域的 MasterUserOptions 并创建一个 AWS Systems Manager Parameter Store 的参数。将 NoEcho 属性设置为 true。创建一个具有 ssm:GetParameter 权限的 IAM 角色。将该角色分配给 Lambda 函数。将参数名称存储为 Lambda 函数的环境变量。在运行时解析参数的值。",
        "reason": "虽然这比直接在环境变量中存储凭证更安全，但 AWS Systems Manager Parameter Store 并不是专门为存储敏感信息设计的。Secrets Manager 提供了更多的安全功能，如自动轮换和细粒度访问控制。"
      },
      "C": {
        "option": "使用 CloudFormation 参数在部署时将主用户凭证传递到 OpenSearch Service 域的 MasterUserOptions 和 Lambda 函数的环境变量中。使用 AWS Key Management Service (AWS KMS) 加密命令加密参数的值。",
        "reason": "尽管 KMS 提供加密功能，但将加密后的值存储在环境变量中仍然不够安全，因为环境变量本身仍然可以被访问。而且，管理加密和解密逻辑增加了复杂性。"
      },
      "D": {
        "option": "使用 CloudFormation 创建一个 AWS Secrets Manager 密钥。使用 CloudFormation 动态引用来检索密钥的值用于 OpenSearch Service 域的 MasterUserOptions。创建一个具有 secretsmanager:GetSecretValue 权限的 IAM 角色。将该角色分配给 Lambda 函数。将密钥名称存储为 Lambda 函数的环境变量。在运行时解析密钥的值。",
        "reason": "AWS Secrets Manager 专门用于安全存储和管理敏感信息，如数据库凭证和 API 密钥。它提供自动轮换和细粒度访问控制功能，是最安全的选择。"
      }
    }
  },
  {
    "number": "157",
    "best": ["A"],
    "question": "应用程序运行在多个 EC2 实例上，位于 ELB 后面。为了能够可靠地跨多个请求提供会话数据，最好的写入位置在哪里？",
    "options": {
      "A": {
        "option": "将数据写入 Amazon ElastiCache。",
        "reason": "Amazon ElastiCache 是一种内存中的数据存储服务，适用于需要快速访问和低延迟的数据，如会话数据。这使得它非常适合在多个 EC2 实例之间共享会话数据。通过使用 ElastiCache，应用程序可以确保会话数据的高可用性和一致性。"
      },
      "B": {
        "option": "将数据写入 Amazon Elastic Block Store。",
        "reason": "Amazon Elastic Block Store (EBS) 提供持久性块存储，但它并不适合用于会话数据的共享和管理。每个 EBS 卷只能连接到一个 EC2 实例，因此不能在多个实例之间共享数据。"
      },
      "C": {
        "option": "将数据写入 Amazon EC2 实例存储。",
        "reason": "Amazon EC2 实例存储是临时存储，仅在 EC2 实例的生命周期内有效。实例存储的数据在实例停止或终止时会丢失，并且不能在多个实例之间共享，因此不适合存储会话数据。"
      },
      "D": {
        "option": "将数据写入根文件系统。",
        "reason": "将数据写入根文件系统类似于写入实例存储，这会导致数据在实例停止或终止时丢失，并且不能在多个实例之间共享。因此，不适合用于存储会话数据。"
      }
    }
  },
  {
    "number": "158",
    "best": ["C"],
    "question": "一个电子商务应用程序运行在一个应用程序负载均衡器后面。一名开发人员在非高峰时段观察到应用程序上有一些意外的负载。开发人员希望分析使用该应用程序的客户端IP地址的模式。他应该使用哪个HTTP头来进行此分析？",
    "options": {
      "A": {
        "option": "X-Forwarded-Proto 头",
        "reason": "X-Forwarded-Proto 头用于指示原始请求使用的协议（HTTP 或 HTTPS），与分析客户端IP地址无关。"
      },
      "B": {
        "option": "X-Forwarded-Host 头",
        "reason": "X-Forwarded-Host 头用于指示原始请求的主机，通常用于多域名托管环境中，与分析客户端IP地址无关。"
      },
      "C": {
        "option": "X-Forwarded-For 头",
        "reason": "X-Forwarded-For 头用于标识客户端的IP地址，代理服务器或负载均衡器会将客户端的原始IP地址添加到此头中。这是用于分析客户端IP地址模式的正确HTTP头。"
      },
      "D": {
        "option": "X-Forwarded-Port 头",
        "reason": "X-Forwarded-Port 头用于指示原始请求的端口，与分析客户端IP地址无关。"
      }
    }
  },
  {
    "number": "159",
    "best": ["B"],
    "question": "开发人员将一个遗留应用程序迁移到 AWS Lambda 函数。该函数使用第三方服务在每月末通过一系列 API 调用获取数据。然后该函数处理数据以生成每月报告。到目前为止，该函数一直工作正常。第三方服务最近发出了限制，允许每分钟和每天固定数量的 API 调用。如果 API 调用超过每分钟或每天的限制，那么服务将产生错误。API 还在响应头中提供每分钟和每天的限制。由于该过程消耗的 API 调用超过了可用限制，这种限制可能会将整个过程延长到多天。为了适应这一变化，最具操作效率的方式是什么？",
    "options": {
      "A": {
        "option": "使用 AWS Step Functions 状态机监控 API 失败。使用 Wait 状态延迟调用 Lambda 函数。",
        "reason": "虽然 Step Functions 提供了良好的控制流程管理和错误处理功能，但它并不是处理这种高频率 API 调用限制的最有效方法。等待状态（Wait state）可能会导致流程变得复杂且难以管理。"
      },
      "B": {
        "option": "使用 Amazon Simple Queue Service (Amazon SQS) 队列来保存 API 调用。配置 Lambda 函数在 API 阈值限制内轮询队列。",
        "reason": "使用 Amazon SQS 队列可以有效地管理 API 调用的频率。通过配置 Lambda 函数在 API 阈值限制内轮询队列，可以确保不会超过第三方服务的 API 调用限制。这是最优的解决方案，因为它简单、高效且易于维护。"
      },
      "C": {
        "option": "使用 Amazon CloudWatch Logs 计数 API 调用次数。配置一个 Amazon CloudWatch 告警，当指标超过 API 阈值限制时停止当前正在运行的 Lambda 函数实例。",
        "reason": "虽然 CloudWatch 可以监控 API 调用次数并触发告警，但停止正在运行的 Lambda 函数并不是最佳实践，因为这可能导致部分调用失败，并且需要额外的逻辑来重新启动函数。这种方法并不高效且可能导致更多的复杂性。"
      },
      "D": {
        "option": "使用 Amazon Kinesis Data Firehose 批量处理 API 调用，并将它们传递到一个带有事件通知的 Amazon S3 存储桶以调用 Lambda 函数。",
        "reason": "虽然 Kinesis Data Firehose 可以用于批量处理数据，但它并不是解决 API 调用频率限制的最佳工具。Firehose 主要用于流数据传输，而不是管理 API 调用次数。在这种情况下，使用 SQS 队列更为适合。"
      }
    }
  },
  {
    "number": "160",
    "best": ["C"],
    "question": "开发人员必须分析以 AWS Lambda 函数编写的生产分布式应用程序的性能问题。这些分布式 Lambda 应用程序调用构成应用程序的其他组件。开发人员应如何识别和解决生产中的性能问题根本原因？",
    "options": {
      "A": {
        "option": "向 Lambda 函数添加日志语句，然后使用 Amazon CloudWatch 查看日志。",
        "reason": "虽然 CloudWatch 日志可以帮助记录和查看 Lambda 函数的日志，但它们主要用于调试和记录，而不是专门用于性能分析和跟踪分布式系统的调用链。"
      },
      "B": {
        "option": "使用 AWS CloudTrail 然后检查日志。",
        "reason": "CloudTrail 主要用于记录 AWS API 调用，追踪用户和角色在 AWS 服务中的活动。它不适合用于详细的性能分析或分布式应用的调用链跟踪。"
      },
      "C": {
        "option": "使用 AWS X-Ray，然后检查段和错误。",
        "reason": "AWS X-Ray 专门设计用于分析和调试分布式应用程序。它可以帮助开发人员查看请求在各个服务之间的流动情况，识别性能瓶颈和错误，并深入了解每个组件的执行时间。对于分析和解决分布式系统中的性能问题，X-Ray 是最佳选择。"
      },
      "D": {
        "option": "运行 Amazon Inspector 代理然后分析性能。",
        "reason": "Amazon Inspector 主要用于评估应用程序的安全性和合规性，识别潜在的安全漏洞。它并不是用于性能分析或调试分布式应用程序的工具。"
      }
    }
  },
  {
    "number": "161",
    "best": ["C"],
    "question": "开发人员希望部署一个新的 AWS Elastic Beanstalk 应用版本。在部署期间，应用程序必须保持全容量并避免服务中断。此外，开发人员必须尽量减少支持部署的额外资源成本。开发人员应使用哪种部署方法来满足这些要求？",
    "options": {
      "A": {
        "option": "一次性全部部署",
        "reason": "一次性全部部署（All at once）会在部署新版本时同时替换所有实例。这会导致在部署期间出现服务中断，并不符合保持全容量的要求。"
      },
      "B": {
        "option": "带有额外批次的滚动部署",
        "reason": "带有额外批次的滚动部署（Rolling with additional batch）在部署过程中会添加额外的实例批次，以保持全容量。然而，这会增加资源成本，并不符合尽量减少额外资源成本的要求。"
      },
      "C": {
        "option": "蓝/绿部署",
        "reason": "蓝/绿部署（Blue/green）通过创建一个新环境（绿色）并在其上部署新版本，确保新版本完全就绪后再切换流量。这种方法可以确保应用程序在整个过程中保持全容量和无服务中断。此外，一旦切换完成，可以终止旧环境（蓝色），从而减少资源成本。"
      },
      "D": {
        "option": "不可变部署",
        "reason": "不可变部署（Immutable）在新的实例上部署新版本，然后替换旧实例。虽然这种方法可以避免服务中断，但它会消耗更多的资源，增加成本，因此不符合尽量减少额外资源成本的要求。"
      }
    }
  },
  {
    "number": "162",
    "best": ["C"],
    "question": "一位开发人员观察到其开发团队在 Node.js 应用程序中部署的 AWS Lambda 函数中的错误有所增加。为了尽量减少这些错误，开发人员希望在一个高度模拟 Lambda 环境的环境中实施自动化测试。开发人员需要让其他开发人员能够在本地运行测试，并在 AWS Cloud Development Kit (AWS CDK) 部署之前将测试集成到团队的持续集成和持续交付 (CI/CD) 管道中。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "根据 Lambda 文档创建示例事件。创建使用 cdk local invoke 命令调用 Lambda 函数的自动化测试脚本。检查响应。为团队中的其他开发人员记录测试脚本。更新 CI/CD 管道以运行测试脚本。",
        "reason": "AWS CDK 并非专门用于模拟 Lambda 环境，虽然可以使用 cdk local invoke 命令进行测试，但这并不是最佳实践，尤其是当需要高度模拟环境时。"
      },
      "B": {
        "option": "安装一个可以重现 Lambda 执行环境的单元测试框架。根据 Lambda 文档创建示例事件。使用单元测试框架调用处理程序函数。检查响应。为团队中的其他开发人员记录如何运行单元测试框架。更新 CI/CD 管道以运行单元测试框架。",
        "reason": "单元测试框架虽然可以进行局部测试，但它并不能完全模拟 Lambda 的执行环境。对于需要高度模拟环境的需求，这不是最佳选择。"
      },
      "C": {
        "option": "安装 AWS Serverless Application Model (AWS SAM) CLI 工具。使用 sam local generate-event 命令生成自动化测试所需的示例事件。创建使用 sam local invoke 命令调用 Lambda 函数的自动化测试脚本。检查响应。为团队中的其他开发人员记录测试脚本。更新 CI/CD 管道以运行测试脚本。",
        "reason": "AWS SAM CLI 专门用于模拟 Lambda 环境，提供了生成事件和本地调用函数的工具。它是最接近生产环境的模拟工具，并且可以很容易地集成到 CI/CD 管道中。"
      },
      "D": {
        "option": "根据 Lambda 文档创建示例事件。创建一个从 Node.js 基本映像生成的 Docker 容器来调用 Lambda 函数。检查响应。为团队中的其他开发人员记录如何运行 Docker 容器。更新 CI/CD 管道以运行 Docker 容器。",
        "reason": "虽然 Docker 容器可以模拟 Lambda 环境，但创建和维护 Docker 容器可能比较复杂，并且需要额外的配置和管理。相比之下，AWS SAM CLI 提供了一种更简便和直接的方式。"
      }
    }
  },
  {
    "number": "163",
    "best": ["A"],
    "question": "开发人员正在对一个使用Amazon DynamoDB的应用程序进行故障排除，该应用程序部署在us-west-2区域的Amazon EC2实例上。该应用程序需要对名为Cars的表进行只读权限。EC2实例有一个附加的IAM角色，其中包含以下IAM策略：当应用程序尝试从Cars表中读取数据时，出现了访问被拒绝的错误。开发人员如何解决这个错误？",
    "options": {
      "A": {
        "option": "修改IAM策略资源为“arn:aws:dynamodb:us-west-2:account-id:table/*”。",
        "reason": "当前IAM策略中的资源指定了特定的表名为Cars。如果表名有误或者策略中没有正确指定资源，可能会导致访问被拒绝的错误。使用通配符“*”来指定所有表可以确保策略适用于所有可能的表名，解决访问被拒绝的问题。"
      },
      "B": {
        "option": "修改IAM策略以包含dynamodb:*操作。",
        "reason": "当前IAM策略已经包含了dynamodb:Query和dynamodb:Scan操作，这对于只读访问来说是足够的。修改策略以包含所有dynamodb操作（例如dynamodb:*）会给予过多的权限，不符合最小权限原则。"
      },
      "C": {
        "option": "创建一个指定EC2服务主体的信任策略。将角色与策略关联。",
        "reason": "信任策略是用于指定哪些实体可以假设该角色的。当前的问题是访问被拒绝的错误，而不是信任策略的问题。"
      },
      "D": {
        "option": "在角色和dynamodb.amazonaws.com之间创建信任关系。",
        "reason": "信任关系是用于允许其他AWS服务或实体假设该角色的。当前的问题在于访问DynamoDB表的权限不足，而不是信任关系的问题。"
      }
    }
  },
  {
    "number": "164",
    "best": ["B"],
    "question": "当使用 AWS Encryption SDK 时，开发人员如何跟踪用于加密数据的数据加密密钥？",
    "options": {
      "A": {
        "option": "开发人员必须手动跟踪用于每个数据对象的数据加密密钥。",
        "reason": "这种方法非常繁琐且容易出错，尤其是当数据量很大时。此外，这也不符合 AWS Encryption SDK 的设计理念。"
      },
      "B": {
        "option": "SDK 会加密数据加密密钥，并将其（加密后）作为返回的密文的一部分存储。",
        "reason": "这是 AWS Encryption SDK 的标准操作方式。SDK 会自动处理数据加密密钥的管理，并将加密后的密钥与密文一起返回，从而简化了开发人员的工作。"
      },
      "C": {
        "option": "SDK 会自动将数据加密密钥存储在 Amazon S3 中。",
        "reason": "虽然 Amazon S3 可以用于存储数据，但这并不是 AWS Encryption SDK 管理数据加密密钥的方式。"
      },
      "D": {
        "option": "数据加密密钥存储在 EC2 实例的用户数据中。",
        "reason": "EC2 实例的用户数据主要用于初始化实例时传递配置数据，而不是用于存储数据加密密钥。这种方式也不符合 AWS Encryption SDK 的设计。"
      }
    }
  },
  {
    "number": "165",
    "best": ["C"],
    "question": "一个运行在AWS Lambda上的应用程序需要访问Amazon S3桶中特定的高度机密对象。根据最小权限原则，公司仅使用临时凭证来授予对S3桶的访问权限。开发人员如何以最安全的方式配置对S3桶的访问？",
    "options": {
      "A": {
        "option": "将访问S3对象所需的凭证硬编码在应用程序代码中。使用这些凭证访问所需的S3对象。",
        "reason": "硬编码凭证在代码中是不安全的做法，因为这些凭证可能会被泄露或滥用。这违反了安全最佳实践。"
      },
      "B": {
        "option": "创建一个具有访问S3桶权限的秘密访问密钥和访问密钥ID。将这些密钥存储在AWS Secrets Manager中。配置应用程序以检索Secrets Manager的秘密并使用这些凭证访问S3对象。",
        "reason": "虽然使用Secrets Manager存储密钥比硬编码要安全，但这种方法仍然依赖于长期凭证，而不是临时凭证，这不符合最小权限原则。"
      },
      "C": {
        "option": "创建一个Lambda函数执行角色。为该角色附加一个策略，授予对S3桶中特定对象的访问权限。",
        "reason": "这种方法使用IAM角色和策略来授予Lambda函数访问权限。通过这种方式，Lambda函数在执行时会自动获取临时凭证，这符合最小权限原则和最佳安全实践。"
      },
      "D": {
        "option": "创建一个具有访问S3桶权限的秘密访问密钥和访问密钥ID。将这些密钥作为环境变量存储在Lambda中。使用环境变量访问所需的S3对象。",
        "reason": "将密钥存储在环境变量中虽然比硬编码安全，但仍然依赖于长期凭证，不符合最小权限原则。"
      }
    }
  },
  {
    "number": "166",
    "best": ["A"],
    "question": "一名开发人员的代码存储在一个 Amazon S3 存储桶中。该代码必须作为 AWS Lambda 函数在与 S3 存储桶相同的 AWS 区域的多个账户中部署。一个在每个账户中运行的 AWS CloudFormation 模板将部署该 Lambda 函数。允许 CloudFormation 访问 S3 存储桶中 Lambda 代码的最安全方式是什么？",
    "options": {
      "A": {
        "option": "授予 CloudFormation 服务角色 S3 ListBucket 和 GetObject 权限。向 Amazon S3 添加一个存储桶策略，包含\"AWS\": [账户号码]的主体。",
        "reason": "此选项是最安全的方式，因为它仅授予 CloudFormation 服务角色需要的权限，并且通过指定账户号码限制了对 S3 存储桶的访问。这样可以确保只有特定的账户可以访问存储桶，增强了安全性。"
      },
      "B": {
        "option": "授予 CloudFormation 服务角色 S3 GetObject 权限。向 Amazon S3 添加一个存储桶策略，包含\"*\"的主体。",
        "reason": "此选项不够安全，因为它允许所有账户对存储桶中的对象进行读取操作。使用通配符\"*\"会导致权限过于宽泛，可能会带来安全风险。"
      },
      "C": {
        "option": "使用基于服务的链接，通过显式添加 S3 存储桶的账户号码在资源中，授予 Lambda 函数 S3 ListBucket 和 GetObject 权限。",
        "reason": "此选项不是最优解，因为它试图直接授予 Lambda 函数权限，而不是通过 CloudFormation 服务角色来实现。此外，应避免授予不必要的 ListBucket 权限，以最小化权限。"
      },
      "D": {
        "option": "使用基于服务的链接，授予 Lambda 函数 S3 GetObject 权限。添加一个资源\"*\"来允许访问 S3 存储桶。",
        "reason": "此选项不够安全，因为它使用了通配符\"*\"来允许访问 S3 存储桶，权限过于宽泛，存在潜在的安全风险。"
      }
    }
  },
  {
    "number": "167",
    "best": ["C"],
    "question": "公司的一名开发人员需要创建一个小型应用程序，该应用程序每天在指定时间进行一次相同的API调用。公司尚未在AWS云中拥有基础设施，但公司希望在AWS上实现此功能。哪种解决方案在操作上最有效地满足这些需求？",
    "options": {
      "A": {
        "option": "使用在 Amazon Elastic Kubernetes Service (Amazon EKS) 上运行的 Kubernetes cron job。",
        "reason": "虽然 Kubernetes cron job 可以实现定时任务，但使用 Amazon EKS 需要配置和管理 Kubernetes 集群，这对于一个只需要每天进行一次API调用的小型应用来说过于复杂和不必要。"
      },
      "B": {
        "option": "使用在 Amazon EC2 上运行的 Amazon Linux crontab 定时任务。",
        "reason": "尽管 crontab 可以实现定时任务，但使用 Amazon EC2 需要启动和管理实例，并且需要确保实例的高可用性和维护，这增加了运维负担。"
      },
      "C": {
        "option": "使用由 Amazon EventBridge 定时事件触发的 AWS Lambda 函数。",
        "reason": "AWS Lambda 与 Amazon EventBridge 相结合是最优解，因为它是一种无服务器解决方案，无需管理基础设施。EventBridge 可以轻松设置定时事件，而 Lambda 可以执行API调用，这种组合在操作上最为高效。"
      },
      "D": {
        "option": "使用提交到 AWS Batch 作业队列的 AWS Batch 作业。",
        "reason": "虽然 AWS Batch 可以处理定时任务，但它主要用于批处理作业，通常用于需要大量计算资源的任务，对于每天一次的小型API调用来说显得过于复杂和不必要。"
      }
    }
  },
  {
    "number": "168",
    "best": ["B"],
    "question": "一位开发人员正在构建一个基于 AWS Lambda 的无服务器应用程序。开发人员在 Lambda 处理函数之外初始化 AWS 软件开发工具包 (SDK)。这样做的主要好处是什么？",
    "options": {
      "A": {
        "option": "提高可读性和风格惯例",
        "reason": "虽然在 Lambda 处理函数之外初始化 SDK 可以提高代码的可读性和风格惯例，但这并不是这样做的主要好处。主要好处是与性能优化相关的。"
      },
      "B": {
        "option": "利用运行时环境重用",
        "reason": "在 Lambda 处理函数之外初始化 SDK，可以利用 Lambda 的运行时环境重用特性。这样可以避免每次函数调用时都重新初始化 SDK，从而减少冷启动时间，提高性能。这是这样做的主要好处。"
      },
      "C": {
        "option": "提供更好的错误处理",
        "reason": "错误处理的能力主要取决于实现逻辑和错误处理机制，而不是 SDK 初始化的位置。因此，这并不是主要好处。"
      },
      "D": {
        "option": "为每次调用创建一个新的 SDK 实例",
        "reason": "如果在 Lambda 处理函数之外初始化 SDK，SDK 实例可以在多次调用之间保持，从而减少不必要的初始化开销。因此，这个选项是错误的。"
      }
    }
  },
  {
    "number": "169",
    "best": ["C"],
    "question": "公司正在使用 Amazon RDS 作为其应用程序的后端数据库。在最近的一次营销活动后，对数据库的读取请求激增，增加了从数据库检索数据的延迟。公司决定在数据库前实现一个缓存层。缓存内容必须加密并且必须高度可用。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "Amazon CloudFront",
        "reason": "Amazon CloudFront 是一个内容分发网络（CDN），主要用于分发静态和动态网页内容，但它不是一个数据库缓存解决方案。虽然 CloudFront 可以与其他服务配合使用来提高读取性能，但它并不是为缓存数据库查询设计的，因此不能满足题目中关于缓存数据库查询的需求。"
      },
      "B": {
        "option": "Amazon ElastiCache for Memcached",
        "reason": "Amazon ElastiCache for Memcached 是一个内存对象缓存系统，适用于简单的缓存需求。虽然它可以提高读取性能，但它不支持原生的数据加密和集群模式下的高可用性，因此不完全满足题目的要求。"
      },
      "C": {
        "option": "Amazon ElastiCache for Redis in cluster mode",
        "reason": "Amazon ElastiCache for Redis in cluster mode 提供高度可用的缓存层，并支持数据加密。Redis 在集群模式下可以提供分布式和高度可用的缓存解决方案，完全满足题目中的要求。因此，这是最佳选择。"
      },
      "D": {
        "option": "Amazon DynamoDB Accelerator (DAX)",
        "reason": "Amazon DynamoDB Accelerator (DAX) 是为 DynamoDB 提供加速的缓存服务，适用于减少读取延迟。但题目中提到的后端数据库是 Amazon RDS，而不是 DynamoDB，因此 DAX 不是合适的选择。"
      }
    }
  },
  {
    "number": "170",
    "best": ["A"],
    "question": "一位公司开发人员最近创建了一个无服务器应用程序，用于处理和显示业务报告中的数据。应用程序的用户界面（UI）允许用户选择并开始处理文件。当结果可查看时，UI会显示一条消息。应用程序使用 AWS Step Functions 和 AWS Lambda 函数来处理文件。开发人员使用 Amazon API Gateway 和 Lambda 函数创建了一个支持 UI 的 API。公司的 UI 团队报告说，由于文件的大小或复杂性，请求处理文件时经常返回超时错误。UI 团队希望 API 提供立即响应，以便 UI 可以在文件处理时显示一条消息。API 调用的后端过程需要在报告处理完成时发送一封电子邮件。开发人员应该如何配置 API 以满足这些要求？",
    "options": {
      "A": {
        "option": "更改 API Gateway 路由，在集成请求中添加一个静态值为 'Event' 的 X-Amz-Invocation-Type 头。部署 API Gateway 阶段以应用更改。",
        "reason": "将 X-Amz-Invocation-Type 头设置为 'Event' 可以使 Lambda 函数异步执行，从而立即返回响应给 UI，并在处理完成后发送电子邮件。这正是题目要求的解决方案。"
      },
      "B": {
        "option": "更改实现文件处理请求的 Lambda 函数的配置。配置事件的最大年龄，以使 Lambda 函数异步运行。",
        "reason": "这个选项提到的配置实际上并不能确保 Lambda 函数异步执行，而只是设置了事件的最大年龄。这个方法并不能确保立即响应给 UI，无法满足题目要求。"
      },
      "C": {
        "option": "将 API Gateway 的超时值更改为匹配 Lambda 函数的超时值。部署 API Gateway 阶段以应用更改。",
        "reason": "这种方法依然会让 API 请求等待 Lambda 函数完成执行并返回结果，无法实现立即响应的需求。"
      },
      "D": {
        "option": "更改 API Gateway 路由，在集成请求中添加一个静态值为 'Async' 的 X-Amz-Target 头。部署 API Gateway 阶段以应用更改。",
        "reason": "没有 'Async' 这个 X-Amz-Target 头的配置选项，因此这个选项是错误的。"
      }
    }
  },
  {
    "number": "171",
    "best": ["C"],
    "question": "一位开发人员有一个由许多不同的 AWS Lambda 函数组成的应用程序。所有的 Lambda 函数都使用一些相同的依赖项。为了避免安全问题，开发人员不断更新所有 Lambda 函数的依赖项，导致每个函数都有重复的工作。开发人员如何在增加最少的复杂性情况下保持 Lambda 函数的依赖项更新？",
    "options": {
      "A": {
        "option": "定义一个维护窗口，以确保 Lambda 函数获得依赖项的更新副本。",
        "reason": "定义维护窗口并不能减少依赖项的重复更新工作，只是规定了更新的时间。它并不能降低复杂性或提高效率。"
      },
      "B": {
        "option": "将 Lambda 函数升级到最新的运行时版本。",
        "reason": "升级运行时版本虽然可以带来一些改进和安全更新，但它并不能解决依赖项的重复更新问题。"
      },
      "C": {
        "option": "定义一个包含所有共享依赖项的 Lambda 层。",
        "reason": "使用 Lambda 层可以将所有共享的依赖项集中在一个地方，减少每个函数的重复工作。这是减少复杂性和提高效率的最佳方法。"
      },
      "D": {
        "option": "使用 AWS CodeCommit 存储库来集中存放依赖项。",
        "reason": "虽然集中存放依赖项可以帮助管理依赖项，但这并不能直接减少每个函数的重复更新工作。"
      }
    }
  },
  {
    "number": "172",
    "best": ["D"],
    "question": "一个移动应用程序在 Amazon DynamoDB 表中存储博客文章。每天都会新增数百万篇文章，每篇文章在表中代表一个单独的项。移动应用程序只需要最近的文章。任何超过 48 小时的文章都可以删除。删除超过 48 小时的文章最具成本效益的方法是什么？",
    "options": {
      "A": {
        "option": "对于每个项，添加一个类型为字符串的新属性，该属性具有设置为博客文章创建时间的时间戳。创建脚本通过表扫描查找旧文章，并使用 BatchWriteItem API 操作删除超过 48 小时的文章。在 Amazon EC2 实例上每小时调度一次 cron 作业以启动脚本。",
        "reason": "这种方法依赖于表扫描和 EC2 实例上的 cron 作业。表扫描在处理大量数据时可能会很昂贵，EC2 实例的持续运行也会产生额外的费用，因此这不是最具成本效益的方法。"
      },
      "B": {
        "option": "对于每个项，添加一个类型为字符串的新属性，该属性具有设置为博客文章创建时间的时间戳。创建脚本通过表扫描查找旧文章，并使用 BatchWriteItem API 操作删除超过 48 小时的文章。将脚本放入容器镜像中。调度一个在 AWS Fargate 上调用容器的 Amazon Elastic Container Service (Amazon ECS) 任务，每 5 分钟一次。",
        "reason": "虽然使用 Fargate 可以减少 EC2 实例的管理和运行费用，但频繁的表扫描仍然会产生高昂的成本，因此这也不是最优的解决方案。"
      },
      "C": {
        "option": "对于每个项，添加一个类型为日期的新属性，该属性具有设置为博客文章创建时间后的 48 小时的时间戳。创建一个使用新属性作为排序键的全局二级索引 (GSI)。创建一个参考 GSI 的 AWS Lambda 函数，通过使用 BatchWriteItem API 操作删除过期项。使用 Amazon CloudWatch 事件每分钟调度该函数。",
        "reason": "这种方法涉及到创建和维护全局二级索引 (GSI) 和频繁的 Lambda 调用。虽然比表扫描更有效，但它仍然不是最具成本效益的解决方案。因为维护 GSI 也会增加一定的费用。"
      },
      "D": {
        "option": "对于每个项，添加一个类型为数字的新属性，该属性具有设置为博客文章创建时间后的 48 小时的时间戳。配置 DynamoDB 表的 TTL 以参考新属性。",
        "reason": "这种方法利用了 DynamoDB 的 TTL（生存时间）功能，自动删除超过指定时间的项。TTL 是一种内置功能，不需要额外的计算资源或复杂的调度，因此它是最具成本效益的解决方案。"
      }
    }
  },
  {
    "number": "173",
    "best": ["B"],
    "question": "开发人员正在修改现有的 AWS Lambda 函数。在检查代码时，开发人员注意到硬编码的参数值，包括 Amazon RDS for SQL Server 的用户名、密码、数据库、主机和端口。还有一些硬编码的参数值用于 Amazon DynamoDB 表、Amazon S3 存储桶和 Amazon Simple Notification Service (Amazon SNS) 主题。开发人员希望在代码之外以加密格式安全地存储参数值，并希望启用凭证轮换。开发人员还希望能够从其他应用程序重用这些参数值，并在不修改代码的情况下更新这些参数值。哪种解决方案能以最少的操作开销满足这些要求？",
    "options": {
      "A": {
        "option": "在 AWS Secrets Manager 中创建一个 RDS 数据库密钥。设置用户名、密码、数据库、主机和端口。启用密钥轮换。为 DynamoDB 表、S3 存储桶和 SNS 主题创建加密的 Lambda 环境变量。",
        "reason": "虽然 AWS Secrets Manager 可以处理 RDS 凭证并启用轮换，但是将 DynamoDB 表、S3 存储桶和 SNS 主题放在 Lambda 环境变量中不符合“在代码之外存储参数值”的要求。"
      },
      "B": {
        "option": "在 AWS Secrets Manager 中创建一个 RDS 数据库密钥。设置用户名、密码、数据库、主机和端口。启用密钥轮换。为 DynamoDB 表、S3 存储桶和 SNS 主题在 AWS Systems Manager Parameter Store 中创建 SecureString 参数。",
        "reason": "AWS Secrets Manager 可以处理 RDS 凭证并启用轮换，而 AWS Systems Manager Parameter Store 可以安全地存储其他参数值并提供加密支持。这种方法实现了参数值的安全存储、重用和更新，操作开销最小。"
      },
      "C": {
        "option": "在 AWS Systems Manager Parameter Store 中为 RDS 用户名、密码、数据库、主机和端口创建参数。为 DynamoDB 表、S3 存储桶和 SNS 主题创建加密的 Lambda 环境变量。创建一个 Lambda 函数并设置凭证轮换任务的逻辑。在 Amazon EventBridge 中安排凭证轮换任务。",
        "reason": "这种方法需要额外创建 Lambda 函数和 EventBridge 规则来处理凭证轮换，增加了操作开销。"
      },
      "D": {
        "option": "在 AWS Systems Manager Parameter Store 中为 RDS 用户名、密码、数据库、主机和端口创建参数。将 DynamoDB 表、S3 存储桶和 SNS 主题存储在 Amazon S3 中。创建一个 Lambda 函数并设置凭证轮换的逻辑。按计划调用 Lambda 函数。",
        "reason": "这种方法同样需要额外创建 Lambda 函数和调用逻辑，增加了操作开销。而且，将 DynamoDB 表、S3 存储桶和 SNS 主题存储在 S3 中并不符合最佳实践。"
      }
    }
  },
  {
    "number": "174",
    "best": ["A"],
    "question": "开发人员通过 SSH 访问 AWS CodeCommit。配置的 SSH 密钥与具有以下权限的用户相关联：开发人员需要创建/删除分支。根据最小权限原则，需要添加哪些特定的 IAM 权限？",
    "options": {
      "A": {
        "option": "\"codecommit:CreateBranch\" 和 \"codecommit:DeleteBranch\"",
        "reason": "根据最小权限原则，用户应仅被授予他们完成任务所需的最低权限。创建和删除分支仅需要 \"codecommit:CreateBranch\" 和 \"codecommit:DeleteBranch\" 权限，因此这是最合适的选择。"
      },
      "B": {
        "option": "\"codecommit:Put*\"",
        "reason": "\"codecommit:Put*\" 权限范围过广，可能允许用户执行超出创建和删除分支的操作，不符合最小权限原则。"
      },
      "C": {
        "option": "\"codecommit:Update*\"",
        "reason": "\"codecommit:Update*\" 权限也涵盖了不必要的操作，不适合仅需创建和删除分支的需求。"
      },
      "D": {
        "option": "\"codecommit:*\"",
        "reason": "\"codecommit:*\" 权限授予用户对 CodeCommit 的所有操作权限，远超出创建和删除分支的需求，完全不符合最小权限原则。"
      }
    }
  },
  {
    "number": "175",
    "best": ["A", "B"],
    "question": "一个部署在 Amazon EC2 上的应用程序正在使用 Amazon DynamoDB。该应用程序调用 DynamoDB REST API。周期性地，应用程序在向 DynamoDB 表写入数据时收到 ProvisionedThroughputExceededException 错误。哪些解决方案将最具成本效益地缓解此错误？（选择两个。）",
    "options": {
      "A": {
        "option": "在收到错误时修改应用程序代码以执行指数退避。",
        "reason": "指数退避是一种常见的错误处理策略，可以有效地减少对 DynamoDB 的写入请求频率，从而减少 ProvisionedThroughputExceededException 错误的发生。这种方法不需要额外的成本，是一种非常有效的解决方案。"
      },
      "B": {
        "option": "修改应用程序以使用 AWS SDKs for DynamoDB。",
        "reason": "使用 AWS SDKs for DynamoDB 可以简化与 DynamoDB 的交互，并且 SDK 内置了许多最佳实践，包括自动重试和指数退避。这可以减少错误的发生，并且不需要额外的成本。"
      },
      "C": {
        "option": "增加 DynamoDB 表的读写吞吐量。",
        "reason": "增加读写吞吐量可以减少 ProvisionedThroughputExceededException 错误的发生，但这会增加成本，因此不是最具成本效益的解决方案。"
      },
      "D": {
        "option": "为 DynamoDB 表创建一个 DynamoDB Accelerator (DAX) 集群。",
        "reason": "DAX 可以加速 DynamoDB 的读操作，但对于写操作的错误没有直接帮助，并且会增加额外的成本，因此不适用于解决这个问题。"
      },
      "E": {
        "option": "创建第二个 DynamoDB 表。在两个表之间分配读写操作。",
        "reason": "创建第二个表并分散读写操作虽然可以减少单个表的负载，但会增加管理和维护的复杂性，并且会增加成本，因此不是最具成本效益的解决方案。"
      }
    }
  },
  {
    "number": "176",
    "best": ["D"],
    "question": "当开发人员尝试运行一个 AWS CodeBuild 项目时，由于所有环境变量的总长度超过了字符数限制而引发错误。推荐的解决方案是什么？",
    "options": {
      "A": {
        "option": "在 pre_build 部分添加 export LC_ALL=\"en_US.utf8\" 命令以确保 POSIX 本地化。",
        "reason": "这个选项与环境变量的长度限制问题无关，它是用来设置本地化环境的，不会解决环境变量长度超限的问题。"
      },
      "B": {
        "option": "使用 Amazon Cognito 存储大量的环境变量键值对。",
        "reason": "Amazon Cognito 主要用于用户身份验证和授权管理，与存储环境变量无关，因此不适合用于解决这个问题。"
      },
      "C": {
        "option": "更新构建项目的设置，以使用 Amazon S3 存储大量的环境变量。",
        "reason": "虽然 Amazon S3 可以用来存储大量数据，但它并不是设计来存储环境变量的解决方案。使用 S3 进行环境变量管理会增加复杂性，并且不是最佳实践。"
      },
      "D": {
        "option": "使用 AWS Systems Manager Parameter Store 存储大量的环境变量。",
        "reason": "AWS Systems Manager Parameter Store 是专门设计用于安全存储和管理配置数据和密钥信息的服务。它可以很好地解决环境变量长度超限的问题，因此是推荐的解决方案。"
      }
    }
  },
  {
    "number": "177",
    "best": ["D"],
    "question": "一家公司正在扩展其照片共享移动应用程序的兼容性，以适应数百种具有独特屏幕尺寸和分辨率的设备。照片以原始格式和分辨率存储在 Amazon S3 中。该公司使用 Amazon CloudFront 分发照片。应用程序在每个请求中都包含显示屏的尺寸和分辨率作为 GET 参数。开发人员需要实施一种解决方案，以优化每个设备上提供的照片，从而减少加载时间并提高照片质量。哪种解决方案最具成本效益地满足这些要求？",
    "options": {
      "A": {
        "option": "使用 S3 Batch Operations 调用 AWS Lambda 函数，创建具有所需尺寸和分辨率的新照片变体。创建一个动态 CloudFront 源，自动将每个设备的请求映射到相应的照片变体。",
        "reason": "此选项涉及创建多个照片变体，并使用动态 CloudFront 源来映射设备请求。这可能导致存储和管理大量照片变体，增加存储成本和复杂性。"
      },
      "B": {
        "option": "使用 S3 Batch Operations 调用 AWS Lambda 函数，创建具有所需尺寸和分辨率的新照片变体。创建一个 Lambda@Edge 函数，通过使用请求头将请求路由到相应的照片变体。",
        "reason": "此选项类似于选项 A，但使用 Lambda@Edge 函数进行请求路由。虽然这减少了一些存储成本，但仍然需要管理和存储多个照片变体。"
      },
      "C": {
        "option": "创建一个 Lambda@Edge 函数，在请求时优化照片并将照片作为响应返回。将 CloudFront TTL 缓存策略更改为可能的最大值。",
        "reason": "此选项每次请求时都动态优化照片，这可能会导致较高的计算成本。尽管增加了 TTL 缓存策略，但随着请求数量增加，计算成本可能会很高。"
      },
      "D": {
        "option": "创建一个 Lambda@Edge 函数，在请求时优化照片并将照片作为响应返回。在同一函数中，将处理后的照片副本存储在 Amazon S3 以供后续请求使用。",
        "reason": "此选项在请求时动态优化照片，并将优化后的照片存储在 S3 中以供后续请求使用。这样可以减少重复计算的成本，同时也确保照片被优化以适应不同设备的需求。综合来看，这是最具成本效益的解决方案。"
      }
    }
  },
  {
    "number": "178",
    "best": ["D"],
    "question": "一家公司正在构建一个股票交易应用程序。该应用程序需要亚毫秒级延迟来处理交易请求。公司使用 Amazon DynamoDB 来存储用于处理每个交易请求的所有交易数据。开发团队对应用程序进行了负载测试，发现数据检索时间比预期的要长。开发团队需要一个解决方案，以最小的努力减少数据检索时间。以下哪种解决方案符合这些要求？",
    "options": {
      "A": {
        "option": "为交易数据添加本地二级索引 (LSI)。",
        "reason": "虽然添加本地二级索引 (LSI) 可以改善特定查询的性能，但它不会显著减少数据检索时间到亚毫秒级。此外，LSI 的添加通常需要对表进行重新设计和数据重新加载，这可能需要较多的努力，不符合“最小的努力”的要求。"
      },
      "B": {
        "option": "将交易数据存储在 Amazon S3 中，并使用 S3 Transfer Acceleration。",
        "reason": "Amazon S3 主要用于存储大规模、不经常访问的数据，而不是需要低延迟、高频率访问的数据。S3 Transfer Acceleration 旨在加快全球传输速度，但并不能显著降低子毫秒级的访问延迟。因此，这不是一个合适的选择。"
      },
      "C": {
        "option": "为 DynamoDB 查询添加指数退避重试机制。",
        "reason": "指数退避重试机制可以提高请求的成功率，特别是在发生暂时性故障时，但它不会显著减少正常操作下的数据检索时间。因此，这个选项不符合减少数据检索时间的要求。"
      },
      "D": {
        "option": "使用 DynamoDB Accelerator (DAX) 缓存交易数据。",
        "reason": "DynamoDB Accelerator (DAX) 是一种完全托管的缓存服务，专为 DynamoDB 提供亚毫秒级的读缓存。通过使用 DAX，应用程序可以显著减少数据检索时间，满足亚毫秒级延迟的需求，并且实施起来也比较简单，不需要对现有的表结构进行重大更改。因此，这是最符合需求的解决方案。"
      }
    }
  },
  {
    "number": "179",
    "best": ["B", "E"],
    "question": "开发人员正在处理一个运行在 Amazon EC2 实例上的 Python 应用程序。开发人员希望启用应用程序请求的跟踪，以调试代码中的性能问题。开发人员应该采取哪些行动来实现这一目标？（选择两个。）",
    "options": {
      "A": {
        "option": "在 EC2 实例上安装 Amazon CloudWatch 代理。",
        "reason": "Amazon CloudWatch 主要用于监控和记录各种 AWS 资源和应用程序的指标和日志，但它并不直接用于跟踪应用程序请求，因此不是此问题的最佳选择。"
      },
      "B": {
        "option": "在 EC2 实例上安装 AWS X-Ray 守护程序。",
        "reason": "AWS X-Ray 守护程序用于收集、处理和发送追踪数据到 AWS X-Ray 服务，从而帮助开发人员分析和调试应用程序的性能问题。因此，这是一个正确的选择。"
      },
      "C": {
        "option": "配置应用程序以 JSON 格式将日志写入 /var/log/cloudwatch。",
        "reason": "虽然写入日志可以帮助调试，但它不能直接用于跟踪应用程序请求的性能问题。因此，这不是最佳选择。"
      },
      "D": {
        "option": "配置应用程序将跟踪数据写入 /var/log/xray。",
        "reason": "仅配置应用程序将跟踪数据写入日志文件并不能直接实现 X-Ray 跟踪功能，需要配合 X-Ray 守护程序和 SDK 的使用。因此，这不是最佳选择。"
      },
      "E": {
        "option": "在应用程序中安装和配置 AWS X-Ray Python SDK。",
        "reason": "AWS X-Ray SDK 用于在代码中插入跟踪点，并与 X-Ray 守护程序一起工作，从而提供详细的请求跟踪和性能分析。因此，这是一个正确的选择。"
      }
    }
  },
  {
    "number": "180",
    "best": ["C"],
    "question": "一家公司有一个应用程序，以一系列 AWS Lambda 函数的形式运行。每个 Lambda 函数从 Amazon Simple Notification Service (Amazon SNS) 主题接收数据，并将数据写入 Amazon Aurora 数据库实例。为了符合信息安全政策，公司必须确保所有 Lambda 函数都使用单一的安全加密数据库连接字符串来访问 Aurora。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "使用 Aurora 的 IAM 数据库身份验证来为所有 Lambda 函数启用安全的数据库连接。",
        "reason": "IAM 数据库身份验证可以提供对数据库的安全访问，但是它不直接解决如何安全地存储和管理数据库连接字符串的问题。"
      },
      "B": {
        "option": "将凭证存储在一个加密的 Amazon RDS 数据库实例中并从中读取。",
        "reason": "虽然加密的 RDS 可以安全地存储数据，但这并不是最佳实践来存储和管理连接字符串或凭证。"
      },
      "C": {
        "option": "将凭证存储在 AWS Systems Manager 参数存储中，作为安全字符串参数。",
        "reason": "AWS Systems Manager Parameter Store 提供了一种安全的方式来存储和管理敏感信息，如数据库连接字符串。通过将其存储为加密的安全字符串参数，Lambda 函数可以安全地访问这些信息。"
      },
      "D": {
        "option": "使用 Lambda 环境变量，并使用共享的 AWS Key Management Service (AWS KMS) 密钥进行加密。",
        "reason": "虽然 Lambda 环境变量可以使用 KMS 密钥进行加密，但这种方法的安全性和灵活性不如 AWS Systems Manager 参数存储。环境变量容易被意外暴露，且管理起来不如参数存储方便。"
      }
    }
  },
  {
    "number": "181",
    "best": ["D"],
    "question": "开发人员正在排查 Amazon API Gateway API 的问题。当客户端尝试访问 API 的一个端点时，客户端收到 HTTP 400 响应错误。开发人员如何确定这些错误的原因？",
    "options": {
      "A": {
        "option": "创建一个 Amazon Kinesis Data Firehose 传输流以接收来自 API Gateway 的 API 调用日志。将 Amazon CloudWatch Logs 配置为传输流的目标。",
        "reason": "Kinesis Data Firehose 传输流通常用于大规模数据传输和存储，但在这种情况下，它并不是排查 API Gateway 错误的最佳选择。"
      },
      "B": {
        "option": "开启 AWS CloudTrail Insights 并创建一个 trail。为 API 的阶段指定 trail 的 Amazon 资源名称 (ARN)。",
        "reason": "AWS CloudTrail Insights 主要用于检测异常活动，虽然可以记录 API 调用，但并不能直接提供 API Gateway 的错误信息。"
      },
      "C": {
        "option": "为 API 阶段开启 AWS X-Ray。创建一个 Amazon CloudWatch Logs 日志组。为 API 阶段指定日志组的 Amazon 资源名称 (ARN)。",
        "reason": "AWS X-Ray 用于跟踪和分析应用程序中的请求路径。然而，它更适用于在多个服务之间追踪请求链路，不是排查 API Gateway 特定错误的最佳工具。"
      },
      "D": {
        "option": "在 Amazon CloudWatch Logs 中为 API 阶段开启执行日志记录和访问日志记录。创建一个 CloudWatch Logs 日志组。为 API 阶段指定日志组的 Amazon 资源名称 (ARN)。",
        "reason": "开启执行日志记录和访问日志记录可以直接捕获 API Gateway 的请求和响应的详细信息，包括错误信息。这是排查 HTTP 400 错误的最佳方法。"
      }
    }
  },
  {
    "number": "182",
    "best": ["B"],
    "question": "公司通过使用Amazon CloudFront、Amazon API Gateway和AWS Lambda在AWS上开发了一个API应用程序。该API每秒最少有四个请求。开发人员注意到许多API用户使用POST方法运行相同的查询。开发人员希望缓存POST请求以优化API资源。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "配置CloudFront缓存。更新应用程序以根据默认请求头返回缓存的内容。",
        "reason": "CloudFront缓存通常用于GET请求，而不是POST请求。即使可以配置CloudFront来缓存POST请求，但这需要复杂的配置，并且默认情况下CloudFront不会缓存POST请求。因此，这不是最佳解决方案。"
      },
      "B": {
        "option": "覆盖API Gateway选定阶段中的缓存方法。选择POST方法。",
        "reason": "API Gateway可以配置以缓存POST请求的响应。这是最直接和有效的方法来缓存API Gateway中的POST请求，并优化API资源。因此，这是最佳解决方案。"
      },
      "C": {
        "option": "将最新的请求响应保存在Lambda /tmp目录中。更新Lambda函数以检查/tmp目录。",
        "reason": "虽然Lambda函数的/tmp目录可以用于临时存储，但这种方法不可靠且不持久。/tmp目录的内容在每次调用后可能会丢失，不适合长期缓存。因此，这不是一个好的选择。"
      },
      "D": {
        "option": "将最新的请求保存在AWS Systems Manager Parameter Store中。修改Lambda函数以从Parameter Store获取最新的请求响应。",
        "reason": "Parameter Store通常用于存储配置参数和密钥，而不是用于缓存API响应。它的读取速度和性能不适合高频率的API请求响应缓存。因此，这不是一个合适的选项。"
      }
    }
  },
  {
    "number": "183",
    "best": ["C", "D"],
    "question": "一家公司正在构建一个由许多 AWS Lambda 函数组成的微服务应用程序。开发团队希望使用 AWS Serverless Application Model (AWS SAM) 模板来自动测试这些 Lambda 函数。开发团队计划在将新更新完全部署到应用程序之前，先测试一小部分流量。哪种步骤组合能以最具操作效率的方式满足这些要求？（选择两个。）",
    "options": {
      "A": {
        "option": "在 AWS CodeDeploy 中使用 AWS SAM CLI 命令调用 Lambda 函数以测试部署。",
        "reason": "虽然可以使用 AWS SAM CLI 命令来测试 Lambda 函数，但题目中提到的是使用 AWS SAM 模板来实现自动化测试和部署。这个选项不完全符合题意。"
      },
      "B": {
        "option": "在 AWS SAM 模板中声明 Lambda 函数的 EventInvokeConfig，并配置 OnSuccess 和 OnFailure。",
        "reason": "此选项是为了配置事件调用的成功和失败处理，但不涉及流量分配和逐步部署的需求，不完全符合题意。"
      },
      "C": {
        "option": "通过 AWS SAM 模板启用逐步部署。",
        "reason": "AWS SAM 模板支持通过配置来启用逐步部署，这是实现流量控制和逐步发布的有效方法。"
      },
      "D": {
        "option": "将部署偏好类型设置为 Canary10Percent30Minutes。使用钩子测试部署。",
        "reason": "Canary 部署策略允许在初始阶段只将一小部分流量（10%）导向新版本，然后在 30 分钟后完成剩余的部署。这种策略符合题意中的逐步部署和流量测试需求。"
      },
      "E": {
        "option": "将部署偏好类型设置为 Linear10PercentEvery10Minutes。使用钩子测试部署。",
        "reason": "Linear 部署策略在每 10 分钟增加 10% 的流量。这种策略虽然也能逐步部署，但与 Canary 策略相比，操作效率略低，因为需要多个时间段才能完成完全部署。"
      }
    }
  },
  {
    "number": "184",
    "best": ["D"],
    "question": "一家公司正在使用 AWS CloudFormation 部署一个两层应用程序。该应用程序将使用 Amazon RDS 作为其后端数据库。公司希望在部署期间随机生成数据库密码的解决方案。该解决方案还必须自动轮换数据库密码，而无需对应用程序进行更改。最具操作效率的解决方案是什么？",
    "options": {
      "A": {
        "option": "使用 AWS Lambda 函数作为 CloudFormation 自定义资源来生成和轮换密码。",
        "reason": "虽然 AWS Lambda 可以用于这种情况，但它需要额外的管理和编写自定义代码来生成和轮换密码，这并不是最具操作效率的解决方案。"
      },
      "B": {
        "option": "使用具有 SecureString 数据类型的 AWS Systems Manager 参数存储资源来生成和轮换密码。",
        "reason": "虽然 AWS Systems Manager 参数存储支持 SecureString 类型，并且可以存储敏感数据，但它不具备自动轮换密码的功能。"
      },
      "C": {
        "option": "在应用程序的主机上使用 cron 守护进程来生成和轮换密码。",
        "reason": "使用 cron 守护进程进行密码轮换需要开发和维护额外的脚本，并且不符合最具操作效率的要求。"
      },
      "D": {
        "option": "使用 AWS Secrets Manager 资源来生成和轮换密码。",
        "reason": "AWS Secrets Manager 支持安全地存储、自动生成和轮换数据库密码，并且可以与 RDS 集成，无需对应用程序进行更改。这是最具操作效率的解决方案。"
      }
    }
  },
  {
    "number": "185",
    "best": ["B"],
    "question": "开发人员被要求创建一个 AWS Lambda 函数，该函数在 Amazon DynamoDB 表中的项目更新时被调用。函数已创建，并已向 Lambda 执行角色添加了适当的权限。DynamoDB 表已启用了 DynamoDB 流，但函数仍未被调用。哪种选项可以使 DynamoDB 表更新调用 Lambda 函数？",
    "options": {
      "A": {
        "option": "将 DynamoDB 表的 StreamViewType 参数值更改为 NEW_AND_OLD_IMAGES。",
        "reason": "虽然 NEW_AND_OLD_IMAGES 确保 DynamoDB 流包含项目更新前后的图像，但这并不是触发 Lambda 函数调用的必要条件。实际上，任何 StreamViewType 都能触发 Lambda 调用，只要事件源映射正确配置。"
      },
      "B": {
        "option": "为 Lambda 函数配置事件源映射。",
        "reason": "要使 DynamoDB 表更新触发 Lambda 函数，必须配置事件源映射。这将 DynamoDB 流与 Lambda 函数关联，确保当 DynamoDB 表中的项目发生变化时，Lambda 函数被调用。"
      },
      "C": {
        "option": "将 Amazon Simple Notification Service (Amazon SNS) 主题映射到 DynamoDB 流。",
        "reason": "将 SNS 主题映射到 DynamoDB 流不能直接解决问题。SNS 主要用于消息分发，而不是直接触发 Lambda 函数。"
      },
      "D": {
        "option": "增加 Lambda 函数的最大运行时间（超时）设置。",
        "reason": "增加 Lambda 函数的超时设置不会解决函数未被调用的问题。超时设置仅影响函数的执行时间，而不是触发方式。"
      }
    }
  },
  {
    "number": "186",
    "best": ["B"],
    "question": "开发人员需要使用 Amazon ECS 在 AWS Fargate 上部署一个应用程序。该应用程序有一些环境变量，必须传递给容器以便应用程序初始化。应该如何将环境变量传递给容器？",
    "options": {
      "A": {
        "option": "在服务定义中的 environment 参数下定义一个包含环境变量的数组。",
        "reason": "服务定义中没有 environment 参数，因此不能在这里定义环境变量。"
      },
      "B": {
        "option": "在任务定义中的 environment 参数下定义一个包含环境变量的数组。",
        "reason": "这是正确的答案。在 Amazon ECS 中，环境变量是通过任务定义中的 environment 参数传递给容器的。这符合 AWS 的最佳实践和官方文档。"
      },
      "C": {
        "option": "在任务定义中的 entryPoint 参数下定义一个包含环境变量的数组。",
        "reason": "entryPoint 参数用于定义容器启动时执行的命令，而不是传递环境变量。"
      },
      "D": {
        "option": "在服务定义中的 entryPoint 参数下定义一个包含环境变量的数组。",
        "reason": "entryPoint 参数在服务定义中不存在，并且即使存在也不是用于传递环境变量的。"
      }
    }
  },
  {
    "number": "187",
    "best": ["A", "B"],
    "question": "开发团队使用一个单一的 AWS RDS 模板来维护一个 Web 应用程序。模板定义了 Web 服务器和一个 Amazon RDS 数据库。团队使用 CloudFormation 模板将 CloudFormation 栈部署到不同的环境中。在最近的一次应用程序部署过程中，一名开发人员导致主开发数据库被删除并重新创建。这次事件导致了数据丢失。团队需要避免将来发生意外的数据库删除。哪些解决方案可以满足这些要求？（选择两个。）",
    "options": {
      "A": {
        "option": "在数据库资源中添加一个 CloudFormation DeletionPolicy 属性，并将其值设置为 Retain。",
        "reason": "在数据库资源中添加 DeletionPolicy 属性并将其值设置为 Retain 可以防止数据库被意外删除。这意味着即使删除 CloudFormation 栈，数据库也会被保留，而不会被删除。因此，这是一个有效的解决方案。"
      },
      "B": {
        "option": "更新 CloudFormation 栈策略以防止对数据库的更新。",
        "reason": "更新 CloudFormation 栈策略以防止对数据库的更新可以避免开发人员意外删除或更新数据库。这是通过限制对数据库资源的特定操作来增加保护的一种方式，因此也是一个有效的解决方案。"
      },
      "C": {
        "option": "将数据库修改为使用 Multi-AZ 部署。",
        "reason": "Multi-AZ 部署可以提高数据库的可用性和容错能力，但它并不能防止数据库被意外删除。因此，这不是解决意外删除问题的最佳选择。"
      },
      "D": {
        "option": "为 Web 应用程序和数据库部署创建一个 CloudFormation 栈集。",
        "reason": "CloudFormation 栈集用于跨多个账户和区域部署 CloudFormation 栈，但这并不能防止数据库被意外删除。因此，这不是解决意外删除问题的最佳选择。"
      },
      "E": {
        "option": "在栈中添加一个 CloudFormation DeletionPolicy 属性，并将其值设置为 Retain。",
        "reason": "DeletionPolicy 属性只能应用于资源级别，而不是栈级别。因此，这不是一个有效的解决方案。"
      }
    }
  },
  {
    "number": "188",
    "best": ["B"],
    "question": "开发人员正在将应用程序生成的敏感数据存储在 Amazon S3 中。开发人员希望对静态数据进行加密。公司政策要求对 AWS Key Management Service (AWS KMS) 密钥的使用时间和使用者进行审计。哪种加密选项可以满足这些要求？",
    "options": {
      "A": {
        "option": "使用 Amazon S3 管理密钥的服务器端加密 (SSE-S3)",
        "reason": "SSE-S3 使用 Amazon S3 管理的密钥进行加密，但不提供对密钥使用情况的详细审计记录，因此不符合公司政策要求。"
      },
      "B": {
        "option": "使用 AWS KMS 管理密钥的服务器端加密 (SSE-KMS)",
        "reason": "SSE-KMS 使用 AWS KMS 管理的密钥进行加密，并且 AWS KMS 提供对密钥使用情况的详细审计记录，包括使用时间和使用者。这个选项符合公司政策要求，因此是最佳选择。"
      },
      "C": {
        "option": "使用客户提供的密钥的服务器端加密 (SSE-C)",
        "reason": "SSE-C 需要客户提供和管理密钥，虽然可以加密数据，但 AWS 不会提供密钥使用的详细审计记录，因此不符合公司政策要求。"
      },
      "D": {
        "option": "使用自我管理密钥的服务器端加密",
        "reason": "使用自我管理密钥进行加密需要用户自己管理和保护密钥，并且 AWS 不提供密钥使用的详细审计记录，因此不符合公司政策要求。"
      }
    }
  },
  {
    "number": "189",
    "best": ["A"],
    "question": "一家公司有一个电子商务应用程序。为了跟踪产品评论，公司的开发团队使用了一个 Amazon DynamoDB 表。每条记录包括以下内容：• 一个 16 位的全球唯一标识符 (UUID) 的评论 ID • 一个 16 位的 UUID 的产品 ID 和用户 ID，引用其他表 • 一个 1-5 级别的产品评分 • 用户的可选评论 该表的分区键是评论 ID。对该表执行最多的查询是查找给定产品的评分最高的 10 条评论。哪种索引将为这个查询提供最快的响应？",
    "options": {
      "A": {
        "option": "一个全局二级索引 (GSI)，使用产品 ID 作为分区键，产品评分作为排序键",
        "reason": "为了查找给定产品的评分最高的 10 条评论，最佳方法是使用全局二级索引 (GSI)，其中产品 ID 作为分区键，产品评分作为排序键。这将允许我们快速检索按评分排序的评论，并且只需获取前 10 条记录即可。全局二级索引 (GSI) 允许我们按不同于主键的属性进行高效查询，非常适合这种场景。"
      },
      "B": {
        "option": "一个全局二级索引 (GSI)，使用产品 ID 作为分区键，评论 ID 作为排序键",
        "reason": "虽然这个选项可以基于产品 ID 进行查询，但由于评论 ID 作为排序键，并不能直接按照产品评分排序，因此不适合快速查找评分最高的评论。"
      },
      "C": {
        "option": "一个本地二级索引 (LSI)，使用产品 ID 作为分区键，产品评分作为排序键",
        "reason": "本地二级索引 (LSI) 只能在创建表时定义，并且只能在与主表相同的分区键上使用。在这种情况下，表的分区键是评论 ID，而不是产品 ID，因此不能使用 LSI 来实现查询需求。"
      },
      "D": {
        "option": "一个本地二级索引 (LSI)，使用评论 ID 作为分区键，产品 ID 作为排序键",
        "reason": "本地二级索引 (LSI) 在这种场景中同样不适用。虽然它可以在主表的分区键上进行不同的排序，但这里的需求是基于产品 ID 查询，并按评分排序。因此这个索引不适合快速找到评分最高的评论。"
      }
    }
  },
  {
    "number": "190",
    "best": ["A"],
    "question": "公司需要向全球客户分发固件更新。哪项服务能以最低成本实现对下载访问的轻松和安全控制？",
    "options": {
      "A": {
        "option": "使用带有 Amazon S3 的 Amazon CloudFront 签名 URL。",
        "reason": "使用 Amazon CloudFront 和带有签名 URL 的 S3 可以提供安全的内容分发，同时确保只有授权用户可以访问下载。CloudFront 作为内容分发网络（CDN），能够以低延迟和高吞吐量将内容分发到全球，签名 URL 则确保了访问控制的安全性。这种方式成本较低，因为只需配置一个 CloudFront 分配和管理签名 URL。"
      },
      "B": {
        "option": "为每个客户创建一个专用的 Amazon CloudFront 分配。",
        "reason": "为每个客户创建一个专用的 CloudFront 分配将会非常昂贵且难以管理。每个分配都需要单独配置和维护，这对成本和运营效率来说都是不利的。"
      },
      "C": {
        "option": "使用 Amazon CloudFront 和 AWS Lambda@Edge。",
        "reason": "虽然 Lambda@Edge 可以在 CloudFront 分配中执行自定义逻辑，但它增加了复杂性和成本。对于只需要简单的访问控制和内容分发的场景，使用 Lambda@Edge 可能是过度设计。"
      },
      "D": {
        "option": "使用 Amazon API Gateway 和 AWS Lambda 来控制对 S3 存储桶的访问。",
        "reason": "使用 API Gateway 和 Lambda 可以实现对 S3 存储桶的访问控制，但这种方法比直接使用 CloudFront 更复杂和昂贵。API Gateway 和 Lambda 适用于需要复杂业务逻辑的场景，而对于简单的内容分发和访问控制，CloudFront 和签名 URL 是更好的选择。"
      }
    }
  },
  {
    "number": "191",
    "best": ["B"],
    "question": "开发人员正在测试一个异步调用 AWS Lambda 函数的应用程序。在测试阶段，Lambda 函数在两次重试后仍然处理失败。开发人员如何排查失败原因？",
    "options": {
      "A": {
        "option": "配置 AWS CloudTrail 日志以调查调用失败。",
        "reason": "AWS CloudTrail 主要用于记录 AWS 账户中的 API 调用和相关活动。虽然它可以提供调用的历史记录，但并不直接帮助解决 Lambda 函数的故障问题，因此不太适合此场景。"
      },
      "B": {
        "option": "通过将事件发送到 Amazon SQS 配置死信队列进行调查。",
        "reason": "配置死信队列（Dead Letter Queue, DLQ）是处理 Lambda 函数失败的最佳实践之一。当 Lambda 函数多次重试失败时，可以将失败的事件发送到 Amazon SQS 队列进行调查和后续处理。这有助于开发人员查看和分析未能成功处理的事件。"
      },
      "C": {
        "option": "配置 Amazon Simple Workflow Service 处理任何未处理的事件。",
        "reason": "Amazon Simple Workflow Service (SWF) 主要用于构建和运行分布式应用程序。它不是专门用于处理 Lambda 函数失败的工具，因此不太适合此场景。"
      },
      "D": {
        "option": "配置 AWS Config 处理任何未处理的事件。",
        "reason": "AWS Config 主要用于记录和审计 AWS 资源的配置变化，帮助评估配置是否符合预期。它并不适用于处理 Lambda 函数的未处理事件，因此不适合此场景。"
      }
    }
  },
  {
    "number": "192",
    "best": ["B"],
    "question": "一家公司正在将其 PostgreSQL 数据库迁移到 AWS 云中。该公司希望使用一种能够保护和定期轮换数据库凭证的数据库解决方案，并且不需要额外的编程开销。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "使用 Amazon Aurora PostgreSQL 作为数据库。将数据库凭证存储在 AWS Systems Manager 参数存储中。开启轮换。",
        "reason": "虽然 AWS Systems Manager 参数存储可以存储数据库凭证，但它的轮换功能不如 AWS Secrets Manager 自动化。需要额外的脚本编写来实现定期轮换。"
      },
      "B": {
        "option": "使用 Amazon Aurora PostgreSQL 作为数据库。将数据库凭证存储在 AWS Secrets Manager 中。开启轮换。",
        "reason": "AWS Secrets Manager 专门设计用于安全存储和管理敏感信息，如数据库凭证。它提供内置的自动轮换功能，非常适合此场景，不需要额外的编程开销。"
      },
      "C": {
        "option": "使用 Amazon DynamoDB 作为数据库。将数据库凭证存储在 AWS Systems Manager 参数存储中。开启轮换。",
        "reason": "虽然 AWS Systems Manager 参数存储可以存储数据库凭证，但使用 DynamoDB 作为数据库不符合题目要求。题目明确提到迁移的是 PostgreSQL 数据库。"
      },
      "D": {
        "option": "使用 Amazon DynamoDB 作为数据库。将数据库凭证存储在 AWS Secrets Manager 中。开启轮换。",
        "reason": "虽然 AWS Secrets Manager 适合存储和轮换数据库凭证，但使用 DynamoDB 作为数据库不符合题目要求。题目明确提到迁移的是 PostgreSQL 数据库。"
      }
    }
  },
  {
    "number": "193",
    "best": ["D"],
    "question": "一名开发人员正在创建一个不需要用户登录的移动应用程序。最有效的方法是什么来授予用户访问 AWS 资源的权限？",
    "options": {
      "A": {
        "option": "使用身份提供商安全地进行应用程序认证。",
        "reason": "身份提供商通常用于需要用户身份验证的场景，而题目明确指出不需要用户登录，因此这个选项并不合适。"
      },
      "B": {
        "option": "创建一个 AWS Lambda 函数，当用户访问应用程序时创建一个 IAM 用户。",
        "reason": "这种方法效率低下且不安全。创建大量 IAM 用户会增加管理复杂性和安全风险。"
      },
      "C": {
        "option": "使用 AWS KMS 创建凭证，并在用户使用应用程序时将这些凭证应用于用户。",
        "reason": "AWS KMS 用于密钥管理，不是用于生成用户凭证的最佳工具。此外，这样的方案在管理和安全性上也不理想。"
      },
      "D": {
        "option": "使用 Amazon Cognito 将未认证用户与具有有限资源访问权限的 IAM 角色关联。",
        "reason": "Amazon Cognito 提供了一种有效的方法来管理未认证用户，并可以将他们与具有有限权限的 IAM 角色关联。这符合题目需求，是最优选项。"
      }
    }
  },
  {
    "number": "194",
    "best": ["C"],
    "question": "在部署新的无服务器应用程序之前，开发人员应完成哪一步？",
    "options": {
      "A": {
        "option": "将应用程序压缩成.zip文件并上传到AWS Lambda。",
        "reason": "虽然AWS Lambda支持通过.zip文件上传函数代码，但这并不是使用AWS SAM CLI部署无服务器应用程序的标准步骤。"
      },
      "B": {
        "option": "首先在AWS X-Ray中跟踪新AWS Lambda函数进行测试。",
        "reason": "使用AWS X-Ray进行跟踪和测试可以帮助了解函数性能，但这不是部署应用程序的前提步骤。"
      },
      "C": {
        "option": "使用SAM package打包无服务器应用程序。",
        "reason": "在使用AWS SAM CLI部署无服务器应用程序之前，正确的步骤是使用`sam package`命令打包应用程序。这会创建一个由AWS CloudFormation支持的部署包。"
      },
      "D": {
        "option": "使用eb create my-env命令创建应用程序环境。",
        "reason": "`eb create my-env`命令是用于AWS Elastic Beanstalk的，与AWS SAM CLI和无服务器应用程序部署无关。"
      }
    }
  },
  {
    "number": "195",
    "best": ["B"],
    "question": "公司希望自动化部分部署流程。开发人员需要自动化检查和删除支持以前部署的堆栈但不再使用的未使用资源的过程。公司有一个使用 AWS Cloud Development Kit (AWS CDK) 管理所有部署堆栈的中央应用程序。堆栈分布在多个账户中。开发人员的解决方案必须尽可能无缝地集成到当前的部署过程中。哪种解决方案能够以最少的配置满足这些要求？",
    "options": {
      "A": {
        "option": "在中央 AWS CDK 应用程序中，编写一个使用 AWS SDK 调用检查和删除未使用资源的处理函数。从一个 JSON 文件创建一个 AWS CloudFormation 模板。使用该模板将函数代码附加到 AWS Lambda 函数，并在部署堆栈运行时调用 Lambda 函数。",
        "reason": "虽然这种方法可以实现目标，但需要额外的步骤来生成 CloudFormation 模板并在部署堆栈中调用它，增加了配置复杂性。"
      },
      "B": {
        "option": "在中央 AWS CDK 应用程序中，编写一个使用 AWS SDK 调用检查和删除未使用资源的处理函数。创建一个 AWS CDK 自定义资源。使用自定义资源将函数代码附加到 AWS Lambda 函数，并在部署堆栈运行时调用 Lambda 函数。",
        "reason": "这种方法在现有的 AWS CDK 应用程序中实现了最无缝的集成。自定义资源可以轻松地与 AWS Lambda 集成，并在部署堆栈运行时调用，减少了配置复杂性。"
      },
      "C": {
        "option": "在中央 AWS CDK 中，编写一个使用 AWS SDK 调用检查和删除未使用资源的处理函数。创建一个 AWS Amplify API。使用该 API 将函数代码附加到 AWS Lambda 函数，并在部署堆栈运行时调用 Lambda 函数。",
        "reason": "这种方法引入了 AWS Amplify 作为额外的服务，增加了配置复杂性，不符合最少配置的要求。"
      },
      "D": {
        "option": "在 AWS Lambda 控制台中，编写一个使用 AWS SDK 调用检查和删除未使用资源的处理函数。创建一个 AWS CDK 自定义资源。使用自定义资源将 Lambda 函数导入堆栈，并在部署堆栈运行时调用 Lambda 函数。",
        "reason": "这种方法要求在 AWS Lambda 控制台中单独编写代码，而不是在 AWS CDK 应用程序中实现，增加了配置步骤，不符合最少配置的要求。"
      }
    }
  },
  {
    "number": "196",
    "best": ["C"],
    "question": "一家公司在 AWS 云中构建了一个新应用程序。该公司通过使用 AWS CloudFormation 模板自动化新资源的引导。引导脚本包含敏感数据。公司需要一种与 CloudFormation 集成的解决方案来管理引导脚本中的敏感数据。哪种解决方案最能满足这些需求，并且是最安全的方式？",
    "options": {
      "A": {
        "option": "将敏感数据放入 CloudFormation 参数中。使用 AWS Key Management Service (AWS KMS) 密钥加密 CloudFormation 模板。",
        "reason": "虽然使用 KMS 加密 CloudFormation 模板可以提供一定的安全性，但 CloudFormation 参数本身在模板中是明文的，无法确保敏感数据的完全安全性。"
      },
      "B": {
        "option": "将敏感数据放入 Amazon S3 存储桶中。在引导期间更新 CloudFormation 模板以从 Amazon S3 下载对象。",
        "reason": "将敏感数据放入 S3 并非最佳实践，因为这需要额外的步骤来确保 S3 对象的安全性和访问控制，增加了复杂性和潜在的安全风险。"
      },
      "C": {
        "option": "将敏感数据放入 AWS Systems Manager Parameter Store 作为安全字符串参数。更新 CloudFormation 模板以使用动态引用来指定模板值。",
        "reason": "AWS Systems Manager Parameter Store 的安全字符串参数可以安全地存储和访问敏感数据。动态引用允许 CloudFormation 在不暴露敏感数据的情况下访问参数，这是最安全和集成度最高的解决方案。"
      },
      "D": {
        "option": "将敏感数据放入 Amazon Elastic File System (Amazon EFS)。在文件系统创建后强制 EFS 加密。更新 CloudFormation 模板以从 Amazon EFS 检索数据。",
        "reason": "使用 EFS 存储敏感数据并不是最佳选择，因为这增加了管理和访问复杂性。EFS 更适合于共享文件系统，而不是敏感数据的安全存储和管理。"
      }
    }
  },
  {
    "number": "197",
    "best": ["D"],
    "question": "公司需要为其所有 AWS 云资源设置安全的数据库凭证。公司的资源包括 Amazon RDS 数据库实例、Amazon DocumentDB 集群和 Amazon Aurora 数据库实例。公司的安全策略要求数据库凭证必须静态加密并定期轮换。哪种解决方案最安全地满足这些要求？",
    "options": {
      "A": {
        "option": "设置 IAM 数据库身份验证以进行基于令牌的访问。生成用户令牌以提供对 RDS 数据库实例、Amazon DocumentDB 集群和 Aurora 数据库实例的集中访问。",
        "reason": "此选项涉及 IAM 数据库身份验证和基于令牌的访问，但没有提到凭证的静态加密和自动轮换，因此不符合公司安全策略的全部要求。IAM 数据库身份验证主要用于简化用户管理，但不直接管理静态加密和定期轮换。"
      },
      "B": {
        "option": "在 AWS Systems Manager 参数存储中为数据库凭证创建参数。将 Type 参数设置为 SecureString。设置参数的自动轮换。",
        "reason": "此选项涉及使用 AWS Systems Manager 参数存储和 SecureString 类型来存储加密的数据库凭证，但 AWS Systems Manager 参数存储本身并不提供自动凭证轮换功能，必须由用户自定义脚本或其他方式实现，因此不完全满足定期轮换的要求。"
      },
      "C": {
        "option": "将数据库访问凭证作为加密的 Amazon S3 对象存储在 S3 存储桶中。阻止 S3 存储桶的所有公共访问。使用 S3 服务器端加密设置加密密钥的自动轮换。",
        "reason": "此选项涉及将凭证存储在 S3 中并使用服务器端加密进行保护，但 S3 本身不提供自动凭证轮换功能，只能针对加密密钥进行轮换，并且需要额外的逻辑来管理数据库凭证的更新，因此不完全符合要求。"
      },
      "D": {
        "option": "在 AWS Secrets Manager 控制台中使用 SecretsManagerRotationTemplate 模板创建一个 AWS Lambda 函数。在 Secrets Manager 中为数据库凭证创建秘密。按计划设置秘密轮换。",
        "reason": "此选项使用 AWS Secrets Manager 存储和管理数据库凭证，并使用 SecretsManagerRotationTemplate 模板创建的 Lambda 函数来自动轮换秘密。Secrets Manager 提供集成的加密和自动轮换功能，完全符合公司对静态加密和定期轮换的安全要求。因此，这是最符合要求的解决方案。"
      }
    }
  },
  {
    "number": "198",
    "best": ["D"],
    "question": "开发人员创建了一个 AWS Lambda 函数，该函数对 Amazon Aurora MySQL DB 实例进行查询。当开发人员进行测试时，DB 实例显示连接过多的错误。哪种解决方案可以以最少的运营工作量满足这些需求？",
    "options": {
      "A": {
        "option": "为 DB 实例创建一个只读副本。查询副本 DB 实例而不是主 DB 实例。",
        "reason": "创建只读副本可以分散读请求，从而减轻主实例的压力。但是，这并不能解决连接数过多的问题，只是将部分读流量转移到了副本上。此方案的运营工作量较大，因为需要管理和同步副本。"
      },
      "B": {
        "option": "将数据迁移到 Amazon DynamoDB 数据库。",
        "reason": "将数据迁移到 DynamoDB 是一个更彻底的解决方案，因为 DynamoDB 是无服务器的并且可以自动扩展以处理大量请求。但是，这会带来大量的迁移工作和代码修改，运营工作量较大。"
      },
      "C": {
        "option": "将 Amazon Aurora MySQL DB 实例配置为多可用区部署。",
        "reason": "多可用区部署可以提高数据库的可用性和容错能力，但并不能解决连接数过多的问题。因此，这并不是最合适的解决方案。"
      },
      "D": {
        "option": "在 Amazon RDS Proxy 中创建一个代理。查询代理而不是 DB 实例。",
        "reason": "Amazon RDS Proxy 可以有效管理数据库连接池，减少数据库连接数过多的问题。它可以缓存和重用数据库连接，这样 Lambda 函数就不需要频繁打开和关闭数据库连接，从而减轻数据库的负担。此方案的运营工作量最小，因为 RDS Proxy 是一个托管服务，配置和管理都很简单。"
      }
    }
  },
  {
    "number": "199",
    "best": ["D"],
    "question": "一名开发人员正在使用 Amazon API Gateway 和 AWS Lambda 创建一个新的 REST API。开发团队在将 API 部署到生产环境之前，测试了 API 并验证了已知用例的响应。开发人员希望通过本地使用 API Gateway 来测试 REST API。哪一个 AWS Serverless Application Model Command Line Interface (AWS SAM CLI) 子命令可以满足这些需求？",
    "options": {
      "A": {
        "option": "Sam local invoke",
        "reason": "该命令用于在本地调用 Lambda 函数，但不包括本地启动 API Gateway 服务。"
      },
      "B": {
        "option": "Sam local generate-event",
        "reason": "该命令用于生成各种 AWS 事件以测试 Lambda 函数，但不涉及启动 API Gateway。"
      },
      "C": {
        "option": "Sam local start-lambda",
        "reason": "该命令用于本地启动 Lambda 运行时环境，但不会启动 API Gateway。"
      },
      "D": {
        "option": "Sam local start-api",
        "reason": "该命令用于本地启动 API Gateway 服务，使开发人员能够测试 REST API。"
      }
    }
  },
  {
    "number": "200",
    "best": ["B"],
    "question": "一家公司在 AWS 上有一个无服务器应用程序，该应用程序使用一组带有别名的 AWS Lambda 函数。该公司定期通过内部部署解决方案发布新的 Lambda 函数。公司希望改进发布流程并使用流量转移。新发布的函数版本应最初仅对固定比例的生产用户可用。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "使用加权别名在新函数的别名上配置路由。",
        "reason": "加权别名确实允许流量以特定的百分比转移到新的 Lambda 版本，但它不是一个完整的部署策略，且需要手动设置和管理。"
      },
      "B": {
        "option": "为 Lambda 配置金丝雀部署类型。",
        "reason": "金丝雀部署允许以特定百分比的流量转移到新版本，并在验证新版本的稳定性后逐步增加流量。这种方法最符合题目要求，能够有效地进行流量转移和版本发布。"
      },
      "C": {
        "option": "使用环境变量在新版本上配置路由。",
        "reason": "环境变量通常用于配置 Lambda 的运行时设置，而不是用于流量路由和版本管理。"
      },
      "D": {
        "option": "为 Lambda 配置线性部署类型。",
        "reason": "线性部署类型可以逐步增加新版本的流量，但它不是在初始阶段将流量限制在固定百分比的最佳方法。金丝雀部署更适合这种情况。"
      }
    }
  },
  {
    "number": "201",
    "best": ["D"],
    "question": "一家公司有一个应用程序，将数据存储在 Amazon RDS 实例中。该应用程序周期性地经历高流量激增，导致性能问题。在高峰流量期间，开发人员注意到所有数据库查询的查询速度下降。团队的技术负责人确定应该使用多线程和可扩展的缓存解决方案来减轻繁重的读取流量。该解决方案需要提高性能。哪个解决方案在最少复杂度的情况下满足这些要求？",
    "options": {
      "A": {
        "option": "使用 Amazon ElastiCache for Memcached 来减轻主数据库的读取请求。",
        "reason": "虽然 Memcached 是一种高效的缓存解决方案，但其不具备持久化和高级数据结构功能。对于需要更复杂数据处理和更强大持久化的应用，Redis 可能是更好的选择。"
      },
      "B": {
        "option": "将数据复制到 Amazon DynamoDB 并设置 DynamoDB Accelerator (DAX) 集群。",
        "reason": "将数据从 RDS 复制到 DynamoDB 然后使用 DAX 可能会带来额外的复杂性和数据一致性问题。这个过程涉及到数据迁移、同步等步骤，不是最简单的解决方案。"
      },
      "C": {
        "option": "配置 Amazon RDS 实例使用 Multi-AZ 部署，并有一个备用实例。从主数据库卸载读取请求到备用实例。",
        "reason": "Multi-AZ 部署的主要目的是提供高可用性和故障恢复，而不是在高流量期间处理读取负载。备用实例是热备份，仅在主实例发生故障时才会被激活，不适合平衡读取负载。"
      },
      "D": {
        "option": "使用 Amazon ElastiCache for Redis 来减轻主数据库的读取请求。",
        "reason": "ElastiCache for Redis 是一个多线程、可扩展的缓存解决方案，支持高级数据结构和持久化。它能够有效地减轻 RDS 的读取负载，提高查询性能，同时保持数据的一致性和高可用性。"
      }
    }
  },
  {
    "number": "202",
    "best": ["A"],
    "question": "开发人员必须为 AWS Lambda 函数提供一个 API 密钥，以便与第三方系统进行身份验证。Lambda 函数将按计划运行。开发人员需要确保 API 密钥在静止状态下保持加密。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "使用 AWS Key Management Service (AWS KMS) 客户管理密钥将 API 密钥作为 Lambda 环境变量存储。",
        "reason": "选项 A 提供了一种安全的方法来存储 API 密钥。AWS Key Management Service (KMS) 允许你加密敏感数据，如 API 密钥，并将其作为环境变量存储在 Lambda 函数中。这样可以确保密钥在静止状态下保持加密，并且只有在 Lambda 函数运行时才解密。这符合题目要求的加密和安全性需求。"
      },
      "B": {
        "option": "配置应用程序以在第一次运行时提示用户向 Lambda 函数提供密码。",
        "reason": "选项 B 不合适，因为它需要人工干预，而题目明确表示 Lambda 函数将按计划运行。这意味着无人值守操作是必要的，因此用户输入并不是一个可行的解决方案。"
      },
      "C": {
        "option": "将 API 密钥作为值存储在应用程序代码中。",
        "reason": "选项 C 不安全，因为将敏感信息硬编码到代码中是不推荐的做法。这不仅违反了最佳安全实践，而且还会增加泄露密钥的风险。"
      },
      "D": {
        "option": "使用 Lambda@Edge 并仅通过 HTTPS 协议进行通信。",
        "reason": "选项 D 并不完全符合题目要求。虽然使用 HTTPS 协议可以保护数据在传输中的安全性，但这并不能确保 API 密钥在静止状态下加密。此外，Lambda@Edge 主要用于在边缘位置运行 Lambda 函数，这与题目中提到的按计划运行的需求不完全相关。"
      }
    }
  },
  {
    "number": "203",
    "best": ["A"],
    "question": "某 IT 部门使用 Amazon S3 存储敏感图像。一年后，公司将这些图像转移到归档存储中。公司很少访问这些图像，但希望有一个最大化弹性的存储解决方案。IT 部门需要在 24 小时内访问已归档的图像。哪种解决方案最具成本效益地满足这些要求？",
    "options": {
      "A": {
        "option": "使用 S3 标准-不频繁访问 (S3 Standard-IA) 存储图像。使用 S3 Glacier Deep Archive 的标准检索来存储和检索归档图像。",
        "reason": "S3 Standard-IA 适用于不频繁访问的数据，且存储成本低。S3 Glacier Deep Archive 的标准检索可以在 12 小时内访问数据，满足 24 小时内访问的要求，同时成本较低，适合长期存储和归档数据。"
      },
      "B": {
        "option": "使用 S3 标准-不频繁访问 (S3 Standard-IA) 存储图像。使用 S3 Glacier Deep Archive 的批量检索来存储和检索归档图像。",
        "reason": "虽然 S3 Glacier Deep Archive 的批量检索成本最低，但检索时间通常在 48 小时内，无法满足 24 小时内访问数据的要求。"
      },
      "C": {
        "option": "使用 S3 智能分层 (S3 Intelligent-Tiering) 存储图像。使用 S3 Glacier Deep Archive 的标准检索来存储和检索归档图像。",
        "reason": "S3 Intelligent-Tiering 可以自动在不同存储层之间移动数据，但其成本高于 S3 Standard-IA。虽然同样使用 S3 Glacier Deep Archive 的标准检索，但总体成本效益不如选项 A。"
      },
      "D": {
        "option": "使用 S3 单区-不频繁访问 (S3 One Zone-IA) 存储图像。使用 S3 Glacier Deep Archive 的批量检索来存储和检索归档图像。",
        "reason": "S3 One Zone-IA 仅在单个可用区存储数据，弹性较低，不适合存储敏感数据。另外，S3 Glacier Deep Archive 的批量检索无法满足 24 小时内访问的要求。"
      }
    }
  },
  {
    "number": "204",
    "best": ["A"],
    "question": "开发人员正在使用 AWS 无服务器应用程序模型（AWS SAM）构建无服务器应用程序。开发人员目前正在开发环境中测试该应用程序。当应用程序接近完成时，开发人员需要为质量保证团队设置额外的测试和暂存环境。开发人员希望使用 AWS SAM 的一个功能来设置多个环境的部署。哪种解决方案以最少的开发工作量满足这些要求？",
    "options": {
      "A": {
        "option": "添加一个 TOML 格式的配置文件，以将配置条目分组到每个环境中。为每个测试和暂存环境添加一个表。使用 sam deploy 命令和对应于每个环境的 --config-env 标志将更新部署到环境中。",
        "reason": "选项 A 使用了 AWS SAM 的内置功能，可以通过简单地添加一个 TOML 配置文件来管理不同环境的配置。这种方法减少了额外模板和脚本的创建工作量，同时使用 --config-env 标志可以方便地部署到不同的环境，符合题目中要求的“最少的开发工作量”。"
      },
      "B": {
        "option": "为每个测试和暂存环境创建额外的 AWS SAM 模板。编写一个自定义 shell 脚本，使用 sam deploy 命令和 --template-file 标志将更新部署到环境中。",
        "reason": "选项 B 虽然有效，但需要为每个环境创建额外的模板和自定义脚本，这增加了开发工作量，不符合题目中要求的“最少的开发工作量”。"
      },
      "C": {
        "option": "创建一个具有默认参数的 AWS SAM 配置文件。使用 AWS SAM CLI 中的 --parameter-overrides 标志和更新将覆盖的参数对测试和暂存环境进行更新。",
        "reason": "选项 C 使用参数覆盖的方法，但这仍需要手动管理和指定参数，增加了部署过程中的复杂性和可能的错误，不如选项 A 简单直接。"
      },
      "D": {
        "option": "使用现有的 AWS SAM 模板。添加额外的参数来配置每个环境中的无服务器功能和数据库表资源的特定属性。使用 sam deploy 命令将更新部署到测试和暂存环境中。",
        "reason": "选项 D 需要在现有模板中添加额外的参数来配置每个环境，这增加了管理和维护的复杂性，开发工作量也较大，不符合题目中要求的“最少的开发工作量”。"
      }
    }
  },
  {
    "number": "205",
    "best": ["C"],
    "question": "一名开发人员正在开发一个应用程序，该应用程序处理来自 IoT 设备的操作数据。每个 IoT 设备每小时向 Amazon S3 存储桶上传一个数据文件。开发人员希望在数据文件上传到 Amazon S3 后立即处理每个数据文件。开发人员将使用 AWS Lambda 函数处理来自 Amazon S3 的数据文件。Lambda 函数配置了文件上传的 S3 存储桶信息。开发人员希望在每个数据文件上传后立即调用 Lambda 函数。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "添加异步调用到 Lambda 函数。选择 S3 存储桶作为源。",
        "reason": "异步调用并不能自动触发 Lambda 函数。需要其他机制（如事件触发器）来实现自动化。"
      },
      "B": {
        "option": "向 Lambda 函数添加 Amazon EventBridge 事件。选择 S3 存储桶作为源。",
        "reason": "EventBridge 用于管理事件流和事件总线。虽然可以用它来处理 S3 事件，但这不是最直接和简便的方式。"
      },
      "C": {
        "option": "向 Lambda 函数添加一个触发器。选择 S3 存储桶作为源。",
        "reason": "这是最适合的解决方案。通过在 Lambda 函数中添加 S3 触发器，当文件上传到 S3 存储桶时，Lambda 函数会自动被触发来处理上传的文件。"
      },
      "D": {
        "option": "向 Lambda 函数添加一个层。选择 S3 存储桶作为源。",
        "reason": "Lambda 层用于共享代码和依赖项，不能用于触发 Lambda 函数。"
      }
    }
  },
  {
    "number": "206",
    "best": ["B"],
    "question": "开发人员正在使用 AWS CloudFormation 设置基础设施。如果在 CloudFormation 模板中描述的资源配置时发生错误，必须保留已成功配置的资源。开发人员必须使用 AWS CLI 配置和更新 CloudFormation 堆栈。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "在 create-stack 命令和 update-stack 命令中添加 --enable-termination-protection 命令行选项。",
        "reason": "启用终止保护选项可防止堆栈被意外删除，但并不能在资源配置出错时保留已成功配置的资源。"
      },
      "B": {
        "option": "在 create-stack 命令和 update-stack 命令中添加 --disable-rollback 命令行选项。",
        "reason": "禁用回滚选项会在资源配置出错时保留已成功配置的资源。这正是题目要求的行为，因此是最佳选择。"
      },
      "C": {
        "option": "在 create-stack 命令和 update-stack 命令中添加 --parameters ParameterKey=PreserveResources,ParameterValue=True 命令行选项。",
        "reason": "该选项并不存在于 AWS CLI 中，不是有效的解决方案。"
      },
      "D": {
        "option": "在 create-stack 命令和 update-stack 命令中添加 --tags Key=PreserveResources,Value=True 命令行选项。",
        "reason": "标签选项用于标记资源，并不会影响资源配置失败时的行为，因此不是有效的解决方案。"
      }
    }
  },
  {
    "number": "207",
    "best": ["C"],
    "question": "开发人员正在构建一个连接到 Amazon Aurora PostgreSQL 数据库的无服务器应用程序。该无服务器应用程序由数百个 AWS Lambda 函数组成。每次 Lambda 函数扩展时，都会创建一个新的数据库连接，这会增加数据库资源消耗。开发人员需要减少与数据库建立连接的数量。该解决方案不得影响 Lambda 函数的可扩展性。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "通过设置 ProvisionedConcurrentExecutions 参数为 10，为每个 Lambda 函数配置预置并发。",
        "reason": "配置预置并发可以确保有一定数量的并发实例预先启动，但这并不能减少数据库连接的数量，反而可能会因为更多的并发实例而增加数据库负载。"
      },
      "B": {
        "option": "为 Aurora PostgreSQL 启用集群缓存管理。更改每个 Lambda 函数的连接字符串以指向集群缓存管理。",
        "reason": "集群缓存管理主要用于提高查询性能和减少读取延迟，但并不能直接解决数据库连接数量的问题。"
      },
      "C": {
        "option": "使用 Amazon RDS Proxy 创建一个连接池来管理数据库连接。更改每个 Lambda 函数的连接字符串以引用代理。",
        "reason": "Amazon RDS Proxy 能够池化和管理数据库连接，从而减少数据库连接的数量，同时保持 Lambda 函数的可扩展性。它是针对这种情况的最佳选择。"
      },
      "D": {
        "option": "通过设置 ReservedConcurrentExecutions 参数为 10，为每个 Lambda 函数配置保留并发。",
        "reason": "保留并发可以确保一定数量的并发实例，但它不能减少数据库连接的数量，反而可能会因为更多的并发实例而增加数据库负载。"
      }
    }
  },
  {
    "number": "208",
    "best": ["A"],
    "question": "一位开发人员正在准备开发一个新版本的应用程序。应用程序的前一个版本已经部署在生产环境中。在开发新版本应用程序的过程中，开发人员需要对当前版本进行修复和更新。新版本应用程序的代码存储在AWS CodeCommit中。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "从主分支创建一个用于生产错误修复的功能分支。从主分支创建第二个用于新版本开发的功能分支。",
        "reason": "此选项允许开发人员在独立的分支上进行生产错误修复和新版本的开发，从而避免相互影响。这种方法符合Git的最佳实践，能有效管理代码的不同开发阶段。"
      },
      "B": {
        "option": "对当前部署在生产环境中的代码创建一个Git标签。对新版本的开发创建一个Git标签。将这两个标签推送到CodeCommit存储库。",
        "reason": "此选项使用标签来区分不同版本，但标签通常用于标记特定的发布版本，而不是用于并行开发和错误修复管理。因此，这种方法不太适合当前的需求。"
      },
      "C": {
        "option": "从主分支创建当前部署在生产环境中的代码的分支。应用一个IAM策略，确保其他用户不能推送或合并到该分支。",
        "reason": "此选项创建了一个独立的分支来保护生产代码，但不允许其他用户推送或合并可能会限制团队协作，并且没有明确解决新版本开发的需求。因此，这并不是最优的解决方案。"
      },
      "D": {
        "option": "为新版本的开发创建一个新的CodeCommit存储库。为新版本的开发创建一个Git标签。",
        "reason": "创建一个新的存储库可能会导致代码库的分散管理，增加复杂性。标签通常用于标记特定的发布版本，而不是用于并行开发管理。因此，这种方法不太适合当前的需求。"
      }
    }
  },
  {
    "number": "209",
    "best": ["D"],
    "question": "一个开发人员正在创建一个 AWS CloudFormation 堆栈。堆栈包含具有自定义名称的 IAM 资源。当开发人员尝试部署堆栈时，他们收到 InsufficientCapabilities 错误。开发人员应该如何解决这个问题？",
    "options": {
      "A": {
        "option": "在 CloudFormation 堆栈中指定 CAPABILITY_AUTO_EXPAND 能力。",
        "reason": "CAPABILITY_AUTO_EXPAND 主要用于自动扩展宏，这与 IAM 资源的自定义名称无关，因此不能解决 InsufficientCapabilities 错误。"
      },
      "B": {
        "option": "使用管理员角色来部署具有 CloudFormation 的 IAM 资源。",
        "reason": "使用管理员角色可能会有助于获得必要的权限，但这不会解决 InsufficientCapabilities 错误，因为问题的根源在于需要显式声明 IAM 能力。"
      },
      "C": {
        "option": "在 CloudFormation 堆栈中指定 CAPABILITY_IAM 能力。",
        "reason": "CAPABILITY_IAM 允许 CloudFormation 创建或修改 IAM 资源，但对于具有自定义名称的 IAM 资源，应该使用 CAPABILITY_NAMED_IAM。"
      },
      "D": {
        "option": "在 CloudFormation 堆栈中指定 CAPABILITY_NAMED_IAM 能力。",
        "reason": "CAPABILITY_NAMED_IAM 是专门用于允许 CloudFormation 创建或修改具有自定义名称的 IAM 资源。这正是解决这个问题的正确选项，因为它允许 CloudFormation 堆栈处理具有自定义名称的 IAM 资源。"
      }
    }
  },
  {
    "number": "210",
    "best": ["D"],
    "question": "公司使用 Amazon API Gateway 向客户公开一组 API。这些 API 在 API Gateway 中启用了缓存。客户需要一种方法来在测试 API 时使每个 API 的缓存失效。开发人员应该怎么做才能让客户有能力使 API 缓存失效？",
    "options": {
      "A": {
        "option": "要求客户使用 AWS 凭证调用 InvalidateCache API 操作。",
        "reason": "要求客户使用 AWS 凭证直接调用 InvalidateCache API 操作是不合理的，因为这会暴露不必要的权限并增加安全风险。"
      },
      "B": {
        "option": "将 InvalidateCache 策略附加到客户用来调用 API 的 IAM 执行角色中。要求客户在发出 API 调用时发送包含 Cache-Control:max-age=0 HTTP 头的请求。",
        "reason": "通过 HTTP 头来控制缓存虽然可行，但这种方法不如直接使用 API Gateway 提供的缓存失效机制直观和可靠。"
      },
      "C": {
        "option": "要求客户使用 AWS SDK API Gateway 类调用 InvalidateCache API 操作。",
        "reason": "这与选项 A 类似，要求客户使用 SDK 直接调用 InvalidateCache API 操作也是不合理的，因为这会暴露过多权限并增加复杂性。"
      },
      "D": {
        "option": "将 InvalidateCache 策略附加到客户用来调用 API 的 IAM 执行角色中。要求客户在发出 API 调用时添加 INVALIDATE_CACHE 查询字符串参数。",
        "reason": "选项 D 是最优选择，因为它使用了 API Gateway 提供的缓存失效机制，并通过查询字符串参数让客户在调用 API 时能够方便地使缓存失效，同时保持安全性和简便性。"
      }
    }
  },
  {
    "number": "211",
    "best": ["C"],
    "question": "开发人员正在创建一个 AWS Lambda 函数，用于生成和导出文件。函数在运行时需要 100 MB 的临时存储空间用于临时文件。这些文件在函数完成后将不再需要。开发人员应如何最有效地处理这些临时文件？",
    "options": {
      "A": {
        "option": "将文件存储在 Amazon Elastic Block Store (Amazon EBS) 中，并在 Lambda 函数结束时删除这些文件。",
        "reason": "Amazon EBS 主要用于提供持久性块存储，对于临时文件存储而言不是最有效的方法，且需要进行额外的管理和清理。"
      },
      "B": {
        "option": "将文件复制到 Amazon Elastic File System (Amazon EFS)，并在 Lambda 函数结束时删除这些文件。",
        "reason": "Amazon EFS 是一个可扩展的文件存储服务，适用于需要跨多个实例共享数据的场景。对于临时文件存储而言，这种方式显得过于复杂且效率不高。"
      },
      "C": {
        "option": "将文件存储在 /tmp 目录中，并在 Lambda 函数结束时删除这些文件。",
        "reason": "Lambda 函数在执行期间提供一个 /tmp 目录用于存储临时文件，大小为 512 MB。对于需要临时存储的文件，这是最简单且最有效的方式，文件在函数结束后会自动删除。"
      },
      "D": {
        "option": "将文件复制到一个带有生命周期策略的 Amazon S3 存储桶中，以删除文件。",
        "reason": "虽然 Amazon S3 可以用于存储和管理文件，但对于需要短期临时存储的文件而言，这种方法显得过于复杂且成本较高。生命周期策略适用于管理长期文件存储。"
      }
    }
  },
  {
    "number": "212",
    "best": ["A"],
    "question": "公司使用 Amazon DynamoDB 作为其订单管理系统的数据存储。公司前端应用程序将订单存储在 DynamoDB 表中。DynamoDB 表配置为将更改事件发送到 DynamoDB 流。公司使用 AWS Lambda 函数根据来自 DynamoDB 流的数据记录和处理传入的订单。操作审查显示，传入订单的订单数量有时会设置为 0。开发人员需要创建一个仪表板，每天显示受此问题影响的唯一客户数量。开发人员应该如何实现这个仪表板？",
    "options": {
      "A": {
        "option": "授予 Lambda 函数的执行角色将日志上传到 Amazon CloudWatch Logs 的权限。实现一个 CloudWatch Logs Insights 查询，选择订单数量等于 0 的订单的唯一客户数量，并将结果按 1 天的周期分组。将 CloudWatch Logs Insights 查询添加到 CloudWatch 仪表板。",
        "reason": "此选项使用了 CloudWatch Logs Insights 查询来处理日志数据，并将结果分组到 CloudWatch 仪表板中。这是一个有效的解决方案，因为它利用了现有的日志记录机制，并且 CloudWatch Logs Insights 可以进行复杂的查询和分组。"
      },
      "B": {
        "option": "使用 Amazon Athena 查询 AWS CloudTrail API 日志以获取 API 调用。实现一个 Athena 查询，选择订单数量等于 0 的订单的唯一客户数量，并将结果按 1 天的周期分组。将 Athena 查询添加到 Amazon CloudWatch 仪表板。",
        "reason": "此选项涉及使用 Athena 查询 CloudTrail 日志。这是一个不太合适的解决方案，因为 CloudTrail 主要用于记录 API 调用而不是应用程序日志。此外，Athena 查询 CloudTrail 日志的延迟可能较高，不适合及时处理和显示数据。"
      },
      "C": {
        "option": "配置 Lambda 函数以将事件发送到 Amazon EventBridge。创建一个 EventBridge 规则，将订单数量等于 0 的订单的唯一客户数量按 1 天的周期分组。将 CloudWatch 仪表板作为规则的目标。",
        "reason": "此选项涉及使用 EventBridge 和 CloudWatch，但 EventBridge 主要用于事件驱动的应用程序集成，而不是日志处理和分析。这个方案需要额外的配置和开发工作，复杂度较高。"
      },
      "D": {
        "option": "为 DynamoDB 表的 DynamoDB 流打开自定义 Amazon CloudWatch 指标。创建一个 CloudWatch 警报，将订单数量等于 0 的订单的唯一客户数量按 1 天的周期分组。将 CloudWatch 警报添加到 CloudWatch 仪表板。",
        "reason": "此选项涉及创建自定义 CloudWatch 指标和警报。然而，CloudWatch 指标和警报适用于实时监控和告警，不太适合用于复杂的查询和分组分析。"
      }
    }
  },
  {
    "number": "213",
    "best": ["A", "E"],
    "question": "开发人员需要在开发环境中对 AWS Lambda 函数进行故障排除。该 Lambda 函数配置在 VPC 模式下，需要连接到现有的 Amazon RDS for SQL Server DB 实例。DB 实例部署在私有子网中，并通过端口 1433 接受连接。当开发人员测试该函数时，该函数在尝试连接到数据库时报告错误。开发人员应采取哪些步骤来诊断此问题？（选择两个）",
    "options": {
      "A": {
        "option": "检查函数的安全组是否具有通过端口 1433 访问 DB 实例的安全组的出站访问权限。检查 DB 实例的安全组是否具有从函数的安全组通过端口 1433 的入站访问权限。",
        "reason": "安全组配置是排查网络连接问题的关键步骤。Lambda 函数和 RDS 实例之间需要相互的安全组规则来允许流量通过指定端口（此处为 1433）。"
      },
      "B": {
        "option": "检查函数的安全组是否具有从 DB 实例的安全组通过端口 1433 的入站访问权限。检查 DB 实例的安全组是否具有到函数的安全组通过端口 1433 的出站访问权限。",
        "reason": "此选项不太正确，因为 Lambda 函数发起连接，因此需要确保 Lambda 函数的安全组有出站规则，而 RDS 实例的安全组有入站规则。"
      },
      "C": {
        "option": "检查 VPC 是否设置了 NAT 网关。检查 DB 实例是否打开了公共访问选项。",
        "reason": "此选项不适用，因为 RDS 实例已经在私有子网中，且不需要公共访问。NAT 网关也不相关，因为 Lambda 函数和 RDS 实例都在同一 VPC 内。"
      },
      "D": {
        "option": "检查函数的执行角色权限是否包括 rds:DescribeDBInstances、rds:ModifyDBInstance 和 rds:DescribeDBSecurityGroups。",
        "reason": "这些权限与数据库实例的描述和修改相关，但与连接问题无关。Lambda 函数需要的权限主要与网络接口相关。"
      },
      "E": {
        "option": "检查函数的执行角色权限是否包括 ec2:CreateNetworkInterface、ec2:DescribeNetworkInterfaces 和 ec2:DeleteNetworkInterface。",
        "reason": "这些权限对于在 VPC 模式下运行的 Lambda 函数是必要的，因为它需要管理网络接口来连接到 RDS 实例。"
      }
    }
  },
  {
    "number": "214",
    "best": ["D"],
    "question": "开发人员需要使用 AWS CLI 启动一个新的 Amazon EC2 实例。开发人员应该使用哪个 AWS CLI 命令来满足这个要求？",
    "options": {
      "A": {
        "option": "aws ec2 bundle-instance",
        "reason": "`aws ec2 bundle-instance` 命令用于将实例打包成 Amazon Machine Image (AMI)，而不是启动一个新的实例。因此，这个选项不符合要求。"
      },
      "B": {
        "option": "aws ec2 start-instances",
        "reason": "`aws ec2 start-instances` 命令用于启动已经存在的 EC2 实例，而不是创建一个新的实例。因此，这个选项不符合要求。"
      },
      "C": {
        "option": "aws ec2 confirm-product-instance",
        "reason": "`aws ec2 confirm-product-instance` 命令用于确认实例是否与特定产品代码相关联，通常用于市场产品的验证。这与启动新实例无关，因此不符合要求。"
      },
      "D": {
        "option": "aws ec2 run-instances",
        "reason": "`aws ec2 run-instances` 命令用于启动一个或多个新的 EC2 实例。这正是题目要求的操作，因此这是最优选项。"
      }
    }
  },
  {
    "number": "215",
    "best": ["D"],
    "question": "一名开发人员需要将 AWS 基础设施管理为代码，必须能够部署多个相同的基础设施副本、进行分阶段更改并恢复到以前的版本。哪种方法可以满足这些要求？",
    "options": {
      "A": {
        "option": "使用成本分配报告和 AWS OpsWorks 部署和管理基础设施。",
        "reason": "成本分配报告并不用于基础设施的部署和管理，而是用于成本管理。AWS OpsWorks 是一种配置管理服务，虽然可以用于基础设施管理，但不适合版本控制和多副本部署的需求。"
      },
      "B": {
        "option": "使用 Amazon CloudWatch 指标和警报以及资源标记来部署和管理基础设施。",
        "reason": "Amazon CloudWatch 主要用于监控和警报，而资源标记用于管理资源，但二者都不具备基础设施部署、版本控制和多副本部署的功能。"
      },
      "C": {
        "option": "使用 AWS Elastic Beanstalk 和 AWS CodeCommit 来部署和管理基础设施。",
        "reason": "AWS Elastic Beanstalk 是一种用于应用部署的服务，虽然 AWS CodeCommit 可以用于版本控制，但 Elastic Beanstalk 不适合处理复杂的基础设施管理和多副本部署。"
      },
      "D": {
        "option": "使用 AWS CloudFormation 和 AWS CodeCommit 来部署和管理基础设施。",
        "reason": "AWS CloudFormation 允许通过代码（模板）来定义和部署 AWS 基础设施，支持多副本部署、分阶段更改和恢复到以前的版本。AWS CodeCommit 是一种托管的源代码控制服务，可以用于版本控制。因此，这个选项最能满足题目中的需求。"
      }
    }
  },
  {
    "number": "216",
    "best": ["D"],
    "question": "一位开发人员正在开发一个访问 Amazon DynamoDB 的 AWS Lambda 函数。该 Lambda 函数必须检索一个项目并更新其一些属性，或者在项目不存在时创建该项目。Lambda 函数有访问主键的权限。开发人员应该为 Lambda 函数请求哪些 IAM 权限以实现此功能？",
    "options": {
      "A": {
        "option": "dynamodb:DeleteItem, dynamodb:GetItem, dynamodb:PutItem",
        "reason": "dynamodb:DeleteItem 权限用于删除项目，而不是更新或创建项目，因此这里不需要。"
      },
      "B": {
        "option": "dynamodb:UpdateItem, dynamodb:GetItem, dynamodb:DescribeTable",
        "reason": "dynamodb:DescribeTable 权限用于描述表的结构和信息，与检索、更新或创建项目无关。"
      },
      "C": {
        "option": "dynamodb:GetRecords, dynamodb:PutItem, dynamodb:UpdateTable",
        "reason": "dynamodb:GetRecords 用于获取流数据，而不是获取表中的项目。dynamodb:UpdateTable 用于更新表的设置，比如吞吐量，而不是更新项目。"
      },
      "D": {
        "option": "dynamodb:UpdateItem, dynamodb:GetItem, dynamodb:PutItem",
        "reason": "dynamodb:GetItem 用于检索项目，dynamodb:UpdateItem 用于更新现有项目，dynamodb:PutItem 用于创建新项目。这三个权限正好满足题目要求。"
      }
    }
  },
  {
    "number": "217",
    "best": ["A"],
    "question": "开发人员构建了一个市场应用程序，将定价数据存储在 Amazon DynamoDB 中，并在前端使用 Amazon ElastiCache。市场中的商品价格频繁变动。卖家开始抱怨他们更新商品价格后，产品列表中的价格并没有实际变化。可能是什么原因导致了这个问题？",
    "options": {
      "A": {
        "option": "在商品价格变更时，缓存未被无效化。",
        "reason": "当缓存中的数据未被及时更新或无效化时，应用程序会继续从缓存中获取过期的数据，从而导致显示的价格没有变化。Amazon ElastiCache 是一个内存缓存服务，用于加速对常用数据的访问，但需要确保在数据更新时，缓存也得到同步更新或无效化。"
      },
      "B": {
        "option": "价格使用写通式 ElastiCache 集群进行检索。",
        "reason": "写通式缓存主要用于在写入数据库时同时更新缓存，读取时依然会从缓存中获取数据。因此，这种机制不会导致价格更新后不变化的问题，因为它会保证缓存中的数据也是最新的。"
      },
      "C": {
        "option": "DynamoDB 表预置了不足的读取容量。",
        "reason": "读取容量不足会导致读取操作失败或延迟，但不会导致数据不更新。如果读取操作成功，应该能获取到最新价格。"
      },
      "D": {
        "option": "DynamoDB 表预置了不足的写入容量。",
        "reason": "写入容量不足会导致写入操作失败或延迟，但如果写入成功，数据会被更新。因此，这也不会导致价格没有变化的问题。"
      }
    }
  },
  {
    "number": "218",
    "best": ["B"],
    "question": "一家公司要求所有运行在 Amazon EC2 上的应用程序必须使用 IAM 角色来访问 AWS 服务。一位开发人员正在修改一个当前依赖存储在环境变量中的 IAM 用户访问密钥来访问 Amazon DynamoDB 表的应用程序，并使用 boto（AWS 的 Python SDK）。开发人员将一个具有与 IAM 用户相同权限的角色关联到 EC2 实例，然后删除了 IAM 用户。当应用程序重新启动时，应用程序日志中开始出现 AWS AccessDeniedException 消息。开发人员能够使用他们的个人账户在服务器上使用 AWS CLI 运行 DynamoDB API 命令。最可能导致异常的原因是什么？",
    "options": {
      "A": {
        "option": "IAM 策略可能需要几分钟时间传播到资源。",
        "reason": "IAM 策略的传播通常不会导致这种问题，因为开发人员已经使用其个人账户测试过，并且问题是立即出现的。"
      },
      "B": {
        "option": "禁用的环境变量凭证仍然被应用程序使用。",
        "reason": "应用程序可能仍在使用已删除的 IAM 用户的环境变量凭证。应用程序需要被配置为使用实例角色，而不是依赖环境变量中的旧凭证。"
      },
      "C": {
        "option": "AWS SDK 不支持使用实例角色获取的凭证。",
        "reason": "AWS SDK 完全支持实例角色凭证，所以这不是问题的原因。"
      },
      "D": {
        "option": "实例的安全组不允许访问 http://169.254.169.254。",
        "reason": "访问 http://169.254.169.254 是实例元数据服务的默认行为，通常安全组不会阻止对其的访问。"
      }
    }
  },
  {
    "number": "219",
    "best": ["A"],
    "question": "一家公司有一个现有的应用程序，硬编码了数据库凭证。开发人员需要修改现有的应用程序。该应用程序在两个 AWS 区域中以主动-被动故障转移配置部署，以符合公司的灾难恢复策略。开发人员需要一个解决方案将凭证存储在代码之外。该解决方案必须符合公司的灾难恢复策略。哪种解决方案可以用最安全的方式满足这些要求？",
    "options": {
      "A": {
        "option": "将凭证存储在主区域的 AWS Secrets Manager 中。启用秘密复制到辅助区域。更新应用程序以使用基于区域的 Amazon 资源名称 (ARN)。",
        "reason": "AWS Secrets Manager 是一种专门设计用于管理和轮换凭证的服务。它提供了高安全性和自动化特性。此外，它支持跨区域的秘密复制，这完全符合灾难恢复策略。因此，这是最安全和最符合要求的解决方案。"
      },
      "B": {
        "option": "将凭证存储在主区域的 AWS Systems Manager 参数存储中。启用参数复制到辅助区域。更新应用程序以使用基于区域的 Amazon 资源名称 (ARN)。",
        "reason": "AWS Systems Manager Parameter Store 是一个用于存储配置数据和秘密的服务，尽管它也支持跨区域复制，但它的安全特性和专门管理秘密的能力不如 AWS Secrets Manager 强大。因此，这不是最优方案。"
      },
      "C": {
        "option": "将凭证存储在配置文件中。将配置文件上传到主区域的 S3 存储桶中。启用跨区域复制 (CRR) 到辅助区域的 S3 存储桶。更新应用程序以根据区域从 S3 存储桶访问配置文件。",
        "reason": "虽然 S3 支持跨区域复制，但将凭证存储在配置文件中并且在 S3 存储桶中可能不如使用专门设计的秘密管理服务（如 AWS Secrets Manager）那样安全。因此，这不是最佳选择。"
      },
      "D": {
        "option": "将凭证存储在配置文件中。将配置文件上传到 Amazon Elastic File System (Amazon EFS) 文件系统中。更新应用程序以使用 Amazon EFS 文件系统区域端点访问主区域和辅助区域的配置文件。",
        "reason": "Amazon EFS 是一种文件存储服务，尽管它可以跨多个区域使用，但它不专门用于存储秘密或凭证，因此不如 AWS Secrets Manager 安全和合适。因此，这不是最佳选择。"
      }
    }
  },
  {
    "number": "220",
    "best": ["D"],
    "question": "开发人员在调用 Amazon CloudWatch API 时，间歇性地收到 HTTP 400: ThrottlingException 错误。当调用失败时，没有数据被检索到。应该首先应用哪种最佳实践来解决此问题？",
    "options": {
      "A": {
        "option": "联系 AWS 支持以增加限制。",
        "reason": "虽然联系 AWS 支持以增加限制可能是一个解决方案，但这不是最佳的第一步。AWS 有内置的机制来处理 API 限制，例如指数退避。只有在确认应用程序已经采用了这些最佳实践后，并且仍然遇到问题时，才应该考虑联系支持。"
      },
      "B": {
        "option": "使用 AWS CLI 获取指标。",
        "reason": "使用 AWS CLI 获取指标不会解决 ThrottlingException 问题，因为该问题是由于请求频率过高导致的。使用 AWS CLI 进行相同的调用仍然会遇到相同的限制。"
      },
      "C": {
        "option": "分析应用程序并移除 API 调用。",
        "reason": "移除 API 调用不是一个实际的解决方案，因为这可能会影响应用程序的功能。应该寻找一种方法来优化调用频率，而不是直接删除调用。"
      },
      "D": {
        "option": "使用指数退避重试调用。",
        "reason": "指数退避是一种最佳实践，当遇到 API 调用限制时，它能够通过逐步增加重试间隔来减少请求频率，从而减少 ThrottlingException 错误。这是解决 ThrottlingException 问题的推荐方法。"
      }
    }
  },
  {
    "number": "221",
    "best": ["C"],
    "question": "一个应用程序需要在处理过程中使用客户端的 IP 地址。该应用程序已迁移到 AWS 并被放置在一个应用负载均衡器（ALB）后面。然而，现在所有客户端 IP 地址似乎都是相同的。该应用程序必须保持水平扩展的能力。基于这种情况，最具成本效益的解决方案是什么？",
    "options": {
      "A": {
        "option": "将应用程序从 ALB 中移除。删除 ALB 并更改 Amazon Route 53 以将流量定向到运行该应用程序的实例。",
        "reason": "这种方法会失去负载均衡的好处，并且无法水平扩展，不是一个有效的解决方案。"
      },
      "B": {
        "option": "将应用程序从 ALB 中移除，创建一个经典负载均衡器（Classic Load Balancer）来替代它。使用 HTTP 协议将流量定向到应用程序。",
        "reason": "虽然经典负载均衡器也可以传递客户端 IP 地址，但它是一种过时的服务，AWS 建议使用应用负载均衡器（ALB）或网络负载均衡器（NLB）。这种方法也是次优的。"
      },
      "C": {
        "option": "修改应用程序代码以检查 X-Forwarded-For 头。确保代码可以在头中传递 IP 地址列表的情况下正常工作。",
        "reason": "应用负载均衡器（ALB）会使用 X-Forwarded-For 头传递客户端的原始 IP 地址。修改应用程序代码以检查这个头是最具成本效益且符合 AWS 最佳实践的解决方案。"
      },
      "D": {
        "option": "修改应用程序代码以检查一个自定义头。修改客户端代码以在自定义头中传递 IP 地址。",
        "reason": "这种方法需要修改客户端代码，不仅增加了复杂性，还可能导致兼容性问题。此外，使用 ALB 的 X-Forwarded-For 头是一个更标准和简便的解决方案。"
      }
    }
  },
  {
    "number": "222",
    "best": ["A"],
    "question": "开发人员正在设计一个无服务器应用程序，客户使用该应用程序选择音乐会场地的座位。客户将票务请求发送到 Amazon API Gateway API，该 API 与一个 AWS Lambda 函数连接，函数会确认订单并生成订单 ID。该应用程序包括两个额外的 Lambda 函数：一个用于库存管理，另一个用于支付处理。这两个 Lambda 函数并行运行并将订单写入 Amazon DynamoDB 表中。应用程序必须根据以下要求为客户提供座位。如果座位被意外多次出售，应用程序收到的第一个订单必须获得座位。在这些情况下，应用程序必须仅处理第一个订单的支付。但是，如果第一个订单在支付处理期间被拒绝，则第二个订单必须获得座位。在这些情况下，应用程序必须处理第二个订单的支付。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "将订单 ID 发送到一个 Amazon Simple Notification Service (Amazon SNS) FIFO 主题，该主题会传递给一个用于库存管理的 Amazon Simple Queue Service (Amazon SQS) FIFO 队列和另一个用于支付处理的 SQS FIFO 队列。",
        "reason": "使用 Amazon SNS FIFO 主题和 SQS FIFO 队列可以确保消息的顺序性和一致性。这样可以确保第一个订单首先被处理，并且如果第一个订单支付失败，第二个订单可以获得座位。这种解决方案符合题目要求，并且 FIFO 队列确保了消息的顺序处理。"
      },
      "B": {
        "option": "更改生成订单 ID 的 Lambda 函数以启动库存管理的 Lambda 函数。然后启动支付处理的 Lambda 函数。",
        "reason": "这个选项没有解决并行处理的问题，并且没有提供确保第一个订单优先处理的机制。"
      },
      "C": {
        "option": "将订单 ID 发送到一个 Amazon Simple Notification Service (Amazon SNS) 主题。将用于库存管理和支付处理的 Lambda 函数订阅到该主题。",
        "reason": "这个选项使用了 SNS 主题，但没有提供 FIFO 的顺序保证，这可能导致并发问题，无法确保第一个订单优先处理。"
      },
      "D": {
        "option": "将订单 ID 发送到一个 Amazon Simple Queue Service (Amazon SQS) 队列。配置用于库存管理和支付处理的 Lambda 函数轮询该队列。",
        "reason": "虽然这个选项使用了 SQS 队列，但没有使用 FIFO 队列，因此无法保证消息的顺序处理，可能会导致并发问题。"
      }
    }
  },
  {
    "number": "223",
    "best": ["A"],
    "question": "一个应用程序每小时生成大量的 AWS X-Ray 跟踪数据。开发人员希望使用过滤表达式通过用户指定的自定义属性来限制返回的结果。开发人员应该如何使用过滤表达式来过滤 X-Ray 中的结果？",
    "options": {
      "A": {
        "option": "在段文档中将自定义属性添加为注释。",
        "reason": "在 AWS X-Ray 中，注释（Annotations）是可索引的自定义属性，可以用于筛选和分组跟踪数据。因此，开发人员应将自定义属性添加为注释，以便使用过滤表达式进行筛选。"
      },
      "B": {
        "option": "在段文档中将自定义属性添加为元数据。",
        "reason": "元数据（Metadata）虽然可以存储自定义属性，但这些属性不是索引的，不能用于过滤表达式进行筛选。因此，这不是最佳选择。"
      },
      "C": {
        "option": "在段文档中将自定义属性添加为新的段字段。",
        "reason": "在 X-Ray 中，段字段是预定义的，无法动态添加新的段字段。因此，这不是一个可行的选项。"
      },
      "D": {
        "option": "基于自定义属性创建新的采样规则。",
        "reason": "采样规则用于决定哪些请求会被记录和跟踪，而不是用于过滤已生成的跟踪数据。因此，这不是合适的选项。"
      }
    }
  },
  {
    "number": "224",
    "best": ["D"],
    "question": "一个Web应用程序正在使用Amazon Kinesis Data Streams来处理点击流数据，这些数据可能长达12小时不会被消费。开发人员如何在Kinesis Data Streams中实现数据的静态加密？",
    "options": {
      "A": {
        "option": "启用与Kinesis的SSL连接。",
        "reason": "启用SSL连接可以保护数据在传输中的安全性，但不能加密存储在Kinesis Data Streams中的数据。"
      },
      "B": {
        "option": "使用Amazon Kinesis Consumer Library。",
        "reason": "Kinesis Consumer Library用于消费Kinesis数据流中的数据，但并不提供数据加密的功能。"
      },
      "C": {
        "option": "使用Lambda函数在数据静态时加密数据。",
        "reason": "虽然Lambda函数可以用来加密数据，但这是一个额外的步骤，并不是最佳实践。Kinesis Data Streams自身提供了更简便的加密解决方案。"
      },
      "D": {
        "option": "在Kinesis Data Streams中启用服务器端加密。",
        "reason": "在Kinesis Data Streams中启用服务器端加密是实现数据静态加密的最佳方法。AWS Kinesis Data Streams提供了内置的服务器端加密功能，可以轻松启用并管理。"
      }
    }
  },
  {
    "number": "225",
    "best": ["D"],
    "question": "一个应用程序正在通过API实时处理数百万个事件。哪种服务可以让多个消费者同时处理数据，并且成本最为有效？",
    "options": {
      "A": {
        "option": "使用 Amazon SNS 将消息分发到每个应用程序的 SQS 队列",
        "reason": "Amazon SNS 和 SQS 的组合可以实现消息传递和队列服务，但对于需要实时处理大量事件的应用程序来说，可能不是最具成本效益的选择，因为每条消息的传递和处理都会产生费用。"
      },
      "B": {
        "option": "使用 Amazon SNS 将消息分发到每个应用程序的 SQS FIFO（先进先出）队列",
        "reason": "虽然 SQS FIFO 队列确保了消息按顺序处理，但它的吞吐量相对较低，不适合需要高并发处理的场景。另外，使用 SNS 和 SQS FIFO 队列的组合也会增加成本。"
      },
      "C": {
        "option": "使用 Amazon Kinesis Firehose",
        "reason": "Amazon Kinesis Firehose 主要用于将数据流传输到诸如 S3、Redshift 或 Elasticsearch 这样的持久存储，但它不适合需要多个消费者并发处理的场景。"
      },
      "D": {
        "option": "使用 Amazon Kinesis Data Streams",
        "reason": "Amazon Kinesis Data Streams 是专为高吞吐量的实时数据流处理设计的，允许多个消费者并发处理数据，从而实现高效的实时处理，是最具成本效益的选择。"
      }
    }
  },
  {
    "number": "226",
    "best": ["A"],
    "question": "以下 AWS CloudFormation 模板中，最有效的方法是如何在另一个 AWS CloudFormation 模板中引用新的 Amazon S3 bucket?",
    "options": {
      "A": {
        "option": "在原始模板的 Outputs 部分添加一个 Export 声明，并在其他模板中使用 ImportValue。",
        "reason": "在 AWS CloudFormation 中，最有效的方法是通过导出和导入值来引用资源。通过在原始模板的 Outputs 部分添加 Export 声明，您可以将该资源导出为一个可以在其他堆栈中使用的共享值。然后，您可以在其他模板中使用 ImportValue 函数导入该值。这种方法不仅简洁高效，还遵循 AWS CloudFormation 的最佳实践。"
      },
      "B": {
        "option": "在原始模板的 Content.Bucket 中添加 Exported: true 并在其他模板中使用 ImportResource。",
        "reason": "AWS CloudFormation 并没有名为 ImportResource 的函数，因此此选项是无效的。"
      },
      "C": {
        "option": "创建一个自定义 AWS CloudFormation 资源，从第一个堆栈的 ContentBucket 资源中获取 bucket 名称。",
        "reason": "尽管这是一种解决方案，但它复杂且不高效。创建和维护自定义资源需要额外的开发和运维工作，这不是最好的选择。"
      },
      "D": {
        "option": "使用 Fn::Include 将现有模板包含在其他模板中，并直接使用 ContentBucket 资源。",
        "reason": "Fn::Include 函数用于包含外部文件的内容，而不是引用特定的资源。此外，这种方法并不适用于跨堆栈引用资源，无法实现题目中所需的功能。"
      }
    }
  },
  {
    "number": "227",
    "best": ["B", "C"],
    "question": "开发人员构建了一个应用程序，该应用程序将数据插入到一个 Amazon DynamoDB 表中。该表配置为使用预置容量。该应用程序部署在可突发的 nano Amazon EC2 实例上。应用程序日志显示，由于 ProvisionedThroughputExceededException 错误，应用程序一直在失败。开发人员应该采取哪些操作来解决此问题？（选择两个。）",
    "options": {
      "A": {
        "option": "将应用程序移动到更大的 EC2 实例。",
        "reason": "更大的 EC2 实例可以提供更多的计算资源，但这个问题是由于 DynamoDB 表的预置容量不足导致的，因此更换 EC2 实例不会直接解决问题。"
      },
      "B": {
        "option": "增加为 DynamoDB 表预置的读取容量单位 (RCUs)。",
        "reason": "ProvisionedThroughputExceededException 错误表明 DynamoDB 表的读取或写入容量不足，增加预置的读取容量单位可以解决这个问题。"
      },
      "C": {
        "option": "通过实施指数退避来减少对 DynamoDB 的请求频率。",
        "reason": "实施指数退避可以帮助减少请求频率，避免触发 DynamoDB 的容量限制，从而减少 ProvisionedThroughputExceededException 错误。"
      },
      "D": {
        "option": "通过减少重试延迟来增加对 DynamoDB 的请求频率。",
        "reason": "增加请求频率可能会使问题变得更糟，因为这会导致更多的 ProvisionedThroughputExceededException 错误。"
      },
      "E": {
        "option": "将 DynamoDB 表的容量模式从预置改为按需。",
        "reason": "虽然改变容量模式可以解决问题，但这不是最佳选择，因为开发人员可能希望继续使用预置容量来控制成本。"
      }
    }
  },
  {
    "number": "228",
    "best": ["A"],
    "question": "公司正在为外部用户举办一个研讨会，并希望将参考文档与外部用户分享7天。公司将参考文档存储在一个公司拥有的Amazon S3桶中。分享这些文档的最安全方式是什么？",
    "options": {
      "A": {
        "option": "使用S3预签名URL与外部用户分享文档。设置7天的到期时间。",
        "reason": "S3预签名URL允许你为特定对象生成一个临时的URL，这个URL包含有时间限制的访问权限。通过设置7天的到期时间，可以确保外部用户只能在指定的时间内访问文档，这样可以最大限度地确保安全性和便利性。"
      },
      "B": {
        "option": "将文档移动到一个Amazon WorkDocs文件夹中。与外部用户分享WorkDocs文件夹的链接。",
        "reason": "虽然Amazon WorkDocs可以用于共享文档，但这种方法需要将文档从S3迁移到WorkDocs，这会带来额外的管理和复杂性。此外，它不一定是最安全的方法，因为它涉及另一个服务，而不是直接使用S3的功能。"
      },
      "C": {
        "option": "创建具有只读访问S3桶的临时IAM用户。与外部用户分享访问密钥。7天后使凭证过期。",
        "reason": "创建临时IAM用户并分享访问密钥的方式虽然可以实现7天的访问限制，但这种方法涉及到管理和共享IAM凭证，这可能会带来安全风险。相比于预签名URL，这种方法更复杂且更不安全。"
      },
      "D": {
        "option": "创建一个具有只读访问S3桶的角色。与外部用户分享该角色的Amazon资源名称（ARN）。",
        "reason": "分享角色的ARN并不能直接让外部用户访问S3桶，还需要额外的步骤来使用该角色获得临时凭证。这种方法复杂且不直观，难以实现安全且方便的访问控制。"
      }
    }
  },
  {
    "number": "Question #229",
    "best": ["C"],
    "question": "开发人员计划使用 Amazon API Gateway 和 AWS Lambda 提供 REST API。开发人员将有三个不同的环境需要管理：开发、测试和生产。应该如何部署应用程序以最小化需要管理的资源数量？",
    "options": {
      "A": {
        "option": "在同一地区为每个环境创建单独的 API Gateway 和单独的 Lambda 函数。",
        "reason": "这种方法需要为每个环境创建和管理多个 API Gateway 和 Lambda 函数，增加了管理的复杂性和成本，不利于资源的最小化管理。"
      },
      "B": {
        "option": "为每个环境分配一个地区，并在每个地区部署 API Gateway 和 Lambda。",
        "reason": "这种方法会创建多个地区的 API Gateway 和 Lambda 函数，增加了管理复杂性和跨地区通信的延迟。"
      },
      "C": {
        "option": "创建一个 API Gateway，使用多个阶段和一个具有多个别名的 Lambda 函数。",
        "reason": "这种方法最小化了需要管理的资源数量。通过 API Gateway 的不同阶段（stages）和 Lambda 函数的别名（aliases），可以轻松地管理不同环境的版本。这是 AWS 推荐的最佳实践。"
      },
      "D": {
        "option": "创建一个 API Gateway 和一个 Lambda 函数，并使用 REST 参数来识别环境。",
        "reason": "虽然这种方法减少了资源数量，但使用 REST 参数来区分环境并不是管理不同环境的最佳实践，这可能会导致代码混乱和管理困难。"
      }
    }
  },
  {
    "number": "230",
    "best": ["C"],
    "question": "为什么当客户端通过应用负载均衡器（ALB）发送请求时，Lambda 函数没有被调用？",
    "options": {
      "A": {
        "option": "Lambda 函数不能作为 ALB 的目标注册。",
        "reason": "这不正确。实际上，Lambda 函数可以作为 ALB 的目标注册。"
      },
      "B": {
        "option": "只能使用 AWS 管理控制台将 Lambda 函数注册到 ALB。",
        "reason": "这不正确。可以使用 AWS CLI 命令将 Lambda 函数注册到 ALB。"
      },
      "C": {
        "option": "缺少调用 Lambda 函数的权限。",
        "reason": "这是正确的。为了让 ALB 调用 Lambda 函数，需要在 Lambda 函数的资源策略中授予 ALB 权限。"
      },
      "D": {
        "option": "ALB 上未启用跨区功能。",
        "reason": "这不相关。跨区功能与 ALB 能否调用 Lambda 函数无关。"
      }
    }
  },
  {
    "number": "231",
    "best": ["B"],
    "question": "开发人员正在创建一个将连接到 Amazon RDS for MySQL 实例的 AWS Lambda 函数。开发人员希望存储数据库凭证。数据库凭证需要加密，数据库密码需要自动轮换。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "将数据库凭证存储为 Lambda 函数的环境变量。设置环境变量自动轮换。",
        "reason": "环境变量不适合存储敏感信息，因为它们缺乏足够的安全性，而且 AWS Lambda 并不提供环境变量自动轮换的功能。"
      },
      "B": {
        "option": "将数据库凭证存储在 AWS Secrets Manager 中。设置数据库凭证的托管轮换。",
        "reason": "AWS Secrets Manager 专门用于管理和轮换数据库凭证等敏感信息。它提供了加密存储和自动轮换功能，完全符合题目要求。"
      },
      "C": {
        "option": "将数据库凭证存储在 AWS Systems Manager 参数存储中，作为安全字符串参数。设置参数的托管轮换。",
        "reason": "虽然 AWS Systems Manager Parameter Store 可以安全存储敏感信息，但它不支持自动轮换功能。"
      },
      "D": {
        "option": "将数据库凭证存储在 X-Amz-Security-Token 参数中。设置参数的托管轮换。",
        "reason": "X-Amz-Security-Token 不是用于存储数据库凭证的参数，也不支持自动轮换功能。"
      }
    }
  },
  {
    "number": "232",
    "best": ["B"],
    "question": "一位开发人员希望在部署现有 AWS Lambda 函数的新版本时降低风险。为了测试 Lambda 函数，开发人员需要在现有版本和新版本之间分配流量。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "在 Amazon Route 53 中配置加权路由策略。将 Lambda 函数的各个版本与加权路由策略关联。",
        "reason": "Route 53 的加权路由策略通常用于 DNS 级别的流量管理，适用于分配到不同的服务或区域，而不是在 Lambda 函数的不同版本之间。"
      },
      "B": {
        "option": "创建一个函数别名。将该别名配置为在两个版本的 Lambda 函数之间分配流量。",
        "reason": "使用 Lambda 别名是 AWS 官方推荐的最佳实践之一。通过配置别名权重，可以在不同版本之间分配流量，从而安全地测试新版本。这种方法最直接有效。"
      },
      "C": {
        "option": "创建一个使用 Lambda 函数作为目标的应用程序负载均衡器 (ALB)。配置 ALB 在两个版本的 Lambda 函数之间分配流量。",
        "reason": "虽然 ALB 可以用来分配流量，但这种方法通常用于 HTTP 请求管理，不是管理 Lambda 函数版本之间流量的最佳实践。"
      },
      "D": {
        "option": "将 Lambda 函数的新版本作为现有版本的 Lambda 层来创建。配置函数在两个层之间分配流量。",
        "reason": "Lambda 层用于共享代码和依赖项，不用于版本管理和流量分配。这个选项不符合题目要求。"
      }
    }
  },
  {
    "number": "233",
    "best": ["C", "E"],
    "question": "一位开发人员创建了一个大型的 AWS Lambda 函数。由于 InvalidParameterValueException 错误，函数的部署失败。错误消息显示函数解压后的大小超过了支持的最大值。开发人员可以采取哪些措施来解决此错误？（选择两个。）",
    "options": {
      "A": {
        "option": "向 AWS 支持提交配额增加请求，以将函数增加到所需大小。",
        "reason": "AWS Lambda 函数的大小限制是固定的，无法通过配额增加请求来扩展。因此，选项A不是一个可行的解决方案。"
      },
      "B": {
        "option": "使用比ZIP更有效的压缩算法。",
        "reason": "尽管更有效的压缩算法可能会减少文件的压缩大小，但解压后的大小仍然会超过限制。因此，选项B不是一个有效的解决方案。"
      },
      "C": {
        "option": "将函数分解为多个较小的函数。",
        "reason": "将大型函数分解为多个较小的函数可以减少每个函数的大小，这也是一种推荐的做法，可以提高代码的可维护性和可伸缩性。因此，选项C是一个有效的解决方案。"
      },
      "D": {
        "option": "将.zip文件压缩两次以进一步压缩文件。",
        "reason": "双重压缩不会影响解压后的大小，解压后的大小仍然会超过限制。因此，选项D不是一个有效的解决方案。"
      },
      "E": {
        "option": "将公共库、函数依赖项和自定义运行时移入Lambda层。",
        "reason": "将公共库、函数依赖项和自定义运行时移入Lambda层可以减少主函数的大小，从而符合大小限制。这是一种推荐的做法，特别是当多个函数共享相同的依赖项时。因此，选项E是一个有效的解决方案。"
      }
    }
  },
  {
    "number": "234",
    "best": ["D"],
    "question": "开发人员正在集成环境中排查一个应用程序。在该应用程序中，Amazon Simple Queue Service (Amazon SQS) 队列会接收消息，然后 AWS Lambda 函数处理这些消息。Lambda 函数会转换消息并向第三方服务发起 API 调用。由于应用程序使用量增加，第三方 API 经常返回 HTTP 429 Too Many Requests 错误消息。该错误消息阻止了大量消息被成功处理。开发人员如何解决这个问题？",
    "options": {
      "A": {
        "option": "增加 SQS 事件源的批处理大小设置。",
        "reason": "增加批处理大小会导致更多的消息同时传递给 Lambda 函数，这可能会加重第三方 API 的负担，并不能解决 HTTP 429 错误。"
      },
      "B": {
        "option": "根据第三方 API 的文档化速率限制，为 Lambda 函数配置预置并发。",
        "reason": "预置并发可以确保 Lambda 函数的响应速度，但并不能直接控制调用第三方 API 的频率，因此不能解决 HTTP 429 错误。"
      },
      "C": {
        "option": "增加 Lambda 函数异步配置中的重试次数和最大事件年龄。",
        "reason": "增加重试次数和最大事件年龄可能会导致消息处理延迟增加，但并不能减少第三方 API 的请求次数，因此不能解决 HTTP 429 错误。"
      },
      "D": {
        "option": "根据第三方服务的文档化速率限制配置 SQS 事件源的最大并发。",
        "reason": "配置最大并发可以控制同时调用第三方 API 的 Lambda 函数数量，从而避免超过第三方服务的速率限制，这是解决 HTTP 429 错误的最佳方法。"
      }
    }
  },
  {
    "number": "235",
    "best": ["A"],
    "question": "公司有一个三层应用程序，部署在 Amazon Elastic Container Service (Amazon ECS) 上。该应用程序使用 Amazon RDS for MySQL 数据库实例。应用程序的数据库读取操作多于写入操作。在高峰期，应用程序的性能下降。当这种性能下降发生时，数据库实例的 ReadLatency 指标在 Amazon CloudWatch 中突然增加。开发人员应如何修改应用程序以提高性能？",
    "options": {
      "A": {
        "option": "使用 Amazon ElastiCache 缓存查询结果。",
        "reason": "由于应用程序的数据库读取操作多于写入操作，并且 ReadLatency 指标在高峰期突然增加，使用 Amazon ElastiCache 缓存查询结果可以显著减少对数据库的读取压力，从而提高性能。ElastiCache 适用于需要频繁读取但不经常更新的数据。"
      },
      "B": {
        "option": "扩展 ECS 集群以包含更多 ECS 实例。",
        "reason": "扩展 ECS 集群可能会提高应用程序的计算能力，但问题的根源在于数据库的读取延迟增加，因此增加 ECS 实例不会直接解决数据库性能问题。"
      },
      "C": {
        "option": "向数据库实例添加读取容量单位 (RCU)。",
        "reason": "Amazon RDS for MySQL 不使用读取容量单位 (RCU)，这是 Amazon DynamoDB 的一个概念。因此，这个选项不适用。"
      },
      "D": {
        "option": "修改 ECS 任务定义以增加任务内存。",
        "reason": "增加 ECS 任务内存可能会提升单个任务的性能，但这与数据库读取延迟增加的问题无关，因此无法解决根本问题。"
      }
    }
  },
  {
    "number": "236",
    "best": ["A"],
    "question": "一家公司有一个在线Web应用程序，其中包含一个产品目录。目录存储在名为DOC-EXAMPLE-BUCKET的Amazon S3桶中。应用程序必须能够列出S3桶中的对象，并且必须能够通过IAM策略下载对象。哪种策略允许满足这些要求的最小访问权限？",
    "options": {
      "A": {
        "option": "允许应用程序列出和下载对象的最小访问权限的策略。",
        "reason": "选项A提供了应用程序所需的最小权限：列出S3桶中的对象和下载对象。IAM策略应该遵循最小权限原则，只授予应用程序完成其任务所需的最低限度的权限。这既可以确保安全性，也可以减少潜在的误操作风险。"
      },
      "B": {
        "option": "允许应用程序对S3桶进行读取和写入操作的策略。",
        "reason": "选项B授予了读取和写入权限，而题目中只要求列出和下载对象，这超出了最小权限原则。"
      },
      "C": {
        "option": "允许应用程序对S3桶进行完全访问的策略。",
        "reason": "选项C授予了完全访问权限，这远远超出了题目中要求的列出和下载对象的权限，不符合最小权限原则。"
      },
      "D": {
        "option": "允许应用程序对S3桶进行列出对象操作的策略。",
        "reason": "选项D只授予了列出对象的权限，但题目中还要求能够下载对象，因此不满足所有需求。"
      }
    }
  },
  {
    "number": "237",
    "best": ["A"],
    "question": "开发人员正在编写一个应用程序，以在将文件上传到 Amazon S3 存储桶之前对 AWS 之外的文件进行加密。加密必须是对称的，并且必须在应用程序内部执行。开发人员如何在应用程序中实现加密以满足这些要求？",
    "options": {
      "A": {
        "option": "在 AWS Key Management Service (AWS KMS) 中创建一个数据密钥。使用 AWS Encryption SDK 来加密文件。",
        "reason": "此选项是最优解，因为 AWS Encryption SDK 提供了对称加密的功能，并且能够与 AWS KMS 集成来管理数据密钥。开发人员可以使用 SDK 在应用程序内部进行文件加密，符合题目要求。"
      },
      "B": {
        "option": "在 AWS Key Management Service (AWS KMS) 中创建一个基于散列的消息认证码 (HMAC) 密钥。使用 AWS Encryption SDK 来加密文件。",
        "reason": "此选项不合适。HMAC 通常用于消息认证和完整性检查，而不是数据加密。题目要求对文件进行对称加密，因此使用 HMAC 密钥不符合要求。"
      },
      "C": {
        "option": "在 AWS Key Management Service (AWS KMS) 中创建一对数据密钥。使用 AWS CLI 来加密文件。",
        "reason": "此选项不合适。首先，数据密钥对（公钥和私钥）通常用于非对称加密，而题目要求对称加密。其次，AWS CLI 并不适合在应用程序内部进行加密操作，因为它主要用于命令行管理 AWS 资源。"
      },
      "D": {
        "option": "在 AWS Key Management Service (AWS KMS) 中创建一个数据密钥。使用 AWS CLI 来加密文件。",
        "reason": "此选项不合适。虽然数据密钥可以用于对称加密，但使用 AWS CLI 并不适合在应用程序内部执行加密操作。题目要求加密必须在应用程序内部执行，因此这个选项不符合要求。"
      }
    }
  },
  {
    "number": "238",
    "best": ["C"],
    "question": "一名开发人员正在处理一个部署在 Amazon EC2 实例上的应用程序。开发人员需要一个解决方案，将文件从应用程序安全地传输到 Amazon S3 存储桶。开发人员应该怎么做才能以最安全的方式满足这些需求？",
    "options": {
      "A": {
        "option": "创建一个 IAM 用户。为 IAM 用户创建一个访问密钥。将访问密钥存储在应用程序的环境变量中。",
        "reason": "不推荐这种方法，因为将访问密钥存储在环境变量中存在安全风险。如果密钥被泄露，可能会导致整个 AWS 账户的安全问题。"
      },
      "B": {
        "option": "创建一个 IAM 角色。为 IAM 角色创建一个访问密钥。将访问密钥存储在应用程序的环境变量中。",
        "reason": "这种方法也不安全，因为依然需要将访问密钥存储在环境变量中，存在泄露风险。而且 IAM 角色主要是用来赋予 EC2 实例或其他 AWS 服务权限的，不应创建访问密钥。"
      },
      "C": {
        "option": "创建一个 IAM 角色。配置该 IAM 角色以访问应用程序所需的特定 Amazon S3 API 调用。将该 IAM 角色与 EC2 实例关联。",
        "reason": "这是最安全的方法。通过将 IAM 角色与 EC2 实例关联，不需要在应用程序中存储任何访问密钥。IAM 角色可以配置特定的权限，确保应用程序只有必要的访问权限，从而最小化安全风险。"
      },
      "D": {
        "option": "为 S3 存储桶配置一个存储桶策略。将 S3 存储桶策略配置为允许 EC2 实例 ID 访问。",
        "reason": "这种方法并不是最佳实践，因为管理存储桶策略复杂且容易出错。更好的方法是使用 IAM 角色来控制访问权限。"
      }
    }
  },
  {
    "number": "239",
    "best": ["B"],
    "question": "开发人员创建了一个 Web API，该 API 使用具有 HTTPS 监听器的面向互联网的应用程序负载均衡器 (ALB) 接收请求。开发人员配置了一个 Amazon Cognito 用户池，并希望确保对 API 的每个请求都通过 Amazon Cognito 进行身份验证。开发人员应该怎么做来满足这个要求？",
    "options": {
      "A": {
        "option": "如果 Authorization 标头缺失，则向监听器添加一个侦听规则以返回固定响应。将固定响应设置为 401 Unauthorized。",
        "reason": "这种方法虽然可以阻止未授权的请求，但它并没有实现通过 Amazon Cognito 进行身份验证的功能。"
      },
      "B": {
        "option": "为监听器规则创建一个身份验证操作，将规则操作类型设置为 authenticate-cognito。将 OnUnauthenticatedRequest 字段设置为“deny”（拒绝）。",
        "reason": "这是最优解。通过为监听器规则创建 authenticate-cognito 操作，可以直接在 ALB 上使用 Amazon Cognito 进行身份验证，并且可以确保未经过身份验证的请求被拒绝。"
      },
      "C": {
        "option": "创建一个 Amazon API Gateway API。配置所有 API 方法转发到 ALB 端点。创建一个类型为 COGNITO_USER_POOLS 的授权器。配置每个 API 方法使用该授权器。",
        "reason": "这种方法虽然可以实现通过 Amazon Cognito 进行身份验证，但它增加了额外的复杂性，因为需要引入 API Gateway。题目要求直接在 ALB 上实现身份验证。"
      },
      "D": {
        "option": "创建一个包含使用 Amazon Cognito 验证 Authorization 标头的 AWS Lambda 函数目标的新目标组。将目标组与监听器关联。",
        "reason": "这也是一种可行的方法，但它增加了额外的复杂性和延迟。因为需要额外的 Lambda 函数来进行身份验证。题目要求直接在 ALB 上实现身份验证。"
      }
    }
  },
  {
    "number": "240",
    "best": ["C", "E"],
    "question": "一家公司最近部署了一项 AWS Lambda 函数。一名开发人员注意到 Amazon CloudWatch 中函数节流指标有所增加。哪种是减少函数节流的最有效运营解决方案？（选择两个。）",
    "options": {
      "A": {
        "option": "将函数迁移到 Amazon Elastic Kubernetes Service (Amazon EKS)。",
        "reason": "将函数迁移到 Amazon EKS 不是解决 Lambda 函数节流问题的直接方法。虽然 EKS 可以提供更高的扩展性和控制性，但它涉及到重构应用程序并不是迅速解决 Lambda 节流问题的最佳选择。"
      },
      "B": {
        "option": "增加 Lambda 中事件的最大年龄。",
        "reason": "增加事件的最大年龄不会直接解决函数节流问题。它只会影响事件在失败后重试的时间窗口，并不能减少节流的发生。"
      },
      "C": {
        "option": "增加函数的保留并发量。",
        "reason": "增加函数的保留并发量可以有效减少节流，因为它直接增加了Lambda函数可以同时处理的并发请求数。"
      },
      "D": {
        "option": "向执行角色添加 lambda:GetFunctionConcurrency 操作。",
        "reason": "添加 lambda:GetFunctionConcurrency 操作并不会直接减少节流。这只是允许执行角色获取函数的并发配额信息，无法解决节流问题。"
      },
      "E": {
        "option": "请求增加并发限制的服务配额变更。",
        "reason": "请求增加并发限制的服务配额可以有效减少节流，因为这将增加 Lambda 函数的整体并发处理能力。"
      }
    }
  },
  {
    "number": "241",
    "best": ["D"],
    "question": "一家公司正在使用具有 AWS Lambda 集成的 Amazon API Gateway 创建一个 REST 服务。为了测试目的，该服务必须运行不同的版本。最好的实现方法是什么？",
    "options": {
      "A": {
        "option": "使用 X-Version 头来表示调用的是哪个版本，并将该头传递给 Lambda 函数。",
        "reason": "虽然可以使用 X-Version 头来标识版本，但这种方法需要在 Lambda 函数中处理额外的逻辑来解析和路由请求，增加了复杂性和维护成本。"
      },
      "B": {
        "option": "创建一个 API Gateway Lambda 授权器，将 API 客户端路由到正确的 API 版本。",
        "reason": "使用 Lambda 授权器来路由不同版本的 API 请求不是最佳实践。Lambda 授权器主要用于身份验证和授权，而不是路由功能。"
      },
      "C": {
        "option": "创建一个 API Gateway 资源策略来隔离版本，并向 Lambda 函数提供上下文。",
        "reason": "API Gateway 资源策略主要用于控制访问权限，并不直接用于版本管理，因此不适合这种场景。"
      },
      "D": {
        "option": "将 API 版本部署为具有唯一端点的独特阶段，并使用阶段变量来提供进一步的上下文。",
        "reason": "将 API 版本作为不同的阶段进行部署是最佳实践。这种方法清晰明了，每个版本都有自己的端点，易于管理和测试。同时，使用阶段变量可以为 Lambda 函数提供额外的上下文信息。"
      }
    }
  },
  {
    "number": "242",
    "best": ["A", "B"],
    "question": "公司正在使用AWS CodePipeline交付其应用程序。交付流水线由对AWS CodeCommit存储库主分支的更改触发，并使用AWS CodeBuild实现测试和构建阶段，然后使用AWS CodeDeploy部署应用程序。流水线已经成功运行了几个月，没有进行过修改。在最近对应用程序的源代码进行更改后，AWS CodeDeploy未按预期部署更新的应用程序。可能的原因是什么？（选择两个。）",
    "options": {
      "A": {
        "option": "更改未在AWS CodeCommit存储库的主分支中进行。",
        "reason": "根据题目，流水线是由对主分支的更改触发的。如果更改未在主分支中进行，流水线将不会触发，因此AWS CodeDeploy不会部署更新的应用程序。"
      },
      "B": {
        "option": "流水线中的一个早期阶段失败，流水线已终止。",
        "reason": "如果流水线中任何一个阶段（如测试或构建）失败，流水线将停止执行，后续的部署阶段也不会执行。因此，可导致AWS CodeDeploy未按预期部署更新的应用程序。"
      },
      "C": {
        "option": "公司AWS CodePipeline集群中的一个Amazon EC2实例处于非活动状态。",
        "reason": "AWS CodePipeline本身是一个托管服务，不依赖于用户管理的EC2实例，因此此选项不正确。"
      },
      "D": {
        "option": "AWS CodePipeline配置错误，未调用AWS CodeDeploy。",
        "reason": "题目中提到流水线已经成功运行了几个月，没有进行过修改，因此AWS CodePipeline配置错误的可能性较低。"
      },
      "E": {
        "option": "AWS CodePipeline没有访问AWS CodeCommit的权限。",
        "reason": "如果AWS CodePipeline没有访问AWS CodeCommit的权限，那么流水线从一开始就无法正常工作，而题目中提到流水线已经成功运行了几个月，因此此选项不太可能是原因。"
      }
    }
  },
  {
    "number": "243",
    "best": ["A"],
    "question": "开发人员正在使用 AWS Serverless Application Model (AWS SAM) 在多个 AWS Lambda 函数上构建无服务器应用程序。当应用程序部署时，开发人员希望在部署后的前10分钟内将10%的流量转移到应用程序的新部署版本。如果没有问题，则所有流量必须切换到新版本。对 AWS SAM 模板做出哪些更改可以满足这些要求？",
    "options": {
      "A": {
        "option": "将 Deployment Preference Type 设置为 Canary10Percent10Minutes。将 AutoPublishAlias 属性设置为 Lambda 别名。",
        "reason": "Canary 部署策略允许将流量分阶段转移到新版本。Canary10Percent10Minutes 表示在前10分钟内将10%的流量转移到新版本，如果没有问题，则所有流量转移。AutoPublishAlias 属性自动管理 Lambda 函数的别名和版本，这与问题要求相符。"
      },
      "B": {
        "option": "将 Deployment Preference Type 设置为 Linear10PercentEvery10Minutes。将 AutoPublishAlias 属性设置为 Lambda 别名。",
        "reason": "Linear 部署策略表示每10分钟增加10%的流量，直到所有流量都转移到新版本。这与问题中的要求不符，因为问题要求在前10分钟内转移10%的流量，然后全部转移。"
      },
      "C": {
        "option": "将 Deployment Preference Type 设置为 Canary10Percent10Minutes。将 PreTraffic 和 PostTraffic 属性设置为 Lambda 别名。",
        "reason": "虽然 Canary10Percent10Minutes 部署策略是正确的，但 PreTraffic 和 PostTraffic 属性用于在流量转移前后执行 Lambda 函数，不是用于配置流量分配的。因此这不是最佳选项。"
      },
      "D": {
        "option": "将 Deployment Preference Type 设置为 Linear10PercentEvery10Minutes。将 PreTraffic 和 PostTraffic 属性设置为 Lambda 别名。",
        "reason": "Linear 部署策略不符合问题要求，因为它每10分钟增加10%的流量，而不是在前10分钟转移10%的流量然后全部转移。PreTraffic 和 PostTraffic 属性也不相关，因为它们用于在流量转移前后执行 Lambda 函数。"
      }
    }
  },
  {
    "number": "244",
    "best": ["B"],
    "question": "一个公司的共享AWS账户中的AWS Lambda函数需要执行一个ec2:DescribeInstances操作，该操作指向公司的开发账户。开发人员必须配置跨账户的所需权限，如何按照最小权限原则配置这些权限？",
    "options": {
      "A": {
        "option": "在共享账户中创建一个IAM角色。为该角色添加ec2:DescribeInstances权限。为该角色在开发账户之间建立信任关系。通过添加ec2:DescribeInstances权限来更新共享账户中的Lambda函数IAM角色。",
        "reason": "该选项没有遵循最小权限原则，因为它为共享账户中的Lambda函数IAM角色直接添加了ec2:DescribeInstances权限，这样会使该角色拥有更多不必要的权限。"
      },
      "B": {
        "option": "在开发账户中创建一个IAM角色。为该角色添加ec2:DescribeInstances权限。与共享账户为该角色建立信任关系。通过添加iam:AssumeRole权限来更新共享账户中的Lambda函数IAM角色。",
        "reason": "这是最佳选项。通过在开发账户中创建一个具有必要权限的IAM角色，并与共享账户建立信任关系，Lambda函数可以使用iam:AssumeRole权限来临时获取该角色的权限，这样符合最小权限原则。"
      },
      "C": {
        "option": "在共享账户中创建一个IAM角色。为该角色添加ec2:DescribeInstances权限。为该角色在开发账户之间建立信任关系。通过添加iam:AssumeRole权限来更新共享账户中的Lambda函数IAM角色。",
        "reason": "虽然这个选项使用了iam:AssumeRole权限，但它在共享账户中创建了一个拥有ec2:DescribeInstances权限的角色，这样会使共享账户中的角色拥有更多不必要的权限，不符合最小权限原则。"
      },
      "D": {
        "option": "在开发账户中创建一个IAM角色。为该角色添加ec2:DescribeInstances权限。与共享账户为该角色建立信任关系。通过添加ec2:DescribeInstances权限来更新共享账户中的Lambda函数IAM角色。",
        "reason": "这个选项直接在共享账户中的Lambda函数IAM角色上添加了ec2:DescribeInstances权限，这样会赋予该角色更多不必要的权限，不符合最小权限原则。"
      }
    }
  },
  {
    "number": "245",
    "best": ["B", "E"],
    "question": "开发人员正在构建一个将在AWS上部署的新应用程序。开发人员为应用程序创建了一个AWS CodeCommit存储库。开发人员通过调用AWS Cloud Development Kit (AWS CDK) cdk init命令初始化了一个新项目。开发人员必须为AWS CDK生成的基础设施即代码（IaC）模板编写单元测试。开发人员还必须在CDK应用程序的所有构建上运行验证工具，以确保激活关键的安全配置。哪种操作组合将以最少的开发开销满足这些要求？（选择两项。）",
    "options": {
      "A": {
        "option": "使用单元测试框架针对AWS CDK生成的cdk.out文件编写自定义单元测试。在每次提交到存储库后调用的持续集成和持续交付（CI/CD）管道中运行单元测试。",
        "reason": "虽然这种方法可以实现单元测试，但它涉及到手动编写和维护自定义测试代码，这增加了开发开销。"
      },
      "B": {
        "option": "使用CDK断言模块将单元测试集成到应用程序中。在每次提交到存储库后调用的持续集成和持续交付（CI/CD）管道中运行单元测试。",
        "reason": "CDK断言模块专门用于测试CDK应用程序，能够简化单元测试的编写和维护，减少开发开销。"
      },
      "C": {
        "option": "使用CDK运行时上下文设置必须存在于由AWS CDK生成的cdk.out文件中的键值对。如果存在任何违规则使堆栈合成失败。",
        "reason": "这方法更适合于特定配置的验证，而不是单元测试，并且需要手动设置上下文值，增加了开发开销。"
      },
      "D": {
        "option": "编写一个脚本，搜索应用程序中特定的关键配置字符串。配置该脚本以生成任何安全违规的报告。",
        "reason": "虽然可以检测安全问题，但需要手动编写和维护脚本，增加了开发开销。"
      },
      "E": {
        "option": "使用CDK Aspects类创建应用于CDK应用程序的自定义规则。如果存在任何违规则使堆栈合成失败。",
        "reason": "CDK Aspects类可以用来自动化安全配置的检查和验证，减少了手动检查的需要和开发开销。"
      }
    }
  },
  {
    "number": "246",
    "best": ["A"],
    "question": "一家在线销售公司正在开发一个在AWS上运行的无服务器应用程序。该应用程序使用一个AWS Lambda函数来计算订单成功率，并将数据存储在Amazon DynamoDB表中。一名开发人员希望以一种高效的方式每15分钟调用一次Lambda函数。哪种解决方案能够以最少的开发工作量满足这一要求？",
    "options": {
      "A": {
        "option": "创建一个具有速率表达式的Amazon EventBridge规则，该规则将每15分钟运行一次。将Lambda函数添加为EventBridge规则的目标。",
        "reason": "使用Amazon EventBridge可以非常简便地设置定时任务，只需定义一个规则并将Lambda函数作为目标即可实现每15分钟调用一次。这种方法不仅简单高效，而且无需额外的维护和管理，最适合以最少的开发工作量实现需求。"
      },
      "B": {
        "option": "创建一个包含脚本的AWS Systems Manager文档，该脚本将在Amazon EC2上调用Lambda函数。使用Systems Manager Run Command任务每15分钟运行一次shell脚本。",
        "reason": "虽然AWS Systems Manager可以实现定时任务，但它需要依赖EC2实例，并且需要编写和维护脚本，相较于直接使用EventBridge，开发和维护工作量较大，不是最优选择。"
      },
      "C": {
        "option": "创建一个AWS Step Functions状态机。配置状态机在指定间隔时间使用Wait状态调用Lambda函数的执行角色。将间隔设置为15分钟。",
        "reason": "AWS Step Functions适合用于复杂的工作流和任务编排，对于简单的定时调用Lambda函数来说，过于复杂且增加了不必要的复杂性和维护成本。"
      },
      "D": {
        "option": "配置一个小型Amazon EC2实例。设置一个每15分钟调用Lambda函数的cron任务。",
        "reason": "使用EC2实例和cron任务虽然可以实现需求，但需要维护EC2实例和cron任务的配置，这增加了额外的管理和成本，不是最优选择。"
      }
    }
  },
  {
    "number": "247",
    "best": ["A"],
    "question": "公司将一个照片处理应用程序部署到Amazon EC2实例。应用程序需要在不超过5秒的时间内处理每张照片。如果处理时间超过5秒，公司开发团队必须收到通知。开发人员如何以最少的操作开销实现所需的时间测量和通知？",
    "options": {
      "A": {
        "option": "创建一个Amazon CloudWatch自定义指标。每次处理照片时，将处理时间作为指标值发布。创建一个基于5秒静态阈值的CloudWatch报警。使用Amazon Simple Notification Service (Amazon SNS)主题通知开发团队。",
        "reason": "这是最优选项，因为使用Amazon CloudWatch自定义指标和基于静态阈值的报警可以很方便地监控照片处理时间，并且使用SNS主题可以轻松地通知开发团队。这样的方法具有较低的操作开销，并且直接解决了问题。"
      },
      "B": {
        "option": "创建一个Amazon Simple Queue Service (Amazon SQS)队列。每次处理照片时，将处理时间发布到队列。创建一个应用程序从队列中消费，并确定是否有任何值超过5秒。使用Amazon Simple Notification Service (Amazon SNS)主题通知开发团队。",
        "reason": "虽然可以实现，但操作开销较高，因为需要维护额外的应用程序来消费队列并检查处理时间。这比直接使用CloudWatch自定义指标和报警更复杂。"
      },
      "C": {
        "option": "创建一个Amazon CloudWatch自定义指标。每次处理照片时，将处理时间作为指标值发布。创建一个基于平均值大于5秒的CloudWatch报警。通过发送Amazon Simple Email Service (Amazon SES)消息通知开发团队。",
        "reason": "使用平均值作为报警条件不适合这种场景，因为我们需要基于单次处理时间来触发报警。此外，SES发送邮件通知的方法相较于SNS稍显繁琐。"
      },
      "D": {
        "option": "创建一个Amazon Kinesis数据流。每次处理照片时，将处理时间发布到数据流。创建一个Amazon CloudWatch报警，如果任何值超过5秒则进入报警状态。使用Amazon Simple Notification Service (Amazon SNS)主题通知开发团队。",
        "reason": "Kinesis数据流适用于实时数据流处理，但在这种情况下，它增加了不必要的复杂性和操作开销。直接使用CloudWatch自定义指标和报警更为简便和高效。"
      }
    }
  },
  {
    "number": "248",
    "best": ["B", "D"],
    "question": "公司使用 AWS Elastic Beanstalk 管理在 Amazon EC2 实例上运行的 Web 应用程序。开发人员需要进行配置更改。开发人员必须仅将更改部署到新实例。开发人员可以使用哪些类型的部署来满足此要求？（选择两个。）",
    "options": {
      "A": {
        "option": "全部同时部署",
        "reason": "全部同时部署会将更改应用到所有现有实例，而不仅仅是新实例。因此不符合题目要求。"
      },
      "B": {
        "option": "不可变部署",
        "reason": "不可变部署会创建新的实例，并在这些新的实例上进行配置更改，然后逐渐替换旧的实例。这确保了更改仅应用于新实例，符合题目要求。"
      },
      "C": {
        "option": "滚动部署",
        "reason": "滚动部署会逐步将更改应用到现有实例，直到所有实例都更新。这同样不符合题目要求，因为它会影响现有实例。"
      },
      "D": {
        "option": "蓝绿部署",
        "reason": "蓝绿部署创建一个并行的生产环境（蓝色环境），在新环境中应用更改，然后将流量从旧环境（绿色环境）切换到新环境。这确保更改仅部署到新实例，完全符合题目要求。"
      },
      "E": {
        "option": "带有额外批次的滚动部署",
        "reason": "带有额外批次的滚动部署会在滚动部署的基础上添加额外的实例以保证容量，但更改仍然会逐步应用到现有实例。这也不符合题目要求。"
      }
    }
  },
  {
    "number": "249",
    "best": ["B"],
    "question": "一名开发人员需要使用 Amazon DynamoDB 来存储客户订单。开发人员的公司要求所有客户数据在静态存储时使用公司生成的密钥进行加密。开发人员应该如何满足这些要求？",
    "options": {
      "A": {
        "option": "创建 DynamoDB 表时将加密设置为 None。编写应用程序代码，在从表中读取数据时使用密钥解密数据。在将数据写入表时使用密钥加密数据。",
        "reason": "此选项要求开发人员手动处理加密和解密。这不仅增加了开发的复杂性，还可能导致安全漏洞。AWS 提供了更简单和更安全的方式来处理数据加密，应该利用这些功能。"
      },
      "B": {
        "option": "使用 AWS Key Management Service (AWS KMS) 存储密钥。在创建 DynamoDB 表时选择一个 AWS KMS 客户管理密钥。提供 AWS KMS 密钥的 Amazon 资源名称 (ARN)。",
        "reason": "这个选项最符合要求。使用 AWS KMS 客户管理密钥，可以确保数据在静态存储时使用公司生成的密钥进行加密。这是最安全和最方便的方式来满足公司的加密要求。"
      },
      "C": {
        "option": "使用 AWS Key Management Service (AWS KMS) 存储密钥。创建 DynamoDB 表时使用默认加密。在使用 DynamoDB 软件开发工具包 (SDK) 时包含 kms:Encrypt 参数和 AWS KMS 密钥的 Amazon 资源名称 (ARN)。",
        "reason": "这个选项要求在每次操作中手动包含 kms:Encrypt 参数，这增加了操作的复杂性。使用客户管理密钥在创建表时指定加密方式是更简单和更安全的方法。"
      },
      "D": {
        "option": "使用 AWS Key Management Service (AWS KMS) 存储密钥。在创建 DynamoDB 表时选择一个 AWS KMS AWS 管理密钥。提供 AWS KMS 密钥的 Amazon 资源名称 (ARN)。",
        "reason": "AWS 管理密钥是由 AWS 管理的密钥，而非公司生成的密钥。由于题目要求使用公司生成的密钥，此选项不符合要求。"
      }
    }
  },
  {
    "number": "250",
    "best": ["D"],
    "question": "一家公司使用 AWS CloudFormation 部署一个应用程序，该应用程序使用具有 AWS Lambda 函数集成的 Amazon API Gateway REST API。应用程序使用 Amazon DynamoDB 进行数据持久化。该应用程序有三个阶段：开发、测试和生产。每个阶段使用自己的 DynamoDB 表。公司在将更改提升到生产阶段时遇到了意外问题。这些更改在开发和测试阶段是成功的。开发人员需要在下一次生产发布时将 20% 的流量路由到新的生产阶段 API。开发人员需要将剩余的 80% 流量路由到现有的生产阶段。解决方案必须将任何单个客户体验的错误次数降到最低。开发人员应采取哪种方法来满足这些要求？",
    "options": {
      "A": {
        "option": "将 20% 的计划更改更新到生产阶段。部署新的生产阶段。监控结果。重复此过程五次以测试所有计划的更改。",
        "reason": "此选项建议分阶段进行更新，但它并没有真正解决问题。它没有提供一种简单的方法来在新旧版本之间分配流量，并且可能导致更多的复杂性和错误。"
      },
      "B": {
        "option": "更新生产阶段 API 的 Amazon Route 53 DNS 记录条目以使用加权路由策略。将权重设置为 80。为生产域名添加第二条记录。将第二条路由策略更改为加权路由策略。将第二条策略的权重设置为 20。将第二条策略的别名更改为使用测试阶段 API。",
        "reason": "此选项建议使用 Route 53 的加权路由策略，但它将流量路由到测试阶段 API，这不是问题的要求。我们需要将流量分配到新的生产阶段 API，而不是测试阶段。"
      },
      "C": {
        "option": "在 REST API 前部署一个应用程序负载均衡器 (ALB)。将生产 API 的 Amazon Route 53 记录更改为将流量指向 ALB。将生产和测试阶段注册为 ALB 的目标，权重分别为 80% 和 20%。",
        "reason": "此选项建议使用 ALB 和加权目标，但它增加了额外的复杂性。使用 API Gateway 的内置功能来实现流量分配会更加简单和直接。"
      },
      "D": {
        "option": "为生产阶段 API 配置金丝雀设置。将流量导向金丝雀部署的百分比更改为 20%。对生产阶段进行计划更新。部署更改。",
        "reason": "此选项使用 API Gateway 的金丝雀部署功能，这是最适合该问题的解决方案。金丝雀部署允许您逐步发布更改，并将流量的一部分路由到新版本，以最小化客户体验的错误次数。"
      }
    }
  },
  {
    "number": "251",
    "best": ["A"],
    "question": "开发人员创建了一个数据收集应用程序，该应用程序使用 Amazon API Gateway、AWS Lambda 和 Amazon S3。应用程序的用户会定期上传数据文件，并等待验证状态显示在处理仪表板上。对于大文件，验证过程复杂且耗时。一些用户上传了大量大文件，必须等待并刷新处理仪表板以查看文件是否已验证。开发人员必须重构应用程序，以便在不重新加载整个仪表板的情况下立即更新用户仪表板上的验证结果。最符合操作效率的解决方案是什么？",
    "options": {
      "A": {
        "option": "将客户端与 API Gateway WebSocket API 集成。保存用户上传的文件和 WebSocket 连接 ID。在处理完成后将验证状态推送到连接 ID 以启动用户界面的更新。",
        "reason": "选项 A 是最佳选择，因为 WebSocket API 可以实现实时双向通信。在用户上传文件后，服务器可以通过 WebSocket 连接 ID 将验证结果实时推送到用户界面，从而立即更新用户仪表板，而无需用户手动刷新页面。这种方法非常高效，适合需要即时更新的应用场景。"
      },
      "B": {
        "option": "启动一个 Amazon EC2 微实例，并设置一个 WebSocket 服务器。用户上传文件后将文件和用户详细信息发送到 EC2 实例。使用 WebSocket 服务器在上传文件处理完成后向用户界面发送更新。",
        "reason": "选项 B 不太合适，因为启动和维护一个 EC2 实例会增加运维开销和复杂性。相比之下，使用 API Gateway WebSocket API 可以更简单地实现相同的功能，并且更具可扩展性。"
      },
      "C": {
        "option": "与用户上传的文件一起保存用户的电子邮件地址。验证过程完成后，通过 Amazon Simple Notification Service (Amazon SNS) 向上传文件的用户发送电子邮件通知。",
        "reason": "选项 C 不合适，因为电子邮件通知不是实时的，用户仍需要手动刷新仪表板查看验证结果。这与题目要求的即时更新用户界面的需求不符。"
      },
      "D": {
        "option": "将用户上传的文件和用户详细信息保存到 Amazon DynamoDB。使用 Amazon DynamoDB Streams 和 Amazon Simple Notification Service (Amazon SNS) 推送通知，将更新发送到浏览器以更新用户界面。",
        "reason": "选项 D 不太合适，因为虽然 DynamoDB Streams 和 SNS 可以实现一定程度的通知功能，但并不是为实时更新用户界面而设计的。相比之下，WebSocket 更适合实时双向通信。这种方法可能会导致延迟，无法满足即时更新的需求。"
      }
    }
  },
  {
    "number": "252",
    "best": ["A"],
    "question": "某公司的一名开发人员正在创建一个使用 Amazon API Gateway 的应用程序。该公司希望确保只有销售部门的用户才能使用该应用程序。用户通过 Amazon Cognito 使用来自第三方身份提供商 (IdP) 的联合凭证进行身份验证。开发人员设置了属性映射，以映射一个名为 Department 的属性，并将该属性传递给自定义 AWS Lambda 授权器。为了测试访问限制，开发人员在 IdP 中将他们的部门设置为工程部门，并尝试登录到应用程序。开发人员被拒绝访问。然后，开发人员将他们的部门更新为销售部门，并尝试登录。开发人员再次被拒绝访问。开发人员检查日志，发现访问被拒绝是因为开发人员的访问令牌的部门值为工程部门。以下哪项可能是开发人员的部门仍然报告为工程部门而不是销售部门的原因？",
    "options": {
      "A": {
        "option": "自定义 Lambda 授权器中启用了授权缓存。",
        "reason": "当 Lambda 授权器启用了授权缓存时，之前的授权信息会被缓存并用于后续请求，直到缓存过期。因此，即使开发人员更新了他们在 IdP 中的部门信息，缓存的旧信息仍然会被使用，导致访问被拒绝。这种情况在设置访问控制时非常常见，尤其是当访问权限依赖于动态变化的用户属性时，应该定期清除或更新缓存。"
      },
      "B": {
        "option": "在 Amazon Cognito 用户池上启用了授权缓存。",
        "reason": "Amazon Cognito 用户池并没有授权缓存的功能，因此这个选项不可能是问题的原因。Cognito 用户池主要用于身份验证和用户管理，而授权和缓存更多是由 API Gateway 和 Lambda 授权器处理的。"
      },
      "C": {
        "option": "自定义 Lambda 授权器的 IAM 角色没有 Department 标签。",
        "reason": "自定义 Lambda 授权器的 IAM 角色与 Department 标签的设置无关。IAM 角色的标签主要用于资源的标识和管理，而不是用于动态访问控制。"
      },
      "D": {
        "option": "Amazon Cognito 用户池的 IAM 角色没有 Department 标签。",
        "reason": "与自定义 Lambda 授权器的 IAM 角色类似，Cognito 用户池的 IAM 角色的标签设置不影响身份验证流程中的动态属性映射和授权。因此，这个选项也不是问题的原因。"
      }
    }
  },
  {
    "number": "253",
    "best": ["D"],
    "question": "公司已将应用程序迁移到 Amazon EC2 实例。自动扩展对应用程序用户界面运行良好。然而，向公司仓库工作人员发送运输请求的过程遇到了问题。重复的运输请求到达，一些请求丢失或到达顺序不正确。公司必须避免重复的运输请求，并且必须按请求到达的顺序处理请求。请求的大小从不超过 250 KB，处理时间为 5-10 分钟。开发人员需要重新设计应用程序以提高请求交付和处理的可靠性。开发人员应该怎么做以满足这些要求？",
    "options": {
      "A": {
        "option": "创建 Amazon Kinesis Data Firehose 交付流来处理请求。创建 Amazon Kinesis 数据流。修改应用程序以将请求写入 Kinesis 数据流。",
        "reason": "Amazon Kinesis 适用于流数据的实时处理，但在本题场景中，要求按顺序处理且避免重复，Kinesis 并不是最佳选择。"
      },
      "B": {
        "option": "创建一个 AWS Lambda 函数来处理请求。创建一个 Amazon Simple Notification Service (Amazon SNS) 主题。将 Lambda 函数订阅到 SNS 主题。修改应用程序以将请求写入 SNS 主题。",
        "reason": "Amazon SNS 适用于广播消息到多个订阅者，但无法保证消息的有序性和唯一性，因此不符合题目要求。"
      },
      "C": {
        "option": "创建一个 AWS Lambda 函数来处理请求。创建一个 Amazon Simple Queue Service (Amazon SQS) 标准队列。将 SQS 队列设置为 Lambda 函数的事件源。修改应用程序以将请求写入 SQS 队列。",
        "reason": "Amazon SQS 标准队列无法保证消息的顺序和唯一性，因此不符合题目要求。"
      },
      "D": {
        "option": "创建一个 AWS Lambda 函数来处理请求。创建一个 Amazon Simple Queue Service (Amazon SQS) FIFO 队列。将 SQS 队列设置为 Lambda 函数的事件源。修改应用程序以将请求写入 SQS 队列。",
        "reason": "Amazon SQS FIFO 队列可以保证消息的顺序和唯一性，符合题目要求，因此是最佳选择。"
      }
    }
  },
  {
    "number": "254",
    "best": ["D"],
    "question": "开发人员正在 AWS Step Functions 中创建一个包含 AWS Lambda 函数的机器学习（ML）管道。开发人员已经配置了一个 Amazon Simple Queue Service（Amazon SQS）队列，将 ML 模型参数传递到 ML 管道以训练 ML 模型。开发人员将训练好的模型上传到 Amazon S3 存储桶。开发人员需要一种解决方案，可以在本地测试 ML 管道，而不需要进行 Amazon SQS 和 Amazon S3 的服务集成调用。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "使用 Amazon CodeGuru Profiler 分析 AWS Step Functions 管道中使用的 Lambda 函数。",
        "reason": "Amazon CodeGuru Profiler 用于分析和优化应用程序的性能，而不是用于本地测试 AWS Step Functions 管道。因此，不适合用于本地测试包含服务集成的 ML 管道。"
      },
      "B": {
        "option": "使用 AWS Step Functions Local Docker 映像来运行和本地测试 Lambda 函数。",
        "reason": "虽然 AWS Step Functions Local Docker 映像可以本地运行和测试 Lambda 函数，但它并不能模拟 SQS 和 S3 的服务集成调用。"
      },
      "C": {
        "option": "使用 AWS Serverless Application Model（AWS SAM）CLI 本地运行和测试 Lambda 函数。",
        "reason": "AWS SAM CLI 主要用于本地开发、构建、测试和调试无服务器应用程序，虽然可以测试 Lambda 函数，但不能完全模拟 AWS Step Functions 与其他服务的集成。"
      },
      "D": {
        "option": "使用 AWS Step Functions Local 并模拟服务集成。",
        "reason": "AWS Step Functions Local 允许开发人员在本地运行和测试状态机，并可以模拟 Amazon SQS 和 Amazon S3 的服务集成调用，因此是最适合本地测试 ML 管道的解决方案。"
      }
    }
  },
  {
    "number": "255",
    "best": ["B"],
    "question": "一家公司通过使用 AWS Lambda 函数和 Amazon API Gateway API 运行批处理应用程序，并为开发、用户验收测试和生产部署阶段配置这些 API。开发团队需要配置部署阶段的 API 以连接到第三方服务端点。哪种解决方案能满足这一需求？",
    "options": {
      "A": {
        "option": "将第三方服务端点存储在与阶段对应的 Lambda 层中。",
        "reason": "Lambda 层通常用于共享代码和库，而不是存储特定的配置或者端点信息。因此，这不是一个理想的选择。"
      },
      "B": {
        "option": "将第三方服务端点存储在与阶段对应的 API Gateway 阶段变量中。",
        "reason": "API Gateway 阶段变量是专门设计用来在不同部署阶段之间管理和存储环境特定的变量，如第三方服务端点。此方法符合题目要求，是最佳选择。"
      },
      "C": {
        "option": "将第三方服务端点编码为 API Gateway 请求 URL 中的查询参数。",
        "reason": "将服务端点编码为查询参数并不是一种安全或高效的做法，尤其是对于不同部署阶段的管理，这样会使得 API URL 变得复杂且难以维护。"
      },
      "D": {
        "option": "将每个环境的第三方服务端点存储在 AWS AppConfig 中。",
        "reason": "虽然 AWS AppConfig 可以用于管理和存储环境配置，但其主要适用于应用程序配置的动态管理。对于 API Gateway 配置，使用阶段变量会更加直接和合适。"
      }
    }
  },
  {
    "number": "256",
    "best": ["A"],
    "question": "开发人员正在构建一个在 AWS 上运行的无服务器应用程序。开发人员希望创建一个加速的开发工作流程，以便将增量更改部署到 AWS 进行测试。开发人员希望部署增量更改，但不希望在每次代码提交时完全部署整个应用程序。开发人员应如何满足这些要求？",
    "options": {
      "A": {
        "option": "使用 AWS 无服务器应用程序模型 (AWS SAM) 构建应用程序。使用 sam sync 命令部署增量更改。",
        "reason": "AWS SAM (Serverless Application Model) 提供了 sam sync 命令，用于将本地项目的增量更改同步到云中，使开发人员可以快速测试更改而无需完全重新部署整个应用程序。这个选项符合题目中要求的加速开发工作流程。"
      },
      "B": {
        "option": "使用 AWS 无服务器应用程序模型 (AWS SAM) 构建应用程序。使用 sam init 命令部署增量更改。",
        "reason": "sam init 命令用于初始化一个新的 AWS SAM 项目，而不是用于部署增量更改。因此，这个选项不符合要求。"
      },
      "C": {
        "option": "使用 AWS 云开发工具包 (AWS CDK) 构建应用程序。使用 cdk synth 命令部署增量更改。",
        "reason": "cdk synth 命令用于合成 AWS CDK 应用程序并生成 CloudFormation 模板，但它并不直接用于部署增量更改。这个选项不符合题目的要求。"
      },
      "D": {
        "option": "使用 AWS 云开发工具包 (AWS CDK) 构建应用程序。使用 cdk bootstrap 命令部署增量更改。",
        "reason": "cdk bootstrap 命令用于初始化 AWS CDK 应用程序需要的环境资源，而不是用于部署增量更改。因此，这个选项不符合要求。"
      }
    }
  },
  {
    "number": "257",
    "best": ["B"],
    "question": "开发人员正在构建一个应用程序，该应用程序将使用 Amazon API Gateway API 和 AWS Lambda 后端。前端开发团队需要立即访问 API 端点以构建 UI。为了准备后端应用程序进行集成，开发人员需要设置端点。这些端点需要返回预定义的 HTTP 状态码和 JSON 响应以供前端团队使用。开发人员为 API 资源创建了一种方法。哪种解决方案可以满足这些需求？",
    "options": {
      "A": {
        "option": "将集成类型设置为 AWS_PROXY。提供 Lambda 函数以返回硬编码的 JSON 数据。",
        "reason": "选择此选项的原因是 AWS_PROXY 可以将请求直接传递给 Lambda 函数并返回结果。但是，这需要编写 Lambda 函数来返回硬编码的 JSON 数据，这增加了开发工作量，并且不符合快速设置端点的需求。"
      },
      "B": {
        "option": "将集成类型设置为 MOCK。配置方法的集成请求和集成响应，以将 JSON 响应与特定的 HTTP 状态码关联。",
        "reason": "此选项可以快速满足需求，因为 MOCK 集成类型允许开发人员在不需要后端的情况下配置 API 端点，并返回预定义的 JSON 响应和 HTTP 状态码。这正是题目要求的快速设置端点的方法。"
      },
      "C": {
        "option": "将集成类型设置为 HTTP_PROXY。配置 API Gateway 将所有请求传递给团队将构建的外部占位 API。",
        "reason": "选择此选项的原因是 HTTP_PROXY 能够将请求传递给外部 API。但这需要外部 API 的存在，并且仍需开发工作，不符合题目中快速设置端点的要求。"
      },
      "D": {
        "option": "将集成类型设置为 MOCK。使用方法请求定义 HTTP 状态码。使用集成请求定义 JSON 响应。",
        "reason": "此选项描述了使用 MOCK 集成类型，但对于题目要求的快速设置端点和返回预定义的响应，配置集成请求和集成响应是最直接的方法。这种方法的描述不如选项 B 明确。"
      }
    }
  },
  {
    "number": "258",
    "best": ["C"],
    "question": "开发人员正在将应用程序迁移到 Amazon Elastic Kubernetes Service (Amazon EKS)。开发人员将应用程序迁移到 Amazon Elastic Container Registry (Amazon ECR) 并创建了一个 EKS 集群。作为将应用程序迁移到新后端的一部分，开发人员创建了一个新的 AWS 账户。开发人员对应用程序进行配置更改，以将应用程序指向新 AWS 账户并使用新的后端资源。开发人员通过部署管道成功测试了这些更改。Docker 镜像构建和管道部署成功，但应用程序仍然连接到旧的后端。开发人员发现应用程序的配置仍然引用原始的 EKS 集群，而不是引用新的后端资源。哪个原因可以解释为什么应用程序没有连接到新的资源？",
    "options": {
      "A": {
        "option": "开发人员没有成功创建新的 AWS 账户。",
        "reason": "如果新的 AWS 账户没有创建成功，那么开发人员在测试时就会立即发现问题，而不是在 Docker 镜像构建和管道部署成功后才发现应用程序仍然连接到旧的后端。因此，这不是原因。"
      },
      "B": {
        "option": "开发人员向 Docker 镜像添加了一个新标签。",
        "reason": "添加新标签不会影响应用程序的配置。标签只是标识镜像的方式，不会改变镜像的内容或其运行时的行为。因此，这不是原因。"
      },
      "C": {
        "option": "开发人员没有将 Docker 镜像标签更新到新版本。",
        "reason": "如果开发人员没有更新 Docker 镜像标签到新版本，那么管道部署的仍然是旧的镜像版本，导致应用程序配置仍然指向旧的 EKS 集群和后端资源。这是最可能的原因。"
      },
      "D": {
        "option": "开发人员将更改推送到了新的 Docker 镜像标签。",
        "reason": "推送更改到新的 Docker 镜像标签本身是正确的做法，但如果没有更新部署配置以使用新的镜像标签，那么应用程序仍然会使用旧的镜像标签，从而连接到旧的后端资源。因此，这不是主要原因。"
      }
    }
  },
  {
    "number": "259",
    "best": ["B"],
    "question": "开发人员正在创建一个应用程序，该应用程序读取和写入多个 Amazon S3 存储桶。该应用程序将部署到 Amazon EC2 实例上。开发人员希望从 EC2 实例中进行安全的 API 请求，而无需管理应用程序的安全凭证。开发人员需要应用最小权限原则。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个 IAM 用户。为该用户创建访问密钥和秘密密钥。将用户与允许 s3:* 权限的 IAM 策略关联。",
        "reason": "这种方法需要管理访问密钥和秘密密钥，不符合题目要求的“不需要管理应用程序的安全凭证”。此外，s3:* 权限过于宽泛，不符合最小权限原则。"
      },
      "B": {
        "option": "将 EC2 实例与具有允许特定 S3 存储桶的 s3:ListBucket 和 s3:*Object 权限的 IAM 策略的 IAM 角色关联。",
        "reason": "通过将 EC2 实例与具有特定权限的 IAM 角色关联，可以确保安全的 API 请求且无需管理安全凭证。这也符合最小权限原则，因为只授予了所需的最低权限。"
      },
      "C": {
        "option": "将 EC2 实例与具有 AmazonS3FullAccess AWS 管理策略的 IAM 角色关联。",
        "reason": "AmazonS3FullAccess 管理策略授予了所有 S3 操作的完全访问权限，权限过大，不符合最小权限原则。"
      },
      "D": {
        "option": "在 S3 存储桶上创建一个存储桶策略，允许 EC2 实例具有 s3:ListBucket 和 s3:*Object 权限。",
        "reason": "存储桶策略可以控制存储桶的访问权限，但无法直接向 EC2 实例授予权限。EC2 实例需要通过 IAM 角色来获得适当的权限。"
      }
    }
  },
  {
    "number": "260",
    "best": ["A"],
    "question": "开发人员正在编写一个应用程序，该应用程序将从第三方系统检索敏感数据。应用程序将把数据格式化为 PDF 文件。PDF 文件可能超过 1 MB。应用程序将使用 AWS Key Management Service (AWS KMS) 将数据加密到磁盘上。用户请求下载时，应用程序将解密该文件。检索和格式化部分的应用程序已经完成。开发人员需要使用 GenerateDataKey API 来加密 PDF 文件，以便以后可以解密 PDF 文件。开发人员需要使用 AWS KMS 对称客户管理密钥进行加密。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "将 GenerateDataKey API 的加密密钥写入磁盘以备后用。使用 GenerateDataKey API 的明文密钥和对称加密算法来加密文件。",
        "reason": "这是正确的解决方案。GenerateDataKey API 返回一个明文数据密钥和一个加密的密钥。明文密钥用于加密数据，而加密的密钥被安全地存储以供以后解密。这样可以确保文件数据被加密，同时在需要时可以解密。"
      },
      "B": {
        "option": "将 GenerateDataKey API 的明文密钥写入磁盘以备后用。使用 GenerateDataKey API 的加密密钥和对称加密算法来加密文件。",
        "reason": "这是不正确的。明文密钥不应写入磁盘，因为这会带来安全风险。应将加密的密钥写入磁盘，以确保密钥安全。"
      },
      "C": {
        "option": "将 GenerateDataKey API 的加密密钥写入磁盘以备后用。使用 GenerateDataKey API 的明文密钥通过 KMS Encrypt API 来加密文件。",
        "reason": "这是不正确的。KMS Encrypt API 用于加密数据或数据密钥，但在这种情况下，明文密钥应直接用于对称加密算法来加密文件，而不是再次使用 KMS Encrypt API。"
      },
      "D": {
        "option": "将 GenerateDataKey API 的明文密钥写入磁盘以备后用。使用 GenerateDataKey API 的加密密钥通过 KMS Encrypt API 来加密文件。",
        "reason": "这是不正确的。明文密钥不应写入磁盘，且加密密钥是加密后的密钥，不能直接用于加密文件。正确的方法是使用明文密钥加密文件，并将加密密钥安全存储。"
      }
    }
  },
  {
    "number": "261",
    "best": ["B"],
    "question": "一家公司在 Amazon EC2 实例上运行一个应用程序。EC2 实例打开与 Amazon RDS for SQL Server 数据库的连接。一位开发人员需要存储和访问凭证，并希望自动轮换凭证。开发人员不希望在代码中存储凭证。哪种解决方案能够以最安全的方式满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个具有访问数据库权限的 IAM 角色。将 IAM 角色附加到 EC2 实例。",
        "reason": "将 IAM 角色附加到 EC2 实例可以提供对数据库的访问权限，但这并不能解决存储和自动轮换凭证的问题。IAM 角色的主要作用是提供对 AWS 服务的访问权限，而不是管理数据库凭证。"
      },
      "B": {
        "option": "将凭证存储为 AWS Secrets Manager 中的密钥。创建一个 AWS Lambda 函数来更新密钥和数据库。根据需要从 Secrets Manager 中检索凭证。",
        "reason": "AWS Secrets Manager 专为安全存储和管理敏感信息（如数据库凭证）而设计。它还提供自动轮换密钥的功能。通过创建一个 AWS Lambda 函数，可以实现自动更新密钥和数据库，从而确保凭证的安全性和便捷性。这是最符合题目要求的解决方案。"
      },
      "C": {
        "option": "将凭证存储在 Amazon S3 存储桶中的加密文本文件中。配置 EC2 实例启动模板，在实例启动时从 Amazon S3 下载凭证。创建一个 AWS Lambda 函数来更新密钥和数据库。",
        "reason": "虽然将凭证存储在加密的 S3 文本文件中可以保证一定程度的安全性，但这种方法不如 AWS Secrets Manager 专门针对凭证存储和管理的功能。同时，这种方法的实施复杂度更高，不如使用 AWS Secrets Manager 的集成度高。"
      },
      "D": {
        "option": "将凭证存储在 Amazon DynamoDB 表中。配置一个 Amazon CloudWatch Events 规则，定期调用一个 AWS Lambda 函数来更新密钥和数据库。",
        "reason": "虽然可以将凭证存储在 DynamoDB 表中，并通过 CloudWatch Events 和 Lambda 函数实现自动更新，但这种方法没有 AWS Secrets Manager 这样专门针对凭证管理的服务安全和便捷。DynamoDB 主要用于存储和快速查询数据，不是专门为管理敏感信息设计的。"
      }
    }
  },
  {
    "number": "262",
    "best": ["B"],
    "question": "一家公司希望更频繁地测试其Web应用程序。公司使用单独的AWS CloudFormation堆栈为每个环境部署应用程序。公司在应用程序通过开发生命周期时将同一个CloudFormation模板部署到每个堆栈。开发人员需要为质量保证（QA）团队建立通知。开发人员希望在最终的预生产环境中进行新部署时发送通知。哪种解决方案可以满足这些需求？",
    "options": {
      "A": {
        "option": "创建一个Amazon Simple Notification Service（Amazon SNS）主题。将QA团队订阅到Amazon SNS主题。在预生产环境中更新CloudFormation堆栈选项以指向SNS主题。",
        "reason": "虽然SNS可以用于发送通知，但题目没有提及如何区分不同环境的部署。没有明确提到如何在预生产环境中过滤特定的堆栈事件。"
      },
      "B": {
        "option": "创建一个AWS Lambda函数来通知QA团队。创建一个Amazon EventBridge规则以在默认事件总线上调用Lambda函数。根据CloudFormation服务和CloudFormation堆栈Amazon资源名称（ARN）过滤事件。",
        "reason": "这是最佳答案。EventBridge可以灵活地过滤特定的事件，并结合Lambda函数可以实现精确的通知。能够根据CloudFormation堆栈的ARN进行过滤，确保只在预生产环境中触发通知。"
      },
      "C": {
        "option": "创建一个监控CloudFormation度量的Amazon CloudWatch警报。根据堆栈名称和堆栈状态过滤度量。配置CloudWatch警报以通知QA团队。",
        "reason": "CloudWatch警报通常用于监控特定度量标准的异常情况，不太适合事件驱动的通知需求。虽然可以监控堆栈状态，但实现起来复杂且不够灵活。"
      },
      "D": {
        "option": "创建一个AWS Lambda函数来通知QA团队。配置事件源映射以接收来自CloudFormation的事件。指定过滤值以限制调用到所需的CloudFormation堆栈。",
        "reason": "虽然Lambda函数可以进行通知，但事件源映射通常用于处理数据流或队列，不适合直接处理CloudFormation事件。EventBridge是处理这种事件过滤的更好选择。"
      }
    }
  },
  {
    "number": "263",
    "best": ["B"],
    "question": "一个开发人员管理三个 AWS 账户。每个账户包含一个位于私有子网中的 Amazon RDS 数据库实例。开发人员需要以一致的方式在每个数据库中定义用户。开发人员必须确保在所有三个账户中创建和更新相同的用户。哪种解决方案最能满足这些要求并具有最高的操作效率？",
    "options": {
      "A": {
        "option": "创建一个 AWS CloudFormation 模板。在模板中声明用户。将用户附加到数据库。在每个账户中部署模板。",
        "reason": "虽然 CloudFormation 模板可以帮助声明用户，但它不能直接附加到 RDS 数据库用户管理中，这需要额外的步骤来确保用户创建和更新，并且操作效率不高。"
      },
      "B": {
        "option": "创建一个包含自定义资源的 AWS CloudFormation 模板，以在数据库中创建用户。在每个账户中部署模板。",
        "reason": "这是最优解，因为自定义资源可以在 CloudFormation 部署过程中执行自定义逻辑，这样可以确保用户在所有账户中的一致性创建和更新，同时保持高操作效率。"
      },
      "C": {
        "option": "编写一个创建用户的脚本。在每个账户中部署一个 Amazon EC2 实例以在数据库上运行脚本。在每个账户中运行脚本。",
        "reason": "用脚本和 EC2 实例来管理用户虽然可行，但操作效率低，维护成本高，并且增加了管理和安全风险。"
      },
      "D": {
        "option": "实现一个 AWS Lambda 函数，在数据库中创建用户。向函数提供所有三个账户的详细信息。",
        "reason": "使用 Lambda 函数虽然可以实现自动化，但需要额外的步骤来管理跨账户访问和权限，这增加了复杂性和安全风险。相比之下，使用 CloudFormation 自定义资源更为简洁和高效。"
      }
    }
  },
  {
    "number": "264",
    "best": ["A"],
    "question": "公司正在构建一个在 AWS 上运行的新应用程序，并使用 Amazon API Gateway 来公开 API。开发团队正在并行工作于应用程序的不同组件。公司希望在没有集成后端的情况下发布一个 API，以便依赖应用程序后端的团队能够在 API 后端开发完成之前继续进行开发工作。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "创建 API Gateway 资源并将集成类型值设置为 MOCK。配置方法集成请求和集成响应以将响应与 HTTP 状态码关联。创建一个 API Gateway 阶段并部署 API。",
        "reason": "选项 A 使用了 API Gateway 的 MOCK 集成类型，这是在后端尚未开发完成时进行 API 开发和测试的理想选择。MOCK 集成类型允许开发人员创建虚拟响应，从而使前端开发人员可以继续工作。"
      },
      "B": {
        "option": "创建一个返回模拟响应和各种 HTTP 状态码的 AWS Lambda 函数。创建 API Gateway 资源并将集成类型值设置为 AWS_PROXY。部署 API。",
        "reason": "选项 B 虽然可以实现类似的目标，但创建和维护一个返回模拟响应的 Lambda 函数会增加不必要的复杂性。相比之下，MOCK 集成更适合这种情况，因为它更简单且直接。"
      },
      "C": {
        "option": "创建一个返回模拟 HTTP 响应的 EC2 应用程序。创建 API Gateway 资源并将集成类型值设置为 AWS。创建一个 API Gateway 阶段并部署 API。",
        "reason": "选项 C 依赖于 EC2 实例来返回模拟响应，这不仅增加了成本，还增加了管理和维护的复杂性。在这种情况下，使用 MOCK 集成类型更为简便和高效。"
      },
      "D": {
        "option": "创建 API Gateway 资源并将集成类型值设置为 HTTP_PROXY。添加映射模板并部署 API。创建一个返回各种 HTTP 状态码的 AWS Lambda 层。将 Lambda 层与 API 部署关联。",
        "reason": "选项 D 的方法过于复杂且没有必要。HTTP_PROXY 集成类型通常用于代理现有的 HTTP 端点，而不是用于创建模拟响应。MOCK 集成类型更适合这种需求。"
      }
    }
  },
  {
    "number": "265",
    "best": ["A"],
    "question": "一个在 AWS 上运行的应用程序从 Amazon Simple Queue Service (Amazon SQS) 队列接收消息并批量处理这些消息。应用程序将数据发送到另一个 SQS 队列以供另一个遗留应用程序使用。遗留系统可能需要最多 5 分钟来处理某些事务数据。开发人员希望确保遗留系统中没有乱序更新。开发人员不能更改遗留系统的行为。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "使用 SQS FIFO 队列。配置可见性超时值。",
        "reason": "SQS FIFO 队列确保消息按顺序传递，这对于防止遗留系统中出现乱序更新是必要的。可见性超时值可以确保消息在处理期间不会被其他消费者看到，适合需要较长时间处理消息的场景。"
      },
      "B": {
        "option": "使用 SQS 标准队列和 SendMessageBatchRequestEntry 数据类型。配置 DelaySeconds 值。",
        "reason": "SQS 标准队列不能保证消息按顺序传递，可能导致遗留系统中出现乱序更新。DelaySeconds 只能延迟消息的可见性，不能解决顺序问题。"
      },
      "C": {
        "option": "使用 SQS 标准队列和 SendMessageBatchRequestEntry 数据类型。配置可见性超时值。",
        "reason": "虽然可见性超时可以确保消息在处理期间不会被其他消费者看到，但 SQS 标准队列不能保证消息按顺序传递，因此不能满足防止乱序更新的需求。"
      },
      "D": {
        "option": "使用 SQS FIFO 队列。配置 DelaySeconds 值。",
        "reason": "虽然 SQS FIFO 队列可以确保消息按顺序传递，但 DelaySeconds 仅用于延迟消息的可见性，而不是处理时间。因此，配置 DelaySeconds 并不能解决处理时间较长的问题。"
      }
    }
  },
  {
    "number": "266",
    "best": ["A"],
    "question": "公司正在构建一个计算密集型应用程序，该应用程序将在一组 Amazon EC2 实例上运行。该应用程序使用附加的 Amazon Elastic Block Store (Amazon EBS) 卷来存储数据。Amazon EBS 卷将在初始部署时创建。应用程序将处理敏感信息。所有数据都必须加密。解决方案不应影响应用程序的性能。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "配置一组 EC2 实例以使用加密的 EBS 卷来存储数据。",
        "reason": "选择 A 是最佳答案，因为 Amazon EBS 提供了透明的数据加密功能，可以在不影响性能的情况下保护静态数据。通过使用加密的 EBS 卷，数据在传输和存储过程中都将被加密，符合处理敏感信息的要求。此外，Amazon EBS 加密是由硬件加速的，不会显著影响性能。"
      },
      "B": {
        "option": "配置应用程序将所有数据写入加密的 Amazon S3 存储桶。",
        "reason": "尽管 Amazon S3 提供了加密存储，但题目明确要求使用 EBS 卷来存储数据，因此此选项不符合题目要求。使用 S3 可能会改变应用程序的架构，可能会对性能产生影响。"
      },
      "C": {
        "option": "为应用程序配置自定义加密算法，以加密和解密所有数据。",
        "reason": "自定义加密算法可能会增加开发和维护的复杂性，并且可能会对应用程序的性能产生显著影响。AWS 提供的 EBS 加密是经过优化的，可以满足性能要求，因此自定义加密不必要。"
      },
      "D": {
        "option": "配置一个具有加密根卷的 Amazon 机器映像 (AMI)，并将数据存储在临时磁盘上。",
        "reason": "临时磁盘（实例存储）数据在实例停止或终止时会丢失，不适合存储需要持久保存的敏感数据。此外，实例存储不支持加密，而使用 EBS 卷可以确保数据持久性和加密。"
      }
    }
  },
  {
    "number": "267",
    "best": ["D"],
    "question": "开发人员正在更新 AWS Lambda 函数的生产版本以修复缺陷。开发人员已经在测试环境中测试了更新后的代码。开发人员希望在将更新推送给所有用户之前，先逐步将更新推送给一小部分生产用户。最初只有 10% 的用户应该接触到生产中的新代码。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "更新 Lambda 代码并创建 Lambda 函数的新版本。创建一个 Lambda 函数触发器。在触发器中配置两个 Lambda 函数版本之间的流量权重。将 90% 的流量发送到生产版本，将 10% 的流量发送到新版本。",
        "reason": "虽然提到了配置流量权重，但 Lambda 函数触发器本身并不支持流量分配功能。"
      },
      "B": {
        "option": "创建一个使用更新代码的新 Lambda 函数。为生产 Lambda 函数创建一个 Lambda 别名。将 Lambda 别名配置为将 90% 的流量发送到生产 Lambda 函数，将 10% 的流量发送到测试 Lambda 函数。",
        "reason": "这提到了创建一个新函数和通过别名分配流量，但不符合题目要求，因为不需要创建新的 Lambda 函数，而是需要使用现有函数的不同版本。"
      },
      "C": {
        "option": "更新 Lambda 代码并创建 Lambda 函数的新版本。创建一个 Lambda 代理集成。将 Lambda 代理配置为在两个 Lambda 函数版本之间分配流量。将 90% 的流量发送到生产版本，将 10% 的流量发送到新版本。",
        "reason": "Lambda 代理集成更多用于 API Gateway 集成，而不是直接用于 Lambda 函数版本的流量分配。"
      },
      "D": {
        "option": "更新 Lambda 代码并创建 Lambda 函数的新版本。创建一个 Lambda 函数别名。在 Lambda 别名中配置两个 Lambda 函数版本之间的流量权重。将 90% 的流量发送到生产版本，将 10% 的流量发送到新版本。",
        "reason": "这是最佳选择，因为它正确利用了 Lambda 函数别名的流量权重功能，能够满足逐步发布更新的需求。"
      }
    }
  },
  {
    "number": "268",
    "best": ["A"],
    "question": "一位开发人员正在创建一个 AWS Lambda 函数，该函数从 Amazon Simple Queue Service (Amazon SQS) 标准队列中消费消息。开发人员注意到 Lambda 函数处理一些消息多次。开发人员应该如何最具成本效益地解决这个问题？",
    "options": {
      "A": {
        "option": "使用 Amazon SQS 消息去重 ID 将 Amazon SQS 标准队列更改为 Amazon SQS FIFO 队列。",
        "reason": "Amazon SQS 标准队列保证消息至少一次交付，可能会导致消息被多次处理。而 Amazon SQS FIFO 队列通过使用消息去重 ID 可以确保每条消息仅处理一次，这解决了消息重复处理的问题。虽然 FIFO 队列的吞吐量较低，但它是解决消息重复处理的最直接和成本效益最高的方法。"
      },
      "B": {
        "option": "设置死信队列。",
        "reason": "死信队列用于处理无法成功处理的消息，但它并不能解决消息多次处理的问题。因此，这不是解决这个问题的有效方法。"
      },
      "C": {
        "option": "将 AWS Lambda 函数的最大并发限制设置为 1。",
        "reason": "将并发限制设置为 1 可以确保一次只有一个实例在运行，但这会极大地限制函数的吞吐量，并且并不能完全解决消息重复处理的问题。这不是最优的解决方案。"
      },
      "D": {
        "option": "将消息处理更改为使用 Amazon Kinesis Data Streams 而不是 Amazon SQS。",
        "reason": "虽然 Amazon Kinesis Data Streams 也可以用于消息处理，但它的复杂性和成本较高，而且并不是针对解决消息重复处理问题的最佳选择。因此，改变消息处理服务不是最具成本效益的解决方案。"
      }
    }
  },
  {
    "number": "269",
    "best": ["A"],
    "question": "开发人员正在优化 AWS Lambda 函数，并希望在生产环境中对所有流量的一小部分进行测试。Lambda 函数处理对 Amazon API Gateway 中 REST API 的请求。开发人员需要部署他们的更改并在生产环境中进行测试，而不更改 API Gateway URL。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "为当前部署的生产 Lambda 函数定义一个函数版本。更新 API Gateway 端点以引用新的 Lambda 函数版本。上传并发布优化后的 Lambda 函数代码。在生产 API Gateway 阶段，定义一个金丝雀发布并设置流量的百分比以引导到金丝雀发布。更新 API Gateway 端点以使用最新版本的 Lambda 函数。将 API 发布到金丝雀阶段。",
        "reason": "此选项满足所有要求。通过定义函数版本和金丝雀发布，可以在生产环境中逐步测试新的 Lambda 函数版本而不更改 API Gateway URL，从而减少对用户的影响。同时，这种方法确保了现有的生产流量不会被大规模扰动。"
      },
      "B": {
        "option": "为当前部署的生产 Lambda 函数定义一个函数版本。更新 API Gateway 端点以引用新的 Lambda 函数版本。上传并发布优化后的 Lambda 函数代码。更新 API Gateway 端点以使用最新版本的 Lambda 函数。部署一个新的 API Gateway 阶段。",
        "reason": "此选项要求部署一个新的 API Gateway 阶段，这将改变 API Gateway URL，不符合不更改 API Gateway URL 的要求。"
      },
      "C": {
        "option": "在最新版本的 Lambda 函数上定义一个别名。更新 API Gateway 端点以引用新的 Lambda 函数别名。上传并发布优化后的 Lambda 函数代码。在生产 API Gateway 阶段，定义一个金丝雀发布并设置流量的百分比以引导到金丝雀发布。更新 API Gateway 端点以使用最新版本的 Lambda 函数。发布到金丝雀阶段。",
        "reason": "此选项没有先创建一个函数版本，这在生产环境中可能会导致不必要的风险。引用别名而不是版本可能引发潜在的版本管理问题。"
      },
      "D": {
        "option": "为当前部署的生产 Lambda 函数定义一个函数版本。更新 API Gateway 端点以引用新的 Lambda 函数版本。上传并发布优化后的 Lambda 函数代码。更新 API Gateway 端点以使用最新版本的 Lambda 函数。将 API 部署到生产 API Gateway 阶段。",
        "reason": "此选项没有使用金丝雀发布策略，因此无法在生产环境中逐步测试新的 Lambda 函数版本。直接更新和部署到生产阶段可能会导致所有流量立即受到影响，风险较大。"
      }
    }
  },
  {
    "number": "270",
    "best": ["C"],
    "question": "一家公司注意到用于连接到外部SaaS供应商的凭证以明文形式存储在配置文件中。开发人员需要确保API凭证的安全，并每季度自动轮换凭证。哪种解决方案最安全地满足这些要求？",
    "options": {
      "A": {
        "option": "使用AWS Key Management Service（AWS KMS）加密配置文件。当用户向SaaS供应商发出API调用时，解密配置文件。启用轮换。",
        "reason": "虽然AWS KMS可以加密和解密配置文件，但它本身并不直接提供自动凭证轮换功能。此外，加密和解密整个配置文件可能会引入不必要的复杂性和开销。"
      },
      "B": {
        "option": "每15分钟从AWS Security Token Service（AWS STS）检索临时凭证。当用户向SaaS供应商发出API调用时，使用临时凭证。",
        "reason": "AWS STS主要用于生成短期的临时凭证，以提供对AWS资源的临时访问。这不是存储和轮换长期凭证的最佳工具，并且每15分钟轮换一次并不符合每季度轮换的要求。"
      },
      "C": {
        "option": "将凭证存储在AWS Secrets Manager中并启用轮换。配置API以访问Secrets Manager。",
        "reason": "AWS Secrets Manager专门用于安全存储和管理敏感信息，如API密钥和凭证。它提供自动凭证轮换功能，非常适合本题的要求。"
      },
      "D": {
        "option": "将凭证存储在AWS Systems Manager Parameter Store中并启用轮换。当用户向SaaS供应商发出API调用时，检索凭证。",
        "reason": "虽然AWS Systems Manager Parameter Store可以存储敏感数据并支持凭证轮换，但其轮换功能不如AWS Secrets Manager强大和直接。因此，AWS Secrets Manager是更好的选择。"
      }
    }
  },
  {
    "number": "271",
    "best": ["A", "C"],
    "question": "一家公司有一个托管在 Amazon EC2 实例上的应用程序。该应用程序将对象存储在 Amazon S3 存储桶中，并允许用户从 S3 存储桶中下载对象。开发人员为 S3 存储桶开启了 S3 公共访问阻止。更改后，用户在尝试下载对象时报告错误。开发人员需要实施一个解决方案，以便只有登录到该应用程序的用户才能访问 S3 存储桶中的对象。哪种步骤组合可以以最安全的方式满足这些要求？（选择两个）",
    "options": {
      "A": {
        "option": "为 EC2 实例创建具有适当策略的实例配置文件和角色。将角色与 EC2 实例关联。",
        "reason": "通过为 EC2 实例分配适当的 IAM 角色和策略，可以确保 EC2 实例以安全的方式访问 S3 存储桶，而无需在实例上存储长期凭证。这种方法符合最佳安全实践。"
      },
      "B": {
        "option": "创建一个具有适当策略的 IAM 用户。在 EC2 实例上存储访问密钥 ID 和秘密访问密钥。",
        "reason": "在 EC2 实例上存储访问密钥和秘密访问密钥不符合安全最佳实践，因为这增加了凭证泄露的风险。因此，不建议使用这种方法。"
      },
      "C": {
        "option": "修改应用程序以使用 S3 GeneratePresignedUrl API 调用。",
        "reason": "使用预签名 URL 是一种安全的方式，允许应用程序生成临时访问 S3 对象的 URL。这确保了只有经过身份验证的用户可以访问特定对象，且 URL 具有有限的有效期。"
      },
      "D": {
        "option": "修改应用程序以使用 S3 GetObject API 调用并返回对象句柄给用户。",
        "reason": "直接返回对象句柄给用户可能会引发安全问题，因为这可能使对象句柄暴露给未经授权的用户。因此，这不是最佳的解决方案。"
      },
      "E": {
        "option": "修改应用程序以委托对 S3 存储桶的请求。",
        "reason": "这个选项不够明确，且直接委托请求到 S3 存储桶可能会引发安全和权限管理问题，因此不推荐使用这种方法。"
      }
    }
  },
  {
    "number": "272",
    "best": ["A", "B"],
    "question": "一个 Amazon Simple Queue Service (Amazon SQS) 队列用作 AWS Lambda 函数的事件源。在 SQS 队列中，每个项目对应一个需要 Lambda 函数转换为较小分辨率的视频文件。对于较长的视频文件，Lambda 函数超时了，但是 Lambda 函数的超时时间已经配置为最大值。开发人员应该怎么做才能避免超时，而无需进行额外的代码更改？",
    "options": {
      "A": {
        "option": "增加 Lambda 函数的内存配置。",
        "reason": "增加内存配置不仅会增加可用内存，还会增加 CPU 资源，这可能会加快视频转换过程并减少超时的可能性。"
      },
      "B": {
        "option": "增加 SQS 队列的可见性超时。",
        "reason": "增加可见性超时可以给 Lambda 函数更多的时间来处理每个消息，从而减少超时的可能性，特别是在 Lambda 函数的最大超时时间已经达到的情况下。"
      },
      "C": {
        "option": "增加运行 Lambda 函数的主机实例的大小。",
        "reason": "Lambda 函数是无服务器的，不运行在固定大小的主机实例上，因此这个选项不适用。"
      },
      "D": {
        "option": "使用多线程进行转换。",
        "reason": "使用多线程需要额外的代码修改，而题目要求不进行额外的代码更改，因此这个选项不合适。"
      }
    }
  },
  {
    "number": "273",
    "best": ["A"],
    "question": "某公司正在 AWS 上构建一个应用程序。该应用程序的后端包括一个 Amazon API Gateway REST API。公司的前端应用程序开发人员在后端 API 准备好进行集成之前无法继续工作。公司需要一个解决方案，以便前端应用程序开发人员能够继续他们的工作。哪种解决方案在操作上是最有效的？",
    "options": {
      "A": {
        "option": "为 API Gateway API 方法配置模拟集成。",
        "reason": "配置模拟集成为 API Gateway 方法，可以返回预定义的响应，这样前端开发人员就可以继续开发和测试他们的应用程序，而无需后端实际实现。这种方法在操作上是最有效的，因为无需编写额外的代码，只需在 API Gateway 中进行配置即可。"
      },
      "B": {
        "option": "将 Lambda 函数与 API Gateway 集成并返回模拟响应。",
        "reason": "虽然可以使用 Lambda 函数返回模拟响应，但这需要编写和部署额外的代码，并增加了不必要的复杂性和维护成本，因此在操作上不如直接使用 API Gateway 的模拟集成有效。"
      },
      "C": {
        "option": "向 API Gateway 阶段添加新的 API 端点并返回模拟响应。",
        "reason": "这种方法也可以实现模拟响应，但需要额外的配置和管理新端点，增加了复杂性和操作负担，不如直接使用 API Gateway 的模拟集成有效。"
      },
      "D": {
        "option": "为 API Gateway API 方法配置代理资源。",
        "reason": "代理资源通常用于将请求直接传递给后端服务，而不处理或修改请求。虽然可以用于某些集成场景，但不适合用于返回模拟响应。因此，这种方法不符合题目的需求。"
      }
    }
  },
  {
    "number": "274",
    "best": ["B", "E"],
    "question": "公司正在准备将一个应用程序迁移到公司的第一个 AWS 环境。在此迁移之前，开发人员正在创建一个概念验证应用程序，以验证在 AWS 上构建和部署基于容器的应用程序的模型。开发人员应采取哪些步骤以最少的操作工作量来部署容器化的概念验证应用程序？（选择两个）",
    "options": {
      "A": {
        "option": "使用命令行工具将应用程序打包成 .zip 文件。将该包上传到 Amazon S3。",
        "reason": "这种方法虽然可以将应用程序打包并上传到 Amazon S3，但它并不是部署容器化应用程序的最佳实践，也不符合题目中要求的最少操作工作量。"
      },
      "B": {
        "option": "使用 Docker CLI 将应用程序打包成容器镜像。将镜像上传到 Amazon Elastic Container Registry (Amazon ECR)。",
        "reason": "这是部署容器化应用程序的标准步骤之一。使用 Docker CLI 打包成容器镜像后，上传到 Amazon ECR，这样其他 AWS 服务可以轻松访问并部署这些镜像。"
      },
      "C": {
        "option": "使用 AWS CodeDeploy 将应用程序部署到 Amazon EC2 实例。",
        "reason": "虽然 AWS CodeDeploy 可以部署应用程序到 EC2 实例，但这并不是部署容器化应用程序的最优选择，尤其是在考虑最少操作工作量的情况下。"
      },
      "D": {
        "option": "将应用程序部署到 Amazon Elastic Kubernetes Service (Amazon EKS) 上的 AWS Fargate。",
        "reason": "虽然 Amazon EKS 是一个强大的托管 Kubernetes 服务，并且 AWS Fargate 可以无服务器运行容器，但对于概念验证应用程序来说，这可能有些复杂，且操作工作量相对较大。"
      },
      "E": {
        "option": "将应用程序部署到 Amazon Elastic Container Service (Amazon ECS) 上的 AWS Fargate。",
        "reason": "Amazon ECS 是一种简化的托管容器编排服务，结合 AWS Fargate 无服务器运行容器，能以最少的操作工作量来部署容器化应用程序。这符合题目要求的最少操作工作量的条件。"
      }
    }
  },
  {
    "number": "275",
    "best": ["A"],
    "question": "一名开发人员支持一个访问 Amazon DynamoDB 表中数据的应用程序。其中一个项属性是以时间戳格式表示的 expirationDate。应用程序使用此属性查找项目、归档它们并根据时间戳值从表中删除它们。该应用程序即将停用，开发人员必须找到另一种方法来实现此功能。开发人员需要一个代码量最少的解决方案。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "在表中的 expirationDate 属性上启用 TTL。创建一个 DynamoDB 流。创建一个 AWS Lambda 函数来处理已删除的项目。为 Lambda 函数创建一个 DynamoDB 触发器。",
        "reason": "选项 A 通过启用 TTL（Time to Live）来自动删除过期的项目，同时通过 DynamoDB 流和 Lambda 函数处理删除的项目。这样可以减少手动编写代码的量，并利用内置的 AWS 功能来完成任务，因此是最优解。"
      },
      "B": {
        "option": "创建两个 AWS Lambda 函数：一个用于删除项目，一个用于处理项目。创建一个 DynamoDB 流。使用 DeleteItem API 操作根据 expirationDate 属性删除项目。使用 GetRecords API 操作从 DynamoDB 流中获取项目并处理它们。",
        "reason": "选项 B 需要手动编写更多的代码来处理删除和获取记录的逻辑，而不是利用 DynamoDB 的 TTL 功能，因此不是最佳选择。"
      },
      "C": {
        "option": "创建两个 AWS Lambda 函数：一个用于删除项目，一个用于处理项目。创建一个 Amazon EventBridge 定时规则来调用 Lambda 函数。使用 DeleteItem API 操作根据 expirationDate 属性删除项目。使用 GetRecords API 操作从 DynamoDB 表中获取项目并处理它们。",
        "reason": "选项 C 需要手动编写更多的代码来处理定时任务和记录获取逻辑，增加了系统复杂性，因此不是最佳选择。"
      },
      "D": {
        "option": "在表中的 expirationDate 属性上启用 TTL。指定一个 Amazon Simple Queue Service (Amazon SQS) 死信队列作为删除项目的目标。创建一个 AWS Lambda 函数来处理项目。",
        "reason": "选项 D 利用 TTL 功能自动删除项目，但将删除的项目发送到 SQS 死信队列并手动处理，增加了额外的步骤和复杂性，因此不是最佳选择。"
      }
    }
  },
  {
    "number": "276",
    "best": ["D"],
    "question": "一名开发人员需要在应用程序中实现一个自定义的机器学习（ML）库。该库的大小为15 GB，并且还在不断增加。应用程序使用AWS Lambda函数。所有的Lambda函数都必须能够访问这个库。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "将库保存在Lambda层中。将这些层附加到所有的Lambda函数。",
        "reason": "Lambda层有资源大小限制，单个层的限制为50 MB，整个Lambda函数的总大小限制为250 MB。因此，15 GB的库明显超出了Lambda层的限制，无法满足需求。"
      },
      "B": {
        "option": "将库保存在Amazon S3中。在Lambda函数内部从Amazon S3下载该库。",
        "reason": "这种方法会导致每次Lambda函数触发时都需要下载15 GB的数据，显著增加了启动时间和延迟，不是一个高效的解决方案。"
      },
      "C": {
        "option": "将库保存为Lambda容器镜像。使用新镜像重新部署Lambda函数。",
        "reason": "Lambda容器镜像的大小限制为10 GB，而库的大小为15 GB，超出了这个限制，不能使用容器镜像的方法。"
      },
      "D": {
        "option": "将库保存在Amazon Elastic File System（Amazon EFS）文件系统中。在所有的Lambda函数中挂载EFS文件系统。",
        "reason": "Amazon EFS可以提供大规模存储，并且可以被多个Lambda函数同时访问。EFS文件系统可以动态扩展，适合存储大量数据，满足15 GB及更大的库需求。因此，这是最优解决方案。"
      }
    }
  },
  {
    "number": "277",
    "best": ["A"],
    "question": "开发人员正在为一款游戏设计一个无服务器应用程序，用户通过网页浏览器注册和登录。应用程序代表用户向一组运行在 Amazon API Gateway HTTP API 后面的 AWS Lambda 函数发出请求。开发人员需要在应用程序的登录页面上实现注册和登录用户的解决方案。解决方案必须最小化运营开销并最小化对用户身份的持续管理。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "为外部社交身份提供商创建 Amazon Cognito 用户池。配置身份池的 IAM 角色。",
        "reason": "Amazon Cognito 是 AWS 提供的一个用于管理用户注册、登录和访问控制的服务，它支持多个外部社交身份提供商（如 Google、Facebook 等），并且能够大大简化用户身份管理。使用 Cognito 用户池可以有效减少运营开销和持续管理工作，因此这是最佳选择。"
      },
      "B": {
        "option": "将登录页面编程为创建附加了 IAM 角色的用户 IAM 组。",
        "reason": "这种方法需要手动管理 IAM 用户和组，不仅增加了操作复杂性和运营开销，而且不适用于大规模用户管理。因此，这不是最佳选择。"
      },
      "C": {
        "option": "创建一个用于存储用户的 Amazon RDS for SQL Server 数据库实例，并管理对 AWS 后端资源的权限。",
        "reason": "虽然 RDS 可以用来存储用户数据，但这需要大量的运营和维护工作，并且不适合管理用户身份和权限。因此，这不是最佳选择。"
      },
      "D": {
        "option": "将登录页面配置为在具有附加 IAM 策略的 Amazon DynamoDB 表中注册和存储用户及其密码。",
        "reason": "尽管 DynamoDB 可以用来存储用户数据，但直接存储用户密码并不安全，也需要额外的工作来实现身份验证和权限管理。因此，这不是最佳选择。"
      }
    }
  },
  {
    "number": "278",
    "best": ["D"],
    "question": "一家公司有一个托管在 Amazon EC2 实例上的 Web 应用程序。这些 EC2 实例被配置为将日志流传输到 Amazon CloudWatch Logs。该公司需要在应用程序错误消息数量在 5 分钟内超过定义的阈值时收到 Amazon Simple Notification Service (Amazon SNS) 通知。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "重写应用程序代码，以将应用程序日志流传输到 Amazon SNS。当错误数量在 5 分钟内超过定义的阈值时，配置一个 SNS 主题发送通知。",
        "reason": "这个选项要求重写应用程序代码，这是不必要且不符合题目要求的。题目明确说明日志已经流传输到 CloudWatch Logs，因此无需将日志直接发送到 SNS。"
      },
      "B": {
        "option": "在 CloudWatch Logs 日志组上配置订阅过滤器。当错误数量在 5 分钟内超过定义的阈值时，配置过滤器发送 SNS 通知。",
        "reason": "CloudWatch Logs 订阅过滤器不支持直接基于数量阈值来发送通知。它们主要用于实时流日志处理和转发，不适合用于这种错误计数的场景。"
      },
      "C": {
        "option": "在 EC2 实例上安装和配置 Amazon Inspector 代理以监控错误。当错误数量在 5 分钟内超过定义的阈值时，配置 Amazon Inspector 发送 SNS 通知。",
        "reason": "Amazon Inspector 主要用于安全漏洞和合规性检查，不适用于监控应用程序日志错误。因此，这不是一个合适的解决方案。"
      },
      "D": {
        "option": "创建一个 CloudWatch 指标过滤器以匹配日志数据中的应用程序错误模式。基于新的自定义指标设置一个 CloudWatch 警报。当错误数量在 5 分钟内超过定义的阈值时，配置警报发送 SNS 通知。",
        "reason": "这是最佳选项。CloudWatch 指标过滤器允许从日志数据中创建自定义指标，然后可以基于这些指标设置警报并配置 SNS 通知。这完全符合题目的要求，且不需要修改应用程序代码。"
      }
    }
  },
  {
    "number": "279",
    "best": ["C"],
    "question": "一个照片分享应用程序使用Amazon S3存储图像文件。所有用户图像由第三方公司手动审核是否有不当内容。审核在用户上传后1-24小时内完成，结果写入一个使用S3对象密钥作为主键的Amazon DynamoDB表。可以通过第三方公司创建的REST API查询数据库项。应用程序开发人员需要实现一个自动化过程，以审核结果标记所有S3对象。开发人员应该怎么做以最有效的方式满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个AWS Lambda函数以响应s3:ObjectCreated事件类型。将S3密钥写入一个具有24小时可见性超时的Amazon Simple Queue Service (Amazon SQS)队列。创建并配置第二个Lambda函数以从队列中读取项。从DynamoDB表中检索每个项的结果。相应地标记每个S3对象。",
        "reason": "此方法较为复杂，需要两个Lambda函数和一个SQS队列。虽然可行，但并非最有效的方法。"
      },
      "B": {
        "option": "创建一个AWS Lambda函数以响应s3:ObjectCreated事件类型。将函数集成到AWS Step Functions标准工作流中。定义一个AWS Step Functions等待状态，并将值设置为24小时。创建并配置第二个Lambda函数以在等待状态结束后检索审核结果并相应地标记S3对象。",
        "reason": "此方法使用了AWS Step Functions，它可以实现等待，但整体流程相对复杂，并且可能会导致不必要的资源消耗。"
      },
      "C": {
        "option": "创建一个AWS Lambda函数以加载所有未标记的S3对象。通过REST API检索每个项的结果并相应地标记每个S3对象。创建并配置一个Amazon EventBridge规则以定期运行。将Lambda函数设置为EventBridge规则的目标。",
        "reason": "这是最有效的方法。使用EventBridge定期触发Lambda函数，减少了管理复杂性，并且Lambda函数可自动处理所有未标记的S3对象。"
      },
      "D": {
        "option": "启动一个Amazon EC2实例。将脚本部署到EC2实例上，以使用外部数据库结果相应地标记S3对象。配置crontab文件以定期运行脚本。",
        "reason": "使用EC2实例运行脚本需要管理和维护服务器，增加了操作复杂性和成本，且不如使用Lambda函数和EventBridge规则高效。"
      }
    }
  },
  {
    "number": "280",
    "best": ["B"],
    "question": "公司构建了一个 AWS Lambda 函数来将大图像文件转换为可在第三方查看器应用程序中使用的输出文件。公司最近为该函数添加了一个新模块以改进生成文件的输出。然而，新模块增加了包的大小，并增加了部署函数代码更改所需的时间。开发人员如何提高 Lambda 函数部署的速度？",
    "options": {
      "A": {
        "option": "使用 AWS CodeDeploy 部署函数代码。",
        "reason": "AWS CodeDeploy 是一种用于自动化代码部署的服务，但它并不会直接减少 Lambda 函数的包大小或加快部署速度。它主要用于管理和自动化部署过程，并不适合解决由于包大小增大而导致的部署速度问题。"
      },
      "B": {
        "option": "使用 Lambda 层来打包和加载依赖项。",
        "reason": "使用 Lambda 层可以将依赖项与函数代码分开，从而减小部署包的大小。通过将公共库和依赖项放在层中，开发人员可以只部署函数代码的变化，而不必每次都包括所有依赖项。这将显著提高部署速度，是解决该问题的最佳方案。"
      },
      "C": {
        "option": "增加函数的内存大小。",
        "reason": "增加内存大小可能会提高函数的执行速度，但它不会减少部署时间。内存大小主要影响的是函数在运行时的性能，而不是部署过程。因此，这不是解决问题的最佳方法。"
      },
      "D": {
        "option": "使用 Amazon S3 托管函数依赖项。",
        "reason": "将依赖项托管在 Amazon S3 上可以减少包的大小，但函数在运行时仍需要从 S3 下载这些依赖项，这可能会引入额外的延迟。相比之下，Lambda 层是更适合这个场景的解决方案，因为它们专门用于管理和加载依赖项。"
      }
    }
  },
  {
    "number": "281",
    "best": ["C"],
    "question": "一名开发人员为他们的部门创建了一个静态网站。开发人员将网站的静态资源部署到一个 Amazon S3 存储桶，并使用 Amazon CloudFront 提供访问。开发人员在 CloudFront 分配中使用了源访问控制 (OAC) 来访问 S3 存储桶。开发人员注意到用户可以访问根 URL 和特定页面，但不能在不指定文件名的情况下访问目录。例如，/products/index.html 可以访问，但 /products/ 返回错误。开发人员需要在不公开 S3 存储桶的情况下启用访问目录而不指定文件名。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "更新 CloudFront 分配的设置，将 index.html 设置为默认根对象。",
        "reason": "此选项会将 index.html 设置为根对象，但它不会解决访问目录而不指定文件名的问题。"
      },
      "B": {
        "option": "更新 Amazon S3 存储桶设置并启用静态网站托管。指定 index.html 作为索引文档。更新 S3 存储桶策略以启用访问。更新 CloudFront 分配的源以使用 S3 网站端点。",
        "reason": "此选项将启用 S3 静态网站托管并更新策略，但这会公开 S3 存储桶，而题目要求是不公开 S3 存储桶。"
      },
      "C": {
        "option": "创建一个 CloudFront 函数，该函数检查请求 URL 并在访问目录时附加 index.html。将该函数作为查看请求 CloudFront 函数添加到 CloudFront 分配的行为中。",
        "reason": "这个选项使用 CloudFront 函数来动态处理请求 URL，并在访问目录时附加 index.html。在不公开 S3 存储桶的情况下，这将解决问题。"
      },
      "D": {
        "option": "在 CloudFront 分配上创建自定义错误响应，将 HTTP 错误代码设置为 HTTP 404 Not Found 响应代码，并将响应页面路径设置为 /index.html。将 HTTP 响应代码设置为 HTTP 200 OK 响应代码。",
        "reason": "此选项将使用自定义错误响应来处理目录访问，但这并不是最佳实践，并且可能导致不必要的开销和复杂性。"
      }
    }
  },
  {
    "number": "282",
    "best": ["A"],
    "question": "一名开发人员正在测试一个通过 Amazon API Gateway 和 AWS Lambda 部署的 RESTful 应用程序。当开发人员使用无效的凭据测试用户登录时，收到 HTTP 405: METHOD_NOT_ALLOWED 错误。开发人员已经验证测试正在为资源发送正确的请求。应用程序应该返回哪个 HTTP 错误以响应请求？",
    "options": {
      "A": {
        "option": "HTTP 401",
        "reason": "HTTP 401 Unauthorized 错误表示请求没有被应用程序授权。对于无效的凭据，这个错误代码是最合适的，因为它明确表示用户未被认证或凭据不正确。"
      },
      "B": {
        "option": "HTTP 404",
        "reason": "HTTP 404 Not Found 错误表示请求的资源在服务器上不存在。此错误不适用于无效的凭据，因为资源存在，只是凭据无效。"
      },
      "C": {
        "option": "HTTP 503",
        "reason": "HTTP 503 Service Unavailable 错误表示服务器由于暂时的过载或维护而无法处理请求。这与无效的凭据无关，因此不适用。"
      },
      "D": {
        "option": "HTTP 505",
        "reason": "HTTP 505 HTTP Version Not Supported 错误表示服务器不支持请求中使用的 HTTP 版本。这与无效的凭据无关，因此不适用。"
      }
    }
  },
  {
    "number": "283",
    "best": ["D"],
    "question": "开发人员必须使用多因素身份验证 (MFA) 来访问另一个 AWS 账户中的 Amazon S3 存储桶中的数据。开发人员应使用哪种 AWS 安全令牌服务 (AWS STS) API 操作与 MFA 信息来满足此要求？",
    "options": {
      "A": {
        "option": "使用 Web 身份假设角色",
        "reason": "AssumeRoleWithWebIdentity 主要用于与第三方身份提供商（如 Google, Facebook 等）集成，允许通过 Web 身份验证来假设角色。这与使用 MFA 访问 S3 存储桶的需求不匹配。"
      },
      "B": {
        "option": "获取联合身份令牌",
        "reason": "GetFederationToken 主要用于为联合用户创建临时安全凭证，通常适用于企业内部的联合身份验证。虽然它支持 MFA，但它不是最佳选择，因为问题明确要求在跨账户场景中使用角色。"
      },
      "C": {
        "option": "使用 SAML 假设角色",
        "reason": "AssumeRoleWithSAML 用于与 SAML 2.0 提供商集成，这通常适用于企业级的单点登录（SSO）解决方案。虽然可以与 MFA 一起使用，但问题没有提到 SAML，因此不是最佳选择。"
      },
      "D": {
        "option": "假设角色",
        "reason": "AssumeRole 是跨账户访问的标准方法，并且支持使用 MFA。开发人员可以使用 MFA 来假设另一个账户中的角色，从而访问 S3 存储桶中的数据。这是最合适的 API 操作。"
      }
    }
  },
  {
    "number": "284",
    "best": ["B", "C"],
    "question": "一名开发人员在 Amazon EC2 实例上设计了一个应用程序。该应用程序向 Amazon S3 存储桶中的对象发出 API 请求。哪种步骤组合将确保应用程序以最安全的方式发出 API 请求？（选择两项）",
    "options": {
      "A": {
        "option": "创建一个拥有 S3 存储桶权限的 IAM 用户，将该用户添加到一个 IAM 组。",
        "reason": "虽然这种方法可以授予权限，但将用户凭证存储在实例上并不安全。最佳实践是使用 IAM 角色而不是 IAM 用户，以避免在实例上存储静态凭证。"
      },
      "B": {
        "option": "创建一个拥有 S3 存储桶权限的 IAM 角色。",
        "reason": "这是最佳实践之一，因为 IAM 角色可以提供临时凭证，并且不需要在实例上存储静态凭证。"
      },
      "C": {
        "option": "将 IAM 角色添加到实例配置文件中，并将实例配置文件附加到 EC2 实例。",
        "reason": "这是确保 EC2 实例能够安全访问 S3 存储桶的最佳方法之一。通过实例配置文件，EC2 实例可以自动获得 IAM 角色的权限，而无需在实例上存储静态凭证。"
      },
      "D": {
        "option": "创建一个拥有 S3 存储桶权限的 IAM 角色，将该角色分配给一个 IAM 组。",
        "reason": "这种方法不合适，因为 IAM 角色不能直接添加到 IAM 组中。IAM 角色是为 AWS 服务或者其他受信实体设计的，而不是为 IAM 组。"
      },
      "E": {
        "option": "将 IAM 用户的凭证存储在 EC2 实例的环境变量中。",
        "reason": "这不是最佳实践，因为存储静态凭证在实例上存在很大的安全风险。使用 IAM 角色和实例配置文件可以避免这种风险。"
      }
    }
  },
  {
    "number": "285",
    "best": ["B"],
    "question": "一个 AWS Lambda 函数需要对一个 Amazon S3 存储桶进行读取访问，并且需要对一个 Amazon DynamoDB 表进行读写访问。已经存在正确的 IAM 策略。最安全的方式是什么来授予 Lambda 函数对 S3 存储桶和 DynamoDB 表的访问权限？",
    "options": {
      "A": {
        "option": "将现有的 IAM 策略附加到 Lambda 函数。",
        "reason": "虽然这种方法可以授予 Lambda 函数所需的权限，但直接将 IAM 策略附加到 Lambda 函数并不是最佳实践。最佳实践是使用 IAM 角色来管理权限，这样可以更安全和方便地管理权限。"
      },
      "B": {
        "option": "为 Lambda 函数创建一个 IAM 角色。将现有的 IAM 策略附加到该角色。将该角色附加到 Lambda 函数。",
        "reason": "这是最安全和推荐的方式。通过创建一个 IAM 角色并将其附加到 Lambda 函数，可以确保权限是通过角色进行管理的，这符合 AWS 最佳实践。此外，IAM 角色可以自动轮换凭证，提供额外的安全性。"
      },
      "C": {
        "option": "创建一个具有编程访问权限的 IAM 用户。将现有的 IAM 策略附加到该用户。将用户的访问密钥 ID 和秘密访问密钥作为环境变量添加到 Lambda 函数中。",
        "reason": "这种方法不符合最佳实践，因为它涉及到在 Lambda 函数中存储和管理长期凭证（访问密钥 ID 和秘密访问密钥）。这种方法容易导致凭证泄漏和安全风险。"
      },
      "D": {
        "option": "将 AWS 账户根用户的访问密钥 ID 和秘密访问密钥作为加密环境变量添加到 Lambda 函数中。",
        "reason": "绝对不推荐这种方法。根用户权限过大，使用根用户的凭证会带来极大的安全风险。如果根用户的凭证泄漏，会导致整个账户的安全问题。"
      }
    }
  },
  {
    "number": "286",
    "best": ["C"],
    "question": "开发人员正在使用 AWS Step Functions 来自动化工作流。工作流将每个步骤定义为 AWS Lambda 函数任务。开发人员注意到Step Functions状态机在GetResource任务中因IllegalArgumentException错误或TooManyRequestsException错误而失败。开发人员希望状态机在遇到IllegalArgumentException错误时停止运行。如果状态机遇到TooManyRequestsException错误，需要在10秒后重试GetResource任务一次。如果第二次尝试失败，开发人员希望状态机停止运行。开发人员如何在不增加状态机复杂性的情况下实现Lambda的重试功能？",
    "options": {
      "A": {
        "option": "在GetResource任务之后添加一个Delay任务。为GetResource任务添加一个捕获器。配置捕获器的错误类型为TooManyRequestsException。将下一个步骤配置为Delay任务。将Delay任务配置为等待10秒。将下一个步骤配置为GetResource任务。",
        "reason": "这种方法增加了额外的任务和步骤，增加了状态机的复杂性。"
      },
      "B": {
        "option": "为GetResource任务添加一个捕获器。配置捕获器的错误类型为TooManyRequestsException，间隔10秒，最大尝试次数为1。将下一个步骤配置为GetResource任务。",
        "reason": "捕获器通常用于处理错误后的补救措施，而不是用于重试逻辑，因此这种方法不太符合实际需求。"
      },
      "C": {
        "option": "为GetResource任务添加一个重试器。配置重试器的错误类型为TooManyRequestsException，间隔10秒，最大尝试次数为1。",
        "reason": "重试器正是用于处理这种错误并进行重试的最佳工具，它可以在不增加状态机复杂性的情况下实现所需的功能。"
      },
      "D": {
        "option": "复制GetResource任务。将新任务重命名为TryAgain。为原始GetResource任务添加一个捕获器。配置捕获器的错误类型为TooManyRequestsException。将下一个步骤配置为TryAgain。",
        "reason": "这种方法虽然能实现目标，但通过复制任务增加了状态机的复杂性，不是最佳选择。"
      }
    }
  },
  {
    "number": "287",
    "best": ["D"],
    "question": "开发人员正在创建一个使用 AWS Lambda 函数的无服务器应用程序。开发人员将使用 AWS CloudFormation 部署该应用程序。应用程序将日志写入 Amazon CloudWatch Logs。开发人员已在 CloudFormation 模板中为应用程序创建了一个日志组。开发人员需要修改 CloudFormation 模板，以便在运行时使应用程序能够使用日志组的名称。哪种解决方案可以满足这个需求？",
    "options": {
      "A": {
        "option": "使用 CloudFormation 中的 AWS::Include 转换来提供日志组的名称给应用程序。",
        "reason": "AWS::Include transform 用于包括外部文件内容，但它不直接用于传递动态信息如日志组的名称给 Lambda 函数。因此，这不是合适的解决方案。"
      },
      "B": {
        "option": "在 CloudFormation 模板的用户数据部分将日志组的名称传递给应用程序。",
        "reason": "用户数据一般用于 EC2 实例的初始化脚本，而不是用于 Lambda 函数环境。因此，这不是一个合适的选择。"
      },
      "C": {
        "option": "使用 CloudFormation 模板的 Mappings 部分为应用程序指定日志组的名称。",
        "reason": "Mappings 部分通常用于创建静态映射，而不是用于动态传递信息。因此，这不是一个合适的选择。"
      },
      "D": {
        "option": "将日志组的 Amazon Resource Name (ARN) 作为环境变量传递给 Lambda 函数。",
        "reason": "通过将日志组的 ARN 作为环境变量传递给 Lambda 函数，您可以在运行时轻松访问和使用该信息。这是一个常见的做法，可以满足题目中的要求。"
      }
    }
  },
  {
    "number": "288",
    "best": ["D"],
    "question": "一名开发人员正在使用 AWS CLI 创建一个 Amazon DynamoDB 表。该 DynamoDB 表必须使用 AWS 拥有的加密密钥进行服务器端加密。开发人员应如何创建符合这些要求的 DynamoDB 表？",
    "options": {
      "A": {
        "option": "创建一个 AWS Key Management Service (AWS KMS) 客户管理密钥。在创建 DynamoDB 表时，在 KMSMasterKeyId 参数中提供该密钥的 Amazon 资源名称 (ARN)。",
        "reason": "客户管理密钥 (CMK) 是一个由用户创建和管理的密钥，此选项不符合使用 AWS 拥有的加密密钥的要求。"
      },
      "B": {
        "option": "创建一个 AWS Key Management Service (AWS KMS) AWS 管理密钥。在创建 DynamoDB 表时，在 KMSMasterKeyId 参数中提供该密钥的 Amazon 资源名称 (ARN)。",
        "reason": "AWS 管理密钥 (AWS managed key) 是由 AWS 为每个服务自动创建和管理的密钥，但此选项仍然需要指定密钥 ARN，不符合题目要求。"
      },
      "C": {
        "option": "创建一个 AWS 拥有的密钥。在创建 DynamoDB 表时，在 KMSMasterKeyId 参数中提供该密钥的 Amazon 资源名称 (ARN)。",
        "reason": "AWS 拥有的密钥是由 AWS 完全管理的密钥，客户无法直接访问或管理这些密钥。因此，在创建 DynamoDB 表时无法提供这种密钥的 ARN。"
      },
      "D": {
        "option": "使用默认加密选项创建 DynamoDB 表。",
        "reason": "默认情况下，DynamoDB 表会使用 AWS 拥有的加密密钥进行服务器端加密。因此，此选项是最符合题目要求的。"
      }
    }
  },
  {
    "number": "289",
    "best": ["B"],
    "question": "一家公司有一个跨多个 AWS 区域运行的应用程序。该应用程序在不规则的时间间隔内出现性能问题。开发人员必须使用 AWS X-Ray 实现分布式跟踪，以排查性能问题的根本原因。开发人员应该怎么做来满足这个要求？",
    "options": {
      "A": {
        "option": "使用 X-Ray 控制台为 AWS 服务和用户定义的服务添加注释。",
        "reason": "X-Ray 控制台主要用于查看和分析跟踪数据，而不是用于添加注释。注释通常是在代码中或通过 X-Ray SDK 添加的。"
      },
      "B": {
        "option": "使用 X-Ray 自动为 AWS 服务添加的区域注释。为用户定义的服务添加区域注释。",
        "reason": "X-Ray 会自动为 AWS 服务添加区域注释。对于用户定义的服务，开发人员需要手动添加区域注释。这是符合题目要求的最佳选项。"
      },
      "C": {
        "option": "使用 X-Ray 守护进程为 AWS 服务和用户定义的服务添加注释。",
        "reason": "X-Ray 守护进程主要用于收集和发送跟踪数据到 X-Ray 服务，而不是用于添加注释。注释通常是在代码中或通过 X-Ray SDK 添加的。"
      },
      "D": {
        "option": "使用 X-Ray 自动为用户定义的服务添加的区域注释。配置 X-Ray 为 AWS 服务添加区域注释。",
        "reason": "X-Ray 不会自动为用户定义的服务添加区域注释，这需要开发人员手动添加。而 AWS 服务的区域注释是自动添加的。"
      }
    }
  },
  {
    "number": "290",
    "best": ["C"],
    "question": "一家公司在AWS上运行一个应用程序。该应用程序使用一个配置了Amazon Simple Queue Service (Amazon SQS)队列（称为高优先级队列）作为事件源的AWS Lambda函数。开发人员正在更新Lambda函数，添加另一个称为低优先级队列的SQS队列作为事件源。Lambda函数必须始终从高优先级队列中读取最多10条同时消息，然后再处理低优先级队列中的消息。Lambda函数的并发调用次数必须限制在100次。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "将事件源映射批量大小设置为高优先级队列的10和低优先级队列的90。",
        "reason": "批量大小只是控制每次批处理的消息数量，而不是并发控制。此选项无法确保高优先级队列的消息优先处理。"
      },
      "B": {
        "option": "将高优先级队列的传递延迟设置为0秒，低优先级队列的传递延迟设置为10秒。",
        "reason": "传递延迟只是消息进入队列中的延迟时间，不影响Lambda函数的并发调用和优先级处理。"
      },
      "C": {
        "option": "将事件源映射的最大并发设置为高优先级队列的10和低优先级队列的90。",
        "reason": "此选项允许高优先级队列最多有10个并发调用，并限制Lambda函数的总并发调用次数为100，从而确保高优先级消息优先处理。"
      },
      "D": {
        "option": "将事件源映射的批量窗口设置为高优先级队列的10和低优先级队列的90。",
        "reason": "批量窗口控制的是批处理时间窗口，而不是并发调用。此选项无法确保高优先级队列的消息优先处理。"
      }
    }
  },
  {
    "number": "291",
    "best": ["D"],
    "question": "一家数据可视化公司希望加强其核心应用程序的安全性。应用程序在 AWS 上跨开发、暂存、预生产和生产环境部署。公司需要加密所有存储的敏感凭证。这些敏感凭证需要自动轮换。每个环境都需要存储一个版本的敏感凭证。哪种解决方案将以最具操作效率的方式满足这些要求？",
    "options": {
      "A": {
        "option": "配置 AWS Secrets Manager 版本以在多个环境中存储相同凭证的不同副本。",
        "reason": "虽然 AWS Secrets Manager 支持版本管理，但该选项没有明确提及为每个环境创建单独的密钥。这个方法可能会导致跨环境凭证管理的复杂性。"
      },
      "B": {
        "option": "在 AWS Systems Manager Parameter Store 中为每个环境创建一个新的参数版本。将特定环境的凭证存储在参数版本中。",
        "reason": "AWS Systems Manager Parameter Store 确实可以存储和管理参数，但自动轮换凭证的功能不如 AWS Secrets Manager 强大。因此，这不是最优选择。"
      },
      "C": {
        "option": "在应用程序代码中配置环境变量。为每种环境类型使用不同的名称。",
        "reason": "虽然可以通过这种方式管理凭证，但这不是最安全和高效的管理敏感凭证的方法。尤其是没有自动轮换机制。"
      },
      "D": {
        "option": "配置 AWS Secrets Manager 为每种环境类型创建一个新的密钥。将特定环境的凭证存储在密钥中。",
        "reason": "AWS Secrets Manager 专为存储、管理和轮换敏感信息而设计。它提供了自动轮换凭证的功能，并且可以为每个环境创建单独的密钥。这种方法最符合题目要求，且操作效率最高。"
      }
    }
  },
  {
    "number": "292",
    "best": ["A", "D"],
    "question": "开发人员正在调查公司应用程序中的一个问题。在应用程序中，消息被发送到 Amazon Simple Queue Service (Amazon SQS) 队列。AWS Lambda 函数从 SQS 队列轮询消息，并使用 Amazon Simple Email Service (Amazon SES) 发送电子邮件消息。在高流量期间，用户收到重复的电子邮件消息。哪些原因可以解释重复的电子邮件消息？（选择两个。）",
    "options": {
      "A": {
        "option": "标准 SQS 队列支持至少一次消息传递。",
        "reason": "标准 SQS 队列在设计上保证消息至少被传递一次（at-least-once delivery），这意味着在高流量期间，可能会有重复消息被处理，从而导致重复的电子邮件。"
      },
      "B": {
        "option": "标准 SQS 队列支持一次性处理，因此重复的电子邮件消息是因为用户错误。",
        "reason": "此选项错误，标准 SQS 队列不支持一次性处理（exactly-once processing），这一特性是 FIFO 队列的功能。"
      },
      "C": {
        "option": "Amazon SES 的域密钥识别邮件 (DKIM) 认证配置错误。",
        "reason": "DKIM 认证错误不会导致重复的电子邮件，而是会影响电子邮件的送达率或被标记为垃圾邮件的概率。"
      },
      "D": {
        "option": "SQS 队列的可见性超时低于或等于 Lambda 函数的超时。",
        "reason": "如果 SQS 队列的可见性超时低于或等于 Lambda 函数的超时，消息可能在 Lambda 函数完成处理前重新变得可见，导致同一消息被多次处理，从而发送重复的电子邮件。"
      },
      "E": {
        "option": "Amazon SES 退信率指标过高。",
        "reason": "退信率高与发送重复电子邮件无关，而是反映了邮件未能成功送达收件人的问题。"
      }
    }
  },
  {
    "number": "293",
    "best": ["B"],
    "question": "一名开发人员正在将公司的应用程序部署到Amazon EC2实例。该应用程序每天生成数GB的数据文件。这些文件很少被访问，但在存储的第一年内，必须在用户请求后的几分钟内可用。公司必须保留这些文件7年。开发人员如何以最具成本效益的方式实现这些需求？",
    "options": {
      "A": {
        "option": "将文件存储在Amazon S3存储桶中。使用S3 Glacier Instant Retrieval存储类。创建S3生命周期策略，在1年后将文件转换到S3 Glacier Deep Archive存储类。",
        "reason": "S3 Glacier Instant Retrieval确实可以在几分钟内检索数据，但其成本较高，而S3 Glacier Deep Archive适用于长期存储，但检索时间较长，不适合在第一年内需要快速访问的情况。"
      },
      "B": {
        "option": "将文件存储在Amazon S3存储桶中。使用S3 Standard存储类。创建S3生命周期策略，在1年后将文件转换到S3 Glacier Flexible Retrieval存储类。",
        "reason": "S3 Standard存储类适用于频繁访问的数据，在第一年内可以快速访问文件。S3 Glacier Flexible Retrieval适用于长期存储，且成本低廉，支持灵活的检索选项，满足了7年保留的需求。"
      },
      "C": {
        "option": "将文件存储在Amazon Elastic Block Store (Amazon EBS)卷上。使用Amazon Data Lifecycle Manager (Amazon DLM)创建EBS卷的快照，并将这些快照存储在Amazon S3中。",
        "reason": "EBS卷适用于高性能存储，但成本较高，不适合大量数据的长期存储。DLM快照存储在S3中，但没有提供直接的检索策略来满足第一年的快速访问需求。"
      },
      "D": {
        "option": "将文件存储在Amazon Elastic File System (Amazon EFS)挂载点上。配置EFS生命周期管理，在1年后将文件转换到EFS Standard-Infrequent Access (Standard-IA)存储类。",
        "reason": "EFS适用于文件存储和共享，但其成本通常高于S3。EFS Standard-IA存储类适用于不频繁访问的数据，但在第一年内需要快速访问的数据，EFS的成本效益不如S3解决方案。"
      }
    }
  },
  {
    "number": "294",
    "best": ["A"],
    "question": "一家公司的一名开发人员使用 AWS CloudFormation 部署了一个应用程序。CloudFormation 堆栈中包括 AWS Systems Manager 参数存储中的参数，应用程序将这些参数用作配置设置。应用程序可以修改参数值。当开发人员更新堆栈以创建带有标签的其他资源时，开发人员注意到参数值被重置，并且忽略了应用程序所做的最新更改。开发人员需要更改公司部署 CloudFormation 堆栈的方式，并且需要避免在堆栈外重置参数值。哪种解决方案以最少的开发努力满足这些要求？",
    "options": {
      "A": {
        "option": "修改 CloudFormation 堆栈以将参数存储参数的删除策略设置为保留。",
        "reason": "设置删除策略为保留（Retain）意味着当 CloudFormation 堆栈更新或删除时，参数存储中的参数将不会被重置或删除。这可以确保参数值在 CloudFormation 堆栈的更新过程中保持不变，满足题目中提到的需求。这也是最少开发努力的解决方案，因为只需修改 CloudFormation 模板即可。"
      },
      "B": {
        "option": "在 CloudFormation 堆栈中创建一个 Amazon DynamoDB 表，作为存储应用程序配置数据的资源。将应用程序修改的参数从参数存储迁移到 DynamoDB 表中。",
        "reason": "虽然将参数存储数据迁移到 DynamoDB 可以解决参数重置的问题，但这需要额外的开发工作，包括创建新的 DynamoDB 表并修改应用程序代码以使用新的数据存储。这不符合最少开发努力的要求。"
      },
      "C": {
        "option": "在 CloudFormation 堆栈中创建一个 Amazon RDS 数据库实例。在数据库中创建一个表用于参数配置。将应用程序修改的参数从参数存储迁移到配置表中。",
        "reason": "使用 RDS 数据库存储配置数据需要更多的开发工作，包括设置数据库、创建表以及修改应用程序代码。这种方法复杂且成本较高，不符合最少开发努力的要求。"
      },
      "D": {
        "option": "修改 CloudFormation 堆栈策略以拒绝对参数存储参数的更新。",
        "reason": "虽然可以通过修改堆栈策略来防止参数被更新，但这并不能解决根本问题，因为应用程序仍然需要对参数进行修改。这种方法可能会导致应用程序功能受限，无法满足需求。"
      }
    }
  },
  {
    "number": "295",
    "best": ["D"],
    "question": "一家公司有一个社交媒体应用程序，接收大量流量。用户帖子和交互会持续更新到 Amazon RDS 数据库。数据频繁变化，数据类型可能很复杂。应用程序必须以最小的延迟处理读取请求。当前的架构难以高效地提供这些快速数据更新。公司需要一个解决方案来提高应用程序的性能。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "在 RDS 数据库前使用 Amazon DynamoDB Accelerator (DAX) 来提供一个缓存层，以处理大量快速变化的数据。",
        "reason": "DAX 是一种专门为 Amazon DynamoDB 设计的缓存解决方案，它不适用于 RDS 数据库。因此，DAX 不能解决此问题。"
      },
      "B": {
        "option": "在 RDS 数据库上设置 Amazon S3 Transfer Acceleration 以增强从数据库到应用程序的数据传输速度。",
        "reason": "S3 Transfer Acceleration 主要用于加速跨地域的数据传输，与数据库性能无关，不适合解决此问题。"
      },
      "C": {
        "option": "在 RDS 数据库前添加一个 Amazon CloudFront 分发，以提供一个缓存层，处理大量快速变化的数据。",
        "reason": "CloudFront 主要用于静态内容分发和缓存，通常用于 CDN 服务。它不适合用作数据库的缓存层，因此不适合解决此问题。"
      },
      "D": {
        "option": "创建一个 Amazon ElastiCache for Redis 集群。更新应用程序代码以使用写通缓存策略，并从 Redis 读取数据。",
        "reason": "ElastiCache for Redis 是一种高性能的内存缓存服务，可以有效地缓存频繁变化的数据。使用写通缓存策略，可以确保数据在写入 RDS 的同时更新 Redis，从而减少读取延迟。此选项满足题目要求，提供最优性能。"
      }
    }
  },
  {
    "number": "296",
    "best": ["A"],
    "question": "一位开发人员创建了一个 AWS Lambda 函数，该函数执行涉及多个 AWS 服务的一系列操作。该函数的持续时间比正常情况要长。为了确定问题的原因，开发人员必须在不更改函数代码的情况下调查服务之间的流量。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "在 Lambda 函数中启用 AWS X-Ray 活动跟踪。查看 X-Ray 中的日志。",
        "reason": "AWS X-Ray 是用于分析和调试分布式应用程序的服务，它可以帮助您了解应用程序和服务的性能。启用 X-Ray 活动跟踪可以捕获 Lambda 函数以及与之交互的其他服务之间的流量，并提供详细的请求路径、时间线和性能数据，而无需更改函数代码。这正是问题中所要求的解决方案。"
      },
      "B": {
        "option": "配置 AWS CloudTrail。查看与 Lambda 函数相关的日志。",
        "reason": "AWS CloudTrail 用于跟踪用户、角色或 AWS 服务的 API 调用，但它不会提供服务之间的流量详细信息或性能数据。因此，它不适用于需要分析 Lambda 函数执行性能的情况。"
      },
      "C": {
        "option": "查看 Amazon CloudWatch 中的 AWS Config 日志。",
        "reason": "AWS Config 是用于评估、审核和记录 AWS 资源配置的服务，它记录配置变化，但不会捕获实时流量或性能数据。因此，它不适用于此问题的要求。"
      },
      "D": {
        "option": "查看与 Lambda 函数相关的 Amazon CloudWatch 日志。",
        "reason": "Amazon CloudWatch Logs 可以帮助您查看 Lambda 函数的执行日志，但它不会提供详细的服务之间的流量或性能分析数据。因此，它不能完全满足问题中所述的需求。"
      }
    }
  },
  {
    "number": "297",
    "best": ["B", "E"],
    "question": "一家公司在本地数据中心运行图像处理服务。该服务由运行在 Kubernetes 集群上的容器化应用程序组成。所有应用程序都可以访问相同的 NFS 共享用于文件和数据存储。公司在数据中心的 NFS 容量即将耗尽，需要尽快迁移到 AWS。Kubernetes 集群必须在 AWS 上具有高可用性。哪种操作组合可以满足这些要求？（选择两个。）",
    "options": {
      "A": {
        "option": "将 NFS 共享中的信息传输到 Amazon Elastic Block Store (Amazon EBS) 卷。将容器映像上传到 Amazon Elastic Container Registry (Amazon ECR)。",
        "reason": "虽然 Amazon EBS 是一种高性能块存储选项，但它不适合共享文件存储。Amazon EBS 卷只能连接到一个 EC2 实例，因此不适用于需要多个节点访问同一文件存储的 Kubernetes 集群。"
      },
      "B": {
        "option": "将 NFS 共享中的信息传输到 Amazon Elastic File System (Amazon EFS) 卷。将容器映像上传到 Amazon Elastic Container Registry (Amazon ECR)。",
        "reason": "Amazon EFS 是一种可扩展的文件存储服务，适合多个 EC2 实例和容器同时访问。将 NFS 共享中的数据迁移到 EFS 可以满足高可用性和共享存储需求。"
      },
      "C": {
        "option": "创建一个 Amazon Elastic Container Service (Amazon ECS) 集群来运行应用程序。配置集群的每个节点在容器映像所需路径挂载 Amazon Elastic Block Store (Amazon EBS) 卷。",
        "reason": "同 A 选项，EBS 不适合共享文件存储。此外，题目要求使用 Kubernetes，而不是 ECS。"
      },
      "D": {
        "option": "创建一个 Amazon Elastic Kubernetes Service (Amazon EKS) 集群来运行应用程序。配置集群的每个节点在容器映像所需路径挂载 Amazon Elastic Block Store (Amazon EBS) 卷。",
        "reason": "虽然 EKS 满足了 Kubernetes 的要求，但 EBS 仍然不适合用于共享文件存储。"
      },
      "E": {
        "option": "创建一个 Amazon Elastic Kubernetes Service (Amazon EKS) 集群来运行应用程序。配置集群的每个节点在容器映像所需路径挂载 Amazon Elastic File System (Amazon EFS) 卷。",
        "reason": "Amazon EKS 满足 Kubernetes 的要求，Amazon EFS 提供了适合高可用性和共享存储的文件系统。该组合可以满足题目中的所有需求。"
      }
    }
  },
  {
    "number": "298",
    "best": ["A"],
    "question": "一家公司有一个分析应用程序，使用 AWS Lambda 函数异步处理交易数据。开发人员注意到 Lambda 函数的异步调用有时会失败。当 Lambda 函数调用失败时，开发人员希望调用第二个 Lambda 函数来处理错误并记录详细信息。哪种解决方案可以满足这些需求？",
    "options": {
      "A": {
        "option": "配置带有失败条件的 Lambda 函数目标。指定 Lambda 函数作为目标类型。指定错误处理 Lambda 函数的 Amazon 资源名称（ARN）作为资源。",
        "reason": "选择此选项是因为 Lambda 函数目标允许您配置在函数调用失败时的处理方式。通过指定错误处理 Lambda 函数的 ARN，可以自动在初始函数失败时调用该错误处理函数。这正好符合题目中开发人员的需求。"
      },
      "B": {
        "option": "在初始 Lambda 函数上启用 AWS X-Ray 活动跟踪。配置 X-Ray 捕获失败调用的堆栈跟踪。通过在事件对象中包含堆栈跟踪来调用错误处理 Lambda 函数。",
        "reason": "不选择此选项的原因是，虽然启用 AWS X-Ray 可以帮助调试和追踪问题，但它本身并不能自动调用错误处理函数。该选项需要手动处理错误调用，这不符合题目中自动处理失败的要求。"
      },
      "C": {
        "option": "配置带有失败条件的 Lambda 函数触发器。指定 Lambda 函数作为目标类型。指定错误处理 Lambda 函数的 Amazon 资源名称（ARN）作为资源。",
        "reason": "不选择此选项的原因是，AWS Lambda 没有直接配置失败条件的触发器。Lambda 函数目标机制更适合处理此类需求，而不是触发器。"
      },
      "D": {
        "option": "在初始 Lambda 函数上创建状态检查警报。配置警报在触发时调用错误处理 Lambda 函数。确保警报在事件对象中传递堆栈跟踪。",
        "reason": "不选择此选项的原因是，虽然状态检查警报可以用来监控 Lambda 函数的健康状态，但它并不是处理函数调用失败的最佳方式。使用状态检查警报来处理错误并不直接、简便，而 Lambda 目标机制更为合适。"
      }
    }
  },
  {
    "number": "299",
    "best": ["A"],
    "question": "一家公司引入了一个新功能，该功能应仅对特定的高级客户组开放。开发人员需要能够根据性能和反馈来开启或关闭该功能。开发人员需要一种解决方案来快速验证和部署这些配置，而不会引起任何中断。开发人员应该怎么做来满足这些要求？",
    "options": {
      "A": {
        "option": "使用 AWS AppConfig 管理功能配置并验证和部署更改。使用功能标志来开启和关闭该功能。",
        "reason": "AWS AppConfig 是 AWS Systems Manager 的一部分，专门用于管理应用程序配置和功能标志。它允许开发人员快速、可靠地进行配置更改，而不会中断应用程序的运行。功能标志是一种常用的方法，用于按需启用或禁用特定功能，非常适合这种需要灵活控制新功能的场景。"
      },
      "B": {
        "option": "使用 AWS Secrets Manager 安全管理和验证功能配置。启用生命周期规则来开启和关闭该功能。",
        "reason": "AWS Secrets Manager 主要用于安全管理和轮换机密数据，如数据库凭证和 API 密钥。它不适用于管理应用程序功能配置，因此不适合这个场景。"
      },
      "C": {
        "option": "使用 AWS Config 管理功能配置和验证。设置 AWS Config 规则，根据预定义条件开启和关闭该功能。",
        "reason": "AWS Config 主要用于记录和审计 AWS 资源的配置变更，并确保资源符合所定义的规则。虽然它能够检测配置偏差，但并不是专门设计来管理应用程序功能配置的，因此不是最佳选择。"
      },
      "D": {
        "option": "使用 AWS Systems Manager Parameter Store 存储和验证功能的配置设置。启用生命周期规则来开启和关闭该功能。",
        "reason": "AWS Systems Manager Parameter Store 用于存储参数配置，但它缺乏专门的功能标志管理和验证功能，无法像 AWS AppConfig 那样灵活地控制应用程序功能。因此，不是最佳选择。"
      }
    }
  },
  {
    "number": "300",
    "best": ["A"],
    "question": "一位开发人员需要在将代码部署到生产环境之前获得产品负责人的批准。开发人员使用 AWS CodePipeline 部署应用程序。开发人员配置了一个 Amazon Simple Notification Service (Amazon SNS) 主题来向产品负责人发送通知。哪种解决方案是开发人员获得产品负责人批准的最具操作效率的方法？",
    "options": {
      "A": {
        "option": "在生产部署之前添加一个新的 CodePipeline 阶段。在新阶段中添加一个手动审批操作。在管道设置中添加一个新的通知规则。指定手动审批作为触发通知的事件。指定 SNS 主题的 Amazon Resource Name (ARN) 以通知产品负责人。",
        "reason": "此选项使用了 CodePipeline 内置的手动审批操作，并结合 SNS 进行通知，这是 AWS 的推荐做法，能够提供良好的操作效率和清晰的流程管理。"
      },
      "B": {
        "option": "开发一个 AWS Step Functions 状态机来发送通知给产品负责人并接受批准。在生产部署之前添加一个新的 CodePipeline 阶段。将状态机作为新的阶段中的 Step Functions 操作。",
        "reason": "虽然 AWS Step Functions 能够实现通知和审批，但相比于 CodePipeline 内置的手动审批操作，这种方法增加了复杂性和维护成本，因此操作效率较低。"
      },
      "C": {
        "option": "在 CodePipeline 中现有的生产部署阶段添加一个手动审批操作。在配置新的手动审批操作时指定 SNS 主题的 Amazon Resource Name (ARN)。",
        "reason": "虽然在现有阶段添加手动审批操作是可行的，但在单一阶段中混合部署和审批操作可能会增加流程的复杂性和管理难度，不如在单独的阶段中进行手动审批更为清晰和高效。"
      },
      "D": {
        "option": "编辑 CodePipeline 设置。创建一个新的通知规则。指定手动审批作为触发通知的事件。创建一个新的通知目标。指定 SNS 主题通知产品负责人。保存通知规则。",
        "reason": "这个选项缺乏在 CodePipeline 中明确添加手动审批操作的步骤，只是创建了通知规则，因此不完整且无法达到审批的目的。"
      }
    }
  },
  {
    "number": "301",
    "best": ["A"],
    "question": "一名开发人员正在 AWS 上构建一个无服务器应用程序，用于处理高数据量的工作流。在工作流中，一个 AWS Step Functions 状态机调用了几个 AWS Lambda 函数。由于高需求期间的超时错误，其中一个 Lambda 函数偶尔会失败。开发人员必须确保工作流在发生超时错误时自动重试失败的函数调用。哪种解决方案可以满足此要求？",
    "options": {
      "A": {
        "option": "在 Step Functions 状态机定义中添加 Retry 字段。配置状态机的最大重试次数和要重试的超时错误类型。",
        "reason": "选项 A 是正确的。AWS Step Functions 允许在状态机中配置重试策略。通过在状态机定义中添加 Retry 字段，可以指定最大重试次数以及要重试的错误类型（如超时错误），这直接满足了题目中的要求。"
      },
      "B": {
        "option": "在 Step Functions 状态机定义中添加 Timeout 字段。配置状态机的最大重试次数。",
        "reason": "选项 B 是不正确的。Timeout 字段用于定义状态的最大执行时间，而不是用于定义重试策略。虽然配置最大重试次数是必要的，但 Timeout 字段不能解决重试的问题。"
      },
      "C": {
        "option": "在 Step Functions 状态机定义中添加 Fail 状态。配置状态机的最大重试次数。",
        "reason": "选项 C 是不正确的。Fail 状态用于表示状态机的失败终止，并不会触发重试机制。因此，添加 Fail 状态并不能满足题目中自动重试的要求。"
      },
      "D": {
        "option": "更新 Step Functions 状态机，将调用请求传递给 Amazon Simple Notification Service (Amazon SNS) 主题。订阅一个 Lambda 函数到该 SNS 主题。为超时错误类型配置 Lambda 函数的最大重试次数。",
        "reason": "选项 D 是不正确的。虽然可以通过 Amazon SNS 和 Lambda 实现某种程度的重试，但这种方法复杂且不直接。使用 Step Functions 的 Retry 字段是更为简洁和直接的解决方案。"
      }
    }
  },
  {
    "number": "302",
    "best": ["B"],
    "question": "公司在 AWS 上运行一个无服务器应用程序。该应用程序包括一个 AWS Lambda 函数。Lambda 函数处理数据并将数据存储在 Amazon RDS for PostgreSQL 数据库中。开发人员为应用程序在数据库中创建了用户凭据。开发人员需要使用 AWS Secrets Manager 来管理用户凭据。密码必须定期轮换。解决方案需要确保在秘密轮换期间应用程序具有高可用性且没有停机时间。开发人员应该怎么做来满足这些要求？",
    "options": {
      "A": {
        "option": "配置单用户轮换策略的托管轮换。",
        "reason": "单用户轮换策略会在同一用户的凭据被更新时进行轮换，这可能会导致在轮换过程中出现短暂的服务不可用情况，因此不符合高可用性和无停机时间的要求。"
      },
      "B": {
        "option": "配置交替用户轮换策略的托管轮换。",
        "reason": "交替用户轮换策略在轮换过程中使用两个用户，这样在一个用户的凭据被更新时，另一个用户仍然可以用于数据库连接，从而确保高可用性和无停机时间。这是满足题目要求的最佳选项。"
      },
      "C": {
        "option": "配置单用户轮换策略的自动轮换。",
        "reason": "自动轮换与托管轮换之间的主要区别在于自动轮换需要用户自己编写轮换逻辑。单用户轮换策略在轮换过程中可能导致短暂的服务不可用，因此不符合高可用性和无停机时间的要求。"
      },
      "D": {
        "option": "配置交替用户轮换策略的自动轮换。",
        "reason": "虽然自动轮换可以满足需求，但需要开发人员自己编写轮换逻辑，增加了复杂性和维护成本。相比之下，托管轮换提供了更便捷的管理方式。因此，托管轮换更优。"
      }
    }
  },
  {
    "number": "303",
    "best": ["A"],
    "question": "一家公司在 AWS 上运行一个应用程序。该应用程序由托管在 Amazon S3 上的静态网站组成。应用程序包括调用 AWS Lambda 函数的 Amazon API Gateway 接口。在应用程序的高流量期间，用户报告应用程序在不规则的时间间隔内运行缓慢。没有失败的请求。开发人员需要找到所有 Lambda 函数中执行缓慢的情况。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "使用 Amazon CloudWatch Logs Insights 对所有 Lambda 函数日志组执行查询。过滤报告类型并按 Lambda 函数执行持续时间降序排序。",
        "reason": "Amazon CloudWatch Logs Insights 可以对 CloudWatch Logs 进行查询和分析，能够快速找到所有 Lambda 函数中执行缓慢的情况。通过过滤和排序，可以轻松找到执行时间较长的 Lambda 函数。"
      },
      "B": {
        "option": "在运行 Lambda 函数的账户上启用 AWS CloudTrail Insights。CloudTrail Insights 处理完成后，查看 CloudTrail Insights 以找到异常函数。",
        "reason": "AWS CloudTrail Insights 主要用于检测和分析账户中的异常活动，适合于审计和安全分析，不能用于直接分析 Lambda 函数的执行时长，因此不适合此场景。"
      },
      "C": {
        "option": "为所有 Lambda 函数启用 AWS X-Ray。在包含所有 Lambda 函数的新组上配置 X-Ray insight。X-Ray insight 处理完成后，查看 X-Ray 日志。",
        "reason": "AWS X-Ray 适用于分布式跟踪和分析应用程序的性能，但设置和分析相对复杂，且对所有函数都启用 X-Ray 可能会增加成本和复杂性，不是最优解。"
      },
      "D": {
        "option": "设置 AWS Glue 爬取 Amazon CloudWatch Logs 中的 Lambda 函数日志。配置 AWS Glue 作业将日志转化为结构化格式并输出到 Amazon S3。使用 Amazon CloudWatch 仪表盘基于持续时间可视化最慢的函数。",
        "reason": "该方案涉及多个服务（AWS Glue 和 Amazon S3）的复杂集成和配置，尽管可以实现目标，但实现起来较为复杂和冗长，效率不高。"
      }
    }
  },
  {
    "number": "304",
    "best": ["A"],
    "question": "一家公司正在 AWS 上构建一个无服务器应用程序。该应用程序使用 Amazon API Gateway 和 AWS Lambda。公司希望将该应用程序部署到其开发、测试和生产环境中。哪种解决方案将以最少的开发工作量满足这些要求？",
    "options": {
      "A": {
        "option": "使用 API Gateway 阶段变量并创建 Lambda 别名以引用特定于环境的资源。",
        "reason": "API Gateway 阶段变量和 Lambda 别名是 AWS 提供的用于管理不同部署环境的功能。通过使用阶段变量和别名，可以在相同的代码库中轻松管理不同环境的配置，减少重复代码和部署复杂度。"
      },
      "B": {
        "option": "使用 Amazon Elastic Container Service (Amazon ECS) 将应用程序部署到各个环境中。",
        "reason": "Amazon ECS 主要用于容器化应用程序的部署和管理，适用于需要高度可扩展的容器化服务。而本题中应用程序是无服务器架构，使用 ECS 会增加不必要的复杂性和开发工作量。"
      },
      "C": {
        "option": "为每个环境复制代码。将代码部署到单独的 API Gateway 阶段。",
        "reason": "这种方法会导致代码重复和管理负担增加，难以维护。每次代码更新都需要在多个地方进行修改，不符合最少开发工作量的要求。"
      },
      "D": {
        "option": "使用 AWS Elastic Beanstalk 将应用程序部署到各个环境中。",
        "reason": "AWS Elastic Beanstalk 是一个用于快速部署和管理应用程序的服务，但更适用于需要管理服务器和基础设施的应用。对于无服务器架构的应用程序，使用 Elastic Beanstalk 会增加不必要的复杂性。"
      }
    }
  },
  {
    "number": "305",
    "best": ["A"],
    "question": "开发人员使用AWS CloudFormation来部署Amazon API Gateway API和AWS Step Functions状态机。状态机必须在CloudFormation模板部署后引用API Gateway API。开发人员需要一个解决方案，使状态机引用API Gateway端点，并且必须是最具成本效益的解决方案。哪种解决方案最能满足这些要求？",
    "options": {
      "A": {
        "option": "配置CloudFormation模板以在AWS::StepFunctions::StateMachine资源的DefinitionSubstitutions属性中引用API端点。",
        "reason": "此选项允许在CloudFormation模板中直接引用API Gateway端点，确保状态机在部署后能够正确引用API端点。这种方法最具成本效益，因为不需要额外的服务来存储和管理端点信息。DefinitionSubstitutions属性专门用于这种场景，使其成为最合适的选择。"
      },
      "B": {
        "option": "配置CloudFormation模板以在AWS::StepFunctions::StateMachine资源的环境变量中存储API端点。配置状态机引用该环境变量。",
        "reason": "虽然使用环境变量可以实现目标，但这可能会增加复杂性，并且环境变量的使用在这种情况下并不是最佳实践。状态机需要额外的逻辑来引用环境变量，增加了不必要的复杂度。"
      },
      "C": {
        "option": "配置CloudFormation模板以在标准AWS::SecretsManager::Secret资源中存储API端点。配置状态机引用该资源。",
        "reason": "使用Secrets Manager来存储API端点信息是过度设计的，因为Secrets Manager主要用于存储敏感数据，如密码和API密钥。使用它来存储API端点会增加不必要的成本。"
      },
      "D": {
        "option": "配置CloudFormation模板以在标准AWS::AppConfig::ConfigurationProfile资源中存储API端点。配置状态机引用该资源。",
        "reason": "AppConfig用于管理应用程序配置，而不是存储API端点信息。使用AppConfig来存储API端点同样是过度设计，并且增加了不必要的复杂性和成本。"
      }
    }
  },
  {
    "number": "306",
    "best": ["C"],
    "question": "开发人员正在 AWS 上构建一个应用程序。该应用程序包括一个处理来自 Amazon Simple Queue Service (Amazon SQS) 队列消息的 AWS Lambda 函数。Lambda 函数有时会失败或超时。开发人员需要找出 Lambda 函数为什么无法处理某些消息。哪种解决方案在最少的操作开销下满足这些要求？",
    "options": {
      "A": {
        "option": "将 Lambda 函数的最大超时时间增加到 15 分钟。检查 AWS CloudTrail 事件历史记录中的错误详细信息。",
        "reason": "延长 Lambda 函数的超时时间并不会根本解决问题，它只是延长了处理时间，且 CloudTrail 主要用于记录 API 调用，不适合用于调试 Lambda 函数的错误。"
      },
      "B": {
        "option": "增加 SQS 队列的可见性超时。检查 Amazon CloudWatch Logs 中的日志以获取错误详细信息。",
        "reason": "增加 SQS 队列的可见性超时可以减少消息重新处理的可能性，但并不能直接帮助开发人员找到错误的原因。查看 CloudWatch Logs 是一个好方法，但这并不是最具操作效率的解决方案。"
      },
      "C": {
        "option": "创建一个死信队列。配置 Lambda 函数将失败的消息发送到死信队列。",
        "reason": "使用死信队列可以有效地捕获那些处理失败的消息，提供一个机制来隔离和分析这些失败的消息，从而帮助开发人员找出问题的根源。这是最少操作开销下的最佳解决方案。"
      },
      "D": {
        "option": "创建一个 Amazon DynamoDB 表。更新 Lambda 函数将失败的消息发送到 DynamoDB 表。",
        "reason": "将失败的消息发送到 DynamoDB 表也可以帮助存储和分析失败的消息，但这个解决方案涉及更多的配置和管理工作，相比死信队列增加了操作开销。"
      }
    }
  },
  {
    "number": "307",
    "best": ["C"],
    "question": "一位开发人员需要使用 AWS CloudFormation 在三个 AWS 区域中部署一个应用程序。每个区域将使用一个带有应用程序负载均衡器 (ALB) 的 AWS Elastic Beanstalk 环境。开发人员希望使用 AWS Certificate Manager (ACM) 向每个 ALB 部署 SSL 证书。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "在任意一个区域的 ACM 中创建一个证书。将证书导入到每个区域中的 ALB。",
        "reason": "AWS Certificate Manager (ACM) 证书无法跨区域使用。每个区域的 ALB 需要在相应区域内创建和管理的 ACM 证书。"
      },
      "B": {
        "option": "在 ACM 中创建一个全球证书。更新 CloudFormation 模板以将全球证书部署到每个 ALB。",
        "reason": "当前，AWS Certificate Manager (ACM) 不支持全球证书。每个区域仍然需要单独的证书。"
      },
      "C": {
        "option": "在每个区域的 ACM 中创建一个证书。将证书导入到每个区域的 ALB。",
        "reason": "这是正确的解决方案。ACM 证书是区域性的，因此需要在每个区域分别创建证书，并将其导入到相应区域的 ALB。"
      },
      "D": {
        "option": "在 us-east-1 区域的 ACM 中创建一个证书。更新 CloudFormation 模板以将证书部署到每个 ALB。",
        "reason": "ACM 证书是区域性的，无法跨区域使用。因此，在单一区域（如 us-east-1）创建证书无法满足其他区域的 ALB 需求。"
      }
    }
  },
  {
    "number": "308",
    "best": ["D"],
    "question": "公司需要使用 AWS CloudFormation 模板部署其所有云资源。开发人员必须创建一个 Amazon Simple Notification Service (Amazon SNS) 自动通知来帮助执行这一规则。开发人员创建了一个 SNS 主题并订阅了公司安全团队的电子邮件地址。 如果创建了一个未使用 CloudFormation 的 IAM 角色，安全团队必须立即收到通知。哪种解决方案能满足这个要求？",
    "options": {
      "A": {
        "option": "创建一个 AWS Lambda 函数来过滤来自 CloudTrail 的事件，判断是否有未使用 CloudFormation 创建的角色。配置 Lambda 函数发布到 SNS 主题。创建一个 Amazon EventBridge 日程表每 15 分钟调用一次 Lambda 函数。",
        "reason": "该选项涉及较多步骤和服务，增加了复杂性和延迟。而且每 15 分钟的间隔不能保证立即通知。"
      },
      "B": {
        "option": "在 Amazon Elastic Container Service (Amazon ECS) 中创建一个 AWS Fargate 任务，来过滤来自 CloudTrail 的事件，判断是否有未使用 CloudFormation 创建的角色。配置 Fargate 任务发布到 SNS 主题。创建一个 Amazon EventBridge 日程表每 15 分钟运行一次 Fargate 任务。",
        "reason": "与选项 A 类似，Fargate 任务增加了复杂性和成本。15 分钟的间隔也不能保证立即通知。"
      },
      "C": {
        "option": "启动一个包含脚本的 Amazon EC2 实例来过滤来自 CloudTrail 的事件，判断是否有未使用 CloudFormation 创建的角色。配置脚本发布到 SNS 主题。创建一个 cron 作业来每 15 分钟在 EC2 实例上运行该脚本。",
        "reason": "这种方法涉及管理 EC2 实例，增加了维护开销和复杂性。同样的，15 分钟的间隔无法保证立即通知。"
      },
      "D": {
        "option": "创建一个 Amazon EventBridge 规则来过滤来自 CloudTrail 的事件，判断是否有未使用 CloudFormation 创建的角色。指定 SNS 主题作为 EventBridge 规则的目标。",
        "reason": "这是最简单和最直接的解决方案。EventBridge 规则可以立即捕获相关事件并触发 SNS 通知，确保安全团队即时收到通知。"
      }
    }
  },
  {
    "number": "309",
    "best": ["C"],
    "question": "一家公司正在为其一些新服务采用无服务器计算。开发团队需要使用 AWS Serverless Application Model (AWS SAM) 创建无服务器基础设施。所有基础设施都必须使用 AWS CloudFormation 模板进行部署。开发团队应该怎么做才能满足这些要求？",
    "options": {
      "A": {
        "option": "在 CloudFormation 模板中添加一个 Resources 部分，其中包含 AWS::Lambda::Function 资源。",
        "reason": "虽然在 CloudFormation 模板中添加 AWS::Lambda::Function 资源可以创建 Lambda 函数，但这并没有利用 AWS SAM 的优势。AWS SAM 提供了简化的语法，专门用于无服务器应用程序的定义和部署，所以这个选项并不是最佳选择。"
      },
      "B": {
        "option": "在 CloudFormation 模板中添加一个 Mappings 部分，其中包含 AWS::Serverless::Function 和 AWS::Serverless::API。",
        "reason": "Mappings 部分通常用于定义静态值的映射，并不适合用于定义 AWS SAM 资源。这个选项并不正确，因为它误用了 Mappings 部分。"
      },
      "C": {
        "option": "在 CloudFormation 模板中添加一个 Transform 部分。使用 AWS SAM 语法定义资源。",
        "reason": "这是最佳选项。在 CloudFormation 模板中添加 Transform 部分，并使用 AWS SAM 语法定义资源，可以简化无服务器应用程序的创建和管理。AWS SAM 是一个用于定义无服务器应用的框架，它扩展了 CloudFormation 的功能，使得定义和部署无服务器资源更加简便。"
      },
      "D": {
        "option": "在 CloudFormation 模板中添加一个 Parameters 部分，指定相关的 AWS SAM Globals 部分。",
        "reason": "Parameters 部分通常用于定义模板参数，而不是直接用于定义 AWS SAM 资源。虽然 Globals 部分在 AWS SAM 中有其用途，但它不是满足题目要求的正确方法。"
      }
    }
  },
  {
    "number": "310",
    "best": ["C"],
    "question": "开发人员正在构建一个异步调用 AWS Lambda 函数来处理事件的应用程序。开发人员注意到 Lambda 函数在随机时间未能处理某些事件。开发人员需要调查失败的事件并捕获 Lambda 函数未能处理的事件。哪种解决方案能满足这些要求？",
    "options": {
      "A": {
        "option": "为 Lambda 函数添加一个 Amazon EventBridge 规则。将 EventBridge 规则配置为对失败事件做出反应，并将事件存储在 Amazon DynamoDB 表中。",
        "reason": "EventBridge 规则通常用于在事件发生时触发目标操作，而不是专门用于捕获失败的事件。虽然可以设置规则来捕获某些类型的失败事件，但这不是最佳实践，特别是对于 Lambda 失败事件的处理。"
      },
      "B": {
        "option": "使用基于 Amazon Kinesis 的死信队列配置 Lambda 函数。更新 Lambda 函数的执行角色以获得所需的权限。",
        "reason": "虽然 Kinesis 可用于处理流数据，但不是处理死信队列的最佳选择。此外，Kinesis 的复杂性和成本可能不适合这个用例。"
      },
      "C": {
        "option": "使用 Amazon Simple Queue Service (Amazon SQS) 死信队列配置 Lambda 函数。更新 Lambda 函数的执行角色以获得所需的权限。",
        "reason": "这是最佳选择。SQS 死信队列 (DLQ) 是处理 Lambda 函数失败事件的最佳实践。它允许捕获未能处理的事件，以便后续调查和分析。同时，SQS 是一种可靠且易于使用的服务，非常适合这个用例。"
      },
      "D": {
        "option": "使用 Amazon Simple Queue Service (Amazon SQS) FIFO 死信队列配置 Lambda 函数。更新 Lambda 函数的执行角色以获得所需的权限。",
        "reason": "FIFO 队列主要用于确保消息的顺序和避免重复。虽然可以用于死信队列，但在这个场景中没有特别的优势，因为题目没有提到需要消息顺序。标准 SQS 队列已经足够满足需求。"
      }
    }
  },
  {
    "number": "311",
    "best": ["B"],
    "question": "公司为其电子商务网站构建了一个无服务器应用程序。该应用程序包括一个在 Amazon API Gateway 中的 REST API，该 API 调用一个 AWS Lambda 函数。Lambda 函数处理数据，并将数据存储在 Amazon DynamoDB 表中。Lambda 函数调用第三方库存应用程序 API 来处理订单。订单处理完毕后，Lambda 函数返回一个 HTTP 200 状态码而没有正文给客户端。在高峰使用期间，当 API 调用超过某个阈值时，第三方库存应用程序有时无法处理数据并响应错误消息。公司需要一个解决方案，不会使第三方库存应用程序不堪重负。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "在 API Gateway 中配置 REST API 直接将请求写入 DynamoDB。配置一个 DynamoDB 内置函数来执行转换。设置一个 DynamoDB 流来调用第三方库存应用程序 API 处理每一行数据。删除 Lambda 函数。",
        "reason": "这种解决方案虽然能够将请求写入 DynamoDB，但并不能解决高峰期第三方应用程序无法处理的问题。DynamoDB Streams 仍然会在高峰期调用第三方 API，从而无法避免对第三方应用程序的压力。"
      },
      "B": {
        "option": "在 API Gateway 中配置 REST API 直接将请求写入 Amazon Simple Queue Service (Amazon SQS) 队列。配置 Lambda 函数的保留并发数等于第三方库存应用程序的阈值。设置 Lambda 函数从 SQS 队列中处理消息。",
        "reason": "使用 SQS 队列来缓冲请求可以有效防止高峰期对第三方应用程序造成过大压力。通过设置 Lambda 函数的保留并发数，可以确保同时处理的请求不会超过第三方应用程序的处理能力。SQS 是一种适用于解耦和缓冲请求的服务，适合这种场景。"
      },
      "C": {
        "option": "在 API Gateway 中配置 REST API 直接将请求写入 Amazon Simple Notification Service (Amazon SNS) 主题。配置 Lambda 函数的预置并发数等于第三方库存应用程序的阈值。设置 Lambda 函数从 SNS 主题处理消息。",
        "reason": "虽然 SNS 可以用来发布消息，但它不是一个适合缓冲和控制并发处理的服务。SNS 通常用于通知和广播消息，而不是用于流量控制。"
      },
      "D": {
        "option": "在 API Gateway 中配置 REST API 直接将请求写入 Amazon Athena。使用 SQL 配置数据转换，并设置多个查询结果位置指向 DynamoDB 表和第三方库存应用程序 API。删除 Lambda 函数。",
        "reason": "Athena 是一种交互式查询服务，主要用于分析数据，并不适合实时数据处理和调用外部 API。而且，这种方法并没有解决第三方应用程序在高峰期的负载问题。"
      }
    }
  },
  {
    "number": "312",
    "best": ["D"],
    "question": "公司在 AWS 上托管其应用程序。该应用程序在使用 AWS Fargate 的 Amazon Elastic Container Service (Amazon ECS) 集群上运行。集群在应用程序负载均衡器后面运行。应用程序将数据存储在 Amazon Aurora 数据库中。开发人员在应用程序内部加密和管理数据库凭证。公司希望使用更安全的凭证存储方法并实施定期凭证轮换。哪种解决方案将在最少的操作开销下满足这些要求？",
    "options": {
      "A": {
        "option": "将秘密凭证迁移到 Amazon RDS 参数组。使用 AWS Key Management Service (AWS KMS) 密钥加密参数。打开机密轮换。使用 IAM 策略和角色授予 AWS KMS 访问 Amazon RDS 的权限。",
        "reason": "RDS 参数组主要用于配置数据库参数，并不是用于存储和管理应用程序凭证的最佳实践。此外，RDS 参数组并不支持自动的凭证轮换功能，因此不能满足题目要求。"
      },
      "B": {
        "option": "将凭证迁移到 AWS Systems Manager 参数存储。使用 AWS Key Management Service (AWS KMS) 密钥加密参数。打开机密轮换。使用 IAM 策略和角色授予 Amazon ECS Fargate 访问 AWS Secrets Manager 的权限。",
        "reason": "AWS Systems Manager 参数存储虽然可以用于存储加密参数，但它并不直接支持自动凭证轮换功能。因此，这个选项不能满足题目中的定期凭证轮换要求。"
      },
      "C": {
        "option": "将凭证迁移到 ECS Fargate 环境变量。使用 AWS Key Management Service (AWS KMS) 密钥加密凭证。打开机密轮换。使用 IAM 策略和角色授予 Amazon ECS Fargate 访问 AWS Secrets Manager 的权限。",
        "reason": "将凭证存储在 ECS Fargate 环境变量中并不是最佳实践，因为环境变量不具备高度安全性。并且此方法依然需要外部的方式来管理和轮换凭证，不符合最少操作开销的要求。"
      },
      "D": {
        "option": "将凭证迁移到 AWS Secrets Manager。使用 AWS Key Management Service (AWS KMS) 密钥加密凭证。打开机密轮换。使用 IAM 策略和角色授予 Amazon ECS Fargate 通过密钥访问 AWS Secrets Manager。",
        "reason": "AWS Secrets Manager 专门用于安全存储和管理敏感信息，如数据库凭证，并且提供自动的凭证轮换功能。它与 AWS KMS 集成，可以加密存储的机密信息。使用 IAM 策略和角色，可以轻松地管理对机密信息的访问权限。这是最符合题目要求并且操作开销最小的解决方案。"
      }
    }
  },
  {
    "number": "313",
    "best": ["A"],
    "question": "公司有一个移动应用程序。该应用程序包括一个 Amazon API Gateway REST API，该 API 调用 AWS Lambda 函数。这些 Lambda 函数处理来自应用程序的数据。公司需要测试具有新功能的更新 Lambda 函数。公司必须在部署前对一部分用户进行这些测试。这些测试不能影响其他应用程序用户。哪种解决方案将以最少的操作努力满足这些要求？",
    "options": {
      "A": {
        "option": "为每个 Lambda 函数创建一个具有加权别名的新版本。为每个 Lambda 函数配置一个权重值。在 REST API 中更新新的加权别名 Amazon 资源名称 (ARN)。",
        "reason": "使用 Lambda 函数的版本和加权别名允许你将流量按比例分配给不同的 Lambda 函数版本，从而可以在不影响所有用户的情况下进行测试。这种方法操作简单，直接在现有的 API Gateway 中进行修改，操作成本最低。"
      },
      "B": {
        "option": "在 API Gateway 中创建一个新的 REST API。设置一个 Lambda 代理集成以连接到多个 Lambda 函数。在部署阶段启用金丝雀设置。指定一个较小比例的 API 流量到新的 Lambda 函数版本。",
        "reason": "虽然此方法也可以实现流量分流和测试，但需要创建一个新的 REST API，相对来说操作复杂度更高，且需要更多的配置和管理工作，不是最优选择。"
      },
      "C": {
        "option": "为每个 Lambda 函数创建一个新版本。集成 AWS CodeDeploy 中的预定义金丝雀部署，以自动缓慢地将流量转移到新版本。",
        "reason": "CodeDeploy 的金丝雀部署是一个强大的功能，适合更复杂的部署场景。然而，对于只是想测试 Lambda 函数的少数用户，这种方法显得过于繁琐且操作成本较高。"
      },
      "D": {
        "option": "在 API Gateway 中创建一个新的 REST API。设置一个 Lambda 非代理集成以连接到多个 Lambda 函数。在 API Gateway 中指定必要的参数和属性。在部署阶段启用金丝雀设置。指定一个较小比例的 API 流量到新的 Lambda 函数版本。",
        "reason": "与选项 B 类似，此方法需要创建新的 REST API，并且配置复杂度较高。相比之下，选项 A 更简单，实施成本更低。"
      }
    }
  },
  {
    "number": "314",
    "best": ["C"],
    "question": "一位开发人员在一家公司工作，该公司只有一个预生产 AWS 账户，并且使用 AWS CloudFormation AWS Serverless Application Model (AWS SAM) 堆栈。该开发人员对 AWS SAM 模板中指定的现有 AWS Lambda 函数和额外的 Amazon Simple Notification Service (Amazon SNS) 主题进行了更改。开发人员希望一次性部署更改以测试这些更改是否有效。开发人员不希望影响目前正在被其他团队成员作为发布管道使用的现有预生产应用程序。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "使用 AWS SAM CLI 将 SAM 应用程序打包并部署到预生产 AWS 账户。指定调试参数。",
        "reason": "在预生产账户部署会影响现有的预生产应用程序，尽管指定调试参数也无法避免潜在的影响。"
      },
      "B": {
        "option": "使用 AWS SAM CLI 将 SAM 应用程序打包并在预生产 AWS 账户中创建一个变更集。在新 AWS 账户中执行变更集，该账户被指定为开发环境。",
        "reason": "变更集通常用于在同一个账户下的不同环境中进行变更的预览，而不是跨账户执行。"
      },
      "C": {
        "option": "使用 AWS SAM CLI 将 SAM 应用程序打包并部署到一个专门用于开发环境的新 AWS 账户。",
        "reason": "这是最合适的解决方案，因为它在一个完全独立的环境中进行部署和测试，从而不会影响现有的预生产应用程序。"
      },
      "D": {
        "option": "在预生产账户中更新 CloudFormation 堆栈。添加一个单独的阶段，指向一个专门用于开发环境的新 AWS 账户。",
        "reason": "此选项涉及对现有预生产账户进行较大的配置更改，可能会引入不必要的复杂性和风险。"
      }
    }
  },
  {
    "number": "315",
    "best": ["A"],
    "question": "公司构建了一个在线活动平台。对于每个活动，公司会组织测验并根据测验分数生成排行榜。公司将排行榜数据存储在 Amazon DynamoDB 中，并在活动结束后保留数据30天。然后，公司使用一个计划任务删除旧的排行榜数据。DynamoDB 表配置了固定的写容量。在许多活动发生的月份，当计划删除任务运行时，DynamoDB 写 API 请求会被限制。开发人员必须创建一个长期解决方案来删除旧的排行榜数据并优化写吞吐量。哪种解决方案满足这些要求？",
    "options": {
      "A": {
        "option": "为排行榜数据配置 TTL 属性。",
        "reason": "配置 TTL（Time to Live）属性是处理 DynamoDB 中数据过期的一种有效方法。TTL 自动删除超过指定时间的数据，从而避免手动删除任务带来的写容量问题。TTL 适用于需要自动删除过期数据的场景，例如临时数据、会话数据和缓存数据。"
      },
      "B": {
        "option": "使用 DynamoDB Streams 来调度并删除排行榜数据。",
        "reason": "DynamoDB Streams 主要用于捕获表中数据项的变化，用于数据复制、触发事件或数据分析。它不适合直接用于调度和删除数据。此外，使用 Streams 仍然需要编写额外的代码来处理删除操作，并不会直接优化写吞吐量。"
      },
      "C": {
        "option": "使用 AWS Step Functions 来调度并删除排行榜数据。",
        "reason": "AWS Step Functions 可以用于调度和管理工作流，但它并不能直接解决写容量问题。虽然可以通过 Step Functions 来调度删除任务，但这仍然会在删除过程中消耗写容量，不是最优的解决方案。"
      },
      "D": {
        "option": "在计划删除任务运行时设置更高的写容量。",
        "reason": "虽然增加写容量可以解决删除过程中的写吞吐量问题，但这是一种临时解决方案，会增加成本。并且需要手动调整写容量，不够灵活和高效。"
      }
    }
  },
  {
    "number": "316",
    "best": ["D"],
    "question": "一家公司使用 AWS Lambda 函数从 Amazon Simple Queue Service (Amazon SQS) 标准队列读取消息。Lambda 函数为每个消息进行一次第三方 API 的 HTTP 调用。公司希望确保 Lambda 函数不会同时发送超过两个请求给第三方 API。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "为 Lambda 函数配置两个预置并发量。",
        "reason": "预置并发量确保有固定数量的并发实例可用，但它不会限制 Lambda 的并发调用数量。预置并发主要用于减少冷启动延迟，而不是限制并发请求数量。"
      },
      "B": {
        "option": "在 Lambda 函数的 Amazon SQS 事件源映射中配置批处理大小为两个。",
        "reason": "批处理大小决定每次 Lambda 调用从 SQS 队列中读取的消息数，但并不会限制 Lambda 的并发调用数量。因此，这个选项不能确保不会同时发送超过两个请求。"
      },
      "C": {
        "option": "配置 Lambda 事件过滤，以便每次调用处理两个来自 Amazon SQS 的消息。",
        "reason": "Lambda 事件过滤可以选择性地处理特定的消息，但它不限制并发调用数量。因此，这个选项不能确保不会同时发送超过两个请求。"
      },
      "D": {
        "option": "在 Lambda 函数的 Amazon SQS 事件源映射中配置最大并发量为两个。",
        "reason": "配置最大并发量为两个可以确保 Lambda 函数在任何时候最多只有两个并发实例在处理消息，从而有效地限制了同时发送给第三方 API 的请求数量。这个选项符合题目要求。"
      }
    }
  },
  {
    "number": "317",
    "best": ["A"],
    "question": "一家公司正在使用 Amazon API Gateway 为其在 AWS 上的应用程序开发 API。开发人员需要测试并生成 API 响应。其他团队需要立即测试 API。开发人员应如何满足这些要求？",
    "options": {
      "A": {
        "option": "在 API Gateway 中设置模拟集成请求。配置方法的集成请求和集成响应，将响应与给定的状态代码关联。",
        "reason": "设置模拟集成请求是最适合的解决方案，因为它允许开发人员在没有后端服务的情况下快速生成和测试 API 响应。这种方法可以立即生成响应，从而使其他团队能够立即测试 API。模拟集成请求的主要使用场景是开发和测试阶段，特别是在后端服务尚未完全开发或不可用的情况下。"
      },
      "B": {
        "option": "在 API 的 OpenAPI 定义文件中设置请求验证器。将 OpenAPI 定义导入 API Gateway 以测试 API。",
        "reason": "虽然设置请求验证器可以帮助验证传入请求的格式和内容，但它并不能直接生成 API 响应。此选项不满足题目中立即生成和测试响应的要求。"
      },
      "C": {
        "option": "在 API Gateway 中为 API 设置网关响应。配置响应头与硬编码的 HTTP 状态代码和响应。",
        "reason": "网关响应主要用于处理 API Gateway 本身的错误和异常情况，而不是用于生成和测试应用程序级别的 API 响应。因此，该选项不适合用于满足题目中的要求。"
      },
      "D": {
        "option": "设置基于请求参数的 Lambda 授权器来控制对 API 的访问。使用必要的映射模板配置 Lambda 函数。",
        "reason": "Lambda 授权器用于基于身份验证和授权逻辑控制 API 访问，并不能直接生成 API 响应。虽然它可以用于实现复杂的访问控制逻辑，但它并不能满足题目中立即生成和测试响应的需求。"
      }
    }
  },
  {
    "number": "318",
    "best": ["A"],
    "question": "公司正在发布一个新功能。用户可以通过使用申请表请求提前访问新功能。公司预计在申请表可用时会有大量请求。每个请求将作为一个项目存储在 Amazon DynamoDB 表中。每个项目将包含用户名、提交日期和验证状态（UNVALIDATED、VALID 或 NOT VALID）。每个项目还将包含用户对流程的评分，评分范围为 1 到 5。每个用户可以提交一个请求。对于 DynamoDB 表，开发人员必须选择一个分区键，该键将使工作负载在分区之间分布良好。哪个 DynamoDB 属性将满足这些要求？",
    "options": {
      "A": {
        "option": "用户名",
        "reason": "选择用户名作为分区键是最合理的，因为每个用户只能提交一个请求，这将确保表中的每个项目都有一个唯一的分区键。使用用户名作为分区键还将使记录在分区之间分布得非常均匀，因为用户名通常是多样化和独特的。"
      },
      "B": {
        "option": "提交日期",
        "reason": "提交日期不适合作为分区键，因为它会导致大量请求集中在特定日期，造成分区键的热点问题，不能均匀分布记录。"
      },
      "C": {
        "option": "验证状态",
        "reason": "验证状态只有三个可能的值（UNVALIDATED、VALID 或 NOT VALID），不能提供足够的多样性来有效地分布记录，可能会导致分区热点问题。"
      },
      "D": {
        "option": "流程评分（1到5）",
        "reason": "评分范围仅为 1 到 5，这也将导致分区键选择的多样性不足，不能有效地分布记录。"
      }
    }
  },
  {
    "number": "319",
    "best": ["A"],
    "question": "开发人员正在创建一个仅包含静态资产的公共企业网站。开发人员正在 Amazon S3 上托管该网站，并通过 Amazon CloudFront 分发向用户提供网站。此应用程序的用户不能直接从 S3 存储桶访问应用程序内容。所有内容必须通过 Amazon CloudFront 分发提供。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "在 CloudFront 中创建一个新的源访问控制（OAC）。配置 CloudFront 分发的源使用新的 OAC。更新 S3 存储桶策略以允许 CloudFront OAC 具有读取和写入访问权限，以访问 Amazon S3 作为源。",
        "reason": "该选项利用了 CloudFront 的源访问控制（OAC），确保所有内容通过 CloudFront 分发，而不是直接从 S3 存储桶访问。更新 S3 存储桶策略以允许 CloudFront OAC 具有读取和写入访问权限，这样可以确保用户无法直接访问 S3 存储桶内容，符合题目要求。"
      },
      "B": {
        "option": "更新 S3 存储桶设置。在 Amazon S3 中启用阻止所有公共访问设置。使用 Amazon S3 作为源配置 CloudFront 分发。更新 S3 存储桶策略以允许 CloudFront 写入访问。",
        "reason": "虽然启用阻止所有公共访问设置是必要的，但该选项仅提到允许 CloudFront 写入访问，没有明确提及如何确保所有内容都通过 CloudFront 分发。"
      },
      "C": {
        "option": "更新 S3 存储桶的静态网站设置。启用静态网站托管并指定索引和错误文档。更新 CloudFront 源以使用 S3 存储桶的网站端点。",
        "reason": "该选项提到了启用 S3 的静态网站托管功能，但没有明确解决如何阻止用户直接从 S3 存储桶访问内容。"
      },
      "D": {
        "option": "更新 CloudFront 分发的源以发送自定义标头。使用 aws:RequestTag/tag-key 键更新 S3 存储桶策略，并将 tag-key 配置为自定义标头名称，匹配的值为标头的值。",
        "reason": "该选项提到了使用自定义标头来限制访问，但没有明确解决如何阻止用户直接从 S3 存储桶访问内容。"
      }
    }
  },
  {
    "number": "320",
    "best": ["C"],
    "question": "开发人员构建了一个应用程序，该应用程序调用外部 API 以获取数据，处理数据，并将结果保存到 Amazon S3。开发人员构建了一个包含运行应用程序所需的所有依赖项的容器镜像。该应用程序在本地运行，并且需要最少的 CPU 和 RAM 资源。开发人员创建了一个 Amazon ECS 集群。开发人员需要在 Amazon Elastic Container Service (Amazon ECS) 中每小时运行一次该应用程序。哪种解决方案可以以最少的基础设施管理开销满足这些要求？",
    "options": {
      "A": {
        "option": "添加容量提供者以管理实例。",
        "reason": "添加容量提供者意味着需要管理底层的 EC2 实例，这将增加基础设施管理的开销。对于这个需求，AWS Fargate 提供了无服务器的计算选项，可以减少基础设施管理。"
      },
      "B": {
        "option": "添加运行应用程序的 Amazon EC2 实例。",
        "reason": "直接添加 EC2 实例意味着开发人员需要管理和维护这些 EC2 实例，这会增加基础设施管理开销。对于这种轻量级应用，AWS Fargate 是更好的选择。"
      },
      "C": {
        "option": "使用 AWS Fargate 启动类型定义任务定义。",
        "reason": "AWS Fargate 是一种无服务器计算引擎，可以直接运行容器而无需管理底层的 EC2 实例。这种方式可以最大程度减少基础设施管理开销，符合题目中的需求。"
      },
      "D": {
        "option": "创建一个 Amazon ECS 集群并添加托管节点组功能以运行应用程序。",
        "reason": "托管节点组意味着仍然需要管理底层的 EC2 实例，这会增加基础设施管理工作。因此，这不是最优选择。"
      }
    }
  },
  {
    "number": "321",
    "best": ["D"],
    "question": "一家公司在 AWS 上运行其网站。公司每天在其网站上发布投票，并在第二天发布投票结果。网站将用户响应存储在 Amazon DynamoDB 表中。发布投票结果后，公司不需要保留用户响应。开发人员需要实现一个解决方案，以自动删除 DynamoDB 表中的旧用户响应。开发人员在 DynamoDB 表中添加了一个新的 expiration_date 属性，并计划使用该属性进行自动化。哪种解决方案在最少开发工作量的情况下满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个 AWS Lambda 函数，根据 expiration_date 属性删除旧的用户响应。创建一个 Amazon EventBridge 计划，每天运行 Lambda 函数。",
        "reason": "这种方法可以实现目标，但需要开发、部署和维护 Lambda 函数和 EventBridge 计划，相对增加了开发工作量。"
      },
      "B": {
        "option": "创建一个 AWS Fargate 任务在 Amazon Elastic Container Service (Amazon ECS) 中，根据 expiration_date 属性删除旧的用户响应。创建一个 Amazon EventBridge 计划，每天运行 Fargate 任务。",
        "reason": "这种方法同样可以实现目标，但需要设置和管理 ECS 和 Fargate 任务，增加了不必要的复杂性和开发工作量。"
      },
      "C": {
        "option": "创建一个 AWS Glue 作业，根据 expiration_date 属性删除旧的用户响应。创建一个 AWS Glue 触发器计划，每天运行作业。",
        "reason": "这种方法也可以实现目标，但需要学习和配置 AWS Glue，增加了不必要的复杂性和开发工作量。"
      },
      "D": {
        "option": "在 DynamoDB 表上启用 TTL，并指定 expiration_date 属性。使用 DynamoDB TTL 过期旧的用户响应。",
        "reason": "这是最优选项，因为 DynamoDB 的 TTL（Time to Live）功能可以自动删除过期项，只需启用并配置 TTL 属性，最少开发工作量即可实现目标。"
      }
    }
  },
  {
    "number": "322",
    "best": ["D"],
    "question": "开发人员正在使用 AWS CloudFormation 和 AWS Lambda 函数创建一个简单的概念验证演示。该演示将使用一个 CloudFormation 模板部署一个现有的 Lambda 函数。Lambda 函数使用存储在 Amazon S3 中的部署包和依赖项。开发人员在 CloudFormation 模板中定义了一个 AWS::Lambda::Function 资源。开发人员需要将 S3 存储桶添加到 CloudFormation 模板中。开发人员应该怎么做以最小的开发工作量满足这些要求？",
    "options": {
      "A": {
        "option": "在 CloudFormation 模板中将函数代码内联添加为 code 属性。",
        "reason": "内联代码适用于较小的脚本或简单的函数，但对于包含依赖项的 Lambda 函数，这种方法不太合适，也不符合题目中提到的使用部署包的要求。"
      },
      "B": {
        "option": "在 CloudFormation 模板中将函数代码添加为 ZipFile 属性。",
        "reason": "ZipFile 属性适用于较小的代码片段，而不是包含多个文件和依赖项的复杂部署包。"
      },
      "C": {
        "option": "找到 Lambda 函数的 S3 键。将 S3 键添加为 CloudFormation 模板中的 ZipFile 属性。",
        "reason": "此选项混淆了 ZipFile 属性和 S3 存储桶的使用方法。ZipFile 属性用于内联代码，不涉及 S3 存储桶。"
      },
      "D": {
        "option": "将相关的键和存储桶添加到 CloudFormation 模板中的 S3Bucket 和 S3Key 属性。",
        "reason": "这是最符合题意的选项。AWS::Lambda::Function 资源有一个 Code 属性，可以使用 S3Bucket 和 S3Key 子属性来指定 Lambda 部署包在 S3 中的位置。这种方法最符合题目要求，并且开发工作量最小。"
      }
    }
  },
  {
    "number": "323",
    "best": ["B"],
    "question": "一名开发人员正在使用 Python 在 AWS 上构建基于微服务的应用程序，并使用多个 AWS 服务。开发人员必须使用 AWS X-Ray。开发人员通过控制台查看服务地图以查看服务依赖关系。在测试过程中，开发人员注意到服务地图中缺少一些服务。开发人员可以做什么来确保所有服务都出现在 X-Ray 服务地图中？",
    "options": {
      "A": {
        "option": "修改每个服务中的 X-Ray Python 代理配置以增加采样率。",
        "reason": "增加采样率可能会帮助捕获更多请求，但这并不能保证所有服务都会出现在服务地图中。如果服务未正确配置以使用 X-Ray SDK，增加采样率也无济于事。"
      },
      "B": {
        "option": "使用 X-Ray SDK for Python 对应用程序进行检测。为该应用程序使用的所有服务安装 X-Ray SDK。",
        "reason": "正确使用 X-Ray SDK for Python 并为所有服务安装 SDK 是确保所有服务出现在 X-Ray 服务地图中的关键步骤。X-Ray SDK 提供了自动捕获和发送跟踪数据的能力，这对于可见性至关重要。"
      },
      "C": {
        "option": "在 Amazon CloudWatch Logs 中为应用程序使用的所有服务启用 X-Ray 数据聚合。",
        "reason": "虽然 CloudWatch Logs 可以与 X-Ray 集成以查看日志数据，但这并不是确保服务出现在 X-Ray 服务地图中的直接方法。X-Ray 服务地图主要依赖于跟踪数据。"
      },
      "D": {
        "option": "在 X-Ray 控制台中增加 X-Ray 服务地图超时值。",
        "reason": "增加超时值可能会帮助显示更多服务，但这不是根本问题的解决方案。如果服务未正确配置 X-Ray，那么增加超时值也无法使其出现在服务地图中。"
      }
    }
  },
  {
    "number": "324",
    "best": ["A", "E"],
    "question": "一名开发人员正在 AWS 上构建容器化应用程序。该应用程序通过使用 API 密钥与第三方服务通信。开发人员需要一种安全的方式来存储 API 密钥并将其传递给容器化应用程序。哪些解决方案可以满足这些要求？（选择两项）",
    "options": {
      "A": {
        "option": "将 API 密钥作为 SecureString 参数存储在 AWS Systems Manager Parameter Store 中。授予应用程序从 Parameter Store 检索值的权限。",
        "reason": "AWS Systems Manager Parameter Store 是一种安全的存储服务，可以存储配置数据和机密数据。使用 SecureString 类型的参数可以确保数据的加密和安全访问。这个选项能够满足安全存储和访问 API 密钥的需求。"
      },
      "B": {
        "option": "使用 base64 编码将 API 密钥存储在 AWS CloudFormation 模板中。通过容器定义环境变量将 API 密钥传递给应用程序。",
        "reason": "虽然 base64 编码可以隐藏 API 密钥，但它并不是一种安全的存储方式。如果模板文件被泄露，API 密钥可能会被解码并被滥用。因此，这个选项不符合安全存储的要求。"
      },
      "C": {
        "option": "在 CloudFormation 模板中添加一个新的 AWS CloudFormation 参数。通过容器定义环境变量将 API 密钥传递给应用程序。",
        "reason": "将 API 密钥直接作为参数存储在 CloudFormation 模板中是不安全的。如果模板文件被泄露，API 密钥将会暴露。因此，这个选项不符合安全存储的要求。"
      },
      "D": {
        "option": "将 API 密钥嵌入应用程序中。在本地构建容器镜像。将容器镜像上传到 Amazon Elastic Container Registry (Amazon ECR)。",
        "reason": "将 API 密钥嵌入应用程序代码中是不安全的，因为任何访问容器镜像的人都可以获取这些密钥。这种方法不符合安全存储和管理密钥的最佳实践。"
      },
      "E": {
        "option": "将 API 密钥作为 SecretString 参数存储在 AWS Secrets Manager 中。授予应用程序从 Secrets Manager 检索值的权限。",
        "reason": "AWS Secrets Manager 是一种专门用于存储和管理密钥和其他机密数据的服务。它提供了自动轮换、审计和安全访问控制等功能，非常适合存储和管理 API 密钥。这个选项能够满足安全存储和访问 API 密钥的需求。"
      }
    }
  },
  {
    "number": "325",
    "best": ["B"],
    "question": "公司在 AWS 上运行一个应用程序。该应用程序将数据存储在 Amazon DynamoDB 表中。一些查询运行时间较长。这些慢查询涉及的属性不是表的分区键或排序键。预计应用程序存储在 DynamoDB 表中的数据量将显著增加。开发人员必须提高查询的性能。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "通过将 Limit 参数设置为高于默认值来增加每个请求的分页大小。配置应用程序以重试任何超出预置吞吐量的请求。",
        "reason": "增加分页大小可能会导致更大的数据吞吐量，但这并不能解决查询涉及非分区键或排序键的属性的问题。此外，配置应用程序重试超出预置吞吐量的请求也不是最佳解决方案，因为这可能会导致更多的延迟和资源消耗。因此，这不是最优选项。"
      },
      "B": {
        "option": "创建一个全球二级索引（GSI）。将查询属性设置为索引的分区键。",
        "reason": "全球二级索引（GSI）允许在 DynamoDB 表中创建新的查询路径，从而提高查询性能。通过将查询属性设置为 GSI 的分区键，可以显著提高查询涉及非分区键或排序键属性的性能。这是解决问题的最佳方案。"
      },
      "C": {
        "option": "通过发出单独的扫描请求来执行并行扫描操作。在参数中指定扫描请求的段和并行扫描的总段数。",
        "reason": "并行扫描操作可以加速扫描整个表的数据，但这不是解决查询性能问题的最佳方法，因为它会消耗大量的读取容量，并且处理复杂度较高。并行扫描更适用于需要从整个表中快速检索数据的情况，而不是解决特定查询的性能问题。因此，这不是最优选项。"
      },
      "D": {
        "option": "为 DynamoDB 表启用读取容量自动扩展。增加最大读取容量单位（RCUs）。",
        "reason": "启用读取容量自动扩展可以帮助应对读请求的高峰，但这并不能解决查询涉及非分区键或排序键属性的性能问题。增加 RCUs 仅能在一定程度上缓解读取请求的负载，而不能从根本上优化特定查询的性能。因此，这不是最佳解决方案。"
      }
    }
  },
  {
    "number": "326",
    "best": ["D"],
    "question": "一家公司在 Amazon EC2 实例上运行支付应用程序，这些实例位于 Application Load Balancer 后面。EC2 实例在多个可用区中运行在一个 Auto Scaling 组中。应用程序需要在启动时检索应用程序密钥，并将密钥导出为环境变量。这些密钥必须静态加密并且需要每月轮换一次。哪种解决方案以最少的开发努力满足这些要求？",
    "options": {
      "A": {
        "option": "将密钥保存为一个文本文件，并将文本文件存储在 Amazon S3 中。配置一个客户管理的密钥，用于在 Amazon S3 中加密密钥。读取文本文件的内容并将其导出为环境变量。配置 S3 Object Lambda 每月轮换一次文本文件。",
        "reason": "虽然这种方法可以实现密钥的存储和加密，但它需要配置和管理 S3 Object Lambda 的轮换，这增加了复杂性和开发努力。因此，这不是最优选择。"
      },
      "B": {
        "option": "将密钥作为字符串存储在 AWS Systems Manager Parameter Store 中，并使用默认的 AWS Key Management Service (AWS KMS) 密钥。在 Amazon EC2 用户数据脚本中配置以在启动时检索密钥并导出为环境变量。配置一个 AWS Lambda 函数以每月轮换 Parameter Store 中的密钥。",
        "reason": "这种方法使用了 AWS Systems Manager Parameter Store 和 AWS KMS 的默认密钥，并通过用户数据脚本实现了启动时的检索。但它需要额外配置一个 Lambda 函数进行密钥轮换，这增加了开发工作量。因此，这不是最优选择。"
      },
      "C": {
        "option": "将密钥作为 base64 编码的环境变量保存在应用程序属性中。在应用程序启动时检索密钥。在应用程序代码中引用密钥。编写一个脚本来轮换保存在环境变量中的密钥。",
        "reason": "这种方法将密钥直接保存在应用程序属性中，这可能不够安全，并且需要编写和维护额外的脚本来进行轮换，因此这不是一个好的选择。"
      },
      "D": {
        "option": "将密钥存储在 AWS Secrets Manager 中。配置一个新的客户主密钥来加密密钥。启用自动轮换。在 Amazon EC2 用户数据脚本中配置以在启动时程序化地检索密钥并导出为环境变量。",
        "reason": "这种方法利用了 AWS Secrets Manager 的内置功能，包括密钥存储、加密和自动轮换。通过用户数据脚本在启动时检索密钥并导出为环境变量，开发工作量最少。因此，这是最优选择。"
      }
    }
  },
  {
    "number": "327",
    "best": ["D"],
    "question": "一家公司正在使用 Amazon API Gateway 调用一个新的 AWS Lambda 函数。公司在其 PROD 和 DEV 环境中有 Lambda 函数版本。在每个环境中，有一个 Lambda 函数别名指向相应的 Lambda 函数版本。API Gateway 有一个阶段配置指向 PROD 别名。公司希望配置 API Gateway 以使 PROD 和 DEV Lambda 函数版本同时和独立地可用。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "在 API Gateway 中为 Lambda 函数别名启用 Lambda 授权器。重新发布 PROD 并为 DEV 创建一个新阶段。为 PROD 和 DEV 阶段创建 API Gateway 阶段变量。将每个阶段变量指向 PROD Lambda 授权器到 DEV Lambda 授权器。",
        "reason": "此选项涉及使用 Lambda 授权器，但题目并没有要求添加授权机制，只是需要不同阶段指向不同的 Lambda 函数版本。"
      },
      "B": {
        "option": "在 API Gateway 中为 Lambda 函数别名设置网关响应。重新发布 PROD 并为 DEV 创建一个新阶段。为 PROD 和 DEV Lambda 别名创建 API Gateway 网关响应。",
        "reason": "此选项涉及设置网关响应，但这不是解决不同阶段指向不同 Lambda 函数版本的正确方法。网关响应用于处理 API Gateway 返回的错误响应。"
      },
      "C": {
        "option": "在 API Gateway 中使用 Lambda 函数别名的环境变量。重新发布 PROD 并为开发环境创建一个新阶段。为 PROD 和 DEV 阶段创建 API Gateway 环境变量。将每个阶段变量指向 PROD Lambda 函数别名到 DEV Lambda 函数别名。",
        "reason": "此选项提到使用环境变量，但环境变量主要用于在 Lambda 函数内部传递配置信息，而不是在 API Gateway 中区分不同的 Lambda 函数版本。"
      },
      "D": {
        "option": "使用 API Gateway 阶段变量配置 Lambda 函数别名。重新发布 PROD 并为开发环境创建一个新阶段。为 PROD 和 DEV 阶段创建 API Gateway 阶段变量。将每个阶段变量指向 PROD Lambda 函数别名和 DEV Lambda 函数别名。",
        "reason": "此选项是正确的，因为使用 API Gateway 阶段变量可以让不同的阶段指向不同的 Lambda 函数别名，从而实现题目要求的同时和独立地使用 PROD 和 DEV 版本。"
      }
    }
  },
  {
    "number": "#328",
    "best": ["D"],
    "question": "一名开发人员正在开发一个电商平台，该平台需要与多个第三方支付处理 API 进行通信。这些第三方支付服务不提供测试环境。开发人员需要验证电商平台与第三方支付处理 API 的集成。开发人员必须在不调用第三方支付处理 API 的情况下测试 API 集成代码。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "设置一个 Amazon API Gateway REST API，使用状态代码 200 配置网关响应。添加包含从真实第三方 API 捕获的示例响应的响应模板。",
        "reason": "虽然设置 API Gateway REST API 并配置网关响应可以模拟响应，但这种方法更适用于简单的响应和错误处理，不一定适合复杂的集成测试。"
      },
      "B": {
        "option": "设置一个 AWS AppSync GraphQL API，并为每个第三方 API 配置数据源。指定 Mock 的集成类型。使用从真实第三方 API 捕获的示例响应配置集成响应。",
        "reason": "AWS AppSync 主要用于 GraphQL API，而题目中提到的是 REST API。因此，这种方法与题目需求不完全匹配。"
      },
      "C": {
        "option": "为每个第三方 API 创建一个 AWS Lambda 函数。嵌入从真实第三方 API 捕获的响应。使用 Amazon Route 53 Resolver 为每个 Lambda 函数的 Amazon Resource Name (ARN) 配置入站端点。",
        "reason": "这种方法过于复杂，且使用 Route 53 Resolver 似乎不太适合这种需求。主要问题在于管理和维护多个 Lambda 函数的复杂性。"
      },
      "D": {
        "option": "为每个第三方 API 设置一个 Amazon API Gateway REST API。指定 Mock 的集成请求类型。使用从真实第三方 API 捕获的示例响应配置集成响应。",
        "reason": "这是最符合题目需求的选项。使用 API Gateway 的 Mock 集成请求类型可以在不调用实际第三方 API 的情况下模拟响应，从而满足测试集成代码的需要。"
      }
    }
  },
  {
    "number": "329",
    "best": ["C"],
    "question": "开发人员正在将许多对象存储在单个 Amazon S3 存储桶中。开发人员需要优化 S3 存储桶以实现高请求率。开发人员应该如何存储对象以满足此需求？",
    "options": {
      "A": {
        "option": "使用 S3 智能分层存储对象。",
        "reason": "S3 Intelligent-Tiering 是一种存储类，可以在不同访问层之间自动迁移数据以优化成本。虽然它可以帮助节省成本，但它并不是专门为优化高请求率设计的。"
      },
      "B": {
        "option": "将对象存储在 S3 存储桶的根目录。",
        "reason": "将所有对象存储在根目录不会提高请求率的性能。相反，它可能会导致性能问题，因为所有请求都会集中在单一的根目录上。"
      },
      "C": {
        "option": "使用分布在多个前缀中的对象键名存储对象。",
        "reason": "使用分布在多个前缀中的对象键名可以帮助均匀分布请求，从而提高请求率。这是因为 Amazon S3 对象前缀的分布有助于优化性能，特别是在处理高请求率时。"
      },
      "D": {
        "option": "将每个对象存储为包含唯一值的对象标签名为 \"prefix\" 的对象。",
        "reason": "对象标签主要用于标记和管理对象，而不是优化请求率。虽然标签可以帮助组织对象，但它们不会直接影响请求性能。"
      }
    }
  },
  {
    "number": "330",
    "best": ["A"],
    "question": "公司向 AWS 部署了一个新应用程序。公司将应用程序日志流式传输到 Amazon CloudWatch Logs。公司开发团队必须在任何日志行中出现单词“ERROR”时通过电子邮件接收通知。一名开发人员设置了一个 Amazon Simple Notification Service (Amazon SNS) 主题，并将开发团队订阅到该主题。为了满足要求，开发人员接下来应该怎么做？",
    "options": {
      "A": {
        "option": "选择适当的日志组。创建一个包含“ERROR”作为搜索词的 CloudWatch 指标过滤器。创建一个在指标为1或更高时通知 SNS 主题的警报。",
        "reason": "此选项提供了一种通过创建 CloudWatch 指标过滤器来监控日志内容的方法，并在发现包含'ERROR'的日志行时触发警报。CloudWatch Metrics 是用于监控和收集日志数据的专用工具，一旦设置了过滤器和警报，就可以自动触发 SNS 通知。"
      },
      "B": {
        "option": "在 CloudWatch Logs Insights 中选择适当的日志组。创建一个指标查询来搜索日志中的“ERROR”一词。创建一个在指标为1或更高时通知 SNS 主题的警报。",
        "reason": "虽然 CloudWatch Logs Insights 可以用来查询日志，但它主要用于临时查询和分析，而不是持续监控。它不适合用于设置长期的自动化警报。"
      },
      "C": {
        "option": "选择适当的日志组。创建一个包含“ERROR”作为过滤模式的 SNS 订阅过滤器。选择 SNS 主题作为目标。",
        "reason": "SNS 订阅过滤器用于过滤从 SNS 主题发布的消息，而不是用于直接过滤 CloudWatch 日志。因此，这不是一个适用的解决方案。"
      },
      "D": {
        "option": "创建一个包含“ERROR”作为过滤模式的 CloudWatch 警报，一个定义了适当日志组的日志组维度，以及一个通知 SNS 主题的目标。",
        "reason": "CloudWatch 警报本身无法直接包含过滤模式。警报通常基于指标数据，而不是直接基于日志内容。因此，这种方法在技术上是不可行的。"
      }
    }
  },
  {
    "number": "331",
    "best": ["A"],
    "question": "公司使用Amazon Simple Queue Service（Amazon SQS）对其微服务架构进行解耦。SQS队列中的某些消息包含敏感信息。开发人员必须实现一种解决方案，以静态加密所有数据。哪种解决方案可以满足此要求？",
    "options": {
      "A": {
        "option": "使用SQS托管的加密密钥（SSE-SQS）为SQS队列启用服务器端加密。",
        "reason": "选择此选项的原因是SSE-SQS（Server-Side Encryption with SQS managed encryption keys）是专门为SQS提供的内置加密功能，可以确保队列中的所有消息在存储时被加密。它满足了加密数据静态存储的要求。"
      },
      "B": {
        "option": "在队列策略中使用aws:SecureTransport条件，以确保所有对SQS队列的请求都使用HTTPS（TLS）。",
        "reason": "虽然使用HTTPS（TLS）可以确保传输中的数据安全，但它不能解决数据在静态存储时的加密问题。因此，这并不能满足题目中对加密静态数据的要求。"
      },
      "C": {
        "option": "使用AWS Certificate Manager（ACM）生成SSL/TLS证书。在将消息发送到队列时引用该证书。",
        "reason": "此选项涉及在传输过程中使用SSL/TLS证书进行加密，但这并不适用于静态数据的加密。题目要求的是对存储中的数据进行加密，因此这个选项不满足要求。"
      },
      "D": {
        "option": "在发送到队列的SQS SendMessage请求中设置消息属性。将Name设置为ENCRYPT。将Value设置为TRUE。",
        "reason": "此选项描述的做法并不是SQS提供的功能。SQS没有通过设置消息属性来启用加密的机制，因此这个选项是不正确的。"
      }
    }
  },
  {
    "number": "332",
    "best": ["B"],
    "question": "一家公司最近部署了一个新的无服务器用户门户。用户报告说门户的一部分运行缓慢。初步分析发现一个单一的 Amazon API Gateway 端点导致了性能问题。该端点与一个 AWS Lambda 函数集成。然而，该 Lambda 函数与其他 API 和 AWS 服务进行交互。开发人员如何通过使用操作最佳实践找到响应时间增加的来源？",
    "options": {
      "A": {
        "option": "更新 Lambda 函数，在每个外部请求之前和之后添加带有高精度时间戳的日志语句。部署更新后的 Lambda 函数。在积累了足够的使用数据后，检查 Lambda 函数的 Amazon CloudWatch 日志，以确定响应时间增加的可能来源。",
        "reason": "虽然添加日志语句可以帮助查找问题，但这种方法需要手动分析日志，而且可能会遗漏一些细节。相较而言，X-Ray 提供了更全面和自动化的追踪和分析功能。"
      },
      "B": {
        "option": "使用 AWS X-Ray SDK 对 Lambda 函数进行检测。添加 HTTP 和 HTTPS 拦截器以及 SDK 客户端处理程序。部署更新后的 Lambda 函数。开启 X-Ray 跟踪。在积累了足够的使用数据后，使用 X-Ray 服务地图检查平均响应时间，以确定可能的来源。",
        "reason": "AWS X-Ray 是一个用于分析和调试分布式应用程序的服务。它可以追踪请求在不同服务之间的流动，生成服务地图，帮助快速识别性能瓶颈和延迟的具体来源。这使得它成为诊断 Lambda 函数性能问题的最佳选择。"
      },
      "C": {
        "option": "使用指标浏览器查看 Lambda 函数的 Amazon CloudWatch 指标。对 Duration 指标和 Throttles 指标应用异常检测。查看异常以确定可能的来源。",
        "reason": "虽然异常检测可以帮助识别性能问题的时间点，但它无法提供详细的调用链信息，无法像 X-Ray 那样详细追踪请求在不同服务之间的流动。"
      },
      "D": {
        "option": "使用 Amazon CloudWatch Synthetics 创建一个新的 canary。开启 AWS X-Ray 跟踪。在 canary 上配置扫描用户门户。在积累了足够的使用数据后，使用 CloudWatch Synthetics canary 仪表盘查看 canary 的指标。",
        "reason": "CloudWatch Synthetics 主要用于监控应用程序的可用性和性能，创建 canary 可以模拟用户行为，但这不是专门用于诊断 Lambda 函数性能问题的最佳实践。"
      }
    }
  },
  {
    "number": "333",
    "best": ["C"],
    "question": "开发人员正在使用 AWS Lambda 和 Amazon EventBridge 构建一个事件驱动的应用程序。Lambda 函数需要将事件推送到 EventBridge 事件总线。开发人员使用 SDK 运行 PutEvents EventBridge 操作，并且在代码中未指定任何凭证。部署 Lambda 函数后，开发人员注意到该函数失败，并且日志中出现 AccessDeniedException 错误。开发人员应该如何解决此问题？",
    "options": {
      "A": {
        "option": "在 Lambda 函数和 EventBridge 之间配置 VPC 对等连接。",
        "reason": "VPC 对等连接用于不同 VPC 之间的网络连接，与权限问题无关，因此不能解决 AccessDeniedException 错误。"
      },
      "B": {
        "option": "修改他们的 AWS 凭证以包括 PutEvents EventBridge 操作的权限。",
        "reason": "修改开发人员的个人 AWS 凭证并不能解决问题，因为 Lambda 函数在执行时使用的是其自己的执行角色，而不是开发人员的凭证。"
      },
      "C": {
        "option": "修改 Lambda 函数执行角色以包含 PutEvents EventBridge 操作的权限。",
        "reason": "这是正确的解决方案。Lambda 函数在执行时需要适当的 IAM 权限。开发人员应该修改 Lambda 函数的执行角色，添加对 EventBridge 的 PutEvents 操作的权限，以便函数能够成功推送事件。"
      },
      "D": {
        "option": "添加一个基于资源的策略到 Lambda 函数，以包括 PutEvents EventBridge 操作的权限。",
        "reason": "基于资源的策略通常用于授予其他账户或服务对资源的访问权限，而不是用于 Lambda 函数的执行角色。因此，这不是解决这个特定权限问题的正确方法。"
      }
    }
  },
  {
    "number": "334",
    "best": ["C"],
    "question": "一家公司有一个 AWS Lambda 函数，用于处理来自 IoT 设备的消息。公司希望监控 Lambda 函数，以确保其满足所需的服务等级协议 (SLA)。开发人员必须实现一个解决方案，以近实时确定应用程序的吞吐量。吞吐量必须基于 Lambda 函数在给定时间段内接收和处理的消息数量。Lambda 函数执行的初始化和后处理步骤不应计入吞吐量测量。开发人员应该怎么做以满足这些要求？",
    "options": {
      "A": {
        "option": "使用 Lambda 函数的 ConcurrentExecutions 指标在 Amazon CloudWatch 中测量吞吐量。",
        "reason": "ConcurrentExecutions 指标显示的是同时执行的 Lambda 实例数，而不是处理的消息数量。因此，它不能准确反映应用程序的吞吐量。"
      },
      "B": {
        "option": "修改应用程序，将计算的吞吐量记录到 Amazon CloudWatch Logs。使用 Amazon EventBridge 定期调用一个独立的 Lambda 函数来处理日志。",
        "reason": "虽然这种方法可以实现目标，但它过于复杂，并且涉及额外的 Lambda 函数调用和日志处理，不是最优解。"
      },
      "C": {
        "option": "修改应用程序，在 Lambda 函数接收和处理每条消息时发布自定义 Amazon CloudWatch 指标。使用这些指标计算吞吐量。",
        "reason": "这是最佳选项，因为自定义 CloudWatch 指标可以准确反映 Lambda 函数接收和处理的消息数量，允许精确计算吞吐量。"
      },
      "D": {
        "option": "使用 Lambda 函数的 Invocations 指标和 Duration 指标在 Amazon CloudWatch 中计算吞吐量。",
        "reason": "Invocations 指标表示 Lambda 函数被调用的次数，但它不区分初始化和处理步骤，而 Duration 指标则反映执行时间。两者结合也不能准确衡量消息处理吞吐量。"
      }
    }
  },
  {
    "number": "335",
    "best": ["D"],
    "question": "开发人员正在使用 AWS CodePipeline 管道为 Java 应用程序提供持续集成和持续交付（CI/CD）支持。开发人员需要更新管道以支持引入新的应用程序依赖项 .jar 文件。当新的 .jar 文件版本可用时，管道必须启动构建。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个 Amazon S3 存储桶来存储依赖项 .jar 文件。将依赖项 .jar 文件发布到 S3 存储桶。使用 Amazon Simple Notification Service (Amazon SNS) 通知启动 CodePipeline 管道构建。",
        "reason": "虽然 S3 可以存储 .jar 文件，并且 SNS 可以发送通知，但这并不是管理和发布依赖项的最佳实践。此外，这种方法需要额外的自定义配置来触发 CodePipeline。"
      },
      "B": {
        "option": "创建一个 Amazon Elastic Container Registry (Amazon ECR) 私有仓库。将依赖项 .jar 文件发布到仓库。使用 ECR 源操作启动 CodePipeline 管道构建。",
        "reason": "ECR 主要用于存储和管理 Docker 容器镜像，而不是 .jar 文件。此选项不适合管理 Java 依赖项。"
      },
      "C": {
        "option": "创建一个 Amazon Elastic Container Registry (Amazon ECR) 私有仓库。将依赖项 .jar 文件发布到仓库。使用 Amazon Simple Notification Service (Amazon SNS) 通知启动 CodePipeline 管道构建。",
        "reason": "同样，ECR 主要用于 Docker 容器，而不是 .jar 文件。使用 SNS 通知来启动 CodePipeline 也需要额外的自定义配置。"
      },
      "D": {
        "option": "创建一个 AWS CodeArtifact 仓库。将依赖项 .jar 文件发布到仓库。使用 Amazon EventBridge 规则启动 CodePipeline 管道构建。",
        "reason": "CodeArtifact 是 AWS 提供的包管理服务，适用于存储和管理依赖项（如 .jar 文件）。使用 EventBridge 规则来触发 CodePipeline 是一种自动化和集成良好的解决方案。因此，这是最优选项。"
      }
    }
  },
  {
    "number": "336",
    "best": ["D"],
    "question": "公司有多个分支机构，有一个用于分析和报告的应用程序。每个分支机构每天在预定时间将销售报告推送到一个共享的 Amazon S3 存储桶。公司开发了一个 AWS Lambda 函数，用于在一次运行中分析所有分支机构的报告。Lambda 函数将结果存储在数据库中。公司需要在每天的特定时间开始分析。哪种解决方案最具成本效益地满足这些要求？",
    "options": {
      "A": {
        "option": "配置一个 S3 事件通知，在分支机构上传销售报告时调用 Lambda 函数。",
        "reason": "这种方法会导致每次上传一个报告时都触发 Lambda 函数运行，但需求是在每天的特定时间开始分析，因此不符合要求。"
      },
      "B": {
        "option": "创建一个 AWS Step Functions 状态机，每天在预定时间调用 Lambda 函数。",
        "reason": "AWS Step Functions 可以用于协调多个 AWS 服务，但对于这种简单的按时启动 Lambda 函数的需求，这种方法显得过于复杂和昂贵。"
      },
      "C": {
        "option": "配置 Lambda 函数持续运行，并在每天的预定时间开始分析。",
        "reason": "Lambda 函数并不适合持续运行，因为它是无服务器的，并且按请求计费。持续运行会导致不必要的成本增加。"
      },
      "D": {
        "option": "创建一个 Amazon EventBridge 定时规则，每天在预定时间调用 Lambda 函数。",
        "reason": "Amazon EventBridge 可以轻松创建定时任务，并且与 Lambda 函数集成良好。这种方法符合需求，且成本效益最高，因为它只在指定时间触发 Lambda 函数运行。"
      }
    }
  },
  {
    "number": "337",
    "best": ["C"],
    "question": "一名开发人员有一个异步调用 AWS Lambda 函数的应用程序。开发人员希望存储导致 Lambda 函数调用失败的消息，以便稍后应用程序可以重试调用。开发人员应该怎么做才能以最少的运营开销实现这一目标？",
    "options": {
      "A": {
        "option": "设置 Amazon CloudWatch Logs 日志组，以过滤并将消息存储在 Amazon S3 存储桶中。将消息导入 Lambda。再次运行 Lambda 函数。",
        "reason": "使用 CloudWatch Logs 和 S3 进行存储和重试会涉及多个步骤，增加了操作复杂性和维护开销。不是最优选项。"
      },
      "B": {
        "option": "配置 Amazon EventBridge 将消息发送到 Amazon Simple Notification Service (Amazon SNS)，以再次启动 Lambda 函数。",
        "reason": "虽然 EventBridge 和 SNS 可以帮助重新触发 Lambda，但它没有有效地存储失败的消息以供重试。"
      },
      "C": {
        "option": "为丢弃的消息实现一个死信队列。将死信队列设置为 Lambda 函数的事件源。",
        "reason": "配置死信队列 (DLQ) 是处理 Lambda 函数失败消息的最佳实践。DLQ 可以自动存储失败的消息，并且可以稍后重新处理，具有最低的操作开销。"
      },
      "D": {
        "option": "将 Amazon EventBridge 事件发送到 Amazon Simple Queue Service (Amazon SQS) 队列。配置 Lambda 函数从 SQS 队列中提取消息。再次运行 Lambda 函数。",
        "reason": "虽然使用 SQS 可以可靠地存储消息，但将 EventBridge 与 SQS 集成增加了额外的步骤和复杂性。相比之下，死信队列更直接且操作开销更低。"
      }
    }
  },
  {
    "number": "338",
    "best": ["A"],
    "question": "公司正在使用 AWS CloudFormation 模板来部署 AWS 资源。公司需要更新其中一个 AWS CloudFormation 栈。公司可以做些什么来了解这些更改将如何影响正在运行的资源？",
    "options": {
      "A": {
        "option": "调查变更集。",
        "reason": "变更集（Change Sets）允许用户查看对 AWS CloudFormation 栈进行的更改以及这些更改将如何影响现有资源。通过在执行更改之前查看变更集，公司可以了解资源的潜在影响，这是最安全和最有效的方法。使用场景包括在部署更新之前评估其影响，确保不会意外破坏现有资源。"
      },
      "B": {
        "option": "调查栈策略。",
        "reason": "栈策略（Stack Policies）用于保护栈资源免受意外更新的影响，但它们不会显示具体更改的影响。栈策略主要用于控制谁可以对栈进行操作，而不是评估更改的影响。"
      },
      "C": {
        "option": "调查元数据部分。",
        "reason": "元数据部分（Metadata Section）在 CloudFormation 模板中用于存储栈相关的附加信息和描述性数据，但它并不用于评估更改的影响。元数据更多是用于文档和说明。"
      },
      "D": {
        "option": "调查资源部分。",
        "reason": "资源部分（Resources Section）定义了 CloudFormation 模板中创建的 AWS 资源，但它并不能直接帮助评估对这些资源的更改影响。资源部分更多是定义资源的属性和配置。"
      }
    }
  },
  {
    "number": "339",
    "best": ["A", "D"],
    "question": "公司在账户A中的一个名为PII的Amazon DynamoDB表中存储所有个人身份信息（PII）。开发人员正在账户B中的Amazon EC2实例上运行的应用程序需要访问PII表。账户A中的管理员创建了一个名为AccessPII的IAM角色，具有访问PII表的权限。管理员还创建了一个信任策略，指定账户B可以扮演该角色。开发人员应该在账户B中采取哪些步骤以允许他们的应用程序访问PII表？（选择两项）",
    "options": {
      "A": {
        "option": "允许EC2 IAM角色假设AccessPII角色的权限。",
        "reason": "为了使EC2实例能够假设账户A中的AccessPII角色，必须在账户B中允许EC2 IAM角色假设该角色。这样，EC2实例才能获得临时凭证来访问PII表。"
      },
      "B": {
        "option": "允许EC2 IAM角色访问PII表的权限。",
        "reason": "这个选项不正确，因为访问PII表的权限由账户A中的AccessPII角色提供。账户B中的EC2 IAM角色只需要权限来假设AccessPII角色。"
      },
      "C": {
        "option": "在应用程序代码逻辑中包含AWS API，以从EC2 IAM角色获取临时凭证来访问PII表。",
        "reason": "这个选项不正确，因为应用程序需要通过AssumeRole API来获取临时凭证，而不是直接从EC2 IAM角色获取。"
      },
      "D": {
        "option": "在应用程序代码逻辑中包含AssumeRole API操作，以获取临时凭证来访问PII表。",
        "reason": "为了使应用程序能够使用账户A中的AccessPII角色，必须在应用程序代码中使用AssumeRole API操作来获取临时凭证。这是访问跨账户资源的标准方法。"
      },
      "E": {
        "option": "在应用程序代码逻辑中包含GetSessionToken API操作，以获取临时凭证来访问PII表。",
        "reason": "这个选项不正确，因为GetSessionToken API主要用于当前账户中的临时凭证，而不是跨账户访问。对于跨账户访问，应该使用AssumeRole API。"
      }
    }
  },
  {
    "number": "340",
    "best": ["C", "D"],
    "question": "一家游戏网站允许用户在平台上互相交易游戏物品。平台要求在一个事务中更新并持久化两个用户的记录。如果任何更新失败，事务必须回滚。哪些 AWS 解决方案可以提供所需的事务能力？（选择两个。）",
    "options": {
      "A": {
        "option": "使用 ConsistentRead 参数设置为 true 的 Amazon DynamoDB 进行操作",
        "reason": "ConsistentRead 参数仅用于确保读取操作的一致性，而不是事务处理。它不提供事务能力，因此不能满足题目中要求的在失败时回滚事务的需求。"
      },
      "B": {
        "option": "使用事务块内的操作进行的 Amazon ElastiCache for Memcached",
        "reason": "Amazon ElastiCache for Memcached 是一个内存缓存服务，不支持事务处理。它主要用于缓存数据以提高数据读取速度，而不是用于数据持久化和事务处理。"
      },
      "C": {
        "option": "使用 Transact* 操作进行读写的 Amazon DynamoDB",
        "reason": "Amazon DynamoDB 提供 TransactWriteItems 和 TransactGetItems 操作，这些操作支持原子性、一致性、隔离性和持久性（ACID）事务，可以确保如果任何操作失败，整个事务将回滚，从而满足题目中的需求。"
      },
      "D": {
        "option": "使用事务块内的操作进行的 Amazon Aurora MySQL",
        "reason": "Amazon Aurora MySQL 支持事务处理，可以使用事务块（transaction block）来确保一组操作要么全部成功，要么全部回滚，从而满足题目中的需求。"
      },
      "E": {
        "option": "使用事务块内的操作进行的 Amazon Athena",
        "reason": "Amazon Athena 是一种交互式查询服务，主要用于分析数据，而不是处理事务。它不支持事务处理，因此不能满足题目中要求的在失败时回滚事务的需求。"
      }
    }
  },
  {
    "number": "341",
    "best": ["A"],
    "question": "开发人员正在使用 AWS CloudFormation 在 AWS 云中部署一个应用程序。该应用程序将连接到现有的 Amazon RDS 数据库。RDS 数据库的主机名作为明文值存储在 AWS Systems Manager 参数存储中。开发人员需要将数据库主机名纳入 CloudFormation 模板，以便在创建堆栈时初始化应用程序。开发人员应如何引用包含数据库主机名的参数？",
    "options": {
      "A": {
        "option": "使用 ssm 动态引用。",
        "reason": "ssm 动态引用用于在 CloudFormation 模板中引用存储在 AWS Systems Manager Parameter Store 中的参数。由于问题中提到该值是明文存储的，因此使用 ssm 动态引用是最佳选择。"
      },
      "B": {
        "option": "使用 Ref 内置函数。",
        "reason": "Ref 内置函数用于引用 CloudFormation 模板中的资源和参数，但不适用于从 AWS Systems Manager Parameter Store 中获取参数值。"
      },
      "C": {
        "option": "使用 Fn::ImportValue 内置函数。",
        "reason": "Fn::ImportValue 内置函数用于跨堆栈传递值，但不适用于从 AWS Systems Manager Parameter Store 中获取参数值。"
      },
      "D": {
        "option": "使用 ssm-secure 动态引用。",
        "reason": "ssm-secure 动态引用用于引用存储在 AWS Systems Manager Parameter Store 中的加密参数，但问题中提到该值是明文存储的，因此不适用。"
      }
    }
  },
  {
    "number": "342",
    "best": ["A"],
    "question": "公司使用 AWS Lambda 函数调用第三方服务。第三方服务每分钟有请求限额。如果请求数量超过限额，第三方服务会返回速率限制错误。开发人员需要配置 Lambda 函数以避免收到来自第三方服务的速率限制错误。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "将 Lambda 函数的保留并发量设置为第三方服务允许的并发请求数。",
        "reason": "保留并发量设置可以确保 Lambda 函数不会超过指定数量的并发执行，从而避免超过第三方服务的限额。这种方法直接控制了并发请求数，是最符合题意的解决方案。"
      },
      "B": {
        "option": "减少分配给 Lambda 函数的内存。",
        "reason": "减少内存分配不会直接控制并发请求数，因此无法有效避免速率限制错误。"
      },
      "C": {
        "option": "将 Lambda 函数的预置并发量设置为第三方服务允许的并发请求数。",
        "reason": "预置并发量用于预热 Lambda 函数以减少冷启动延迟，但它不会限制并发请求数。因此，这个选项不符合需求。"
      },
      "D": {
        "option": "增加 Lambda 函数指定的超时时间。",
        "reason": "增加超时时间不会对并发请求数产生影响，因此无法避免速率限制错误。"
      }
    }
  },
  {
    "number": "343",
    "best": ["C"],
    "question": "开发人员正在使用 AWS Copilot 构建一个新的容器化应用程序。开发人员使用 AWS Copilot 命令行界面 (CLI) 在开发过程中部署应用程序。开发人员将应用程序代码提交到一个新的 AWS CodeCommit 存储库。开发人员必须在将新应用程序发布到生产环境之前创建一个自动化部署过程。开发人员该怎么做才能以最具操作效率的方式满足这些要求？",
    "options": {
      "A": {
        "option": "创建一个 buildspec 文件，该文件调用 AWS Copilot CLI 命令来构建和部署应用程序。使用 AWS Copilot CLI 创建一个 AWS CodePipeline，在源阶段使用 CodeCommit 存储库，在构建阶段使用 AWS CodeBuild。",
        "reason": "这种方法虽然可以实现目标，但需要手动创建 buildspec 文件，并且涉及多个步骤，不是最具操作效率的方法。"
      },
      "B": {
        "option": "使用 AWS Serverless Application Model (AWS SAM) CLI 引导和初始化一个 AWS CodePipeline 配置。使用 CodeCommit 存储库作为源。调用 AWS Copilot CLI 来构建和部署应用程序。",
        "reason": "AWS SAM 主要用于无服务器应用程序，不是最适合容器化应用的工具，因此这种方法不太适合这个场景。"
      },
      "C": {
        "option": "使用 AWS Copilot CLI 定义 AWS Copilot pipeline 并部署 AWS CodePipeline。选择 CodeCommit 作为 AWS CodePipeline 的源。",
        "reason": "这是最具操作效率的方法，因为 AWS Copilot 已经集成了创建和管理 AWS CodePipeline 的功能，简化了整个过程。"
      },
      "D": {
        "option": "为 AWS CodePipeline 定义一个 AWS CloudFormation 模板，使用 CodeCommit 作为源。将模板配置为 AWS Copilot CLI 的附加组件。使用 AWS Copilot CLI 部署应用程序。",
        "reason": "这种方法虽然可行，但涉及额外的 CloudFormation 模板配置，增加了复杂性，不如直接使用 AWS Copilot CLI 来定义和管理 pipeline 高效。"
      }
    }
  },
  {
    "number": "344",
    "best": ["A"],
    "question": "开发人员正在为一家宠物店创建一个新的应用程序。该应用程序将管理客户奖励积分。开发人员将使用 Amazon DynamoDB 存储应用程序的数据。开发人员需要在实际性能分析之前优化查询性能并限制分区过载。开发人员应使用哪个选项作为分区键以满足这些要求？",
    "options": {
      "A": {
        "option": "随机生成的全局唯一标识符 (UUID)",
        "reason": "选择随机生成的 UUID 作为分区键可以确保数据在 DynamoDB 中均匀分布，从而减少单个分区过载的风险。这有助于优化查询性能，因为负载将更为平衡。"
      },
      "B": {
        "option": "客户的全名",
        "reason": "使用客户的全名作为分区键可能会导致数据分布不均匀，尤其是在有许多具有相似或相同名字的客户的情况下，这会导致某些分区过载，从而影响查询性能。"
      },
      "C": {
        "option": "客户注册奖励计划的日期",
        "reason": "使用客户注册日期作为分区键可能会导致热点问题，特别是在某些日期有大量用户注册的情况下。这会导致某些分区的负载过大，从而影响查询性能。"
      },
      "D": {
        "option": "客户宠物的名字",
        "reason": "使用客户宠物的名字作为分区键可能会导致数据分布不均匀，因为宠物名字的多样性有限，并且某些常见的宠物名字可能会集中在某些分区，导致这些分区过载。"
      }
    }
  },
  {
    "number": "345",
    "best": ["C"],
    "question": "一位开发人员使用 AWS IAM Identity Center (AWS Single Sign-On) 在本地工作站上与 AWS CLI 和 AWS SDK 进行交互。在首次配置 SSO 访问时，API 调用 AWS 服务是正常的。然而，开发人员现在收到了 Access Denied 错误。开发人员没有更改任何之前在工作站上正常工作的配置文件或脚本。开发人员访问问题最可能的原因是什么？",
    "options": {
      "A": {
        "option": "开发人员的 AWS CLI 二进制文件的访问权限已更改。",
        "reason": "如果 AWS CLI 二进制文件的权限发生了变化，可能会影响 CLI 的执行，但不会直接导致 Access Denied 错误。"
      },
      "B": {
        "option": "IAM Identity Center 假定的许可集没有完成 API 调用所需的必要权限。",
        "reason": "如果权限集没有必要的权限，那么最初的 API 调用就不会成功。因此这个选项不太可能是原因。"
      },
      "C": {
        "option": "来自 IAM Identity Center 联邦角色的凭证已过期。",
        "reason": "这是最有可能的原因。凭证过期是常见的访问被拒绝的原因。IAM Identity Center 提供的临时凭证有一定的有效期，过期后需要重新获取新的凭证。"
      },
      "D": {
        "option": "开发人员正在尝试向错误的 AWS 账户发出 API 调用。",
        "reason": "如果是调用错误的 AWS 账户，通常会导致不同类型的错误信息，而不是 Access Denied。"
      }
    }
  },
  {
    "number": "346",
    "best": ["B"],
    "question": "公司正在构建一个无服务器应用程序。该应用程序使用API密钥来与第三方应用程序进行身份验证。公司希望将外部API密钥作为AWS Lambda配置的一部分进行存储。公司需要完全控制将用于加密API密钥的AWS Key Management Service (AWS KMS)密钥，并且仅授权实体可见。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "将API密钥存储在AWS Systems Manager参数存储中作为字符串参数。使用AWS提供的默认AWS KMS密钥来加密API密钥。",
        "reason": "虽然AWS Systems Manager Parameter Store可以存储和加密参数，但使用默认AWS KMS密钥不会满足公司对完全控制密钥的要求。"
      },
      "B": {
        "option": "将API密钥存储在AWS Lambda环境变量中。创建一个AWS KMS客户管理密钥来加密API密钥。",
        "reason": "将API密钥存储在环境变量中，并使用客户管理的AWS KMS密钥加密，可以完全控制密钥的管理和访问权限，满足公司的要求。"
      },
      "C": {
        "option": "将API密钥存储在代码库中。使用AWS管理的密钥来加密代码库。",
        "reason": "将敏感信息如API密钥存储在代码库中是不安全的，且使用AWS管理的密钥也不符合公司对完全控制密钥的要求。"
      },
      "D": {
        "option": "将API密钥存储为Amazon DynamoDB表记录。使用AWS管理的密钥来加密API密钥。",
        "reason": "虽然DynamoDB可以存储数据并使用AWS KMS加密，但使用AWS管理的密钥不会满足公司对完全控制密钥的要求。"
      }
    }
  },
  {
    "number": "347",
    "best": ["D"],
    "question": "开发人员正在编写一个应用程序来分析一组 Amazon EC2 实例的流量。这些 EC2 实例位于公共应用程序负载均衡器 (ALB) 之后。每个 EC2 实例上运行一个 HTTP 服务器，将所有请求记录到一个日志文件中。开发人员希望捕获客户端的公共 IP 地址。开发人员分析了日志文件，发现只有 ALB 的 IP 地址。开发人员必须做些什么才能在日志文件中捕获客户端的公共 IP 地址？",
    "options": {
      "A": {
        "option": "在 HTTP 服务器日志配置文件中添加 Host 头。",
        "reason": "Host 头通常用于指定请求的目标主机名，不会包含客户端的公共 IP 地址。因此，这个选项不能解决问题。"
      },
      "B": {
        "option": "在每个 EC2 实例上安装 Amazon CloudWatch Logs 代理。配置代理以写入日志文件。",
        "reason": "CloudWatch Logs 代理可以帮助收集和监控日志，但它不会改变日志中记录的客户端 IP 地址。因此，这个选项不能解决问题。"
      },
      "C": {
        "option": "在每个 EC2 实例上安装 AWS X-Ray 守护程序。配置守护程序以写入日志文件。",
        "reason": "AWS X-Ray 用于分布式应用程序的跟踪和分析，不会直接影响日志中记录的客户端 IP 地址。因此，这个选项不能解决问题。"
      },
      "D": {
        "option": "在 HTTP 服务器日志配置文件中添加 X-Forwarded-For 头。",
        "reason": "X-Forwarded-For 头包含了原始客户端的 IP 地址，当请求通过负载均衡器时，这个信息会被添加到请求头中。因此，通过在日志配置文件中记录这个头，开发人员可以捕获客户端的公共 IP 地址。这个选项是最优解。"
      }
    }
  },
  {
    "number": "348",
    "best": ["D"],
    "question": "一家公司正在使用 AWS Lambda 函数开发无服务器应用程序。其中一个 Lambda 函数需要访问一个位于 VPC 内私人子网中的 Amazon RDS DB 实例。公司创建了一个包含访问 DB 实例所需权限的角色，然后将该角色分配给 Lambda 函数。开发人员必须采取额外的措施以使 Lambda 函数能够访问 DB 实例。开发人员应该怎么做来满足这些要求？",
    "options": {
      "A": {
        "option": "为 DB 实例分配一个公共 IP 地址。修改 DB 实例的安全组以允许来自 Lambda 函数 IP 地址的入站流量。",
        "reason": "为 DB 实例分配公共 IP 地址会使数据库暴露在公共互联网中，增加安全风险。这不是一个推荐的做法。"
      },
      "B": {
        "option": "在 Lambda 函数和 DB 实例之间设置 AWS Direct Connect 连接。",
        "reason": "AWS Direct Connect 主要用于在本地数据中心和 AWS 之间建立专用网络连接，用于降低网络延迟和提高稳定性。它不适用于在同一 VPC 中建立连接。"
      },
      "C": {
        "option": "配置 Amazon CloudFront 分配以创建 Lambda 函数和 DB 实例之间的安全连接。",
        "reason": "Amazon CloudFront 是一个内容分发网络服务，用于加速分发静态和动态 Web 内容。它不适用于在同一 VPC 内建立数据库连接。"
      },
      "D": {
        "option": "配置 Lambda 函数以连接到 VPC 内的私人子网。添加安全组规则以允许来自 Lambda 函数的流量到达 DB 实例。",
        "reason": "将 Lambda 函数配置为连接到 VPC 内的私人子网，并通过安全组来管理来自 Lambda 函数到 DB 实例的流量，是在 VPC 内建立安全连接的最佳方法。这种方法符合 AWS 最佳实践。"
      }
    }
  },
  {
    "number": "349",
    "best": ["C"],
    "question": "开发人员需要临时访问第二个账户中的资源。实现这一点的最安全方法是什么？",
    "options": {
      "A": {
        "option": "使用 Amazon Cognito 用户池来获取第二个账户的短期凭证。",
        "reason": "Amazon Cognito 用户池主要用于管理应用程序用户的身份验证和授权，而不是用于账户之间的访问控制。因此，这不是实现跨账户访问的最佳方式。"
      },
      "B": {
        "option": "为第二个账户创建一个专用的 IAM 访问密钥，并通过邮件发送。",
        "reason": "这种方法存在严重的安全风险，因为电子邮件是不安全的传输方式，可能会导致凭证泄漏。"
      },
      "C": {
        "option": "创建跨账户访问角色，并使用 sts:AssumeRole API 获取短期凭证。",
        "reason": "这是最安全和推荐的方法。通过创建跨账户角色，并使用 sts:AssumeRole API，开发人员可以获取短期凭证，实现安全的跨账户访问。这种方式确保了最小权限原则，并且短期凭证的使用时间有限，降低了安全风险。"
      },
      "D": {
        "option": "建立信任，并为第二个账户的 IAM 用户添加 SSH 密钥。",
        "reason": "这种方法不适用于此场景。SSH 密钥主要用于服务器访问，而不是访问 AWS 资源。"
      }
    }
  },
  {
    "number": "350",
    "best": ["C"],
    "question": "一家公司希望将应用程序从本地服务器迁移到 AWS。作为第一步，该公司正在修改并迁移一个非关键应用程序到一个单独的 Amazon EC2 实例。该应用程序将把信息存储在一个 Amazon S3 存储桶中。公司在 AWS 上部署应用程序时需要遵循安全最佳实践。公司应该采取哪种方法来允许应用程序与 Amazon S3 交互？",
    "options": {
      "A": {
        "option": "创建一个具有 AWS 管理访问权限的 IAM 角色。将该角色附加到 EC2 实例。",
        "reason": "不推荐使用具有管理访问权限的 IAM 角色，因为这违反了最小权限原则。应尽可能限制权限，以减少潜在的安全风险。"
      },
      "B": {
        "option": "创建一个 IAM 用户。附加 AdministratorAccess 策略。复制生成的访问密钥和秘密密钥。在应用程序代码中使用访问密钥和秘密密钥以及 AWS SDK 与 Amazon S3 通信。",
        "reason": "将访问密钥和秘密密钥嵌入代码中是不安全的做法，可能导致密钥泄露。此外，不需要管理访问权限，只需要特定的 S3 访问权限。"
      },
      "C": {
        "option": "创建一个具有必要 Amazon S3 访问权限的 IAM 角色。将该角色附加到 EC2 实例。",
        "reason": "这是最佳选项。通过创建一个具有最小必要权限的 IAM 角色，并将其附加到 EC2 实例，可以确保遵循最小权限原则，且不会将凭证明文存储在代码中，从而提高安全性。"
      },
      "D": {
        "option": "创建一个 IAM 用户。附加提供必要的 Amazon S3 访问权限的策略。复制生成的访问密钥和秘密密钥。在应用程序代码中使用访问密钥和秘密密钥以及 AWS SDK 与 Amazon S3 通信。",
        "reason": "尽管此选项比选项 B 更好，但它仍然涉及将访问密钥和秘密密钥嵌入代码中，这在安全性上存在风险。使用 IAM 角色而非用户凭证更为安全。"
      }
    }
  },
  {
    "number": "351",
    "best": ["B", "C"],
    "question": "一家公司有一个包含敏感数据的内部网站。该公司希望将该网站公开。公司必须确保只有通过公司 OpenID Connect (OIDC) 身份提供程序 (IdP) 进行身份验证的员工才能访问该网站。开发人员需要在不编辑网站的情况下实现身份验证。哪种步骤组合可以满足这些要求？（选择两个。）",
    "options": {
      "A": {
        "option": "创建一个公共网络负载均衡器。",
        "reason": "网络负载均衡器（NLB）主要用于处理传输层（第4层）流量，并不支持高级的 HTTP/HTTPS 层（第7层）功能，例如身份验证。因此，NLB 不能满足基于 OIDC 进行身份验证的需求。"
      },
      "B": {
        "option": "创建一个公共应用程序负载均衡器。",
        "reason": "应用程序负载均衡器（ALB）支持高级的 HTTP/HTTPS 层（第7层）功能，包括与 OIDC 身份提供程序集成进行身份验证。这使它成为实现公司要求的适当选择。"
      },
      "C": {
        "option": "为负载均衡器配置一个监听器，监听 HTTPS 端口 443。添加一个默认的身份验证操作，提供 OIDC IdP 配置。",
        "reason": "通过配置 HTTPS 端口 443 的监听器并添加默认的身份验证操作，可以确保所有流量都通过加密通道，并在进入网站前进行 OIDC 身份验证。这满足了公司确保只有经过身份验证的员工访问网站的需求。"
      },
      "D": {
        "option": "为负载均衡器配置一个监听器，监听 HTTP 端口 80。添加一个默认的身份验证操作，提供 OIDC IdP 配置。",
        "reason": "虽然可以使用 HTTP 端口 80，但它不提供加密通信，这对包含敏感数据的网站来说是不安全的。因此，使用 HTTPS 端口 443 是更好的选择。"
      },
      "E": {
        "option": "为负载均衡器配置一个监听器，监听 HTTPS 端口 443。添加一个默认的 AWS Lambda 操作，提供一个 Lambda 认证函数的 Amazon 资源名称 (ARN)。",
        "reason": "使用 Lambda 进行身份验证是一种可行的解决方案，但它增加了额外的复杂性和管理开销。相比之下，直接使用 ALB 的内置 OIDC 身份验证功能更加简便和直接。"
      }
    }
  },
  {
    "number": "352",
    "best": ["C"],
    "question": "一位开发人员正在开发一个需要有选择性激活特定功能的 Web 应用程序。开发人员希望在这些功能准备好公开访问之前将其隐藏不对最终用户显示。哪种解决方案可以满足这些要求？",
    "options": {
      "A": {
        "option": "在 AWS AppSync 中创建一个功能标志配置文件。将功能标志值存储在配置文件中。根据需要激活和停用功能标志。",
        "reason": "AWS AppSync 主要用于构建可扩展的 GraphQL API，并不适用于管理和配置功能标志。"
      },
      "B": {
        "option": "将预发布数据存储在 Amazon DynamoDB 表中。启用表中的 Amazon DynamoDB Streams。通过使用 DynamoDB Streams 在隐藏和可见状态之间切换。",
        "reason": "DynamoDB Streams 用于捕获表中的数据修改事件，不适合用于管理功能标志和控制功能的显示与隐藏。"
      },
      "C": {
        "option": "在 AWS AppConfig 中创建一个功能标志配置文件。将功能标志值存储在配置文件中。根据需要激活和停用功能标志。",
        "reason": "AWS AppConfig 是 AWS Systems Manager 的一部分，专门用于配置和管理应用程序设置，包括功能标志。它允许开发人员动态地激活和停用功能标志，非常适合此场景。"
      },
      "D": {
        "option": "将预发布数据存储在 AWS Amplify DataStore 中。通过使用 Amplify DataStore 云同步在隐藏和可见状态之间切换。",
        "reason": "AWS Amplify DataStore 主要用于在前端和后端之间同步应用程序数据，并不特别适合管理功能标志和控制功能的显示与隐藏。"
      }
    }
  },
  {
    "number": "353",
    "best": ["B", "D"],
    "question": "一位公司的开发人员编写了一个 AWS CloudFormation 模板。该模板引用了公司网络团队编写的另一个 AWS CloudFormation 模板中创建的子网。当开发人员尝试第一次启动堆栈时，启动失败。哪些模板编写错误可能导致了此失败？（选择两个）",
    "options": {
      "A": {
        "option": "开发人员的模板没有使用 Ref 内置函数来引用子网。",
        "reason": "Ref 内置函数用于获取资源的逻辑ID，但在这种情况下，应使用 ImportValue 来引用另一个堆栈的导出值。"
      },
      "B": {
        "option": "开发人员的模板没有使用 ImportValue 内置函数来引用子网。",
        "reason": "ImportValue 函数用于引用另一个堆栈的导出值。如果子网是由另一个堆栈创建的，开发人员应该使用 ImportValue 来引用这些子网。"
      },
      "C": {
        "option": "开发人员的模板的 Mappings 部分没有引用子网。",
        "reason": "Mappings 部分主要用于映射静态值，不用于引用其他堆栈中的资源。"
      },
      "D": {
        "option": "网络团队的模板没有在 Outputs 部分导出子网。",
        "reason": "为了使其他堆栈引用资源，必须在 Outputs 部分导出这些资源。如果网络团队的模板没有导出子网，开发人员的模板将无法引用这些子网。"
      },
      "E": {
        "option": "网络团队的模板没有在 Mappings 部分导出子网。",
        "reason": "Mappings 部分并不用于导出资源。导出资源应在 Outputs 部分完成。"
      }
    }
  },
  {
    "number": "354",
    "best": ["B"],
    "question": "开发人员正在 Amazon EC2 实例上运行一个应用程序。当应用程序尝试读取 Amazon S3 存储桶时，应用程序失败。开发人员注意到关联的 IAM 角色缺少 S3 读取权限。开发人员需要赋予应用程序读取 S3 存储桶的能力。哪种解决方案能在最少应用程序中断的情况下满足这个需求？",
    "options": {
      "A": {
        "option": "添加权限到角色。终止现有的 EC2 实例。启动一个新的 EC2 实例。",
        "reason": "虽然这种方法可以解决问题，但它会导致应用程序中断，因为现有的 EC2 实例会被终止并替换为一个新的实例。这种方法不是最优解。"
      },
      "B": {
        "option": "添加权限到角色，以便更改自动生效。",
        "reason": "这是最优解。IAM 角色的权限更改会自动生效，不需要重新启动或终止实例，因此对应用程序的中断最小。"
      },
      "C": {
        "option": "添加权限到角色。休眠并重启现有的 EC2 实例。",
        "reason": "虽然这种方法比终止实例稍微好一些，但仍然会导致应用程序中断，因为实例需要休眠和重启。"
      },
      "D": {
        "option": "添加权限到 S3 存储桶。重启 EC2 实例。",
        "reason": "这不是最佳方法。首先，权限应该添加到 IAM 角色，而不是 S3 存储桶。其次，重启实例会导致应用程序中断。"
      }
    }
  },
  {
    "number": "355",
    "best": ["B", "E"],
    "question": "一名开发人员正在编写一个Web应用程序，该应用程序部署在一个面向互联网的应用负载均衡器(ALB)后面的Amazon EC2实例上。开发人员必须在ALB前面添加一个Amazon CloudFront分发，并且必须确保来自VPC外部的客户数据在传输中被加密。开发人员应使用哪些CloudFront配置设置来满足这些要求？（选择两个。）",
    "options": {
      "A": {
        "option": "通过使用签名URL限制查看者访问。",
        "reason": "签名URL用于限制对特定内容的访问，不直接涉及加密传输数据的问题。"
      },
      "B": {
        "option": "将源协议策略设置为与查看者匹配。",
        "reason": "将源协议策略设置为与查看者匹配将确保CloudFront和ALB之间的通信使用与查看者相同的协议。如果查看者使用HTTPS，CloudFront将与ALB进行HTTPS通信，从而确保传输中的数据加密。"
      },
      "C": {
        "option": "启用字段级加密。",
        "reason": "字段级加密是用于在应用程序级别加密特定数据字段的。这对于确保传输中的数据加密不是必需的，并且比问题要求的范围更广。"
      },
      "D": {
        "option": "启用自动对象压缩。",
        "reason": "自动对象压缩可以减少传输数据的大小，但与数据加密无关。"
      },
      "E": {
        "option": "将查看者协议策略设置为将HTTP重定向到HTTPS。",
        "reason": "将查看者协议策略设置为将HTTP重定向到HTTPS将确保所有客户数据通过HTTPS传输，从而在传输过程中加密数据。这是确保数据在传输中加密的关键步骤之一。"
      }
    }
  },
  {
    "number": "356",
    "best": ["C"],
    "question": "开发人员正在实现一个 AWS Lambda 函数，当对象上传到 Amazon S3 时将调用该函数。开发人员希望在将函数发布到生产 AWS 账户之前，在本地开发机器上测试该 Lambda 函数。哪种解决方案在最少的操作开销下满足这些要求？",
    "options": {
      "A": {
        "option": "使用 aws s3api put-object CLI 命令将对象上传到 Amazon S3。等待来自 S3 事件的本地 Lambda 调用。",
        "reason": "这个选项需要实际上传一个对象到 Amazon S3，并等待触发 Lambda 函数。这涉及到实际的云端操作，而不是纯粹的本地测试，所以操作开销较高。"
      },
      "B": {
        "option": "为 put object S3 事件创建一个示例 JSON 文本文件。在本地调用 Lambda 函数。使用 aws lambda invoke CLI 命令，将 JSON 文件和 Lambda 函数名称作为参数。",
        "reason": "这个选项虽然可以在本地测试，但需要手动创建 JSON 文件，并且需要分别使用不同的命令来完成测试，操作步骤较多。"
      },
      "C": {
        "option": "使用 sam local start-lambda CLI 命令启动 Lambda。使用 sam local generate-event s3 put CLI 命令创建 Lambda 测试 JSON 文件。使用 sam local invoke CLI 命令，将 JSON 文件作为参数调用 Lambda 函数。",
        "reason": "这个选项使用 AWS SAM（Serverless Application Model）工具套件，可以在本地快速启动 Lambda，并生成测试事件 JSON 文件，然后进行本地调用，统一的命令行工具减少了操作步骤和开销，是最优解。"
      },
      "D": {
        "option": "为 put object S3 事件创建一个 JSON 字符串。在 AWS 管理控制台中，使用 JSON 字符串为本地 Lambda 函数创建一个测试事件。执行测试。",
        "reason": "这个选项涉及到在 AWS 管理控制台中创建测试事件，不完全是本地操作，且需要手动创建 JSON 字符串，操作步骤较多。"
      }
    }
  },
  {
    "number": "357",
    "best": ["D"],
    "question": "开发人员正在将关键日志数据发布到 Amazon CloudWatch Logs 中的一个日志组。该日志组是在 2 个月前创建的。开发人员必须使用 AWS Key Management Service (AWS KMS) 密钥对日志数据进行加密，以便将来的数据可以加密，从而符合公司的安全策略。哪种解决方案能以最少的努力满足这一要求？",
    "options": {
      "A": {
        "option": "使用 AWS Encryption SDK 在写入日志组之前对数据进行加密和解密。",
        "reason": "使用 AWS Encryption SDK 是一种有效的加密方法，但它需要在应用程序代码中进行额外的开发和集成，不符合题目要求的最少努力。因此，这是不优的选择。"
      },
      "B": {
        "option": "使用 AWS KMS 控制台将 KMS 密钥与日志组关联。",
        "reason": "AWS KMS 控制台可以用于创建和管理 KMS 密钥，但它不能直接用于将现有的 KMS 密钥与现有的 CloudWatch Logs 日志组关联。因此，这不是一个有效的选择。"
      },
      "C": {
        "option": "使用 AWS CLI 命令 aws logs create-log-group，并指定密钥的 Amazon Resource Name (ARN)。",
        "reason": "此选项用于创建新的日志组并指定 KMS 密钥，但题目要求的是将 KMS 密钥与现有的日志组关联。因此，这不是正确的解决方案。"
      },
      "D": {
        "option": "使用 AWS CLI 命令 aws logs associate-kms-key，并指定密钥的 Amazon Resource Name (ARN)。",
        "reason": "使用 aws logs associate-kms-key 命令可以将现有的 KMS 密钥与现有的 CloudWatch Logs 日志组关联，这是实现题目要求的最有效和最简便的方法。因此，这是最佳选择。"
      }
    }
  }
]
